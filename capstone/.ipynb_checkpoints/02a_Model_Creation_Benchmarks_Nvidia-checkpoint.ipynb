{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA Capstone: Topic Modelling on AMD vs Nvidia GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- Data Extraction\n",
    "- Data Cleaning\n",
    "- [EDA](#EDA)\n",
    "- [Prepare data for LDA modeling](#Prepare-reddit-comments-for-LDA-modeling)\n",
    "- [Phrase modeling: Bigram and Trigram models](#Phrase-modeling:-Bigram-and-Trigram-models)\n",
    "- [LDA Model Training](#LDA-Model-Training)\n",
    "- [LDA Mallet Model](#LDA-Mallet-Model)\n",
    "- Model creation\n",
    "- Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:47.586399Z",
     "start_time": "2021-01-25T23:48:44.529997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "from pprint import pprint\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Bokeh package for TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label, ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "import re\n",
    "# NLTK Library\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import PRAW package\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# Gensim library\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess, ClippedCorpus\n",
    "from gensim.models import LdaMulticore, CoherenceModel, Phrases\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "# pyLDAvis library\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "# Detect non-english words\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Detect non-english words using spacy\n",
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
    "\n",
    "\n",
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Removes depreciation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:47.618419Z",
     "start_time": "2021-01-25T23:48:47.603405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the max rows and columns for Pandas\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:47.650448Z",
     "start_time": "2021-01-25T23:48:47.634433Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the style use\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:47.714506Z",
     "start_time": "2021-01-25T23:48:47.666463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reddit comments</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pre order time releasing 17th</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>going hard grab 3080 17th</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uk price 3090 1399 3080 649 3070 469 scan aib ...</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talking spatula jensen pot</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10k core completely insane</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25511</th>\n",
       "      <td>motherboard say pcie 0 compatible</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25512</th>\n",
       "      <td>thanks understanding know course 3000s dvi por...</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25513</th>\n",
       "      <td>buy 1400 gpu</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25514</th>\n",
       "      <td>know ill wait 3070 3060</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25515</th>\n",
       "      <td>generational compatibility compatible size pci...</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25516 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Reddit comments     tag\n",
       "0                          pre order time releasing 17th  nvidia\n",
       "1                              going hard grab 3080 17th  nvidia\n",
       "2      uk price 3090 1399 3080 649 3070 469 scan aib ...  nvidia\n",
       "3                             talking spatula jensen pot  nvidia\n",
       "4                             10k core completely insane  nvidia\n",
       "...                                                  ...     ...\n",
       "25511                  motherboard say pcie 0 compatible  nvidia\n",
       "25512  thanks understanding know course 3000s dvi por...  nvidia\n",
       "25513                                       buy 1400 gpu  nvidia\n",
       "25514                            know ill wait 3070 3060  nvidia\n",
       "25515  generational compatibility compatible size pci...  nvidia\n",
       "\n",
       "[25516 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the existing csv file\n",
    "GPU_df = pd.read_csv('./reddit dataset/cleaned_combined_df.csv')\n",
    "GPU_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:47.746535Z",
     "start_time": "2021-01-25T23:48:47.731523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reddit comments</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pre order time releasing 17th</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>going hard grab 3080 17th</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uk price 3090 1399 3080 649 3070 469 scan aib ...</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talking spatula jensen pot</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10k core completely insane</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25511</th>\n",
       "      <td>motherboard say pcie 0 compatible</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25512</th>\n",
       "      <td>thanks understanding know course 3000s dvi por...</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25513</th>\n",
       "      <td>buy 1400 gpu</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25514</th>\n",
       "      <td>know ill wait 3070 3060</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25515</th>\n",
       "      <td>generational compatibility compatible size pci...</td>\n",
       "      <td>nvidia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10990 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Reddit comments     tag\n",
       "0                          pre order time releasing 17th  nvidia\n",
       "1                              going hard grab 3080 17th  nvidia\n",
       "2      uk price 3090 1399 3080 649 3070 469 scan aib ...  nvidia\n",
       "3                             talking spatula jensen pot  nvidia\n",
       "4                             10k core completely insane  nvidia\n",
       "...                                                  ...     ...\n",
       "25511                  motherboard say pcie 0 compatible  nvidia\n",
       "25512  thanks understanding know course 3000s dvi por...  nvidia\n",
       "25513                                       buy 1400 gpu  nvidia\n",
       "25514                            know ill wait 3070 3060  nvidia\n",
       "25515  generational compatibility compatible size pci...  nvidia\n",
       "\n",
       "[10990 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvidia_df = GPU_df[GPU_df['tag'] == 'nvidia']\n",
    "nvidia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare comments for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:47.874293Z",
     "start_time": "2021-01-25T23:48:47.854276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creates the bag of words for each document\n",
    "data = [token.split() for token in nvidia_df['Reddit comments'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:48.624531Z",
     "start_time": "2021-01-25T23:48:48.615523Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pre', 'order', 'time', 'releasing', '17th'], ['going', 'hard', 'grab', '3080', '17th'], ['uk', 'price', '3090', '1399', '3080', '649', '3070', '469', 'scan', 'aib', 'card', 'thanks', 'u', 'benzyl', 'chloride', 'overclockers', 'aib', 'card']]\n"
     ]
    }
   ],
   "source": [
    "# Prints the bag of words from the first 3 documents\n",
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase modeling: Bigram and Trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:52.320817Z",
     "start_time": "2021-01-25T23:48:49.733188Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = Phrases(data, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = Phrases(bigram[data], threshold=100)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram, this reduces memory, making the model smaller and faster\n",
    "bigram_mod = Phraser(bigram)\n",
    "trigram_mod = Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:53.408984Z",
     "start_time": "2021-01-25T23:48:52.353848Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "# Form Bigrams\n",
    "data_bigrams = make_bigrams(data)\n",
    "\n",
    "# Form Trigrams\n",
    "data_trigrams = make_trigrams(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:53.488764Z",
     "start_time": "2021-01-25T23:48:53.473047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the different n-grams dataset\n",
    "phrase_list = {'unigram': data, 'bigrams': data_bigrams, 'trigrams': data_trigrams}\n",
    "# phrase_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA on AMD comments with all the ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:48:54.994519Z",
     "start_time": "2021-01-25T23:48:54.974401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a function to create the LDA model and compute the coherence score\n",
    "def lda_calculate_coherence_values(ngram_data, num_topics):\n",
    "    \"\"\"\n",
    "    This function calculates the coherence score and the perplexity scores for each ngram and stores\n",
    "    the model, corpus and the id2word in their respective dictionaries\n",
    "    \"\"\"\n",
    "    model_dict = {}\n",
    "    score_dict = {}\n",
    "    for key, value in ngram_data.items():\n",
    "        ngram_id2word = corpora.Dictionary(value)\n",
    "        ngram_corpus = [ngram_id2word.doc2bow(text) for text in value]\n",
    "\n",
    "        ngram_lda_model = LdaMulticore(corpus=ngram_corpus, \n",
    "                             id2word=ngram_id2word, \n",
    "                             num_topics=num_topics,\n",
    "                             chunksize=100,\n",
    "                             passes=20, \n",
    "                             random_state=42,\n",
    "                            per_word_topics=True)\n",
    "\n",
    "\n",
    "        # Compute Perplexity score\n",
    "        ngram_perplexity = ngram_lda_model.log_perplexity(ngram_corpus)  # a measure of how good the model is. lower the better.\n",
    "\n",
    "        # Compute Coherence Score\n",
    "        coherence_model_lda = CoherenceModel(model=ngram_lda_model, texts=value, dictionary=ngram_id2word, coherence='c_v')\n",
    "        ngram_coherence_lda = coherence_model_lda.get_coherence()\n",
    "        \n",
    "        # Prints out the topics for each ngram\n",
    "        print(f'*********Displaying {num_topics} topics for {key}******************')\n",
    "        pprint(ngram_lda_model.print_topics())\n",
    "        \n",
    "        # Store the perplexity and coherence scores in score_dict\n",
    "        score_dict[key] = []\n",
    "        score_dict[key].append(ngram_perplexity)\n",
    "        score_dict[key].append(ngram_coherence_lda)\n",
    "        \n",
    "        # Stores the ngram's model, corpus, id2word in model_dict\n",
    "        model_dict[key] = []\n",
    "        model_dict[key].append(ngram_lda_model)\n",
    "        model_dict[key].append(ngram_corpus)\n",
    "        model_dict[key].append(ngram_id2word)\n",
    "\n",
    "    return score_dict, model_dict, num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:50:42.538791Z",
     "start_time": "2021-01-25T23:48:56.662983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********Displaying 5 topics for unigram******************\n",
      "[(0,\n",
      "  '0.020*\"nvidia\" + 0.019*\"amd\" + 0.012*\"time\" + 0.011*\"people\" + 0.009*\"buy\" '\n",
      "  '+ 0.007*\"3080\" + 0.007*\"card\" + 0.007*\"year\" + 0.007*\"know\" + 0.006*\"big\"'),\n",
      " (1,\n",
      "  '0.007*\"3090\" + 0.006*\"benchmark\" + 0.005*\"day\" + 0.005*\"wait\" + '\n",
      "  '0.005*\"video\" + 0.004*\"memory\" + 0.004*\"right\" + 0.004*\"look\" + '\n",
      "  '0.004*\"evga\" + 0.003*\"good\"'),\n",
      " (2,\n",
      "  '0.014*\"core\" + 0.012*\"power\" + 0.012*\"card\" + 0.012*\"3080\" + 0.011*\"psu\" + '\n",
      "  '0.008*\"fe\" + 0.008*\"case\" + 0.007*\"3090\" + 0.007*\"aib\" + 0.007*\"fan\"'),\n",
      " (3,\n",
      "  '0.023*\"3080\" + 0.020*\"3090\" + 0.019*\"price\" + 0.015*\"ti\" + 0.011*\"people\" + '\n",
      "  '0.011*\"card\" + 0.009*\"series\" + 0.009*\"2080\" + 0.009*\"going\" + '\n",
      "  '0.008*\"year\"'),\n",
      " (4,\n",
      "  '0.028*\"game\" + 0.019*\"vram\" + 0.013*\"4k\" + 0.010*\"1440p\" + 0.008*\"need\" + '\n",
      "  '0.008*\"monitor\" + 0.008*\"gpu\" + 0.007*\"memory\" + 0.007*\"play\" + '\n",
      "  '0.007*\"setting\"')]\n",
      "*********Displaying 5 topics for bigrams******************\n",
      "[(0,\n",
      "  '0.015*\"year\" + 0.014*\"price\" + 0.012*\"3080\" + 0.012*\"card\" + 0.011*\"wait\" + '\n",
      "  '0.011*\"new\" + 0.009*\"people\" + 0.009*\"going\" + 0.009*\"nvidia\" + '\n",
      "  '0.009*\"upgrade\"'),\n",
      " (1,\n",
      "  '0.028*\"3090\" + 0.025*\"3080\" + 0.012*\"nvidia\" + 0.012*\"price\" + '\n",
      "  '0.010*\"people\" + 0.010*\"titan\" + 0.009*\"rtx\" + 0.009*\"ti\" + 0.009*\"card\" + '\n",
      "  '0.008*\"2080\"'),\n",
      " (2,\n",
      "  '0.011*\"3080\" + 0.011*\"fe\" + 0.009*\"3090\" + 0.008*\"fan\" + 0.008*\"buy\" + '\n",
      "  '0.008*\"card\" + 0.008*\"time\" + 0.008*\"look\" + 0.007*\"psu\" + 0.007*\"evga\"'),\n",
      " (3,\n",
      "  '0.016*\"vram\" + 0.013*\"ram\" + 0.011*\"cpu\" + 0.011*\"gpu\" + 0.010*\"use\" + '\n",
      "  '0.009*\"memory\" + 0.009*\"console\" + 0.008*\"pc\" + 0.007*\"power\" + '\n",
      "  '0.006*\"need\"'),\n",
      " (4,\n",
      "  '0.038*\"game\" + 0.021*\"4k\" + 0.017*\"1440p\" + 0.016*\"vram\" + 0.012*\"monitor\" '\n",
      "  '+ 0.011*\"setting\" + 0.011*\"1080p\" + 0.011*\"play\" + 0.010*\"fps\" + '\n",
      "  '0.009*\"resolution\"')]\n",
      "*********Displaying 5 topics for trigrams******************\n",
      "[(0,\n",
      "  '0.014*\"buy\" + 0.014*\"card\" + 0.013*\"people\" + 0.013*\"nvidia\" + 0.012*\"wait\" '\n",
      "  '+ 0.011*\"year\" + 0.011*\"time\" + 0.009*\"price\" + 0.009*\"new\" + 0.008*\"3080\"'),\n",
      " (1,\n",
      "  '0.018*\"3090\" + 0.012*\"3080\" + 0.011*\"case\" + 0.009*\"fan\" + 0.007*\"fit\" + '\n",
      "  '0.007*\"people\" + 0.006*\"money\" + 0.005*\"pc\" + 0.005*\"guy\" + 0.005*\"gpu\"'),\n",
      " (2,\n",
      "  '0.033*\"game\" + 0.024*\"vram\" + 0.016*\"4k\" + 0.012*\"1440p\" + 0.009*\"monitor\" '\n",
      "  '+ 0.009*\"play\" + 0.008*\"setting\" + 0.008*\"need\" + 0.008*\"fps\" + '\n",
      "  '0.007*\"1080p\"'),\n",
      " (3,\n",
      "  '0.036*\"3080\" + 0.030*\"3090\" + 0.022*\"ti\" + 0.014*\"2080\" + 0.013*\"rtx\" + '\n",
      "  '0.012*\"price\" + 0.012*\"3070\" + 0.011*\"titan\" + 0.010*\"2080ti\" + '\n",
      "  '0.008*\"nvidia\"'),\n",
      " (4,\n",
      "  '0.013*\"amd\" + 0.011*\"price\" + 0.010*\"card\" + 0.009*\"nvidia\" + 0.008*\"good\" '\n",
      "  '+ 0.008*\"power\" + 0.006*\"better\" + 0.006*\"cpu\" + 0.005*\"going\" + '\n",
      "  '0.005*\"look\"')]\n"
     ]
    }
   ],
   "source": [
    "# Calculate using a dictionary\n",
    "score_dict, model_dict, num_topics = lda_calculate_coherence_values(phrase_list, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrepreting the topics for unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scored between 1 ~ 5 with regards to their intrepretability, >= 3 will be considered intrepretable.\n",
    "* () infers the score\n",
    "\n",
    "Topic 0 (4)\n",
    "* Discusses about the purchase of the GPUs\n",
    "\n",
    "Topic 1 (3)\n",
    "* Has to do with RTX 3090 and waiting on the GPU's benchmark\n",
    "\n",
    "Topic 2 (2)\n",
    "* 3080 and 3090 powersupply required to run the card, compares against fe (Founder's edition), reference cards and aib (AMD / Nvidia's 3rd party manufacturers like MSI, EVGA)\n",
    "\n",
    "Topic 3 (3)\n",
    "* The different types of GPUs\n",
    "\n",
    "Topic 4 (2)\n",
    "* Different resolutions for the monitor and the relationship with the GPU's video ram (vram)\n",
    "\n",
    "**2 topics were intrepretable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the topics for the bigrams \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scored between 1 ~ 5 with regards to their intrepretability, >= 3 will be considered intrepretable.\n",
    "* () is the score\n",
    "\n",
    "Topic 0 (4)\n",
    "* Discusses about the consumers waiting to upgrade their gpu\n",
    "\n",
    "Topic 1 (2)\n",
    "* Compares price against the 3090 and 3080 against the titan and 2080ti\n",
    "\n",
    "Topic 2 (1)\n",
    "* Has to do with 3080 and 3090's fan and psu\n",
    "\n",
    "Topic 3 (2)\n",
    "* gaming consoles and their cpu and gpu\n",
    "\n",
    "Topic 4 (4)\n",
    "* Different resolutions for the monitor to play the game\n",
    "\n",
    "**2 topics were intrepretable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the topics for the trigrams \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scored between 1 ~ 5 with regards to their intrepretability, >= 3 will be considered intrepretable.\n",
    "* () is the score\n",
    "\n",
    "Topic 0 (4)\n",
    "* Discusses about the consumers waiting to upgrade their gpu\n",
    "\n",
    "Topic 1 (1)\n",
    "* Fitting the GPU into their case (Possibly too big?)\n",
    "\n",
    "Topic 2 (4)\n",
    "* Different resolutions and the fps when playing games\n",
    "\n",
    "Topic 3 (3)\n",
    "* Different models of GPUs\n",
    "\n",
    "Topic 4 (1)\n",
    "* CPU and gpu price and power\n",
    "\n",
    "**3 topics were intrepretable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:55:09.708279Z",
     "start_time": "2021-01-26T00:55:09.701273Z"
    }
   },
   "outputs": [],
   "source": [
    "topics_interpretable = [2,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:55:10.275270Z",
     "start_time": "2021-01-26T00:55:10.269263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Perplexity score</th>\n",
       "      <th>Coherence score</th>\n",
       "      <th>no of topics intrepretable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unigram</th>\n",
       "      <td>-7.822553</td>\n",
       "      <td>0.488067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigrams</th>\n",
       "      <td>-7.876956</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trigrams</th>\n",
       "      <td>-7.880959</td>\n",
       "      <td>0.577183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Perplexity score  Coherence score  no of topics intrepretable\n",
       "unigram          -7.822553         0.488067                           2\n",
       "bigrams          -7.876956         0.543750                           2\n",
       "trigrams         -7.880959         0.577183                           3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame(score_dict).T\n",
    "score_df.columns = ['Perplexity score', 'Coherence score']\n",
    "score_df['no of topics intrepretable'] = topics_interpretable\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Using Coherence score as the main metric and no of topic intrepretable as the secondary metric to select the best ngram, between unigrams and bigrams, I'll be choosing **trigrams** as the it has the larger number of intrepretable topics compared to the other n_grams and it has the **second highest coherence score**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the topics-keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:50:52.187474Z",
     "start_time": "2021-01-25T23:50:52.178466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtaining the lda trigram model, corpus and dictionary\n",
    "lda_trigram_model, trigram_corpus, trigram_id2word = model_dict['trigrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T23:51:14.049599Z",
     "start_time": "2021-01-25T23:51:10.455343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1290027834564915527378115303\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1290027834564915527378115303_data = {\"mdsDat\": {\"x\": [-0.08576720932235056, 0.228388379238158, -0.00788814112668265, -0.050751706904631246, -0.08398132188449371], \"y\": [-0.054720423343574444, 0.035576795969153724, -0.13162927179419653, -0.0359543036986397, 0.186727202867257], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [27.074515502821257, 22.42725825544706, 22.29330078293021, 16.742276649369327, 11.462648809432151]}, \"tinfo\": {\"Term\": [\"game\", \"3090\", \"vram\", \"ti\", \"3080\", \"4k\", \"2080\", \"1440p\", \"titan\", \"monitor\", \"play\", \"rtx\", \"buy\", \"setting\", \"amd\", \"wait\", \"1080p\", \"case\", \"fps\", \"price\", \"resolution\", \"fan\", \"8gb\", \"vr\", \"nvidia\", \"power\", \"2080ti\", \"fit\", \"card\", \"ultra\", \"retailer\", \"cable\", \"amazon\", \"online\", \"decide\", \"pre_order\", \"17th\", \"till\", \"connector\", \"ftw3\", \"local\", \"8_pin\", \"holding\", \"luck\", \"blame\", \"30xx\", \"newegg\", \"managed\", \"preorder\", \"uk\", \"disappointed\", \"shortage\", \"future_proof\", \"september\", \"industry\", \"knowing\", \"checkout\", \"microcenter\", \"allowed\", \"folk\", \"sale\", \"info\", \"supply\", \"phone\", \"scalper\", \"store\", \"order\", \"wait\", \"site\", \"purchase\", \"buy\", \"adapter\", \"day\", \"launch\", \"week\", \"sold\", \"stock\", \"fe\", \"waiting\", \"company\", \"release\", \"evga\", \"year\", \"month\", \"time\", \"sell\", \"card\", \"people\", \"nvidia\", \"product\", \"bot\", \"best\", \"new\", \"know\", \"bought\", \"come\", \"price\", \"want\", \"think\", \"going\", \"right\", \"3080\", \"amd\", \"upgrade\", \"need\", \"setting\", \"1080p\", \"4k\", \"game\", \"144hz\", \"1440p\", \"8gb\", \"resolution\", \"playing\", \"texture\", \"vr\", \"play\", \"60fps\", \"144\", \"demanding\", \"6gb\", \"ultrawide\", \"aaa\", \"120hz\", \"maxed\", \"60hz\", \"monitor\", \"ultra\", \"devs\", \"frame_rate\", \"rdr2\", \"warzone\", \"5gb\", \"240hz\", \"1gb\", \"usage\", \"hdmi\", \"fps\", \"dl\", \"8k\", \"vram\", \"0\", \"max\", \"10gb\", \"run\", \"gb\", \"console\", \"ram\", \"4\", \"use\", \"high\", \"need\", \"8\", \"memory\", \"gaming\", \"gpu\", \"year\", \"want\", \"upgrade\", \"titan\", \"cuda_core\", \"confirmed\", \"3000\", \"quadro\", \"lineup\", \"780\", \"application\", \"par\", \"ordered\", \"kid\", \"happening\", \"witcher\", \"flagship\", \"net\", \"scan\", \"replacement\", \"2500\", \"pissed\", \"successor\", \"minecraft\", \"4000\", \"cheapest\", \"xx80\", \"tensor_memory\", \"21\", \"newest\", \"shader\", \"learned\", \"funny\", \"ti\", \"2080\", \"2070\", \"gap\", \"class\", \"500\", \"rtx\", \"gtx_1080\", \"3090\", \"faster\", \"3080ti\", \"3080\", \"2080ti\", \"700\", \"geforce\", \"1400\", \"3070\", \"1200\", \"1080\", \"20\", \"super\", \"rumor\", \"series\", \"v\", \"tier\", \"price\", \"generation\", \"1500\", \"1080ti\", \"increase\", \"memory\", \"nvidia\", \"point\", \"think\", \"going\", \"card\", \"vram\", \"10\", \"new\", \"gaming\", \"gpu\", \"better\", \"people\", \"watch\", \"watt\", \"7nm\", \"tsmc\", \"intel\", \"efficiency\", \"power_limit\", \"gold\", \"scale\", \"ps4\", \"node\", \"rumour\", \"650\", \"obvious\", \"dedicated\", \"wattage\", \"affect\", \"germany\", \"development\", \"19\", \"australia\", \"tsmc_7nm\", \"650w\", \"peak\", \"cutting_edge\", \"yield\", \"750w_psu\", \"rated\", \"aspect\", \"10900k\", \"55\", \"overclocking\", \"tdp\", \"ryzen\", \"power\", \"850\", \"3d\", \"core\", \"tax\", \"amd\", \"750w\", \"power_draw\", \"aibs\", \"cpu\", \"good\", \"price\", \"little\", \"card\", \"tech\", \"psu\", \"nvidia\", \"better\", \"money\", \"look\", \"3060\", \"load\", \"pretty\", \"bad\", \"gpu\", \"going\", \"time\", \"end\", \"higher\", \"gen\", \"know\", \"actually\", \"mean\", \"probably\", \"people\", \"way\", \"sure\", \"think\", \"fit\", \"air\", \"p\", \"ga102\", \"euro\", \"sony\", \"nvme\", \"bother\", \"kept\", \"inflated\", \"knowledge\", \"prevent\", \"address\", \"itx\", \"3k\", \"tower\", \"throwing\", \"tuf\", \"properly\", \"10k\", \"thicc\", \"gamers_nexus\", \"listing\", \"performing\", \"950\", \"tempted\", \"airflow\", \"exhaust\", \"allowing\", \"radiator\", \"slot\", \"xbox\", \"fan\", \"guy\", \"motherboard\", \"person\", \"ps5\", \"mobo\", \"case\", \"boy\", \"return\", \"unit\", \"curious\", \"cooler\", \"3090\", \"x\", \"problem\", \"support\", \"pcie\", \"pc\", \"money\", \"overpriced\", \"3080\", \"work\", \"feel\", \"people\", \"way\", \"cpu\", \"good\", \"gpu\", \"better\", \"look\", \"ram\", \"going\", \"amd\", \"need\", \"probably\", \"want\", \"know\", \"think\", \"buy\", \"price\"], \"Freq\": [1183.0, 1476.0, 1045.0, 814.0, 1952.0, 560.0, 528.0, 424.0, 397.0, 329.0, 315.0, 593.0, 745.0, 291.0, 686.0, 584.0, 255.0, 324.0, 295.0, 1172.0, 232.0, 186.0, 221.0, 222.0, 1085.0, 261.0, 465.0, 132.0, 1158.0, 179.0, 80.25029160761322, 69.56828737200341, 52.621000479360426, 51.32908986653088, 49.2605491860872, 47.74048125400552, 46.20310018142774, 44.23394754655487, 42.29770426902515, 35.65736063329098, 35.35564355631047, 34.53310066770457, 32.747728334182796, 40.67115233525072, 33.56911999074653, 31.416544333432217, 30.0078035171517, 28.379852240981197, 28.083082484457734, 53.311044995665696, 28.0730960427127, 27.842867002005395, 29.411718391873613, 23.243764464473763, 23.142103728061095, 33.13155257058402, 22.45062017170312, 22.632100490073427, 21.821985449095074, 21.55221009907744, 87.21985039085217, 57.56333391828944, 62.607878898616804, 38.027077510143634, 192.41174298249658, 101.16079404953489, 102.74802545442105, 498.03782836215964, 72.19848042280903, 85.92390054146091, 595.3199132489589, 41.96547458072031, 272.64598681241864, 263.5837462113002, 125.5182340918971, 136.21409280966944, 216.66322005490926, 234.2778444042673, 173.3076030100378, 85.6614494090908, 254.01403061670047, 122.59570253548893, 479.08755650678404, 225.022772436087, 457.17774495461055, 200.37134147316516, 579.7163523354568, 544.17365094002, 534.2073160580678, 147.77864542297922, 91.60830723791092, 185.4295603444505, 368.67785355026007, 306.7783098632391, 125.86468546568827, 199.69781118201638, 380.4819517480666, 259.4615415472335, 284.15421837539, 274.69875263656047, 194.69876467838975, 331.3762680826854, 212.26436242181444, 171.94863313075243, 183.86835075348282, 290.62336409679466, 254.71790839196478, 558.4395312208911, 1179.2083604634827, 154.11643429016357, 422.0512621593247, 220.43305889442914, 231.64739538321146, 128.41675628749957, 107.5732080307598, 220.90513694795501, 311.96865148286696, 58.07886914697413, 47.73703112464804, 44.81199525538217, 45.005614340026945, 40.21568354447219, 39.72557290508658, 45.11914523162615, 38.120528897488015, 36.86881587870102, 323.1149680877179, 175.74485012711756, 33.84791381756975, 32.94460334664475, 32.998355825625296, 32.67632393073415, 32.489556982088494, 31.366180730046985, 30.3796560616209, 89.53568961962263, 66.39936404369354, 277.7630845283134, 182.87151549583567, 66.18017379045214, 838.3065791109135, 141.14068369319554, 139.0090816017577, 226.32569855162134, 235.2713409034692, 189.87289405876288, 180.34830170619222, 200.4053546407527, 168.5789545328592, 240.33414455343427, 221.20842309226188, 286.4071178033335, 111.96089336936286, 199.29454406342586, 194.20176694273155, 210.72068430971444, 203.6645379843083, 173.24741713950564, 145.65556309080097, 396.92652965426583, 95.78105873391303, 43.85596913858486, 40.314185738395516, 37.24228173889739, 35.03100067788965, 30.5581716747698, 29.937973767889616, 33.76141513857679, 25.25247326210908, 24.340731530731322, 23.694357255324807, 22.89736824541151, 75.07863813295045, 21.264032718392233, 20.380542996719512, 19.975543726494163, 19.40253192621296, 19.91199968788938, 18.770329622122077, 18.97411223229403, 18.03288250409202, 17.787184608424493, 18.140832189016038, 16.9656535931177, 16.03061503675828, 15.56210237223689, 15.20080392922974, 15.17126077264976, 30.178654168739328, 766.5476890736644, 497.68272868540726, 93.21996267386025, 83.83088969195781, 42.3529352552851, 139.13421605467997, 470.7423771126282, 38.2217514785, 1041.4901268331714, 203.22362529325923, 176.63699893332057, 1247.1109869387851, 333.81768926449604, 103.14424872268916, 59.16198008710633, 62.5127718115921, 410.1764750085053, 57.26049664383606, 201.23553694757985, 171.0452215978877, 243.84276276270336, 96.82014595469377, 234.5861385690862, 121.65151534085729, 80.22775638566952, 438.6453810449034, 159.52059168482978, 75.52346274681526, 161.48014405020982, 111.84327724627562, 180.40734393172963, 294.02732099608323, 141.35039611917838, 212.3343825772705, 207.12019215641746, 238.54997581879206, 205.5833514717149, 134.54966403075315, 178.43942362710945, 147.40512315561924, 158.07177779846197, 148.8565520229996, 158.99244723845285, 58.94926640269707, 57.481753708474514, 50.46183403632765, 41.235787858529385, 100.55151818482449, 47.06844260406244, 31.35525129587615, 25.91797205246309, 25.409401982300626, 24.919557544480575, 23.449160443145878, 22.96756725077749, 28.977318455959846, 23.154799026055954, 22.735590343042315, 22.362091841460664, 22.368712169486678, 20.98335291315079, 19.508340760436663, 19.833562265108338, 19.414757092238574, 18.694071098418984, 38.903505363940084, 17.752143407802347, 17.535188430936863, 17.45940063406525, 17.907109714161447, 16.952774470185282, 16.841565233421065, 16.245467215736916, 16.84689371528302, 25.45465648877926, 48.635703619555734, 58.1787062482421, 206.04623508586081, 24.471339090362445, 53.75538816029419, 115.20128075557234, 79.42255487731985, 349.071537867302, 32.64613394521647, 29.73341054708102, 55.08383560949289, 151.290614320548, 214.0370247123283, 288.6202072554007, 86.11149497038447, 263.8020074699891, 59.045403078041225, 77.8457292905834, 227.3496804755046, 154.03326816572223, 121.59749648600908, 132.23503035265378, 63.07923415030341, 57.673947277689514, 93.7871661883683, 73.04937758156181, 132.08108893137495, 132.73268263504497, 130.32670660725856, 88.96405700060426, 79.39572375414049, 85.21420501408737, 104.5763891839298, 89.71789373084519, 87.3883360804214, 87.2440175322316, 101.14720348681014, 82.76864510146409, 79.6333007075987, 80.1819088032923, 132.08278859436743, 61.85255366302378, 38.96321799648731, 31.16278857301453, 29.38483700830832, 28.5268795208922, 30.671514832423984, 20.290261167912742, 19.91578109256191, 20.512199174309025, 20.124805051142307, 17.74605719163411, 17.24374548012691, 22.332937057189678, 16.358425211552827, 15.994929534933958, 16.100081229135483, 15.920616511285445, 16.013185044694186, 15.71218289717166, 15.266967579761783, 15.063712610168277, 14.498494548612104, 13.85479008517637, 13.330808950178534, 13.265333236134305, 12.970117934993567, 12.98376413600025, 12.474878802300779, 15.267370946799467, 87.05894304100251, 55.698340751663245, 159.45267069288974, 90.83857621891092, 44.40775282418073, 49.00220002343287, 73.4491459094701, 32.72740099218511, 201.07954393143012, 25.401106411941235, 37.226806934052696, 30.996420678669327, 25.76481952860386, 73.45097786809959, 318.91945923209846, 64.4974187239047, 69.39801310127984, 60.209954849030765, 41.07420157255222, 96.84275339921253, 101.12245245861102, 30.72232017134241, 215.01308512810454, 83.57946536001148, 63.63446956939723, 129.90250572088024, 84.69692651007828, 73.6592497152243, 87.21154183344673, 90.62717827724416, 81.03520255937319, 75.5795961468433, 63.72955914679151, 84.16818795499276, 77.61654086279313, 74.32880538386168, 70.59681153379985, 72.36144988539247, 70.175465250758, 69.93025590750527, 64.94646287686761, 64.00718071221822], \"Total\": [1183.0, 1476.0, 1045.0, 814.0, 1952.0, 560.0, 528.0, 424.0, 397.0, 329.0, 315.0, 593.0, 745.0, 291.0, 686.0, 584.0, 255.0, 324.0, 295.0, 1172.0, 232.0, 186.0, 221.0, 222.0, 1085.0, 261.0, 465.0, 132.0, 1158.0, 179.0, 80.98940021451722, 70.3035437720065, 53.35314084499294, 52.073064321243706, 49.99768018423085, 48.47130560368545, 46.94516672398091, 45.00037399114229, 43.061030881503285, 36.391199332263476, 36.0910511614309, 35.26559439201365, 33.484483676759794, 41.59271568865271, 34.332974199636496, 32.173560724526965, 30.73816073652391, 29.123322406026645, 28.821816074722154, 54.72419577482743, 28.82172112973314, 28.59660883901003, 30.28883210443534, 23.981878141565424, 23.88774245083095, 34.23657658181764, 23.209044650299692, 23.399285921588188, 22.56573174234218, 22.29866742242356, 90.36129796855523, 59.85021993897358, 65.15112380593726, 39.51347454595485, 205.33293171470817, 107.4212963512339, 110.73309486484692, 584.1467492946801, 77.8673801014933, 94.58940163045787, 745.1804911943682, 44.210789974893395, 340.3929022016541, 329.55365984302625, 145.87876484400354, 162.95801988130492, 278.2245632184656, 307.29028103912805, 223.65304923111276, 101.10874025857639, 364.1445366431278, 156.51890464233222, 815.1492173405877, 333.02541641249564, 807.8116767046031, 294.36836698056186, 1158.26694329832, 1073.0293790919027, 1085.8804005316533, 208.9316709340336, 112.76865941670184, 297.1826294102547, 781.9426921653378, 637.8168480677899, 181.17088451964145, 383.20815358346783, 1172.058313519485, 639.5087567684134, 784.0305347341347, 813.6550783566543, 436.59278767943033, 1952.559182756288, 686.6285311634568, 473.15388671210565, 613.2118456032891, 291.4174093659509, 255.50058873705385, 560.2870177323899, 1183.7377886464396, 154.88251619867174, 424.20322718555417, 221.6443103404676, 232.98390642357884, 129.17728872450468, 108.33515271459947, 222.47917906883026, 315.44849641624666, 58.83675314211922, 48.48649338922291, 45.559190568652305, 45.801552966286245, 40.96684243365318, 40.47461649319917, 45.977658234493745, 38.869598703172414, 37.620059509229286, 329.71821904063563, 179.47267290879833, 34.60430130140861, 33.69325508440982, 33.75038290375514, 33.425620542223484, 33.23989947365204, 32.141788971129856, 31.138603581229614, 91.98652293108395, 68.41519997094572, 295.3897973059154, 193.43569196630634, 69.35808791704379, 1045.8790728080571, 164.07997275100362, 163.3109931832062, 287.1865306934876, 304.95948268464576, 240.00200139554076, 263.9757541748414, 301.9430963152288, 247.72129128173486, 448.3334021252814, 405.1505296763339, 613.2118456032891, 159.65179444105544, 419.3874824276427, 438.0277242911597, 698.6113982170541, 815.1492173405877, 639.5087567684134, 473.15388671210565, 397.67772654294606, 96.5922710074803, 44.593212452446174, 41.0506675746275, 38.02611179576219, 35.769700954843344, 31.310125929158396, 30.681730589714327, 34.682213836945515, 25.99944177472214, 25.0822736521202, 24.439713331304855, 23.664622973939597, 77.65463489017993, 22.000757461290952, 21.123424843228268, 20.724655213252724, 20.137845110422532, 20.679380526572064, 19.51038745494808, 19.732387051269555, 18.77378211284542, 18.537025532940174, 18.913571344636622, 17.70907908190779, 16.767511786087052, 16.307170598007573, 15.936430103687938, 15.92875401667377, 31.69278633551985, 814.3585309167939, 528.0307463772123, 98.26554646825562, 88.59846965334977, 44.68835955067452, 151.94838436024148, 593.25131006552, 41.462991371103485, 1476.2943079878723, 256.18170234808275, 226.975012410318, 1952.559182756288, 465.3844927875499, 126.65408277075059, 68.45782113529623, 73.36968902644183, 628.3629766135363, 67.37797067118102, 298.5530787124656, 247.85122036673368, 389.15643922048065, 130.17577199476017, 397.07032028650457, 180.94683864196796, 107.21985332076139, 1172.058313519485, 287.74666392818426, 105.42041592796966, 337.62468834095506, 193.6603387097543, 419.3874824276427, 1085.8804005316533, 351.87566071658784, 784.0305347341347, 813.6550783566543, 1158.26694329832, 1045.8790728080571, 326.7665881151376, 781.9426921653378, 438.0277242911597, 698.6113982170541, 575.4424581111724, 1073.0293790919027, 59.69919485671847, 58.225512192339586, 51.208551550891784, 41.97777969072185, 102.5709341699674, 48.04584117792604, 32.09791602257713, 26.665661273682897, 26.17917738978051, 25.676591689777858, 24.198248377281967, 23.720002978123244, 29.928162583419745, 23.920736674213742, 23.48798160673403, 23.106500111075206, 23.156999092637967, 21.72909756728558, 20.255998214637504, 20.597339775948615, 20.16523420594764, 19.436416082085607, 40.51754945508509, 18.502713109589706, 18.278882459337773, 18.204714826238742, 18.67784047012014, 17.69363764118334, 17.591187117992057, 16.98933430184186, 17.619829041457212, 27.10900460410833, 54.287599132930794, 65.72596309237022, 261.15398217092394, 26.405017812741594, 65.24377752436841, 159.06565641625568, 104.04235498352739, 686.6285311634568, 38.97726233740861, 34.99091970689415, 80.4117766664693, 349.90779489038664, 589.8938965899564, 1172.058313519485, 191.03250748524445, 1158.26694329832, 108.16737819409569, 171.59242266816796, 1085.8804005316533, 575.4424581111724, 406.1479386869176, 470.90542573901143, 128.79250453659233, 111.82495375410502, 284.4458029715677, 179.76698541600263, 698.6113982170541, 813.6550783566543, 807.8116767046031, 327.2946206679664, 256.0100948898638, 324.6255016505591, 637.8168480677899, 391.37850854521787, 386.1478593701126, 526.9437461255028, 1073.0293790919027, 469.87027634580113, 411.1661048258979, 784.0305347341347, 132.8632113523582, 62.63337481210631, 39.70747842901938, 31.941805546250098, 30.12656624556278, 29.28975866679553, 31.555552388652504, 21.043933581700596, 20.67001518637793, 21.301773503713587, 20.908576223163458, 18.492029646196226, 17.99006899686781, 23.32618671818647, 17.100347158500156, 16.73384703827525, 16.844970652410534, 16.668797104972995, 16.76765988968011, 16.467961633890017, 16.00337489183218, 15.820417750133632, 15.23800135161489, 14.608027267172536, 14.071732170584852, 14.011241770324173, 13.70834276692241, 13.737233476071633, 13.219307985509339, 16.18533320066069, 96.38463107544194, 60.870892646160584, 186.3694185187997, 113.57688290540293, 52.21932971310025, 58.500872768562104, 93.66516969206691, 38.35852640430949, 324.46236515025, 30.2922473009542, 49.3164337586879, 39.39989569984276, 31.078266809557576, 122.29580692961034, 1476.2943079878723, 134.26042177963143, 153.85721046185765, 127.62210556220731, 71.53063384589062, 339.6917256237869, 406.1479386869176, 45.86629455448221, 1952.559182756288, 331.33656185604207, 218.55486693094312, 1073.0293790919027, 469.87027634580113, 349.90779489038664, 589.8938965899564, 698.6113982170541, 575.4424581111724, 470.90542573901143, 301.9430963152288, 813.6550783566543, 686.6285311634568, 613.2118456032891, 526.9437461255028, 639.5087567684134, 637.8168480677899, 784.0305347341347, 745.1804911943682, 1172.058313519485], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.275000095367432, -6.417900085449219, -6.6971001625061035, -6.72189998626709, -6.7631001472473145, -6.794400215148926, -6.827199935913086, -6.870699882507324, -6.915500164031982, -7.08620023727417, -7.094699859619141, -7.118299961090088, -7.17140007019043, -6.954699993133545, -7.146599769592285, -7.212900161743164, -7.258699893951416, -7.314499855041504, -7.324999809265137, -6.684100151062012, -7.325399875640869, -7.333600044250488, -7.278800010681152, -7.514200210571289, -7.518499851226807, -7.1596999168396, -7.548900127410889, -7.540800094604492, -7.577300071716309, -7.589700222015381, -6.191800117492676, -6.6072998046875, -6.5233001708984375, -7.021900177001953, -5.400599956512451, -6.043499946594238, -6.027900218963623, -4.44950008392334, -6.380799770355225, -6.206699848175049, -4.271100044250488, -6.923399925231934, -5.052000045776367, -5.0858001708984375, -5.827700138092041, -5.745999813079834, -5.281899929046631, -5.203700065612793, -5.505099773406982, -6.209799766540527, -5.122799873352051, -5.85129976272583, -4.48829984664917, -5.24399995803833, -4.535099983215332, -5.360000133514404, -4.297699928283691, -4.360899925231934, -4.37939977645874, -5.6645002365112305, -6.1427001953125, -5.4375, -4.75029993057251, -4.934100151062012, -5.824999809265137, -5.363399982452393, -4.718800067901611, -5.101600170135498, -5.010700225830078, -5.04449987411499, -5.388700008392334, -4.856900215148926, -5.3024001121521, -5.513000011444092, -5.446000099182129, -4.799900054931641, -4.931700229644775, -4.146699905395508, -3.3993000984191895, -5.434199810028076, -4.426799774169922, -5.076300144195557, -5.026700019836426, -5.616600036621094, -5.793700218200684, -5.074100017547607, -4.729000091552734, -6.410099983215332, -6.606200218200684, -6.669400215148926, -6.66510009765625, -6.777599811553955, -6.789899826049805, -6.662600040435791, -6.831099987030029, -6.864500045776367, -4.693900108337402, -5.302800178527832, -6.949999809265137, -6.977099895477295, -6.975399971008301, -6.985199928283691, -6.991000175476074, -7.026199817657471, -7.05810022354126, -5.977200031280518, -6.276199817657471, -4.845099925994873, -5.2631001472473145, -6.2795000076293945, -3.740499973297119, -5.52209997177124, -5.537300109863281, -5.049900054931641, -5.011099815368652, -5.225500106811523, -5.2769999504089355, -5.171500205993652, -5.3445000648498535, -4.9899001121521, -5.072800159454346, -4.814499855041504, -5.753699779510498, -5.17710018157959, -5.203000068664551, -5.121300220489502, -5.155399799346924, -5.317200183868408, -5.490600109100342, -4.482100009918213, -5.903800010681152, -6.684999942779541, -6.769199848175049, -6.848400115966797, -6.9096999168396, -7.046299934387207, -7.066800117492676, -6.946599960327148, -7.236999988555908, -7.27370023727417, -7.3007001876831055, -7.33489990234375, -6.14739990234375, -7.408899784088135, -7.451300144195557, -7.471399784088135, -7.500500202178955, -7.474599838256836, -7.533599853515625, -7.522799968719482, -7.573699951171875, -7.587399959564209, -7.567699909210205, -7.634699821472168, -7.691400051116943, -7.721099853515625, -7.744500160217285, -7.746500015258789, -7.058800220489502, -3.8239998817443848, -4.255899906158447, -5.9309000968933105, -6.037099838256836, -6.719900131225586, -5.5304999351501465, -4.311600208282471, -6.822500228881836, -3.5174999237060547, -5.151599884033203, -5.291800022125244, -3.3373000621795654, -4.655300140380859, -5.829800128936768, -6.3856000900268555, -6.33050012588501, -4.4492998123168945, -6.418300151824951, -5.161399841308594, -5.323999881744385, -4.969399929046631, -5.89300012588501, -5.0081000328063965, -5.664700031280518, -6.080999851226807, -4.382199764251709, -5.393700122833252, -6.14139986038208, -5.381499767303467, -5.748799800872803, -5.270699977874756, -4.782199859619141, -5.514599800109863, -5.107699871063232, -5.132599830627441, -4.991300106048584, -5.139999866485596, -5.564000129699707, -5.281599998474121, -5.472700119018555, -5.4028000831604, -5.462900161743164, -5.396999835968018, -6.10290002822876, -6.1280999183654785, -6.258299827575684, -6.46019983291626, -5.568900108337402, -6.327899932861328, -6.7342000007629395, -6.924600124359131, -6.944399833679199, -6.963900089263916, -7.024700164794922, -7.045499801635742, -6.813000202178955, -7.037300109863281, -7.055600166320801, -7.072199821472168, -7.071899890899658, -7.135799884796143, -7.208700180053711, -7.192200183868408, -7.213500022888184, -7.251299858093262, -6.518499851226807, -7.302999973297119, -7.315299987792969, -7.319699764251709, -7.294300079345703, -7.349100112915039, -7.3557000160217285, -7.39169979095459, -7.355400085449219, -6.942599773406982, -6.295199871063232, -6.116000175476074, -4.851399898529053, -6.98199987411499, -6.195099830627441, -5.4328999519348145, -5.804800033569336, -4.3242998123168945, -6.69379997253418, -6.787300109863281, -6.1707000732421875, -5.160299777984619, -4.813399791717529, -4.514400005340576, -5.723899841308594, -4.604300022125244, -6.101200103759766, -5.82480001449585, -4.7530999183654785, -5.142399787902832, -5.378799915313721, -5.295000076293945, -6.035099983215332, -6.12470006942749, -5.638500213623047, -5.888400077819824, -5.29610013961792, -5.291200160980225, -5.309500217437744, -5.691299915313721, -5.805099964141846, -5.734399795532227, -5.529600143432617, -5.6828999519348145, -5.709199905395508, -5.7108001708984375, -5.563000202178955, -5.763500213623047, -5.80210018157959, -5.795199871063232, -4.917300224304199, -5.675899982452393, -6.1381001472473145, -6.361499786376953, -6.420199871063232, -6.449900150299072, -6.377399921417236, -6.790599822998047, -6.809199810028076, -6.779699802398682, -6.798699855804443, -6.924499988555908, -6.953199863433838, -6.6946001052856445, -7.00600004196167, -7.02839994430542, -7.021900177001953, -7.033100128173828, -7.027299880981445, -7.046299934387207, -7.074999809265137, -7.088399887084961, -7.126699924468994, -7.172100067138672, -7.210599899291992, -7.2154998779296875, -7.23799991607666, -7.236999988555908, -7.2769999504089355, -7.074999809265137, -5.334099769592285, -5.780700206756592, -4.729000091552734, -5.291600227355957, -6.007299900054932, -5.90880012512207, -5.5040998458862305, -6.3125, -4.497000217437744, -6.565899848937988, -6.183700084686279, -6.366799831390381, -6.551700115203857, -5.5040998458862305, -4.035799980163574, -5.634099960327148, -5.560800075531006, -5.702899932861328, -6.085299968719482, -5.22760009765625, -5.1844000816345215, -6.375699996948242, -4.429999828338623, -5.374899864196777, -5.647500038146973, -4.933899879455566, -5.361599922180176, -5.501200199127197, -5.332399845123291, -5.293900012969971, -5.405799865722656, -5.475500106811523, -5.645999908447266, -5.3678998947143555, -5.44890022277832, -5.492199897766113, -5.543700218200684, -5.519000053405762, -5.549699783325195, -5.553199768066406, -5.627099990844727, -5.64169979095459], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2974, 1.2961, 1.2928, 1.2922, 1.2917, 1.2914, 1.2906, 1.2894, 1.2887, 1.2862, 1.286, 1.2856, 1.2843, 1.2842, 1.2841, 1.2828, 1.2825, 1.2807, 1.2806, 1.2804, 1.2803, 1.2799, 1.2772, 1.2753, 1.2749, 1.2738, 1.2734, 1.2732, 1.2731, 1.2725, 1.2712, 1.2676, 1.2668, 1.2682, 1.2416, 1.2465, 1.2317, 1.1471, 1.231, 1.2105, 1.082, 1.2545, 1.0847, 1.0832, 1.1563, 1.1273, 1.0565, 1.0353, 1.0515, 1.1408, 0.9464, 1.0623, 0.7751, 0.9146, 0.7373, 0.9219, 0.6144, 0.6276, 0.5972, 0.9603, 1.0988, 0.8349, 0.5547, 0.5747, 0.9423, 0.6548, 0.1815, 0.4045, 0.2916, 0.2207, 0.499, -0.4671, 0.1326, 0.2944, 0.1021, 1.4922, 1.4918, 1.4916, 1.4911, 1.4899, 1.4898, 1.4894, 1.4891, 1.489, 1.4878, 1.4878, 1.4838, 1.4819, 1.4793, 1.4784, 1.4774, 1.4764, 1.4762, 1.476, 1.4754, 1.4747, 1.4747, 1.4739, 1.4728, 1.4724, 1.4724, 1.4722, 1.4721, 1.4705, 1.4702, 1.4679, 1.465, 1.4334, 1.4387, 1.448, 1.2737, 1.3443, 1.3338, 1.2567, 1.2355, 1.2606, 1.1139, 1.085, 1.11, 0.8714, 0.8897, 0.7336, 1.14, 0.7509, 0.6815, 0.2963, 0.108, 0.1889, 0.3167, 1.499, 1.4925, 1.4842, 1.4828, 1.4801, 1.48, 1.4766, 1.4763, 1.474, 1.4717, 1.4709, 1.4699, 1.4679, 1.4671, 1.4668, 1.4651, 1.4641, 1.4637, 1.4631, 1.4622, 1.4617, 1.4606, 1.4596, 1.4592, 1.458, 1.4559, 1.4541, 1.4536, 1.4522, 1.4519, 1.4404, 1.4417, 1.4482, 1.4456, 1.4472, 1.4128, 1.2696, 1.4195, 1.152, 1.2693, 1.2501, 1.0526, 1.1686, 1.2956, 1.3549, 1.3407, 1.0744, 1.3382, 1.1064, 1.13, 1.0334, 1.2049, 0.9746, 1.1038, 1.2109, 0.5181, 0.911, 1.1674, 0.7633, 0.9519, 0.6573, 0.1944, 0.5888, 0.1946, 0.1326, -0.0792, -0.1259, 0.6136, 0.0234, 0.4118, 0.0148, 0.1487, -0.4085, 1.7746, 1.7744, 1.7725, 1.7694, 1.7673, 1.7667, 1.7638, 1.7588, 1.7574, 1.7573, 1.7558, 1.755, 1.7549, 1.7547, 1.7547, 1.7545, 1.7526, 1.7523, 1.7496, 1.7494, 1.7493, 1.7483, 1.7466, 1.7458, 1.7457, 1.7454, 1.7451, 1.7445, 1.7437, 1.7425, 1.7424, 1.7243, 1.6773, 1.6653, 1.5502, 1.7112, 1.5935, 1.4646, 1.5172, 1.1107, 1.61, 1.6244, 1.4089, 0.9488, 0.7734, 0.3858, 0.9904, 0.3078, 1.1819, 0.9968, 0.2236, 0.4693, 0.5812, 0.5172, 1.0734, 1.1251, 0.6777, 0.8867, 0.1216, -0.026, -0.0371, 0.4846, 0.6165, 0.4497, -0.0209, 0.3142, 0.3014, -0.0112, -0.5744, 0.0508, 0.1457, -0.4929, 2.1602, 2.1535, 2.1472, 2.1414, 2.1411, 2.1397, 2.1377, 2.1296, 2.1289, 2.1283, 2.1279, 2.1249, 2.1237, 2.1226, 2.1217, 2.1209, 2.1208, 2.1202, 2.12, 2.1191, 2.119, 2.1171, 2.1163, 2.1131, 2.112, 2.1114, 2.1107, 2.1097, 2.1081, 2.1077, 2.0643, 2.0773, 2.0101, 1.9427, 2.004, 1.9889, 1.9229, 2.0073, 1.6876, 1.99, 1.8848, 1.9262, 1.9786, 1.6563, 0.6337, 1.4329, 1.3699, 1.4148, 1.6113, 0.9111, 0.7757, 1.7653, -0.0401, 0.7887, 0.9322, 0.0546, 0.4527, 0.6079, 0.2545, 0.1237, 0.2058, 0.3366, 0.6105, -0.1026, -0.0139, 0.0559, 0.156, -0.013, -0.041, -0.2509, -0.274, -0.7414]}, \"token.table\": {\"Topic\": [2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 4, 1, 2, 3, 5, 5, 1, 3, 4, 5, 2, 1, 3, 4, 2, 2, 3, 2, 1, 2, 3, 4, 5, 1, 4, 2, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 3, 2, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 4, 5, 5, 1, 2, 3, 4, 5, 3, 2, 3, 1, 3, 4, 4, 2, 2, 2, 4, 4, 5, 2, 1, 3, 4, 5, 1, 4, 4, 3, 4, 1, 2, 3, 4, 1, 4, 1, 2, 3, 2, 3, 5, 2, 1, 2, 3, 4, 5, 1, 3, 5, 5, 4, 1, 4, 5, 5, 1, 5, 1, 1, 2, 3, 4, 5, 3, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 5, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 3, 4, 1, 2, 3, 4, 1, 2, 4, 5, 3, 1, 1, 2, 3, 4, 5, 1, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 3, 3, 5, 4, 1, 2, 4, 5, 1, 4, 2, 4, 2, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 5, 1, 4, 5, 5, 1, 4, 5, 2, 3, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 3, 5, 1, 2, 3, 2, 1, 3, 5, 1, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 2, 3, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 5, 3, 1, 2, 1, 2, 3, 4, 5, 2, 3, 4, 1, 1, 2, 3, 4, 1, 5, 1, 4, 5, 3, 4, 5, 5, 3, 1, 2, 3, 4, 5, 1, 5, 5, 1, 2, 3, 4, 5, 3, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 1, 1, 2, 3, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 2, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 5, 4, 1, 1, 2, 3, 4, 3, 3, 4, 4, 5, 5, 3, 1, 2, 3, 4, 5, 1, 2, 5, 4, 1, 2, 3, 4, 5, 5, 3, 5, 1, 5, 3, 1, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 4, 5, 4, 1, 1, 1, 2, 3, 4, 5, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 2, 4, 5, 1, 4, 5, 1, 5, 3, 5, 1, 2, 3, 4, 5, 4, 2, 1, 3, 4, 5, 3, 2, 3, 1, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 2, 3, 4, 2, 3, 4, 1, 4, 4, 1, 3, 5, 3, 1, 3, 4, 5, 1, 1, 2, 3, 4, 5, 2, 3, 1, 1, 4, 3, 4, 5, 1, 3, 4, 5, 5, 1, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 4, 5, 3, 4, 1, 2, 3, 4, 5, 3, 2, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 1, 2, 3, 4, 5, 3, 5, 4, 4, 5, 1, 5, 2, 3, 2, 2, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 2, 3, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 4, 4, 1, 2, 3, 4, 5, 1, 4, 5, 3, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 5, 3, 1, 2, 3, 4, 5, 4], \"Freq\": [0.8593370515362763, 0.12798636937774327, 0.012189178035975549, 0.14995413173250943, 0.34275230110287874, 0.41313893436507704, 0.09180865208112823, 0.006120576805408549, 0.0803877156568003, 0.20766826544673408, 0.6732471186257024, 0.02344641706656675, 0.013397952609466714, 0.9980407530975632, 0.08589419257964317, 0.3672717199957156, 0.47686086225250174, 0.02961868709642868, 0.03850429322535728, 0.9417673297690891, 0.010446172363152649, 0.7869449846908328, 0.18454904508236344, 0.01741028727192108, 0.9715835120160238, 0.11873316931793211, 0.8459738313902663, 0.014841646164741514, 0.014841646164741514, 0.9787362325086779, 0.08177763978034103, 0.8586652176935807, 0.05451842652022735, 0.9899664142482401, 0.9948061989057183, 0.004714721321828048, 0.9943020282706428, 0.17074491540897369, 0.00948582863383187, 0.7209229761712221, 0.00948582863383187, 0.0948582863383187, 0.9798665807379465, 0.9709991784159367, 0.9634343403274525, 0.1694564986924599, 0.6899300303907296, 0.14121374891038327, 0.01017650678127605, 0.030529520343828147, 0.9464151306586726, 0.01017650678127605, 0.01704446201617703, 0.03977041137107973, 0.9431268982284622, 0.06661158779553843, 0.15900830635064012, 0.7176861394745108, 0.055867783312387065, 0.9542262563534382, 0.9644764959363207, 0.9434971763769486, 0.9744055910243737, 0.10870197804113935, 0.0621154160235082, 0.3416347881292951, 0.48915890118512706, 0.13686356962576554, 0.06843178481288277, 0.6524891110065566, 0.09230333765458605, 0.05092597939563369, 0.1695211099992119, 0.07221291996945281, 0.6386490156163663, 0.00921867063439823, 0.11011189924420109, 0.09252119771685215, 0.7798215236134681, 0.12776736827565296, 0.06773717100914373, 0.006096345390822935, 0.7051439502051862, 0.00474160197064006, 0.21608157551916848, 0.9635240645393557, 0.8276651360327981, 0.16859845363631074, 0.9356535192940103, 0.1695453781251009, 0.682218307217668, 0.01614717886905723, 0.02825756302085015, 0.10495666264887199, 0.9587838983005996, 0.9959181318502685, 0.0017847995194449255, 0.059230639653677836, 0.9147843235401355, 0.019743546551225944, 0.9648220740394907, 0.9626984589819576, 0.9857783936496621, 0.983517848793483, 0.9689869840544789, 0.9625458727022143, 0.024680663402620876, 0.9824994369322749, 0.13422386099286465, 0.8132386871920623, 0.03947760617437195, 0.00789552123487439, 0.15393590109178787, 0.8466474560048333, 0.9637088414367541, 0.9900950277280877, 0.9763994193491158, 0.06889994590108586, 0.7015267219019651, 0.03758178867331956, 0.1879089433665978, 0.03787158967631734, 0.9089181522316161, 0.9924687391041452, 0.9925813103979896, 0.0045117332290817705, 0.9515833262148136, 0.028835858370145864, 0.9238379356860437, 0.9882737247608283, 0.3091636289630867, 0.2963882723943641, 0.1251984943734814, 0.22995641823700666, 0.04088114101991229, 0.949994334501852, 0.02261891272623457, 0.02261891272623457, 0.944965803241767, 0.9500367431889826, 0.3108997342975595, 0.6839794154546309, 0.9898875828740449, 0.9483276148717548, 0.9749296079204627, 0.9077631002435292, 0.9933810673673567, 0.30875501144815065, 0.008738349380608038, 0.06116844566425626, 0.5082806556387008, 0.11359854194790449, 0.9777805691983076, 0.9663929947406791, 0.9422156869567148, 0.2892633476590025, 0.061190323543250526, 0.016688270057250144, 0.4060812380597535, 0.22251026743000193, 0.6225128311406491, 0.10094802667145661, 0.17497657956385812, 0.010094802667145662, 0.09085322400431095, 0.15292580302268705, 0.17899270126519054, 0.2589311892088679, 0.26762015528970234, 0.14076125050951876, 0.9903016208936533, 0.8158295086229795, 0.18622195305524533, 0.950392659354885, 0.6954759885070818, 0.02207860280974863, 0.18214847318042618, 0.06071615772680873, 0.0386375549170601, 0.13204698747702356, 0.8252936717313972, 0.7984642741335588, 0.017445437922245823, 0.0939369734274775, 0.002683913526499357, 0.08722718961122912, 0.9956823830532513, 0.5007481249083846, 0.04403130063849589, 0.2063427618156964, 0.2279267327169199, 0.022447329737272415, 0.06164043090402342, 0.17259320653126559, 0.043148301632816397, 0.10478873253683982, 0.6194863305854353, 0.9710295736505362, 0.9479063154680915, 0.9398420622796403, 0.04475438391807811, 0.5219095630658008, 0.16701106018105627, 0.2687834249788874, 0.04175276504526407, 0.8505693946938993, 0.05934205079259762, 0.04945170899383135, 0.03956136719506508, 0.9866972478585442, 0.9753598355686592, 0.0984938941884003, 0.6818808059196944, 0.01515290679821543, 0.053035173793754005, 0.14774084128260045, 0.024530685681862393, 0.01635379045457493, 0.351606494773361, 0.5969133515919849, 0.03143356091220346, 0.245181775115187, 0.7229719009806795, 0.008573687250779283, 0.3200843240290932, 0.028578957502597608, 0.4315422582892239, 0.2114842855192223, 0.9938683395544718, 0.16088413265254348, 0.836597489793226, 0.9847429152215318, 0.8020143729033178, 0.0763823212288874, 0.11751126342905754, 0.0029377815857264387, 0.9800454704987389, 0.9792242000651888, 0.9877260644521401, 0.9873618563782992, 0.9825368154049678, 0.9714895191014309, 0.9460508458380883, 0.031018060519281583, 0.015509030259640792, 0.010339353506427194, 0.9782324306894112, 0.30859046749339153, 0.11915869536873534, 0.2413727419007716, 0.27192625353378064, 0.06110702326601813, 0.9626055543011408, 0.7858475644272642, 0.0958350688325932, 0.12139108718795139, 0.9463331916607669, 0.02682843590830667, 0.11267943081488802, 0.853144261884152, 0.1639461351651617, 0.7924063199649483, 0.03903479408694326, 0.7614949591269506, 0.013017007848323943, 0.12691582652115846, 0.10088181082451056, 0.39806937828334626, 0.1555673432371698, 0.004575510095210876, 0.15099183314195894, 0.2928326460934961, 0.9935030070132135, 0.012877531410896611, 0.9658148558172458, 0.025755062821793222, 0.9866060416631346, 0.9411293231366893, 0.05755107371699179, 0.9794245144117704, 0.9892501665391212, 0.9465876456049354, 0.03155292152016451, 0.9574486034987592, 0.9705149558660229, 0.9959976029388593, 0.0008447816818819842, 0.0025343450456459526, 0.9481418403046467, 0.03881032879256747, 0.4428943403387111, 0.3355951960298481, 0.05022513137861672, 0.1301287494809615, 0.948097640158552, 0.04514750667421676, 0.7916600648961514, 0.20416496410479693, 0.13146781259971596, 0.8618445492648047, 0.20023072638935435, 0.30804727136823745, 0.1940697809619896, 0.26184018066300185, 0.03388519985050612, 0.19114035676092803, 0.10425837641505165, 0.5560446742136088, 0.1529122854087424, 0.9664460263465667, 0.3379810528011694, 0.1413375311713981, 0.2544075561085166, 0.1634599273547474, 0.10323784885562994, 0.9750367610669436, 0.22376905535565333, 0.1203606282594802, 0.14578893000444082, 0.36277710489477133, 0.1474841501207715, 0.15316097085314914, 0.30202770887863994, 0.22616292892334175, 0.18894624441696906, 0.13025839577230441, 0.04823578651379809, 0.9164799437621637, 0.024117893256899045, 0.01760921720017427, 0.17609217200174268, 0.8012193826079292, 0.9820082451318435, 0.014616634906054148, 0.9646979037995738, 0.1135380472950348, 0.5454762707000584, 0.15302954200635124, 0.18264816303983858, 0.0049364368389145565, 0.4999802841956913, 0.18749260657338424, 0.3085815816520282, 0.9855310990775094, 0.005163679908144413, 0.2013835164176321, 0.5783321497121742, 0.21687455614206533, 0.9628369046318118, 0.9858334094266387, 0.9690858289098994, 0.016708376360515507, 0.016708376360515507, 0.009749350613721897, 0.9846844119859116, 0.9431460129249288, 0.9675851623553964, 0.9568510547675683, 0.48132939876083475, 0.1505134276255379, 0.09407089226596119, 0.16462406146543207, 0.10974937431028806, 0.9638814184922228, 0.02920852783309766, 0.9565452848885571, 0.8010835022307113, 0.024275257643354888, 0.048550515286709776, 0.12137628821677444, 0.003034407205419361, 0.9416932413105522, 0.9784817615384865, 0.9187556607295031, 0.19368431314161502, 0.14133720148171905, 0.0994595121538023, 0.4501851602751052, 0.11516364565177109, 0.026827643556167104, 0.33087427052606094, 0.0178850957041114, 0.5186677754192307, 0.10731057422466841, 0.969769482286599, 0.19749188460517575, 0.2187275711218613, 0.1401555310101247, 0.2803110620202494, 0.1613912175268103, 0.9857495314061829, 0.9614287686560724, 0.01224657300171062, 0.8511368236188881, 0.00612328650085531, 0.1285890165179615, 0.9776277931291985, 0.1735086661086013, 0.35737605855204446, 0.21753325303167925, 0.22530229778281066, 0.025896815837104674, 0.004768859548270046, 0.4745015250528696, 0.42919735934430414, 0.0309975870637553, 0.05961074435337558, 0.9829359783488176, 0.9628840114798765, 0.10427929263598118, 0.026069823158995295, 0.8603041642468447, 0.3520884544245655, 0.02215941321553209, 0.07632686774238832, 0.30038315692165724, 0.24867785941874904, 0.01819735657149276, 0.9796243620986935, 0.6756241082852007, 0.009008321443802675, 0.16815533361764995, 0.1471359169154437, 0.13404997801501675, 0.01914999685928811, 0.8425998618086767, 0.30005943511899613, 0.46639673067409176, 0.01141530459691833, 0.10110698357270521, 0.12067607716742235, 0.954512590620949, 0.471901590355904, 0.14451186913337982, 0.22763816553753635, 0.07928969810858008, 0.07545309981300362, 0.9759855268227937, 0.9811634644918044, 0.9504820200784897, 0.4917668646920513, 0.010130029047963602, 0.2707480491001181, 0.20904696308070345, 0.017497322901028043, 0.9823944647899023, 0.9615088495495089, 0.979393102072429, 0.930164555824206, 0.02709217152886037, 0.036122895371813825, 0.009030723842953456, 0.9615591064076674, 0.03688811207212129, 0.9222028018030322, 0.30523503448420325, 0.6758775763578786, 0.9821827409593873, 0.9803295764176744, 0.31499148177222286, 0.30321609927606497, 0.005887691248078932, 0.09420305996926291, 0.2855530255318282, 0.1817403160163223, 0.23766041325211376, 0.5731809966668626, 0.9728303029608584, 0.5069758672035461, 0.12953978959796492, 0.1481786082451541, 0.09412603416830544, 0.12115232120672977, 0.9583771815282062, 0.15384385863105493, 0.8375943414357435, 0.9616972548391144, 0.02530782249576617, 0.9671469594701306, 0.00951026882068692, 0.9890679573514396, 0.990886256120335, 0.2358787755622885, 0.17335669047348914, 0.4007097271600323, 0.17051477751490735, 0.019893390710072525, 0.06509569510938412, 0.11870391461122985, 0.022974951215076745, 0.7888066583843016, 0.8573652893750374, 0.14289421489583956, 0.9657947879916916, 0.9902766059668585, 0.9714863188151798, 0.2812486567361887, 0.14765554478649906, 0.16523358583251085, 0.3304671716650217, 0.0773433806024519, 0.973392339531673, 0.32421595036421597, 0.3745547426576074, 0.24657476225068004, 0.054604791640289, 0.24860338691409306, 0.20305772824280885, 0.24860338691409306, 0.16510301268340533, 0.1347392402358825, 0.01299906578311333, 0.2599813156622666, 0.1299906578311333, 0.14298972361424664, 0.4484677695174099, 0.7083655596031122, 0.08615256805983797, 0.2058089125873907, 0.9542178279658107, 0.9736494742778802, 0.032028981635999626, 0.05338163605999938, 0.1281159265439985, 0.779371886475991, 0.466221053098056, 0.4545655267706046, 0.0757609211284341, 0.9091927691432602, 0.08457607154821024, 0.9730156004044425, 0.9267649799997751, 0.0033118823122751558, 0.6623764624550311, 0.11922776324190561, 0.0033118823122751558, 0.21196046798560997, 0.960797341097975, 0.977766684724882, 0.6975252253995159, 0.27736239277697283, 0.019223136133057525, 0.005492324609445006, 0.9650341486603198, 0.9957769339578758, 0.004292141956714982, 0.9877835838776854, 0.22304938053356643, 0.7502570072492689, 0.44664045193339147, 0.21759406632652406, 0.15804200606873853, 0.10536133737915902, 0.07329484339419758, 0.05562566730169615, 0.11967946601274021, 0.7939299787605724, 0.010113757691217482, 0.021913141664304546, 0.03072768410515751, 0.7451463395500696, 0.1382745784732088, 0.07681921026289378, 0.9696457467232489, 0.09509459992752049, 0.7705941718264591, 0.013116496541726964, 0.11804846887554267, 0.0152146876660387, 0.09128812599623219, 0.8824518846302446, 0.9628015749649266, 0.0332000543091354, 0.9549574315409612, 0.9350667639946179, 0.004870139395805302, 0.058441672749663616, 0.9468161601839669, 0.6794208292537312, 0.19703204048358205, 0.05775077048656715, 0.06454497877910446, 0.9590574960072192, 0.2241416581722411, 0.002518445597440911, 0.5918347153986142, 0.17377274622342287, 0.010073782389763645, 0.9985676580995656, 0.9412396567113714, 0.9791370773237921, 0.9246490623693043, 0.0642117404423128, 0.07262568650100426, 0.020750196143144075, 0.9026335322267672, 0.8345707692021506, 0.0981847963767236, 0.030682748867726126, 0.03681929864127135, 0.9901071678298252, 0.7799455141191424, 0.10782656877223167, 0.08266703605871094, 0.028753751672595113, 0.9402232465130724, 0.05585484632750925, 0.973840219415087, 0.20814251503136147, 0.046253892229191435, 0.626997205773484, 0.0847988024201843, 0.03597524951159334, 0.9669825525597269, 0.0306978588114199, 0.01534892940570995, 0.05484943199427128, 0.43095982281213147, 0.03917816571019377, 0.47013798852232525, 0.33563077885136966, 0.2869886369888523, 0.09728428372503467, 0.19456856745006934, 0.08755585535253121, 0.06728029177259859, 0.7593061500050413, 0.1633949943048823, 0.0921020652940794, 0.9026002398819781, 0.175653698159406, 0.212633424087702, 0.064714520374518, 0.545450957442366, 0.9278263991942539, 0.9599595733562334, 0.9969063345903761, 0.9373022941339527, 0.36223079002440206, 0.17473809237092636, 0.2703976319900466, 0.10203684226039494, 0.08928223697784558, 0.9498384016306007, 0.04789045428933411, 0.008595722564752276, 0.9418456010235708, 0.0012279603663931824, 0.0012279603663931824, 0.027979892781844522, 0.7461304741825207, 0.21451251132747468, 0.9777696516180243, 0.5657259150601678, 0.11636375495767128, 0.10893628123696884, 0.1609285972818858, 0.04827857918456574, 0.9982957895358193, 0.956145945603738, 0.9767072080056209, 0.97754647357607, 0.9598773024375307, 0.9684929901588332, 0.018273452644506288, 0.9806506870794585, 0.016715636711581678, 0.9763993909167151, 0.07614233354460308, 0.12690388924100512, 0.7868041132942318, 0.3635180959734033, 0.3085676861169586, 0.1754186160801888, 0.12046820622374411, 0.031702159532564236, 0.9784041958779957, 0.02174231546395546, 0.21189587826751616, 0.5353159029916198, 0.08475835130700647, 0.1137546293857192, 0.05353159029916198, 0.016579455173217898, 0.24869182759826847, 0.6742311770441946, 0.0055264850577393, 0.05526485057739299, 0.993351382025854, 0.00449480263360115, 0.8012398582085334, 0.19696349736391153, 0.0009561334823490851, 0.8525255008288639, 0.003423797192083791, 0.07189974103375961, 0.04964505928521497, 0.02225468174854464, 0.7735195231844559, 0.017884844466692622, 0.14307875573354098, 0.06706816675009734, 0.404998363601442, 0.2705201424828165, 0.15167892381984507, 0.05785690908592028, 0.11258641768070973, 0.987266637527766, 0.9882880354015396, 0.9789523158114731, 0.9521130372078787, 0.2979545782056811, 0.1574902770515743, 0.18941398185932584, 0.17664449993622522, 0.1809009939105921, 0.8637309215960182, 0.13024513897082815, 0.006855007314254113, 0.9719149138918669, 0.2897356073903783, 0.34104295453242445, 0.03319887168014751, 0.0814881395785439, 0.253518656466581, 0.1489642273940345, 0.36496235711538455, 0.0074482113697017256, 0.47668552766091044, 0.0821410658303427, 0.9199799372998383, 0.9516975758840127, 0.5876224742786731, 0.25026092850281695, 0.057658155096237236, 0.06747230915517123, 0.03802984697836924, 0.9338240209892018], \"Term\": [\"0\", \"0\", \"0\", \"10\", \"10\", \"10\", \"10\", \"10\", \"1080\", \"1080\", \"1080\", \"1080\", \"1080\", \"1080p\", \"1080ti\", \"1080ti\", \"1080ti\", \"1080ti\", \"1080ti\", \"10900k\", \"10gb\", \"10gb\", \"10gb\", \"10gb\", \"10k\", \"1200\", \"1200\", \"1200\", \"1200\", \"120hz\", \"1400\", \"1400\", \"1400\", \"144\", \"1440p\", \"1440p\", \"144hz\", \"1500\", \"1500\", \"1500\", \"1500\", \"1500\", \"17th\", \"19\", \"1gb\", \"20\", \"20\", \"20\", \"2070\", \"2070\", \"2070\", \"2070\", \"2080\", \"2080\", \"2080\", \"2080ti\", \"2080ti\", \"2080ti\", \"2080ti\", \"21\", \"240hz\", \"2500\", \"3000\", \"3060\", \"3060\", \"3060\", \"3060\", \"3070\", \"3070\", \"3070\", \"3070\", \"3070\", \"3080\", \"3080\", \"3080\", \"3080\", \"3080\", \"3080ti\", \"3080ti\", \"3080ti\", \"3090\", \"3090\", \"3090\", \"3090\", \"3090\", \"30xx\", \"3d\", \"3d\", \"3k\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4000\", \"4k\", \"4k\", \"500\", \"500\", \"500\", \"55\", \"5gb\", \"60fps\", \"60hz\", \"650\", \"650w\", \"650w\", \"6gb\", \"700\", \"700\", \"700\", \"700\", \"750w\", \"750w\", \"750w_psu\", \"780\", \"7nm\", \"8\", \"8\", \"8\", \"8\", \"850\", \"850\", \"8_pin\", \"8gb\", \"8gb\", \"8k\", \"8k\", \"950\", \"aaa\", \"actually\", \"actually\", \"actually\", \"actually\", \"actually\", \"adapter\", \"adapter\", \"adapter\", \"address\", \"affect\", \"aibs\", \"aibs\", \"air\", \"airflow\", \"allowed\", \"allowing\", \"amazon\", \"amd\", \"amd\", \"amd\", \"amd\", \"amd\", \"application\", \"aspect\", \"australia\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"better\", \"blame\", \"bot\", \"bot\", \"bother\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"boy\", \"boy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"cable\", \"card\", \"card\", \"card\", \"card\", \"card\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cheapest\", \"checkout\", \"class\", \"class\", \"come\", \"come\", \"come\", \"come\", \"company\", \"company\", \"company\", \"company\", \"confirmed\", \"connector\", \"console\", \"console\", \"console\", \"console\", \"console\", \"cooler\", \"cooler\", \"cooler\", \"cooler\", \"core\", \"core\", \"core\", \"cpu\", \"cpu\", \"cpu\", \"cpu\", \"cpu\", \"cuda_core\", \"curious\", \"curious\", \"cutting_edge\", \"day\", \"day\", \"day\", \"day\", \"decide\", \"dedicated\", \"demanding\", \"development\", \"devs\", \"disappointed\", \"dl\", \"dl\", \"dl\", \"dl\", \"efficiency\", \"end\", \"end\", \"end\", \"end\", \"end\", \"euro\", \"evga\", \"evga\", \"evga\", \"exhaust\", \"fan\", \"fan\", \"fan\", \"faster\", \"faster\", \"faster\", \"fe\", \"fe\", \"fe\", \"fe\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"fit\", \"flagship\", \"flagship\", \"flagship\", \"folk\", \"fps\", \"fps\", \"frame_rate\", \"ftw3\", \"funny\", \"funny\", \"future_proof\", \"ga102\", \"game\", \"game\", \"game\", \"gamers_nexus\", \"gaming\", \"gaming\", \"gaming\", \"gaming\", \"gaming\", \"gap\", \"gap\", \"gb\", \"gb\", \"geforce\", \"geforce\", \"gen\", \"gen\", \"gen\", \"gen\", \"gen\", \"generation\", \"generation\", \"generation\", \"generation\", \"germany\", \"going\", \"going\", \"going\", \"going\", \"going\", \"gold\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gpu\", \"gpu\", \"gpu\", \"gpu\", \"gpu\", \"gtx_1080\", \"gtx_1080\", \"gtx_1080\", \"guy\", \"guy\", \"guy\", \"happening\", \"hdmi\", \"hdmi\", \"high\", \"high\", \"high\", \"high\", \"high\", \"higher\", \"higher\", \"higher\", \"holding\", \"increase\", \"increase\", \"increase\", \"increase\", \"industry\", \"inflated\", \"info\", \"info\", \"info\", \"intel\", \"intel\", \"itx\", \"kept\", \"kid\", \"know\", \"know\", \"know\", \"know\", \"know\", \"knowing\", \"knowing\", \"knowledge\", \"launch\", \"launch\", \"launch\", \"launch\", \"launch\", \"learned\", \"lineup\", \"listing\", \"little\", \"little\", \"little\", \"little\", \"little\", \"load\", \"load\", \"load\", \"load\", \"load\", \"local\", \"look\", \"look\", \"look\", \"look\", \"look\", \"luck\", \"managed\", \"max\", \"max\", \"max\", \"max\", \"maxed\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"microcenter\", \"minecraft\", \"mobo\", \"mobo\", \"mobo\", \"money\", \"money\", \"money\", \"money\", \"money\", \"monitor\", \"monitor\", \"month\", \"month\", \"month\", \"month\", \"motherboard\", \"motherboard\", \"motherboard\", \"need\", \"need\", \"need\", \"need\", \"need\", \"net\", \"new\", \"new\", \"new\", \"new\", \"new\", \"newegg\", \"newest\", \"node\", \"nvidia\", \"nvidia\", \"nvidia\", \"nvidia\", \"nvidia\", \"nvme\", \"obvious\", \"online\", \"order\", \"order\", \"order\", \"order\", \"ordered\", \"overclocking\", \"overclocking\", \"overpriced\", \"overpriced\", \"p\", \"par\", \"pc\", \"pc\", \"pc\", \"pc\", \"pc\", \"pcie\", \"pcie\", \"pcie\", \"peak\", \"people\", \"people\", \"people\", \"people\", \"people\", \"performing\", \"person\", \"person\", \"phone\", \"phone\", \"pissed\", \"play\", \"play\", \"playing\", \"point\", \"point\", \"point\", \"point\", \"point\", \"power\", \"power\", \"power\", \"power\", \"power_draw\", \"power_draw\", \"power_limit\", \"pre_order\", \"preorder\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"prevent\", \"price\", \"price\", \"price\", \"price\", \"probably\", \"probably\", \"probably\", \"probably\", \"probably\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"product\", \"product\", \"product\", \"properly\", \"ps4\", \"ps5\", \"ps5\", \"ps5\", \"ps5\", \"psu\", \"psu\", \"psu\", \"purchase\", \"purchase\", \"quadro\", \"radiator\", \"ram\", \"ram\", \"ram\", \"ram\", \"ram\", \"rated\", \"rdr2\", \"release\", \"release\", \"release\", \"release\", \"replacement\", \"resolution\", \"resolution\", \"retailer\", \"return\", \"return\", \"right\", \"right\", \"right\", \"right\", \"right\", \"rtx\", \"rtx\", \"rtx\", \"rtx\", \"rtx\", \"rumor\", \"rumor\", \"rumor\", \"rumor\", \"rumour\", \"run\", \"run\", \"run\", \"run\", \"ryzen\", \"ryzen\", \"ryzen\", \"sale\", \"sale\", \"scale\", \"scalper\", \"scalper\", \"scalper\", \"scan\", \"sell\", \"sell\", \"sell\", \"sell\", \"september\", \"series\", \"series\", \"series\", \"series\", \"series\", \"setting\", \"shader\", \"shortage\", \"site\", \"site\", \"slot\", \"slot\", \"slot\", \"sold\", \"sold\", \"sold\", \"sold\", \"sony\", \"stock\", \"stock\", \"stock\", \"stock\", \"store\", \"store\", \"successor\", \"super\", \"super\", \"super\", \"super\", \"super\", \"supply\", \"supply\", \"supply\", \"support\", \"support\", \"support\", \"support\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"tax\", \"tax\", \"tax\", \"tdp\", \"tdp\", \"tech\", \"tech\", \"tech\", \"tech\", \"tempted\", \"tensor_memory\", \"texture\", \"thicc\", \"think\", \"think\", \"think\", \"think\", \"think\", \"throwing\", \"ti\", \"ti\", \"ti\", \"ti\", \"ti\", \"tier\", \"tier\", \"tier\", \"till\", \"time\", \"time\", \"time\", \"time\", \"time\", \"titan\", \"tower\", \"tsmc\", \"tsmc_7nm\", \"tuf\", \"uk\", \"uk\", \"ultra\", \"ultra\", \"ultrawide\", \"unit\", \"unit\", \"unit\", \"upgrade\", \"upgrade\", \"upgrade\", \"upgrade\", \"upgrade\", \"usage\", \"usage\", \"use\", \"use\", \"use\", \"use\", \"use\", \"v\", \"v\", \"v\", \"v\", \"v\", \"vr\", \"vr\", \"vram\", \"vram\", \"vram\", \"wait\", \"wait\", \"wait\", \"wait\", \"wait\", \"waiting\", \"waiting\", \"waiting\", \"waiting\", \"want\", \"want\", \"want\", \"want\", \"want\", \"warzone\", \"watch\", \"watt\", \"wattage\", \"way\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"witcher\", \"work\", \"work\", \"work\", \"work\", \"work\", \"x\", \"x\", \"x\", \"x\", \"xbox\", \"xbox\", \"xx80\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yield\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 4, 5, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1290027834564915527378115303\", ldavis_el1290027834564915527378115303_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1290027834564915527378115303\", ldavis_el1290027834564915527378115303_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1290027834564915527378115303\", ldavis_el1290027834564915527378115303_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.085767 -0.054720       1        1  27.074516\n",
       "2      0.228388  0.035577       2        1  22.427258\n",
       "3     -0.007888 -0.131629       3        1  22.293301\n",
       "4     -0.050752 -0.035954       4        1  16.742277\n",
       "1     -0.083981  0.186727       5        1  11.462649, topic_info=      Term         Freq        Total Category  logprob  loglift\n",
       "295   game  1183.000000  1183.000000  Default  30.0000  30.0000\n",
       "10    3090  1476.000000  1476.000000  Default  29.0000  29.0000\n",
       "211   vram  1045.000000  1045.000000  Default  28.0000  28.0000\n",
       "35      ti   814.000000   814.000000  Default  27.0000  27.0000\n",
       "4     3080  1952.000000  1952.000000  Default  26.0000  26.0000\n",
       "..     ...          ...          ...      ...      ...      ...\n",
       "343   want    72.361450   639.508757   Topic5  -5.5190  -0.0130\n",
       "389   know    70.175465   637.816848   Topic5  -5.5497  -0.0410\n",
       "280  think    69.930256   784.030535   Topic5  -5.5532  -0.2509\n",
       "345    buy    64.946463   745.180491   Topic5  -5.6271  -0.2740\n",
       "18   price    64.007181  1172.058314   Topic5  -5.6417  -0.7414\n",
       "\n",
       "[376 rows x 6 columns], token_table=      Topic      Freq   Term\n",
       "term                        \n",
       "92        2  0.859337      0\n",
       "92        4  0.127986      0\n",
       "92        5  0.012189      0\n",
       "194       1  0.149954     10\n",
       "194       2  0.342752     10\n",
       "...     ...       ...    ...\n",
       "227       2  0.250261   year\n",
       "227       3  0.057658   year\n",
       "227       4  0.067472   year\n",
       "227       5  0.038030   year\n",
       "3349      4  0.933824  yield\n",
       "\n",
       "[738 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 3, 4, 5, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics for the trigram model\n",
    "pyLDAvis.enable_notebook()\n",
    "# Creates the filepath to save the html file\n",
    "LDAvis_data_filepath = os.path.join(os.getcwd()+'\\\\visualization\\\\'+ 'nvidia_' + 'trigram_' +'ldavis_prepared_'+str(num_topics))\n",
    "\n",
    "trigram_vis = pyLDAvis.gensim.prepare(lda_trigram_model, trigram_corpus, trigram_id2word)\n",
    "\n",
    "# Saves the graph as a html file to the LDAvis_data_filepath\n",
    "pyLDAvis.save_html(trigram_vis, os.getcwd()+ '\\\\visualization\\\\' + 'nvidia_' + 'trigram_' + 'ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "\n",
    "trigram_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T03:00:52.846161Z",
     "start_time": "2021-01-23T03:00:52.823140Z"
    }
   },
   "source": [
    "## Intrepeting the pyLDAvis graph\n",
    "\n",
    "Topics 1 has the largest bubble which shows the larger percentage of the documents belong to topic 1. Topics 1 and 4 overlap one another, which shows that they have close related to one another. Topic 5 is the furtherest apart from the other topics. The blue bars represent the overall term frequency of the corpus and the red bars represent the term frequency with regards to the topic.\n",
    "\n",
    "The GPU model terms tend to appear the most often in topic 3. Topic 2 discusses about the different types of resolutions.(**Stopped here**) Topic 4 mainly discusses about the features the GPUs provide such as ray tracing and super resolution. Topic 5 is quite similar to topic 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Mallet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* Download [link](http://mallet.cs.umass.edu/download.php)\n",
    "* Need to install [JDK](https://www.oracle.com/java/technologies/javase-jdk15-downloads.html) (Java Development Kit) to make it work\n",
    "* Need to configure the [PATH file](https://docs.oracle.com/javase/10/install/installation-jdk-and-jre-microsoft-windows-platforms.htm#JSJIG-GUID-96EB3876-8C7A-4A25-9F3A-A2983FEC016A) after installing\n",
    "\n",
    "Go to *Importing the optimal mallet model pickle file* section if you've not installed the JDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA Mallet model often gives a better quality of topics compared to the LDA. I'll be creating to see if the coherence score is much greater than the LDA and if there's a greater intrepretability in the number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:07:31.255888Z",
     "start_time": "2021-01-26T00:07:31.251884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/mallet/mallet-2.0.8/bin/mallet.bat'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the environment path\n",
    "os.environ.update({'MALLET_HOME': r'C:\\mallet\\mallet-2.0.8'})\n",
    "mallet_path = r'C:/mallet/mallet-2.0.8/bin/mallet.bat'\n",
    "# prefix_path = r'C:/mallet/ga_capstone'\n",
    "mallet_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best k topics for the mallet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:07:31.271902Z",
     "start_time": "2021-01-26T00:07:31.256889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Solution: Follow this\n",
    "def mallet_compute_coherence_values(dictionary, all_corpus, texts, limit, start=2, step=4):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    num_topics_list: Number of topics\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    \n",
    "    #For two lines below update with your path to new_mallet\n",
    "#     os.environ.update({'MALLET_HOME':r'C:\\Users\\Trogg\\Documents\\General Assembly DS 18\\dsi18-projects\\capstone\\mallet\\mallet-2.0.8'})\n",
    "#     mallet_path = r'C:\\Users\\Trogg\\Documents\\General Assembly DS 18\\dsi18-projects\\capstone\\mallet\\mallet-2.0.8\\bin\\mallet.bat'\n",
    "#     prefix_path = r'C:\\Users\\Trogg\\Documents\\General Assembly DS 18\\dsi18-projects\\capstone\\mallet files'\n",
    "    \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    num_topics_list = []\n",
    "\n",
    "\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaMallet(mallet_path, corpus=all_corpus, num_topics=num_topics, id2word=dictionary, random_seed=42)\n",
    "        #model = gensim.models.ldamodel.LdaModel(corpus=all_corpus,num_topics=num_topics,id2word=dictionary,eval_every=1,\n",
    "        #                                        alpha='auto',random_state=42)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        num_topics_list.append(num_topics)\n",
    "\n",
    "    return model_list, coherence_values, num_topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:28.760023Z",
     "start_time": "2021-01-26T00:07:31.272903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using Bigram as it has the highest coherence value\n",
    "model_list, coherence_values, num_topics_list = mallet_compute_coherence_values(dictionary=trigram_id2word, all_corpus=trigram_corpus,\n",
    "                                                                         texts=data_trigrams, start=1, limit=11, step=1)\n",
    "\n",
    "# Creating the dataframe to hold the model list, coherence values and the number of topics list\n",
    "model_values_df = pd.DataFrame({'model_list':model_list,'coherence_values':coherence_values,'num_topics':num_topics_list})\n",
    "\n",
    "# Finds the optimal number of topics based on the highest coherence score\n",
    "optimal_num_topics = model_values_df.loc[model_values_df['coherence_values'].idxmax()]['num_topics']\n",
    "\n",
    "# Train the model based on the optimal number of topics\n",
    "optimal_model = LdaMallet(mallet_path, corpus=trigram_corpus, num_topics=optimal_num_topics, id2word=trigram_id2word,\n",
    "                                                 prefix='nvidia_optimal_', random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:28.766029Z",
     "start_time": "2021-01-26T00:19:28.761024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_list</th>\n",
       "      <th>coherence_values</th>\n",
       "      <th>num_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.533103</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.569926</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.536058</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.535934</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.536693</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.538344</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.519279</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.508902</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.482650</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_list  coherence_values  \\\n",
       "0  <gensim.models.wrappers.ldamallet.LdaMallet ob...          0.371841   \n",
       "1  <gensim.models.wrappers.ldamallet.LdaMallet ob...          0.533103   \n",
       "2  <gensim.models.wrappers.ldamallet.LdaMallet ob...          0.569926   \n",
       "3  <gensim.models.wrappers.ldamallet.LdaMallet ob...          0.536058   \n",
       "4  <gensim.models.wrappers.ldamallet.LdaMallet ob...          0.535934   \n",
       "5  <gensim.models.wrappers.ldamallet.LdaMallet ob...          0.536693   \n",
       "6  <gensim.models.wrappers.ldamallet.LdaMallet ob...          0.538344   \n",
       "7  <gensim.models.wrappers.ldamallet.LdaMallet ob...          0.519279   \n",
       "8  <gensim.models.wrappers.ldamallet.LdaMallet ob...          0.508902   \n",
       "9  <gensim.models.wrappers.ldamallet.LdaMallet ob...          0.482650   \n",
       "\n",
       "   num_topics  \n",
       "0           1  \n",
       "1           2  \n",
       "2           3  \n",
       "3           4  \n",
       "4           5  \n",
       "5           6  \n",
       "6           7  \n",
       "7           8  \n",
       "8           9  \n",
       "9          10  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:28.937181Z",
     "start_time": "2021-01-26T00:19:28.767030Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAGsCAYAAAARwVXXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABZvElEQVR4nO3deXhU1eHG8e+5GZIQQyCZBJCdBFBQBCEsohaRiFYUUakLLrVotWpVwB8WFMUNRSkGqbgj1qUWWi2uVAQrWCgFFxS1BJKAC4shC0SWBJJ7fn9ER2MCDJCZO8m8n+fhcebOvTPvzMH69i7nGmutRUREREQkQjheBxARERER+SkVVBERERGJKCqoIiIiIhJRVFBFREREJKKooIqIiIhIRFFBFREREZGI4vM6gBc2bdrkdYQGLzU1lcLCQq9jSJhovKOLxju6aLyjS7jHu1WrVrUu1x5UEREREYkoKqgiIiIiElFUUEVEREQkokTlOagiIiLiDWstZWVluK6LMcbrOPIz3377LeXl5XX6ntZaHMchPj4+6DEPW0FdtWoVs2fPxnVdBg8ezPDhw6u9/vnnn/Pggw/SvHlzAPr168eIESPYtGkT2dnZgfUKCgq44IILGDp0KHPnzmXRokUkJSUBcPHFF9OrV69wfSURERE5SGVlZTRq1AifT/vIIpHP5yMmJqbO37eiooKysjIaN24cXI46T1AL13WZNWsWEydOxO/3M2HCBDIzM2nTpk219bp27cr48eOrLWvVqhVTp04NvM8111xD3759A68PHTqUYcOGhf5LiIiIyGFzXVflNAr5fL6D2jMblnNQc3NzadmyJS1atMDn8zFgwABWrlx50O+zevVqWrZsSVpaWghSioiISKjpsH70OpixD8v/hSkuLsbv9wee+/1+1q1bV2O9tWvXMm7cOJKTk7nsssto27ZttdeXLl3KiSeeWG3Z22+/zZIlS0hPT+fyyy8nMTGxxvsuXLiQhQsXAjBlyhRSU1Pr4mvJfvh8Pv3OUUTjHV003tGlrsf722+/1R7UCBeq8YmLiwv671JY/oZYa2ss+3mL7tixI48++ijx8fF89NFHTJ06lRkzZgRer6io4MMPP2TkyJGBZUOGDGHEiBEAzJkzh+eee47rrruuxmdlZWWRlZUVeK4Jh0NPEztHF413dNF4R5e6Hu/y8vKQnOModcPn81FRURGS9y4vL6/xd8nTifr9fj9FRUWB50VFRSQnJ1dbJyEhgfj4eAB69epFZWUlpaWlgdc//vhjOnbsSLNmzQLLmjVrhuM4OI7D4MGDycvLC+0XERERkXqvoKCAa6+9lgEDBnDKKadw2WWX7bNDLFu2jMsvvzzMCcNv9OjRvPHGG17HCAhLQc3IyGDz5s0UFBRQUVHBsmXLyMzMrLbOtm3bAntac3NzcV2XJk2aBF6v7fB+SUlJ4PGKFStqnBIgIiIi8lPWWq688kpOOOEEli1bxnvvvccf/vCHkB0VCNXeyIYuLIf4Y2JiGDVqFJMnT8Z1XQYNGkTbtm1ZsGABUHWofvny5SxYsICYmBhiY2MZPXp04DSA8vJyPv30U66++upq7/vCCy+wYcMGjDGkpaXVeF1EREQil/vXp7Bfr6/T9zRtO+Jc9Nt9vr506VIaNWpUba/osccei7WWe+65h3/9618YY7jxxhs555xzANi1axe//e1vycnJ4bjjjuNPf/oTxhg+/fRT7rrrLnbu3ElKSgrZ2dm0aNGCESNG0Lt3bz744ANOO+00BgwYsM/1jj/+eJYtW8b27duZNm0a/fr1o7KyksmTJ7N48WKMMYwcOZJRo0bt8/N+bt26dYwePZo333wTgK+//prf/OY3LFy4kOzsbN555x3KysrIzMzkgQceqHHaZb9+/Zg/fz4pKSl88skn3HPPPfz9739n165dTJw4kTVr1lBRUcHNN9/M6aefTk5ODmPHjmXPnj1Ya3nyySdJT08/rHEM21nKvXr1qjFH6ZAhQwKPzzjjDM4444xat42Li+OZZ56psfyGG26o25AiIiLSoOXk5NC9e/cay9966y0+//xz3nnnHYqLiznzzDPp378/AJ999hnvvvsuLVu25JxzzmHlypUcf/zxTJw4kdmzZ+P3+3n11Vd54IEHeOihhwAoLS3l5ZdfZu/evZx//vn7XK+iooI333yTRYsW8dBDDzFnzhxeeOEFvv76a95++218Ph8lJSXs3bt3v5/3U507d2bPnj18+eWXtG/fntdee42zzjoLgCuuuIIxY8YAVT3qnXfeqdbH9ufhhx/mxBNP5KGHHmL79u0MHTqUk08+meeff54rr7yS8847jz179lBZWXnwA/MzuoxOREREPLG/PZ3htmLFCoYPH05MTAxpaWn079+fTz75hMTERHr27Bm4mOeYY47h66+/JikpiZycHC666CKgan7XH242BATmaM/Ly9vvemeeeSYAxx13HN988w0A//73v7nssssCV9MnJyezZs2a/b7Pz5199tm8/vrr/P73v+e1117jscceA6rOqX3sscfYvXs327Zt46ijjgq6oC5ZsoR33nmHxx9/HKg6wr1x40Z69+7NjBkz2Lx5M7/85S8Pe+8pqKCK1Bm7ayfExWN0daqISMTq0qVL4ND3T9U249APYmNjA49jYmKoqKjAWkuXLl14/fXXa90mISEh8L77W++H9/7hffeV5UDv83PDhg3jmmuu4Ze//CXGGNLT0ykrK+PWW2/lrbfeonXr1kybNq3WyfN9Ph+u6wJUe/2Hw/edOnWqtn7nzp05/vjjWbRoEZdccglTp07lpJNOCirnvoTlIimRhs5+lYc74SrcB/6A3fmd13FERGQfTjrpJPbs2cOLL74YWLZq1SqaNWvGa6+9RmVlJUVFRfz3v/+lZ8+e+3yfjIwMiouL+eCDDwDYu3cvOTk5h7zeT/3iF7/g+eefDxTWkpKSg36fDh06EBMTw/Tp0wN7c38omykpKezcubPWog7Qpk0bPv30U4Bq6wwcOJDZs2cHCvRnn30GEDiV4Morr+S0007jf//7336/XzBUUEUOk934JW72HdAoDr7Ox/3jbdjSkgNvKCIiYWeM4emnn2bJkiUMGDCAQYMGMW3aNIYPH07Xrl057bTTuOCCC7jtttv2ewg9NjaWJ554gvvuu4+srCyGDBkSKI+Hst5PjRw5ktatWwfmcZ83b94hvc+wYcN45ZVXOPvsswFo2rQpI0eOJCsri1GjRtGjR49atxs7dix33HEH5557brU5a0ePHs3evXvJysri1FNP5cEHHwTgtdde49RTT+W0004jLy8vMEf94TB2f/u0G6hNmzZ5HaHBi5aJvO2WjbhTJ4BxcG65DwoLcGdOhpRUnDH3YFKi42470TLeUkXjHV3qerx37doVOPwtkSeUE/XXNvaeTtQv0hDZrVtwH7odrMW5+R5M81aYbj1xRt8F20twHxyP3brF65giIiL1jgqqyCGwxVtxp02EPeU4Y+/GHPnjTSJM5244Y++Bst1VJXXzNx4mFRGRhuzWW2/ltNNOq/Znzpw5Xsc6bDrELyHRkA8B2m3FuFNvhe+24Yy9B9Ohc+3rfbOh6txUa3HG3I1p2zHMScOnIY+31KTxji51Pd47d+7kiCOOqLP3k7oVykP8tY29DvGL1AH73faqw/rbi3FunLTPcgpg2nTAGXc/NGqE+8dbsfn7v2pTRCQaOI6j239GoYqKChwn+NqpeVBFgmR37qjaI1r4Lc5NkzCduh5wG9OyNc4tU3CnTcR96A6cG27HHHVsGNKKiESm+Ph4ysrKKC8vr3GLTfFeXFxcrXOjHg5rLY7jEB8fH/Q2KqgiQbC7d+E+fCds/hrn+omYo2reJm9fjL85zi334z50B+7Dd+JcNwFzbO/QhRURiWDGGBo3bux1DNmHSDmFR4f4RQ7AlpfhzrgbvsrDueYPmGN7HfR7mGZ+nHH3wZFtcB+ZjP3oPyFIKiIi0jCooIrsh91TXjWvad4anKtuxvTsd8jvZZo0xbn5XujQCfeJB3CXv1d3QUVERBoQFVSRfbAVe3EffwDWfIr5zU2YzMO7rzCASUismie18zHYZ7Jxl7xdB0lFREQaFhVUkVrYigrcJ6fC6g8wl16Lc8KgOntvE98Y58Y74Nje2Odn4i58tc7eW0REpCFQQRX5GetWYmdPh4+XYy76Lc4vzqjzzzCxcTjXTYBeA7BzZuG+MYconJJYRESkViqoIj9hXRf73CPYFUsw5/0aZ/DZIfss42uEc/U4zAmDsK++iH3lOZVUERERNM2USIC1FvvSE9ilizBnX4Tzy/ND/pkmJgauuAli47D/fBnKy+Ci32IOYjJjERGRhkYFVYTvy+nfnsG+Nx9z+nmYsy8O22cbx4FLroW4eOyCebCnDC7/PcaJCVsGERGRSKKCKgLYeS9i33kVc+pZmPN/Hfa7mxhjYMRvIK4x9vWXYM8eGDUG49O/oiIiEn30Xz+Jeu6bc7FvzcWcPARz4VWe3XrPGIMZdjFuXDz277Oxe8pxrrkF0yjWkzwiIiJe0YluEtXcd17FznsB0/8UzKXXRsS5n87p52Iu+R18sgL3T/dgy8u8jiQiIhJW3v/XWMQj7ntvYefOwvQ+EXPFTRF1zqdzypmY39wEa1bjTp+E3bXT60giIiJho4IqUclduhD74uPQoy/mqpurrqaPMM6AwTjXjIP1a3Efuh27o9TrSCIiImGhgipRx/3vYuyf/wTdjq86xzOCL0QyvU/Eue5W2Pgl7h9vw24v8TqSiIhIyKmgSlSxH/0H+0w2dD4G57pb68UFSOa4PlW3Ri38FvfB8diirV5HEhERCSkVVIkadvUHuE9OhY5dcG6YiImL8zpS0EzXHjij74LvSqtKasEmryOJiIiEjAqqRAX7v09wH70fWrfHufEOTHyC15EOmunUFefme2FPGe6Dt2I3feV1JBERkZBQQZUGz679HPeRe6FFK5wxd2ESEr2OdMhM+wyc/7sfAHfqBOyXeR4nEhERqXsqqNKg2fVrcf90N6Sk4oy9G5OY5HWkw2Zat8O55T6IjcedNhGbt8brSCIiInVKBVUaLPtVPu70SdCkKc7YezFJyV5HqjOmeSucW6ZAkyTc7Duw//vE60giIiJ1RgVVGiS78Svc7DsgvjHOzfdikv1eR6pzxp+GM+5+8DfHnXE39tOVXkcSERGpEyqo0uDYbzfhZt8OMb6qcupv7nWkkDHNUnDG3Qet2+M+ej/2w6VeRxIRETlsKqjSoNitW3CnTQTXxbn5HkzzVl5HCjmTmIQz9h7o0An3iam4y971OpKIiMhhCdstdFatWsXs2bNxXZfBgwczfPjwaq9//vnnPPjggzRvXrW3q1+/fowYMQKA66+/nvj4eBzHISYmhilTpgCwY8cOsrOz2bp1K2lpaYwZM4bExPp7hbYcHltciPvQ7VBehvN/kzFHtvU6UtiYhCNwxtyNO3MydvZ03D1lOKec6XUsERGRQxKWguq6LrNmzWLixIn4/X4mTJhAZmYmbdq0qbZe165dGT9+fK3vMWnSJJKSql+BPW/ePLp3787w4cOZN28e8+bN49JLLw3Z95DIZbeXVJXTnd/hjL0H07aj15HCzsTF49xwO+7jD2BffBy3vBzn9HO9jiUiInLQwnKIPzc3l5YtW9KiRQt8Ph8DBgxg5crDv6Bj5cqVDBw4EICBAwfWyXtK/WO/K60qp9uKqibh79DZ60ieMY1ica6dgMk8Cfv32biv/QVrrdexREREDkpY9qAWFxfj9/94FbXf72fdunU11lu7di3jxo0jOTmZyy67jLZtfzxEO3nyZABOO+00srKyANi+fTvJyVVTByUnJ1NaWlrr5y9cuJCFCxcCMGXKFFJTU+vmi8k++Xy+sPzO7o5SSu6/G7dwC8kTpxHbvXfIP7M+sOPvp/TR+yl7/a80dhwSf309xpiQfV64xlsig8Y7umi8o0ukjHdYCmpte3B+/h/Ljh078uijjxIfH89HH33E1KlTmTFjBgD33HMPKSkpbN++nXvvvZdWrVrRrVu3oD8/KysrUGoBCgsLD/GbSLBSU1ND/jvbsl24D90BX+fjXH8bpUe2B41tgL3waoyFXa/+hd3bijEjf4dxQnPQJBzjLZFD4x1dNN7RJdzj3apV7Rczh+UQv9/vp6ioKPC8qKgosOfzBwkJCcTHxwPQq1cvKisrA3tEU1JSAGjatCl9+vQhNzc38LykpASAkpKSGueoSsNly8twZ9wNX+XhXHML5ljtOf054ziYi6/BnHE+dvE/sbMfxlZWeh1LRETkgMJSUDMyMti8eTMFBQVUVFSwbNkyMjMzq62zbdu2wJ7W3NxcXNelSZMmlJWVsXv3bgDKysr49NNPadeuHQCZmZksXrwYgMWLF9OnT59wfB3xmN27B3fmZMhdg7lyLKZnf68jRSxjDOa8yzHnXIJd/i/cp6ZiK/Z6HUtERGS/wnKIPyYmhlGjRjF58mRc12XQoEG0bduWBQsWADBkyBCWL1/OggULiImJITY2ltGjR2OMYfv27fzxj38EoLKykpNOOomePXsCMHz4cLKzs3n33XdJTU1l7Nix4fg64iFbsRf3sSnwv08wv7kJp8/JXkeKeMYYzFkX4sbFY+fOwt2zB+d3f8DExnkdTUREpFbGRuElvps2bfI6QoMXinNYbGUl7pNT4aNlmEuvwxl4Rp2+fzRwl/wT+8Jj0OVYnN9PxMQ3rpP31Tlq0UXjHV003tElqs5BFTlc1q3EPjO9qpxeeJXK6SFyfnEGZtRoWPc57vRJ2F07vI4kIiJSgwqqRDzrutjnZmJXLMacdzlO1jCvI9VrTv9BONfcAhtycf94G/a77V5HEhERqUYFVSKatRb70pPYpQsxZ12E88sRXkdqEEyvATi/vw22bMSdeit2W9GBNxIREQkTFVSJWNZa7N9nY997C3P6uZhhF3sdqUExx/bGuelOKC7EfXACtqjA60giIiKACqpEMPvaX7AL5mEGDcWcf0VI74QUrcxRx+KMuQt2fof74Hjslo1eRxIREVFBlcjkvvU37BtzMCcPwVz0W5XTEDIZR+PcPBn27sWdOgG78UuvI4mISJRTQZWI4y58FfuP5zH9BmIuvTZkt+eUH5l26Tjj7gPHqTondcM6ryOJiEgU03/5JaK4783HzpkFvQdgfjMa48R4HSlqmCPb4twyBeIb406biF33hdeRREQkSqmgSsRwly3CvvgYHNcH56qbMTEqp+Fm0lri3HI/NE2pmif1i1VeRxIRkSikgioRwV35PvbZP0G3nlW34fQ18jpS1DIpaTi33AdpLXH/dDf2kxVeRxIRkSijgiqesx8vxz49DTp3xbnuNkyjWK8jRT2TlFx1TmqbjriP3Y+78n2vI4mISBRRQRVP2dUf4j7xIHTojHPD7Zi4OK8jyffMEU1wxt4D6Udhn5qGu3Sh15FERCRKqKCKZ+z/PsF97H5o3R7npkmY+ASvI8nPmMYJODfdBV17YJ+dgfvuG15HEhGRKKCCKp6w677AfeReaH4kzpi7MAmJXkeSfTBxcTi/nwg9+2FfehJ3/steRxIJO+u6XkcQiSo+rwNI9LHr1+HOuAuSU3HG3o1JTPI6khyAadQI55o/YGdPx77yZ9zy3ZhzLtENFCTiWGuhYi+UlUH5bigv+8mf3diyHx/z08flZdifrlu2u9p27NkDnbrinHs5pssxXn9NkQZPBVXCyn69Hnf6JEhMwhl7DyYp2etIEiTj88GVYyA2Dvvm3Kr/cF9wpUqqHDLrVkJ5+c/K4k/KZHlZzaJZVkuZ/HnZPJi9nbGxENcY4uKr/sR//zipGSauMcTHQ2w8xDjY//wLd+qEqqnwzrsc07p96H4ckSingiphYzd9hfvQ7RAfj3PzvZiUVK8jyUEyTgxcdj3ExWMXvlZVCC691utYEgLWdaGyEiorfvxTUQGVlVTs3I79dktweyXLymDPfvZKBstxfiyS8fE/Pk5qhok/8seCGfhTVS5NXHzt28XFQ1zcQd0MxA69CPvuG9j5f8e960ZM/0FVRxL8aYfwC4vI/qigSljYbzdVldMYH87YezGpLbyOJIfIOA5ceFVVSX3rb1Bejh07Cbt3LxgAA8ZUfwxRuafVWvt9uav8vtz98Hhv9fJXUftyu4/l1d7vh3Uq99ZYbmt8xs+z1Pb8+3X3sxey6EBf/EB7JePiai2NplqB/Mney/h48DXy/O+QiYvD/PJ87C+GYOf/HbvoDezK9zGDzsSc+SudriRSh4y11nodItw2bdrkdYQGLzU1lcLCQgBs4bdVh8X27MEZdx+mVTuP00ldcd+ci533wsFtZAxVxfVnjzE/vl6t3P5s3cCqtRfh6v80+1838Hk/36aWTLWt67oHKHuVB/fbHCxjIMYHPt9P/hlT9Tjm+8e+Rt//0/ez5T5MjK/69j9s6/v54+rvn+RP47s9e39WMOMC/4yWWxTb4q3Y117CLnu3am/t6edhsoZV7bVtQH76v+fS8IV7vFu1alXrchVUCYkf/oLbkiLcB8fDrp04/zcZ07aj19GkjtlPVpBQspWdO3d+v8ACFuzPHmN/fP2H5zXWpfr6NdblJ+9h970uP3m/n6/7w+PAqvv4nJ/80+7rc5yYqlvy+n5e9Gope9Ve831fEGtfXrMo/qxkfr/cqyKowlKd3fgV7rznYdV/oWky5uyLMSdmVZ233QBovKNLpBTUhvFvj0QkW1qC+9BE2FFadVhf5bRBMj36ckRqKrv1HzCJUqZ1O2Kuvw2b+wXuy89hX3gU+86rOOdeCr0GeH5qgkh9pHlQJSTc0m24D90BxYU4N07CdOzsdSQRkZAynbrh3HJ/1bzBMTG4jz+Ae9//Ydd86nU0kXpHe1ClztldOyi5/04o2Fx1+9LO3byOJCISFsYY6NEXp3tv7H/ew772Iu60iXDM8Tjn/RrTLt3riCL1gvagSp1zn3iQiq/yca6bgOnaw+s4IiJhZ5wYnBMH49z7OOZXv4ENubj3jMZ9ahp26xav44lEPO1BlTpld+2AL1ZxxAWjKDu2t9dxREQ8ZRrFYoaciz3pNOw/X8Eueg374VLMwDMwQy/AJDXzOqJIRFJBlbqVvxaA2GN6UuZxFBGRSGESEjHnXY49dSj29b9i33sLu3QRZshwzJBzMPEJXkcUiSg6xC91yubngDH4Onf1OoqISMQxzfw4l12Pc9cjcMzx2Ndfwr31Gtx338BW7PU6nkjEUEGVOmXz10CrdjiNj/A6iohIxDIt2xBz7XicCVOhVTvsS0/i3nE97n8XV91mViTKqaBKnbGuC+vXYjKO9jqKiEi9YNKPwrn5XpybJkFcY+zT03Anj8V+/jFReB8dkQCdgyp159tNsGsnpB/ldRIRkXrDGAPH9sbpdjx2xRLsvBdwp0+Co4+rmppK80hLFFJBlTpj89cAYNK1B1VE5GAZx8H0PwXb+0Tskn9i35iDe9/NmN4nYs69DNOi9ltCijREKqhSd/JzIOEI0P+IiogcMtOoEWbw2dgBg7EL5mHfmYddtRxz0mmYsy7CNEvxOqJIyKmgSp2x+TnQsQvG0anNIiKHyzROwJwzEjvol9g35mCXvI39z78wWedgTj8Xk6CLUaXhUpOQOmHLdsHGr3R4X0SkjpmkZJyRv8O5eyamR1/sW3Nxb7sa951XsXs1NZU0TCqoUjfWrwPrYnSBlIhISJjmrXCuHocz8SFol4GdOwv39mtxl72LdSu9jidSp8J2iH/VqlXMnj0b13UZPHgww4cPr/b6559/zoMPPkjz5s0B6NevHyNGjKCwsJCZM2eybds2jDFkZWVx5plnAjB37lwWLVpEUlISABdffDG9evUK11eSn7D5OVUPOnbxNoiISANn2nciZszd2C9W4b7yHHb2dOyCf+Ccdzl0z6yaFUCkngtLQXVdl1mzZjFx4kT8fj8TJkwgMzOTNm3aVFuva9eujB8/vtqymJgYLrvsMtLT09m9ezfjx4/nuOOOC2w7dOhQhg0bFo6vIfth83PgyLaYIxK9jiIiEhVMt544Rx+H/XAZ9h/P4f7pHuhyTNXUVJqPWuq5sBziz83NpWXLlrRo0QKfz8eAAQNYuXJlUNsmJyeTnp4OQOPGjWndujXFxcWhjCsHyVoL+TmYdO09FREJJ+M4OH1Owrn7UczI38GWjbhTbqFy5n3YzV97HU/kkIVlD2pxcTF+vz/w3O/3s27duhrrrV27lnHjxpGcnMxll11G27Ztq71eUFDA+vXr6dSpU2DZ22+/zZIlS0hPT+fyyy8nMbHmHryFCxeycOFCAKZMmUJqampdfTUBKjZ/Q9GOUhKP603C97+tz+fT7xxFNN7RReMdoX51Oe5ZI9j1xhx2/eNF3DtvIP7UoSReeCUxqc0P+W013tElUsbb2DDcS+0///kPn3zyCb/73e8AWLJkCbm5uYwaNSqwzq5du3Ach/j4eD766COeffZZZsyYEXi9rKyMSZMmcd5559GvXz8Atm3bFjj/dM6cOZSUlHDdddcdMM+mTZvq8utFPXf5v7CzsnEmzcC06QBAamoqhYWF3gaTsNF4RxeNd+Sz323HvvU37L/eAsfBnHoW5pcjDuk0LI13dAn3eLdqVfvc6WE5xO/3+ykqKgo8LyoqIjk5udo6CQkJxMfHA9CrVy8qKyspLS0FoKKigmnTpnHyyScHyilAs2bNcBwHx3EYPHgweXl5Yfg2UkN+DsQ1hlZtD7yuiIiEnGnSFOfCq3DufQzT+0Tsgn/g3vpb3H++jN1T7nU8kQMKS0HNyMhg8+bNFBQUUFFRwbJly8jMzKy2zrZt2/hhZ25ubi6u69KkSROstTz++OO0bt2as846q9o2JSUlgccrVqyocUqAhIfNy4GOnTFOjNdRRETkJ0xqC5wrx+DcMR0yumJf/jPubb/DfX8BtlJTU0nkCss5qDExMYwaNYrJkyfjui6DBg2ibdu2LFiwAIAhQ4awfPlyFixYQExMDLGxsYwePRpjDGvWrGHJkiW0a9eOcePGAT9OJ/XCCy+wYcMGjDGkpaVx9dVXh+PryE/Y8nL4Zj3mjBFeRxERkX0wbToSc+Md2JzPcF9+FvvcI9h3XsU59zLo2U9TU0nECcs5qJFG56DWHbv2c9ypE3B+fzumR5/Acp2zFF003tFF412/WWvh4//g/uN52LIRMo6umpqqyzG1rq/xji6Rcg5q2Cbql4bJ5q+peqA7SImI1AvGGOg1AKdHP+zShdjXX8KdOgG6Z+Kcd3ngYlcRL+lWp3JYbH4OND8S0yTJ6ygiInIQTEwMzi9Ox7n3Ccx5l0Pu/3Dvvgn3menYogKv40mU0x5UOWSBCfq79vA6ioiIHCITF4f55QjsL07HvvV37LtvYFcuwQwaijnzVxABc2JK9FFBlUNXvBW2l0C6bqknIlLfmSOaYH71G+zgs7Cv/QW78HXsv9+h9NQzsZ2OhaOOxTSK9TqmRAkVVDlkNj8HAKPzT0VEGgyTkoa54ibsaefivv4Xdr/zGrz5d4iNg649MMdlYo7NxKRoz6qEjgqqHLr8HIiNhdbtvU4iIiJ1zLRuR8zvxuNv0oTCZf/CfvoBdvUH2E9WYAHadMB0z8QclwnpR2kubKlTKqhyyGzeGujQGePTXyMRkYbKxMVVFdHumVXXHmz6GvvZB1WF9e1XsPP/Dkc0wRzTC7r3xhzbC5OoC2fl8KhZyCGxe/fC1/mYwcO8jiIiImFijIHW7TCt28Hp52F37cB+vgpWr8R+9hGsWIw1DqR3+X7vap+qPa26EYAcJBVUOTRf5UFFhc4/FRGJYiYhEdPnJOhzEtZ14cvcH08FmPcCdt4L0MyP6d676lSAo3tg4ht7HVvqARVUOSQ/XCClCfpFRATAOA507ILp2AXOGYndVoz97EPs6g+xK9/Hvr8AfD7o0r3qQqvumZjmR3odWyKUCqocmvwc8DfHNEvxOomIiEQg0ywFc9JpcNJp2Iq9sO6Lqj2rqz/A/vUp7F+fghatf7zQqnM3jK+R17ElQqigyiGx+WswGV29jiEiIvWA8TWqmqKqaw+44EpsweaqPaurV2Lfewu78FWIbwzdemKO7V1VWrUDJKqpoMpBsyVFUFwIp+nwvoiIHDzT/EjM4LNg8FnY8jL43yffF9YPsB/9p2oaq3YZgVMB6NC56hQCiRoqqHLw1muCfhERqRsmLh569sP07Fc1jdXGDT9eaPXm37BvzIEmTaumsTouE3PM8ZiERK9jS4ipoMpBs3k54GsE7dK9jiIiIg2IMQbadMS06Qhn/gq7oxT7+cfw/bmrLP8X1nGgU9fA3Ky0aqdprBogFVQ5aDY/B9pn6GR2EREJKZOYhOk3EPoNxLqVkL+2as/qpx9gX/4z9uU/V12w273qvFWOOg4TF+d1bKkDKqhyUGxFBXyZixn4S6+jiIhIFDFOTNWe005d4dzLsMWF309j9QH2P//CvjcfGsXCUT+Zxiq1hdex5RCpoMrB+WY97N2DydD5pyIi4h2Tkor5xenwi9Or7m649rPv966uxP7lQyxPwJFtvy+rfSDjaN2aux7RSMlB0QT9IiISaUyjRnDM8ZhjjoeLfovdsvHHOVcXvo59+x/Q+AhMt55VF1od2xuT1Mzr2LIfKqhycPJzoFkKJKd6nURERKRWpmVrTMvWcNo52LJd8MUn3xfWD+HDpVhjqqauOvb7W7C2y9A0VhFGBVUOis3PgfSjdcWkiIjUCyY+AXqdgOl1AtZ14ev1VTcI+PQD7Bt/xb7+EjRNxhzbq+pUgG49MY0TvI4d9VRQJWi2dBts3aILpEREpF4yjlM1C037DDjrIux327GffVQ1jdXHy7FLF0FMDHTqhnPaOZgefb2OHLVUUCV4+ZqgX0REGg7TpCnmhEFwwiBsZSXkrfn+blbLcB+5F3PqWZgRv6k6x1XCSgVVgmbzc6r+n2X7DK+jiIiI1CkTEwNdjsF0OQY7bCT2lT9jF76Gzf0fztXjMC1aeR0xquiMYAmazc+pusNHrCZBFhGRhss0aoRz4VU4198Ghd/i3jMG97+LvY4VVVRQJSi2shI2rNPhfRERiRqmZz+cSQ9D2w7Yp6fh/vlP2PJyr2NFBRVUCc6mr6C8DDKO9jqJiIhI2JiUNJz/uw9z5gXYpQtxJ4/FbvzS61gNngqqBMXqAikREYlSJiYG59xLcUbfBTu/w518M+6St7HWeh2twVJBleDkrYEmTUH3NRYRkShluvXEueNh6NQV+/xM7FN/xO7e5XWsBkkFVYJi1+dA+lGaoF9ERKKaaZqMM/ouzPBLsR8uxb1nNPbLXK9jNTgqqHJAdud3sGWjDu+LiIhQNeG/M/QCnHH3QWUF7v234C58TYf865AKqhxY/loAjC6QEhERCTCdulUd8j+2F3bO07gzJ2N3lHodq0FQQZUDsvk5YBxo38nrKCIiIhHFHNEE5/rbMBdeBZ99hHv3aOy6L7yOVe+poMoB2fw10Lo9Jr6x11FEREQijjEGJ2sYzvgHwOfD/eOtuG/Oxbqu19HqLRVU2S/rurB+LSZD55+KiIjsj+nQGef26ZjeJ2LnvYA7fRJ2e4nXseolX7g+aNWqVcyePRvXdRk8eDDDhw+v9vrnn3/Ogw8+SPPmzQHo168fI0aM2O+2O3bsIDs7m61bt5KWlsaYMWNITEwM11eKDlu+gd27QBdIiYiIHJBpnAC//T/o2gP71ydx774J58qxmG49vY5Wr4RlD6rrusyaNYtbb72V7Oxsli5dyjfffFNjva5duzJ16lSmTp0aKKf723bevHl0796dGTNm0L17d+bNmxeOrxNVbN4aQBP0i4iIBMsYg3PyEJxbp8ERTXCnT8L9x/NVtw2XoISloObm5tKyZUtatGiBz+djwIABrFy58rC3XblyJQMHDgRg4MCBQb+nHIT1ayEhEVq09jqJiIhIvWJat8e57SHMiVnYt/6G+8dbscVbvY5VL4TlEH9xcTF+vz/w3O/3s27duhrrrV27lnHjxpGcnMxll11G27Zt97vt9u3bSU5OBiA5OZnS0tqndli4cCELFy4EYMqUKaSmptbZd2voir7MxTm6O8lpaQe1nc/n0+8cRTTe0UXjHV003nXg5rvY3edEvnvsQew9Y2hyw23E9z3Z61S1ipTxDktBrW3i2p/fkahjx448+uijxMfH89FHHzF16lRmzJgR1LYHkpWVRVZWVuB5YWHhQW0freyunbhfr8f07H/Qv1lqaqp+5yii8Y4uGu/oovGuI916YSY+hPvkVLbf/wdKB5+NOf8KTKNGXierJtzj3apVq1qXh+UQv9/vp6ioKPC8qKgosOfzBwkJCcTHxwPQq1cvKisrKS0t3e+2TZs2paSk6uq4kpISkpKSQv1VosuGdWCtruAXERGpA6ZFK5zxD2IGn41d9DruA3/AFmz2OlZECrqgfvrppzz22GNMmTIFgLy8PD777LOgts3IyGDz5s0UFBRQUVHBsmXLyMzMrLbOtm3bAntLc3NzcV2XJk2a7HfbzMxMFi9eDMDixYvp06dPsF9HglA1Qb+BDl28jiIiItIgmEaNcC76Lc51t8LWLbj3jMZdscTrWBEnqEP88+fP56233mLw4MEsX74cgNjYWGbPns299957wO1jYmIYNWoUkydPxnVdBg0aRNu2bVmwYAEAQ4YMYfny5SxYsICYmBhiY2MZPXo0xph9bgswfPhwsrOzeffdd0lNTWXs2LGH+jtILWx+DhzZFpNwhNdRREREGhRzfH+cdhm4T03FPvVH3DWfYi78LSYuzutoESGogvrWW29x++2307x5c1599VUAWrduzaZNm4L+oF69etGrV69qy4YMGRJ4fMYZZ3DGGWcEvS1AkyZNuOOOO4LOIMGz1kJ+Dub4/l5HERERaZCMPw3n/+7DvvYX7D9fxuatwbnmFkyrdl5H81xQh/h3795d44quiooKfL6wzfMv4VawGXZ+pwn6RUREQsj4fDjnXY5z053w3XbcyWNx//1OrReJR5OgCmrXrl1rTII/f/58jjnmmFBkkgjw4wT9R3ucREREpOEzxxyPM2kGZHTF/vlP2Kcfwpbt8jqWZ4IqqKNGjWLFihVcf/31lJWVcdNNN7F8+XJ+/etfhzqfeGV9DjROgCPbeJ1EREQkKpimyTij78QMvxS78n3ce8Zgv8zzOpYnDniM3nVdNm7cyN13381XX33F1q1b8fv9dOrUCccJyyxV4gGbtwY6dMZojEVERMLGODGYoRdgOx+D+9QfcaeMw4wYhTl16EHPA1+fHbB9OI7Dgw8+SGxsLJ06deKEE06gS5cuKqcNmC0vg2++xGTo8L6IiIgXTJdjcCY9DN2Ox/71SdxH78fu/M7rWGET9Dmoa9euDXUWiRQbcsG6GF0gJSIi4hmTmITz+4mYC6+E1R/g3j0am/s/r2OFRVCX4aelpXH//feTmZmJ3++vtov5wgsvDFk48YbNr7pAio6aoF9ERMRLxhhM1jnYTt1wn5yKO3UCZvilmNPPa9Cn4QVVUPfs2RO4S1NxcXFIA4n3bH4OtGiNSdStY0VERCKB6dAZZ2I29vmZ2Feew65ZjXPlaExS8oE3roeCKqjXXXddqHNIhAhM0H/M8V5HERERkZ8wCUfA1eOg63HYvz6Ne/donCvHYrr28DpanQt6pv3NmzezdOlSiouLSUlJ4cQTT+TII48MZTbxQuG3ULpNE/SLiIhEIGMM5hdnYNOPrjrkn30H5sxfYc6+GBMT43W8OhPUyQsffPAB48ePZ+PGjSQmJrJp0ybGjx/PBx98EOp8EmY2PwfQBP0iIiKRzLTpgHPbNMyAwdg35+JOuw1bXOh1rDoT1B7Ul156iXHjxnHssccGln3++ec888wzZGZmhiyceGD9WoiLh9btvU4iIiIi+2Hi4jFX3Ih79HHYFx7DvecmnCtGY3r08TraYQtqD2pxcTFdu3attuzoo4+mqKgoJKHEO4EJ+hvQYQIREZGGzOl/Cs7EhyA5FfeRe3DnzsJW7PU61mEJqqB26NCB119/vdqyN954gw4dOoQik3jE7imHr/Mx6ZpeSkREpD4xLVvjTJiKGTQU+86ruA+Mx27d4nWsQxbUIf6rrrqKBx54gPnz5+P3+ykqKiIuLo5bbrkl1PkknL7Kh8pKTdAvIiJSD5lGsZiR12CPPg73zzNw7xmNuez3OH1O8jraQQuqoLZu3Zrs7GzWrVsXuIq/U6dO+HxBTwIg9UBggn4VVBERkXrL9DoBp30G7pNTsU8+iLvmU8yFV2Ji47yOFrSgGuaGDRtITEzk6KN/vLK7sLCQHTt26DB/A2LzcyC1RYOd9FdERCRaGH9znHH3Y199EfvPl7F5/8O55hbMkW29jhaUoM5B/dOf/kRlZWW1ZRUVFTzyyCMhCSUeycvR4X0REZEGwvh8OOf/GuemSVC6DffesbhLF1XdlCfCBVVQCwsLadGiRbVlLVu2ZOvWrSEJJeFniwthWxFo/lMREZEGxRzbG+eO6dCxC/bZh7HPZGPLdnkda7+CKqgpKSnk5+dXW5afn09ysg4FNxjrf5igX3tQRUREGhrTzI8z9m7MOSOx/12Ce89Y7Ff5B97QI0Gdgzp06FCmTp3KsGHDaNGiBd9++y2vv/465513XqjzSZjYvDXQKBbadvA6ioiIiISAcWIwZ12E7XIs7lN/xL3//zAXXIk55UyMMV7HqyaogpqVlcURRxzBu+++S1FREX6/n8svv5z+/fuHOp+Eic3PgfYZGF8jr6OIiIhICJkux+LcMQN39nTsX57A/u8TnF/fiDki0etoAUHPE3XCCSdwwgknhDKLeMRW7IUv8zCnDvU6ioiIiISBaZKE8/uJ2IWvYV95Dvee0Ti//T9IjYw5U4M6B/Xf//4333zzDQCbNm1i0qRJ3HXXXWzcuDGk4SRMvl4PFXt1/qmIiEgUMY6DM2Q4zh+mgDG4Uyew8/U5XscCgiyoc+bMITGxarfvc889R0ZGBl27duXpp58OaTgJD5tfdYGUruAXERGJPqZjF5zbp2N69sc0ivU6DhDkIf7S0lKaNWvGnj17yMnJ4eabbyYmJoYrr7wy1PkkHPJzIDkVk+z3OomIiIh4wCQcAdfcQuPUVHYVFXkdJ7iCmpSUxJYtW/jqq6/IyMigUaNGlJeXhzqbhInNW6PD+yIiIlHOGBMxV/MHVVDPP/98/vCHP+A4DmPGjAFg9erVtG/fPqThJPTs9hIoKoBTz/I6ioiIiAgQZEE95ZRTAlfwx8XFAdC5c2dGjx4dsmASJvmaoF9EREQiS9DTTP1QTH/QtGnTOg8j4WfzcyDGB+0zvI4iIiIiAgR5Fb80XDY/B9qlR8xVeyIiIiIqqFHMVlbChnU6vC8iIiIRRQU1mm3cAHvKQQVVREREIkjQ56B+8803LF++nG3btnHVVVexceNGKioqdCV/PWZ1gZSIiIhEoKAK6n/+8x9mzZpF3759Wbp0KVdddRVlZWX85S9/4fbbbw/qg1atWsXs2bNxXZfBgwczfPjwWtfLzc3ltttuY8yYMfTv359NmzaRnZ0deL2goIALLriAoUOHMnfuXBYtWkRSUhIAF198Mb169QoqjwB5OZDUDPzNvU4iIiIiEhBUQZ07dy4TJ06kQ4cO/Oc//wGgffv2bNiwIagPcV2XWbNmMXHiRPx+PxMmTCAzM5M2bdrUWO/FF1+kZ8+egWWtWrVi6tSpgdevueYa+vbtG3h96NChDBs2LKgcUp3Nz4H0oyNmUl4RERERCPIc1O3bt9c4lH8wdxvIzc2lZcuWtGjRAp/Px4ABA1i5cmWN9ebPn0+/fv0Ce0R/bvXq1bRs2ZK0tLSgPlf2ze4ohYJNOrwvIiIiESeoPajp6eksWbKEgQMHBpYtXbqUTp06BfUhxcXF+P0/3ufd7/ezbt26GuusWLGCSZMm8dhjj9X6PkuXLuXEE0+stuztt99myZIlpKenc/nll5OYmFhju4ULF7Jw4UIApkyZQmpqalC5G7LyDTlsA5od35fYEPwePp9Pv3MU0XhHF413dNF4R5dIGe+gCupvfvMb7r33Xt59913Ky8uZPHkymzZtYuLEiUF9iLW2xrKf73199tlnueSSS3Cc2nfqVlRU8OGHHzJy5MjAsiFDhjBixAgA5syZw3PPPcd1111XY9usrCyysrICzwsLC4PK3ZC5q1aC47A9OQ0Tgt8jNTVVv3MU0XhHF413dNF4R5dwj3erVq1qXR5UQW3dujXTp0/nww8/pHfv3vj9fnr37k18fHxQH+73+ykqKgo8LyoqIjk5udo6eXl5PPzwwwCUlpby8ccf4zhO4HzTjz/+mI4dO9KsWbPANj99PHjwYB544IGg8sj355+26YCJC24MRURERMIlqIJaXFxMbGwsAwYMCCzbsWMHxcXFpKSkHHD7jIwMNm/eTEFBASkpKSxbtowbb7yx2jozZ86s9rh3797VLoaq7fB+SUlJoOiuWLGCtm3bBvN1op51K2H9Wkz/QV5HEREREakhqII6depUrr322mrndxYXF/P4449z3333HXD7mJgYRo0axeTJk3Fdl0GDBtG2bVsWLFgAVB2q35/y8nI+/fRTrr766mrLX3jhBTZs2IAxhrS0tBqvyz5s/gbKdmuCfhEREYlIQRXUTZs20a5du2rL2rVrx8aNG4P+oF69etWYo3RfxfT666+v9jwuLo5nnnmmxno33HBD0J8vP7J5awBN0C8iIiKRKahpppKSktiyZUu1ZVu2bKFJkyYhCSUhlp8DiU2g+ZFeJxERERGpIag9qIMGDWLatGlcdNFFtGjRgi1btjBnzhxOPfXUUOeTELD5OdDxKE3QLyIiIhEpqII6fPhwfD4fzz//PEVFRfj9fk499VTOOuusUOeTOmZ37YDNX2P6/sLrKCIiIiK1CqqgOo7DsGHDdEvRhmB91Q0STMbRHgcRERERqV1QBRWqLpTasGEDZWVl1ZbrMH/9YvNzwBjo0NnrKCIiIiK1CqqgvvLKK7z88su0b9+euLi4aq+poNYvNn8NtGqHaZzgdRQRERGRWgVVUN966y3uu+8+2rdvH+o8EkLWdSF/Lab3gAOvLCIiIuKRoKaZio2NpXXr1qHOIqFWsAl27dAE/SIiIhLRgiqoF154Ic888wwlJSW4rlvtj9QfNi8H0AT9IiIiEtmCOsT/6KOPArBo0aIar82ZM6duE0no5OdA4yOgZRuvk4iIiIjsU1AF9ZFHHgl1DgmDqgn6u2CcoHaci4iIiHgiqIKalpYGgOu6bN++neTk5JCGkrpny3bBxi8xx/fzOoqIiIjIfgVVUHfu3MnTTz/N8uXLA3eU+uCDD8jNzeWiiy4KdUapCxtywbo6/1REREQiXlDHep966ikSEhJ49NFH8fmqOm2XLl1YtmxZSMNJ3bF5a6oedFRBFRERkcgW1B7U1atX88QTTwTKKUBSUhLbt28PWTCpW3b9WmjZBnNEotdRRERERPYrqD2oCQkJfPfdd9WWFRYW6lzUesJaC/k5OrwvIiIi9UJQBXXw4MFMmzaNzz77DGsta9euZebMmZx22mmhzid1YesW+G67JugXERGReiGoQ/znnHMOjRo1YtasWVRWVvLYY4+RlZXFmWeeGep8Ugds/vcT9GeooIqIiEjkO2BBdV2XRx99lGuuuYahQ4eGI5PUtfwciIuHVu28TiIiIiJyQAc8xO84Dp9++inGmHDkkRCw+TnQoTPGifE6ioiIiMgBBXUO6tChQ5k7dy4VFRWhziN1zJaXwzfrMRlHex1FREREJChBnYP6z3/+k23btvHmm2+SlJRU7bXHHnssJMGkjnyVB5WVuoJfRERE6o2gCuoNN9wQ6hwSIjb/hwn6u3gbRERERCRIQRXUbt26hTqHhIjNz4G0lpikZl5HEREREQlKUAV17969/P3vf2fp0qV89913/PnPf+aTTz5h8+bNnHHGGaHOKIfIWgt5OZiju3sdRURERCRoQV0k9ec//5mvv/6aG2+8MXA1f9u2bVmwYEFIw8lhKi6E7cWgC6RERESkHglqD+qKFSuYMWMG8fHxgYKakpJCcXFxSMPJ4QlM0K8LpERERKQeCWoPqs/nw3XdastKS0tp0qRJSEJJHclfA7Gx0LqD10lEREREghZUQe3fvz+PPPIIBQUFAJSUlDBr1iwGDBgQ0nByeGx+DrTvhPEFtaNcREREJCIEVVBHjhxJ8+bNufnmm9m1axc33ngjycnJjBgxItT55BDZvXvhqzwd3hcREZF6J6hdaz6fjyuuuIIrrrgicGhftz6NcF/lQUWFCqqIiIjUO0Ef+921axebNm2irKys2vJjjz22zkPJ4bPrqy6QQgVVRERE6pmgCup7773HrFmziI+PJzY2NrDcGMMjjzwSsnByGPLXQkoappnf6yQiIiIiByWogvrSSy8xduxYjj/++FDnkTpi89bo8L6IiIjUS0FdJOW6Lj169Ah1FqkjdlsRFG+FDBVUERERqX+C2oN6zjnn8PLLL3P++efjOEF12hpWrVrF7NmzcV2XwYMHM3z48FrXy83N5bbbbmPMmDH0798fgOuvv574+HgcxyEmJoYpU6YAsGPHDrKzs9m6dStpaWmMGTOGxMTEQ8rXoOSvBcB0VEEVERGR+mefBfXaa6+t9nzbtm289tprNQrgY489dsAPcV2XWbNmMXHiRPx+PxMmTCAzM5M2bdrUWO/FF1+kZ8+eNd5j0qRJJCUlVVs2b948unfvzvDhw5k3bx7z5s3j0ksvPWCehs7mrwGfD9pleB1FRERE5KDts6DecMMNdfYhubm5tGzZkhYtWgAwYMAAVq5cWaOgzp8/n379+pGXlxfU+65cuZI777wTgIEDB3LnnXeqoPL9BP3tMjCNGnkdRUREROSg7bOgduvWrc4+pLi4GL//x6vJ/X4/69atq7HOihUrmDRpUq17ZSdPngzAaaedRlZWFgDbt28nOTkZgOTkZEpLS2v9/IULF7Jw4UIApkyZQmpq6uF/qQhlKyoo+DKPhNOH08TD7+nz+Rr07yzVabyji8Y7umi8o0ukjHdQ56BWVFTwyiuvsGTJEkpKSkhOTuYXv/gF5513Hr4gbqNpra2x7OcT/T/77LNccskltZ7jes8995CSksL27du59957adWq1UEV6KysrECpBSgsLAx62/rGfpkLe8rZfWR7yj38nqmpqQ36d5bqNN7RReMdXTTe0SXc492qVatalwdVUF944QXy8vL47W9/S1paGlu3buXll19m165dXHHFFQfc3u/3U1RUFHheVFQU2PP5g7y8PB5++GEASktL+fjjj3Ech759+5KSkgJA06ZN6dOnD7m5uXTr1o2mTZsGCnNJSUmNc1Sjkc2vmqBfU0yJiIhIfRVUQV2+fDlTp06lSZMmQFXb7dixI+PGjQuqoGZkZLB582YKCgpISUlh2bJl3HjjjdXWmTlzZrXHvXv3pm/fvpSVlWGtpXHjxpSVlfHpp58yYsQIADIzM1m8eDHDhw9n8eLF9OnTJ9jv3XDlrYGmKZDi/e55ERERkUMRVEGt7RD9wYiJiWHUqFFMnjwZ13UZNGgQbdu2ZcGCBQAMGTJkn9tu376dP/7xjwBUVlZy0kknBa7yHz58ONnZ2bz77rukpqYyduzYw8rZENj8HMg4qsYpFCIiIiL1hbFBtM9nn32W3NxcRowYETg34eWXXyYjIyOoPaiRZtOmTV5HCAn73XbcsZdhRlyBc/p5nmbROUvRReMdXTTe0UXjHV3q1Tmol156KS+//DKzZs2ipKSElJQUBgwYwPnnn1+nIeUw/XD+qSboFxERkXosqILq8/m48MILufDCC0OdRw6Dzc+BmBho38nrKCIiIiKHbL/3LV2zZg0vvPBCra+9+OKLrF27NiSh5NDY/Bxo0xETF+d1FBEREZFDtt+C+o9//GOf841269aNV155JSSh5OBZtxLWr8Okd/E6ioiIiMhh2W9B3bBhQ+CK+Z877rjjWL9+fSgyyaHY9BWU74b0o71OIiIiInJY9ltQd+/eTUVFRa2vVVZWsnv37pCEkoOnCfpFRESkodhvQW3dujWffPJJra998skntG7dOiSh5BDk5UBiEqS19DqJiIiIyGHZb0EdOnQoTz75JP/9739xXRcA13X573//y1NPPcXQoUPDElIOrGqC/qM1Qb+IiIjUe/udZuqkk05i27ZtzJw5k71795KUlERpaSmxsbH86le/4qSTTgpXTtkPu/M72PINpv8pXkcREREROWwHnAf1rLPO4tRTT2Xt2rXs2LGDxMREunTpQkJCQjjySTDWV033ZTJ0gZSIiIjUf0FN1J+QkLDPq/nFezY/B4wDHTRBv4iIiNR/+z0HVeoHm5cDrdth4rVXW0REROo/FdR6zrourF+L0fynIiIi0kCooNZ3326E3TtB85+KiIhIA6GCWs/ZvDWAJugXERGRhkMFtb7Lz4GERGjRyuskIiIiInVCBbWes/k5kN4F42goRUREpGFQq6nH7O5dsOkrTEcd3hcREZGGQwW1PtuwDqzVBP0iIiLSoKig1mM2P6fqQcfO3gYRERERqUMqqPWYzVsDR7bFJCR6HUVERESkzqig1lPWWlifo+mlREREpMFRQa2vCjbDju80Qb+IiIg0OCqo9dQP55/qAikRERFpaFRQ66v8HIhvDEe28TqJiIiISJ1SQa2nbP4a6NgF48R4HUVERESkTqmg1kO2vAy+2aALpERERKRBUkGtj77MBddVQRUREZEGSQW1HrJ5P0zQr4IqIiIiDY8Kaj1k83OgeStMkySvo4iIiIjUORXUekYT9IuIiEhDp4Ja3xQVwPYSTdAvIiIiDZYKaj3z4wT9KqgiIiLSMKmg1jf5ORAbC607eJ1EREREJCRUUOsZm58DHTpjYjRBv4iIiDRMvnB90KpVq5g9ezau6zJ48GCGDx9e63q5ubncdtttjBkzhv79+1NYWMjMmTPZtm0bxhiysrI488wzAZg7dy6LFi0iKanqavaLL76YXr16hesrhZ3duwe+ysecdo7XUURERERCJiwF1XVdZs2axcSJE/H7/UyYMIHMzEzatGlTY70XX3yRnj17BpbFxMRw2WWXkZ6ezu7duxk/fjzHHXdcYNuhQ4cybNiwcHwN732ZB5UVuoJfREREGrSwHOLPzc2lZcuWtGjRAp/Px4ABA1i5cmWN9ebPn0+/fv0Ce0QBkpOTSU9PB6Bx48a0bt2a4uLicMSOOD9cIKUr+EVERKQhC8se1OLiYvx+f+C53+9n3bp1NdZZsWIFkyZN4rHHHqv1fQoKCli/fj2dOnUKLHv77bdZsmQJ6enpXH755SQmJtbYbuHChSxcuBCAKVOmkJqaWhdfK+y2bdzA3uZHkpbR2esoB+Tz+ert7ywHT+MdXTTe0UXjHV0iZbzDUlCttTWWGWOqPX/22We55JJLcJzad+qWlZUxbdo0rrjiChISEgAYMmQII0aMAGDOnDk899xzXHfddTW2zcrKIisrK/C8sLDwkL+Llyr/9ymmU9d6kT81NbVe5JS6ofGOLhrv6KLxji7hHu9WrVrVujwsBdXv91NUVBR4XlRURHJycrV18vLyePjhhwEoLS3l448/xnEc+vbtS0VFBdOmTePkk0+mX79+gW2aNWsWeDx48GAeeOCB0H4RD9niQigphIyjvY4iIiIiElJhKagZGRls3ryZgoICUlJSWLZsGTfeeGO1dWbOnFntce/evenbty/WWh5//HFat27NWWedVW2bkpKSQNFdsWIFbdu2Df2X8cr6tQC6QEpEREQavLAU1JiYGEaNGsXkyZNxXZdBgwbRtm1bFixYAFQdqt+XnJwclixZQrt27Rg3bhzw43RSL7zwAhs2bMAYQ1paGldffXU4vo4nbP4a8DWCth29jiIiIiISUsbWdoJoA7dp0yavIxy0ygf+ANYSM/5Br6MERecsRReNd3TReEcXjXd0iZRzUHUnqXrAVuyFL/N0eF9ERESiggpqffD1Bti7RwVVREREooIKaj3w4wT9uoJfREREGj4V1Pogfw0082NSvJ84V0RERCTUVFDrAZufo9ubioiISNRQQY1wtrQECr/FZKigioiISHRQQY10359/qgukREREJFqooEY4m58DMTHQLsPrKCIiIiJhoYIa4Wz+WmibjomN8zqKiIiISFiooEYwW1kJ69fq8L6IiIhEFRXUSLbxS9hTriv4RUREJKqooEYwqwukREREJAqpoEay/DXQpCmktvA6iYiIiEjYqKBGMJu/FjKOxhjjdRQRERGRsFFBjVB2Ryl8u1GH90VERCTqqKBGqvVrAZ1/KiIiItFHBTVC2fwcMA506Ox1FBEREZGwUkGNUDZvDbRpj4mL9zqKiIiISFipoEYg62qCfhEREYleKqiRaPNGKNsN6Ud7nUREREQk7FRQI5DNXwPoAikRERGJTiqokSg/B45oAi1aeZ1EREREJOxUUCOQzc+B9KM0Qb+IiIhEJRXUCGN37YTNX2PSu3gdRURERMQTKqiRZsNasBajC6REREQkSqmgRpiqCfqNJugXERGRqKWCGmFsXg4c2RaTcITXUUREREQ8oYIaQay1kJ+DydDhfREREYleKqiR5NuNsGsHdNQFUiIiIhK9VFAjiM3PAdAFUiIiIhLVVFAjSX4ONE6AI9t4nURERETEMyqoEcTm5UDHLhhHwyIiIiLRS00oQtiy3bDxS0z6UV5HEREREfGUCmqk+DIXrKvzT0VERCTq+cL1QatWrWL27Nm4rsvgwYMZPnx4revl5uZy2223MWbMGPr377/fbXfs2EF2djZbt24lLS2NMWPGkJiYGKZvVLds3pqqBx01Qb+IiIhEt7DsQXVdl1mzZnHrrbeSnZ3N0qVL+eabb2pd78UXX6Rnz55BbTtv3jy6d+/OjBkz6N69O/PmzQvH1wkJm58DLVpjEpO8jiIiIiLiqbAU1NzcXFq2bEmLFi3w+XwMGDCAlStX1lhv/vz59OvXj6SkpKC2XblyJQMHDgRg4MCBtb5nfRCYoF/nn4qIiIiE5xB/cXExfr8/8Nzv97Nu3boa66xYsYJJkybx2GOPBbXt9u3bSU5OBiA5OZnS0tJaP3/hwoUsXLgQgClTppCamlo3X6yOVGzZSNF320k8rjcJEZbtUPl8voj7nSV0NN7RReMdXTTe0SVSxjssBdVaW2OZMaba82effZZLLrkE52dTLAWz7YFkZWWRlZUVeF5YWHhQ24ea++FyAHa2aMOuCMt2qFJTUyPud5bQ0XhHF413dNF4R5dwj3erVq1qXR6Wgur3+ykqKgo8LyoqCuz5/EFeXh4PP/wwAKWlpXz88cc4jrPfbZs2bUpJSQnJycmUlJRUOzWgXsnPgbh4aNXO6yQiIiIingtLQc3IyGDz5s0UFBSQkpLCsmXLuPHGG6utM3PmzGqPe/fuTd++famsrNzntpmZmSxevJjhw4ezePFi+vTpE46vU+ds3hro0BkTE+N1FBERERHPhaWgxsTEMGrUKCZPnozrugwaNIi2bduyYMECAIYMGXLQ2wIMHz6c7Oxs3n33XVJTUxk7dmw4vk6dsnvK4Zv1mCHneh1FREREJCIYW9tJng3cpk2bvI4QYNd9gfvgeJzrb8P07Od1nDqjc5aii8Y7umi8o4vGO7pEyjmoupOUx2x+TtUDTTElIiIiAqiges7m50BaS0xSM6+jiIiIiEQEFVQPVU3QvwbTUXtPRURERH6gguqlkkLYVqzD+yIiIiI/oYLqpe/PPzUZKqgiIiIiP1BB9ZDNy4FGsdCmg9dRRERERCKGCqqH7PocaJ+B8TXyOoqIiIhIxFBB9Yjduxe+zMOkH+11FBEREZGIooLqla/zoWIvRhdIiYiIiFSjguqRwAT9ukBKREREpBoVVK/k50BKKqaZ3+skIiIiIhFFBdUjNj9HE/SLiIiI1EIF1QN2WzEUFUCGLpASERER+TkVVC/8MEG/LpASERERqUEF1QM2PwdifNAu3esoIiIiIhFHBdUDdn0OtEvHNIr1OoqIiIhIxFFBDTNbUQEb1unwvoiIiMg+qKCG28YvYc8eUEEVERERqZUKapj9MEG/0RX8IiIiIrVSQQ23/DXQNBlS0rxOIiIiIhKRVFDDzObnQMejMMZ4HUVEREQkIqmghpH9rhQKNmMydP6piIiIyL6ooIaTJugXEREROSAV1DCy+TngONC+s9dRRERERCKWCmoY2fU50KYjJi7O6ygiIiIiEUsFNUysWwn5a3V4X0REROQAVFDDZdPXUL4bdIGUiIiIyH6poIaJzV8D6AIpERERkQNRQQ2X/BxITIK0I71OIiIiIhLRVFDDxOavhXRN0C8iIiJyICqoYWB37oDNX+vwvoiIiEgQVFDDYf1aQOefioiIiARDBTUMbH4OGAMdNUG/iIiIyIGooIaBzV8Drdph4hO8jiIiIiIS8VRQQ8y6LqzXBP0iIiIiwfKF64NWrVrF7NmzcV2XwYMHM3z48Gqvr1y5kjlz5mCMISYmhiuuuIKjjz6aTZs2kZ2dHVivoKCACy64gKFDhzJ37lwWLVpEUlISABdffDG9evUK11cKzrebYNdOyDja6yQiIiIi9UJYCqrrusyaNYuJEyfi9/uZMGECmZmZtGnTJrBO9+7dyczMxBjDl19+SXZ2NtOnT6dVq1ZMnTo18D7XXHMNffv2DWw3dOhQhg0bFo6vcUg0Qb+IiIjIwQnLIf7c3FxatmxJixYt8Pl8DBgwgJUrV1ZbJz4+PjBHaHl5ea3zha5evZqWLVuSlpYWjth1Iz8HEo6AFq29TiIiIiJSL4RlD2pxcTF+vz/w3O/3s27duhrrrVixgr/85S9s376dCRMm1Hh96dKlnHjiidWWvf322yxZsoT09HQuv/xyEhMTa2y3cOFCFi5cCMCUKVNITU093K8UtKIvc3GOOpbk5s3D9pmRwOfzhfV3Fm9pvKOLxju6aLyjS6SMd1gKqrW2xrLa9pD27duXvn378sUXXzBnzhxuv/32wGsVFRV8+OGHjBw5MrBsyJAhjBgxAoA5c+bw3HPPcd1119V436ysLLKysgLPCwsLD+v7BMuW7cL9Kh9zXJ+wfWakSE1NjbrvHM003tFF4x1dNN7RJdzj3apVq1qXh+UQv9/vp6ioKPC8qKiI5OTkfa7frVs3tmzZQmlpaWDZxx9/TMeOHWnWrFlgWbNmzXAcB8dxGDx4MHl5eSHJf8jWrwNrMem6QEpEREQkWGEpqBkZGWzevJmCggIqKipYtmwZmZmZ1dbZsmVLYE9rfn4+FRUVNGnSJPB6bYf3S0pKAo9XrFhB27ZtQ/gtDp7Nz6l60LGLt0FERERE6pGwHOKPiYlh1KhRTJ48Gdd1GTRoEG3btmXBggVA1aH65cuXs2TJEmJiYoiNjWXMmDHVLpr69NNPufrqq6u97wsvvMCGDRswxpCWllbjda/Z/Bxo2QZzRM3zYkVERESkdsbWdoJoA7dp06aQf4a1FnfsZZgefXCuuCnknxdpdM5SdNF4RxeNd3TReEeXSDkHNWwT9UcjZ/Rd4GvkdQwRERGRekUFNUSMMdA+w+sYIiIiIvVOWC6SEhEREREJlgqqiIiIiEQUFVQRERERiSgqqCIiIiISUVRQRURERCSiqKCKiIiISERRQRURERGRiKKCKiIiIiIRRQVVRERERCKKCqqIiIiIRBQVVBERERGJKCqoIiIiIhJRVFBFREREJKKooIqIiIhIRFFBFREREZGIYqy11usQIiIiIiI/0B5UCYnx48d7HUHCSOMdXTTe0UXjHV0iZbxVUEVEREQkoqigioiIiEhEUUGVkMjKyvI6goSRxju6aLyji8Y7ukTKeOsiKRERERGJKNqDKiIiIiIRRQVVRERERCKKz+sA0nAUFhYyc+ZMtm3bhjGGrKwszjzzTK9jSYi5rsv48eNJSUmJmOlJJDR27tzJ448/ztdff40xhmuvvZYuXbp4HUtC5I033uDdd9/FGEPbtm257rrriI2N9TqW1KFHH32Ujz76iKZNmzJt2jQAduzYQXZ2Nlu3biUtLY0xY8aQmJgY9mwqqFJnYmJiuOyyy0hPT2f37t2MHz+e4447jjZt2ngdTULorbfeonXr1uzevdvrKBJis2fPpmfPntx8881UVFRQXl7udSQJkeLiYubPn092djaxsbE89NBDLFu2jFNOOcXraFKHTjnlFM444wxmzpwZWDZv3jy6d+/O8OHDmTdvHvPmzePSSy8NezYd4pc6k5ycTHp6OgCNGzemdevWFBcXe5xKQqmoqIiPPvqIwYMHex1FQmzXrl3873//49RTTwXA5/NxxBFHeJxKQsl1Xfbs2UNlZSV79uwhOTnZ60hSx7p161Zj7+jKlSsZOHAgAAMHDmTlypVeRNMeVAmNgoIC1q9fT6dOnbyOIiH07LPPcumll2rvaRQoKCggKSmJRx99lC+//JL09HSuuOIK4uPjvY4mIZCSksLZZ5/NtddeS2xsLD169KBHjx5ex5Iw2L59e+D/jCQnJ1NaWupJDu1BlTpXVlbGtGnTuOKKK0hISPA6joTIhx9+SNOmTQN7zaVhq6ysZP369QwZMoQHH3yQuLg45s2b53UsCZEdO3awcuVKZs6cyRNPPEFZWRlLlizxOpZEERVUqVMVFRVMmzaNk08+mX79+nkdR0IoJyeHDz74gOuvv57p06fz2WefMWPGDK9jSYj4/X78fj+dO3cGoH///qxfv97jVBIqq1evpnnz5iQlJeHz+ejXrx9r1671OpaEQdOmTSkpKQGgpKSEpKQkT3LoEL/UGWstjz/+OK1bt+ass87yOo6E2MiRIxk5ciQAn3/+Oa+//jo33nijx6kkVJo1a4bf72fTpk20atWK1atX6wLIBiw1NZV169ZRXl5ObGwsq1evJiMjw+tYEgaZmZksXryY4cOHs3jxYvr06eNJDt1JSurMmjVruOOOO2jXrh3GGAAuvvhievXq5XEyCbUfCqqmmWrYNmzYwOOPP05FRQXNmzfnuuuu82T6GQmPuXPnsmzZMmJiYujQoQO/+93vaNSokdexpA5Nnz6dL774gu+++46mTZtywQUX0KdPH7KzsyksLCQ1NZWxY8d68u+5CqqIiIiIRBSdgyoiIiIiEUUFVUREREQiigqqiIiIiEQUFVQRERERiSgqqCIiIiISUVRQRUSi3CuvvMLjjz/udQwRkQBNMyUicpCuv/569uzZw5/+9KfAvegXLVrE+++/z5133hnSzx47dixbt24FYM+ePfh8Phynal/Dueeey3nnnRfSzxcRCQfdSUpE5BBUVlby1ltvhb0QPvTQQ4HHd955JyeffDKDBw8OawYRkVBTQRUROQTDhg3j1Vdf5fTTT+eII46o9lpBQQG///3veemll4iJiQGql8n33nuPRYsWkZGRwXvvvUdiYiI33HADmzdvZs6cOezdu5dLL72UU045Jeg8ruvyj3/8g0WLFrFnzx569uzJqFGjSEhICOS5+uqr+dvf/oa1lrPPPpuzzz4bqLpj0JYtWwK3ql2zZg0vvPAC33zzDY0bN+bCCy/klFNO4aOPPuL555+nqKiIxo0bM3ToUIYNG1Y3P6iIyE+ooIqIHIL09HSOOeYYXn/9dS666KKD3n7dunWceuqpPPPMM8ydO5fp06fTu3dvZsyYwRdffMG0adPo379/4BSCA3nvvfd47733mDRpEk2bNuWRRx5h1qxZ3HDDDYF1PvvsMx5++GEKCgq46667aN++Pccdd1y19yksLOS+++7j6quvpn///uzevZuioiIAHn/8ccaMGUPXrl3ZsWMHBQUFB/29RUSCoYukREQO0QUXXMD8+fMpLS096G2bN2/OoEGDcByHAQMGUFRUxIgRI2jUqBE9evTA5/OxZcuWoN/v3//+N2eddRYtWrQgPj6ekSNHsmzZMiorKwPr/OpXvyI+Pp527doxaNAgli5dWuN93n//fbp3785JJ52Ez+ejSZMmdOjQAYCYmBi++eYbdu3aRWJiIunp6Qf9vUVEgqGCKiJyiNq1a0fv3r2ZN2/eQW/btGnTwOPY2FgAmjVrVm1ZWVlZ0O9XUlJCWlpa4HlqaiqVlZVs3749sMzv91d7vaSkpMb7FBUV0aJFi1o/4+abb+bjjz/m+uuvZ9KkSaxduzbofCIiB0MFVUTkMFxwwQUsWrSI4uLiwLIfDsuXl5cHlm3bti2kOZKTkwNX90PVofqYmJhqRfiHQ/U/vJ6cnFzjffx+P99++22tn9GpUyduueUWnnrqKfr06UN2dnYdfgMRkR+poIqIHIaWLVtywgknMH/+/MCypKQkUlJSeP/993Fdl3fffXefpa+unHjiibz55psUFBRQVlbGSy+9xAknnBC4SAvg5Zdfpry8nK+//pr33nuPAQMG1Hifk08+mdWrVwdOD/juu+/YsGEDFRUVvP/+++zatQufz0dCQkJgeisRkbqmi6RERA7TiBEjeP/996stu+aaa3j66ad56aWXOPXUU+nSpUtIMwwaNIiSkhImTZrEnj176NGjB6NGjaq2Trdu3bjxxhtxXZezzz6bHj161Hif1NRUJkyYwPPPP88TTzxBQkICF154IW3atGHJkiU888wzuK5Lq1atql2AJSJSlzRRv4hIA1fbtFciIpFMx2dEREREJKKooIqIiIhIRNEhfhERERGJKNqDKiIiIiIRRQVVRERERCKKCqqIiIiIRBQVVBERERGJKCqoIiIiIhJR/h9LCwsRnWzf5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 792x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_list, coherence_values = compute_coherence_values(dictionary=trigram_id2word, corpus=trigram_corpus, texts=data_trigrams, start=start, limit=limit, step=step)\n",
    "\n",
    "# Show graph\n",
    "\n",
    "x = model_values_df['num_topics'].values.tolist()\n",
    "\n",
    "plt.figure(figsize=(11,7))\n",
    "\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend([\"Coherence_values\"], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coherence score peaks at creating 6 topics before it plummets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:28.952387Z",
     "start_time": "2021-01-26T00:19:28.938183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 1  has Coherence Value of 0.3718\n",
      "Num Topics = 2  has Coherence Value of 0.5331\n",
      "Num Topics = 3  has Coherence Value of 0.5699\n",
      "Num Topics = 4  has Coherence Value of 0.5361\n",
      "Num Topics = 5  has Coherence Value of 0.5359\n",
      "Num Topics = 6  has Coherence Value of 0.5367\n",
      "Num Topics = 7  has Coherence Value of 0.5383\n",
      "Num Topics = 8  has Coherence Value of 0.5193\n",
      "Num Topics = 9  has Coherence Value of 0.5089\n",
      "Num Topics = 10  has Coherence Value of 0.4826\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the topics and checking if they make sense helps to decide how many topics is the optimal value. I'll be intrepreting the 5 and 6 topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the optimal model to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:28.967816Z",
     "start_time": "2021-01-26T00:19:28.952924Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save to file in the current working directory\n",
    "# Exporting the optimal model\n",
    "\n",
    "pkl_filename = \"./models/nvidia_optimal_ldamallet_model.pkl\"\n",
    "out_file = open(pkl_filename, 'wb')\n",
    "pickle.dump(optimal_model, out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the 5 topics trained model to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:28.983524Z",
     "start_time": "2021-01-26T00:19:28.968817Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save to file in the current working directory\n",
    "# Exporting the optimal model\n",
    "\n",
    "pkl_filename = \"./models/nvidia_5_topics_ldamallet_model.pkl\"\n",
    "out_file = open(pkl_filename, 'wb')\n",
    "pickle.dump(model_values_df['model_list'][4], out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the optimal mallet model pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:28.998879Z",
     "start_time": "2021-01-26T00:19:28.984525Z"
    }
   },
   "outputs": [],
   "source": [
    "# pkl_filename = \"./models/nvidia_optimal_ldamallet_model.pkl\"\n",
    "# infile = open(pkl_filename,'rb')\n",
    "# optimal_model = pickle.load(infile)\n",
    "# infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:29.014531Z",
     "start_time": "2021-01-26T00:19:28.999881Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimal_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the 5 topics mallet model pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:29.030329Z",
     "start_time": "2021-01-26T00:19:29.014531Z"
    }
   },
   "outputs": [],
   "source": [
    "pkl_filename = \"./models/nvidia_5_topics_ldamallet_model.pkl\"\n",
    "infile = open(pkl_filename,'rb')\n",
    "topic_5_ldamallet = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:29.046080Z",
     "start_time": "2021-01-26T00:19:29.030329Z"
    }
   },
   "outputs": [],
   "source": [
    "# topic_5_ldamallet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying topics for the optimal model (6 topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:29.061396Z",
     "start_time": "2021-01-26T00:19:29.046080Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('3080', 0.04898901098901099),\n",
      "   ('3090', 0.03637362637362637),\n",
      "   ('ti', 0.01876923076923077),\n",
      "   ('amd', 0.01567032967032967),\n",
      "   ('3070', 0.015274725274725275),\n",
      "   ('rtx', 0.014351648351648351),\n",
      "   ('2080', 0.012153846153846154),\n",
      "   ('upgrade', 0.011604395604395605),\n",
      "   ('2080ti', 0.01123076923076923),\n",
      "   ('wait', 0.01120879120879121)]),\n",
      " (1,\n",
      "  [('price', 0.026140252089920733),\n",
      "   ('card', 0.026096937670550525),\n",
      "   ('nvidia', 0.0249274483475549),\n",
      "   ('people', 0.02434270368605709),\n",
      "   ('time', 0.01890674405509594),\n",
      "   ('buy', 0.01728245332871313),\n",
      "   ('money', 0.009009399229003335),\n",
      "   ('series', 0.008814484341837398),\n",
      "   ('release', 0.008597912244986357),\n",
      "   ('day', 0.008013167583488544)]),\n",
      " (2,\n",
      "  [('game', 0.02716178979136596),\n",
      "   ('vram', 0.023662686436600622),\n",
      "   ('gpu', 0.014390062546472467),\n",
      "   ('4k', 0.01325285395617373),\n",
      "   ('year', 0.010737873419936142),\n",
      "   ('1440p', 0.010562918252197875),\n",
      "   ('gaming', 0.010453571272361458),\n",
      "   ('good', 0.01034422429252504),\n",
      "   ('high', 0.009053929930455321),\n",
      "   ('pc', 0.008201023487731269)])]\n"
     ]
    }
   ],
   "source": [
    "pprint(optimal_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the 6 topics \n",
    "\n",
    "Topic 0\n",
    "* Comparing against the price and the performance\n",
    "\n",
    "Topic 1\n",
    "* Driver related issue\n",
    "\n",
    "Topic 2\n",
    "* GPU features: ray_tracing, dlss and resolutions: 1440p, 4K\n",
    "\n",
    "Topic 3\n",
    "* Stock availability during launch of GPUs\n",
    "\n",
    "Topic 4\n",
    "* Price and performance for GPU models\n",
    "\n",
    "Topic 5\n",
    "* Comparison against the gaming consoles and the pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying 5 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:29.077105Z",
     "start_time": "2021-01-26T00:19:29.062397Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('game', 0.04372161791107826),\n",
      "   ('vram', 0.03808920336536769),\n",
      "   ('4k', 0.021332770091878762),\n",
      "   ('1440p', 0.017002851409863767),\n",
      "   ('gaming', 0.01682683845531031),\n",
      "   ('memory', 0.014855493364311613),\n",
      "   ('high', 0.014573872637026085),\n",
      "   ('monitor', 0.012391312000563242),\n",
      "   ('play', 0.011405639455063893),\n",
      "   ('fps', 0.011229626500510438)]),\n",
      " (1,\n",
      "  [('card', 0.045618020064357376),\n",
      "   ('nvidia', 0.04357372704902517),\n",
      "   ('wait', 0.021654363051296612),\n",
      "   ('time', 0.01983721370433466),\n",
      "   ('good', 0.015672913117546847),\n",
      "   ('release', 0.015029339390497823),\n",
      "   ('point', 0.014120764717016846),\n",
      "   ('fe', 0.01393147832670831),\n",
      "   ('launch', 0.012833617262918796),\n",
      "   ('review', 0.008631459398069278)]),\n",
      " (2,\n",
      "  [('3080', 0.0800359066427289),\n",
      "   ('3090', 0.05942549371633752),\n",
      "   ('ti', 0.03066427289048474),\n",
      "   ('3070', 0.02495511669658887),\n",
      "   ('rtx', 0.023447037701974864),\n",
      "   ('price', 0.022477558348294433),\n",
      "   ('2080', 0.01985637342908438),\n",
      "   ('upgrade', 0.018922800718132855),\n",
      "   ('2080ti', 0.018348294434470377),\n",
      "   ('year', 0.016050269299820466)]),\n",
      " (3,\n",
      "  [('people', 0.040388070427596116),\n",
      "   ('buy', 0.02867409270571326),\n",
      "   ('price', 0.020912684153790873),\n",
      "   ('money', 0.014983830398850161),\n",
      "   ('day', 0.01329500538986705),\n",
      "   ('month', 0.0127200862378728),\n",
      "   ('time', 0.012540424002874596),\n",
      "   ('sell', 0.011498383039885016),\n",
      "   ('stock', 0.011462450592885375),\n",
      "   ('cost', 0.011390585698886095)]),\n",
      " (4,\n",
      "  [('amd', 0.026507547029518925),\n",
      "   ('gpu', 0.021116811658859393),\n",
      "   ('cpu', 0.014499219272808388),\n",
      "   ('pc', 0.013941556993084988),\n",
      "   ('case', 0.013198007286787121),\n",
      "   ('gen', 0.012231392668599897),\n",
      "   ('year', 0.012194215183285003),\n",
      "   ('work', 0.011896795300765857),\n",
      "   ('run', 0.011859617815450963),\n",
      "   ('pretty', 0.011710907874191389)])]\n"
     ]
    }
   ],
   "source": [
    "pprint(topic_5_ldamallet.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the 5 topics \n",
    "\n",
    "Topic 0\n",
    "* Driver related issue\n",
    "\n",
    "Topic 1\n",
    "* Stock availability\n",
    "\n",
    "Topic 2\n",
    "* GPU features: ray_tracing, dlss and resolutions: 1440p, 4K\n",
    "\n",
    "Topic 3\n",
    "* Price and performance for GPU models\n",
    "\n",
    "Topic 4\n",
    "* Have to do with intel, nvidia and Nvidia cpu and gpus. Unable to intrepret well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I find the 6 topics to be the most intrepretable as well as it's one of the highest coherence score among the other models, I'll be selecting to it to move forward with the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the dominant topic in each sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to investigate the dominant topics for the documents and see if it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:29.092725Z",
     "start_time": "2021-01-26T00:19:29.077105Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for _, row in enumerate(ldamodel[corpus]): # ldamodel[corpus] --> Provides a list of the probability values of which topic a document belongs to\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True) # Sorts the probabilities of a document is descending order\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic (As it's sorted in descending order, the highest probability is the first topic which is index 0)\n",
    "                wp = ldamodel.show_topic(topic_num) # Obtain the dominant topic for the document\n",
    "                topic_keywords = \", \".join([word for word, prop in wp]) # Gets the topic keys words for the topic\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return sent_topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: The last model trained **must match** with the last optimal_file_doctopics text file. If not, there will be an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:29.108744Z",
     "start_time": "2021-01-26T00:19:29.092725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrain the model if you've have not done so\n",
    "# optimal_num_topics = 6\n",
    "# optimal_model = LdaMallet(mallet_path, corpus=trigram_corpus, num_topics=optimal_num_topics, id2word=trigram_id2word,\n",
    "#                                                  prefix='optimal_', random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:49.843118Z",
     "start_time": "2021-01-26T00:19:29.108744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3827</td>\n",
       "      <td>price, card, nvidia, people, time, buy, money,...</td>\n",
       "      <td>[pre_order, time, releasing, 17th]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>price, card, nvidia, people, time, buy, money,...</td>\n",
       "      <td>[going, hard, grab, 3080, 17th]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4343</td>\n",
       "      <td>price, card, nvidia, people, time, buy, money,...</td>\n",
       "      <td>[uk, price, 3090, 1399, 3080, 649, 3070, 469, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3457</td>\n",
       "      <td>3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...</td>\n",
       "      <td>[talking, spatula, jensen, pot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...</td>\n",
       "      <td>[10k, core, completely, insane]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3512</td>\n",
       "      <td>3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...</td>\n",
       "      <td>[rip, 2080, ti, resale_value, x200b, cry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4159</td>\n",
       "      <td>3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...</td>\n",
       "      <td>[shit, 3070, actually, better, value, people, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>price, card, nvidia, people, time, buy, money,...</td>\n",
       "      <td>[send, money]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4740</td>\n",
       "      <td>3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...</td>\n",
       "      <td>[question, nvidia, 3xxx, series, page, reporti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...</td>\n",
       "      <td>[3070, perform, better, 2080ti, price, holy, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             1.0              0.3827   \n",
       "1            1             1.0              0.3642   \n",
       "2            2             1.0              0.4343   \n",
       "3            3             0.0              0.3457   \n",
       "4            4             0.0              0.3395   \n",
       "5            5             0.0              0.3512   \n",
       "6            6             0.0              0.4159   \n",
       "7            7             1.0              0.3568   \n",
       "8            8             0.0              0.4740   \n",
       "9            9             0.0              0.3690   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  price, card, nvidia, people, time, buy, money,...   \n",
       "1  price, card, nvidia, people, time, buy, money,...   \n",
       "2  price, card, nvidia, people, time, buy, money,...   \n",
       "3  3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...   \n",
       "4  3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...   \n",
       "5  3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...   \n",
       "6  3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...   \n",
       "7  price, card, nvidia, people, time, buy, money,...   \n",
       "8  3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...   \n",
       "9  3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...   \n",
       "\n",
       "                                            Document  \n",
       "0                 [pre_order, time, releasing, 17th]  \n",
       "1                    [going, hard, grab, 3080, 17th]  \n",
       "2  [uk, price, 3090, 1399, 3080, 649, 3070, 469, ...  \n",
       "3                    [talking, spatula, jensen, pot]  \n",
       "4                    [10k, core, completely, insane]  \n",
       "5          [rip, 2080, ti, resale_value, x200b, cry]  \n",
       "6  [shit, 3070, actually, better, value, people, ...  \n",
       "7                                      [send, money]  \n",
       "8  [question, nvidia, 3xxx, series, page, reporti...  \n",
       "9  [3070, perform, better, 2080ti, price, holy, f...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=trigram_corpus, texts=data_trigrams)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Document']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:49.856122Z",
     "start_time": "2021-01-26T00:19:49.844119Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sort the dataframe in ascending order by the topic percentage contribution\n",
    "df_dominant_topic_sorted = df_dominant_topic.sort_values('Topic_Perc_Contrib', ascending=False)\n",
    "idx = np.random.randint(df_dominant_topic_sorted.shape[0])\n",
    "# idx = 250\n",
    "document = df_dominant_topic_sorted[['Document']].iloc[idx].values\n",
    "dominant_topic = df_dominant_topic_sorted[['Dominant_Topic']].iloc[idx].values\n",
    "dominant_keywords = df_dominant_topic_sorted[['Keywords']].iloc[idx].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:49.872136Z",
     "start_time": "2021-01-26T00:19:49.857123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant keywords: ['game, vram, gpu, 4k, year, 1440p, gaming, good, high, pc'] \n",
      "\n",
      "Document:[list(['add', 'new', 'console', 'generation', 'launch', 'lot', 'major', 'devs', 'propping', 'gen', 'game'])]\n"
     ]
    }
   ],
   "source": [
    "print(f'Dominant keywords: {dominant_keywords} \\n\\nDocument:{document}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document is relating to the price and performance of AMD against the Nividia's pascal and ampere's generation of GPUs as well as discussing about the Thermal Design Power (TDP) in which the GPUs generate heat and draw electricity as `100w` was seen in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:49.888150Z",
     "start_time": "2021-01-26T00:19:49.872136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant keywords: ['game, vram, gpu, 4k, year, 1440p, gaming, good, high, pc'] \n",
      "\n",
      " Document:[list(['add', 'new', 'console', 'generation', 'launch', 'lot', 'major', 'devs', 'propping', 'gen', 'game'])]\n"
     ]
    }
   ],
   "source": [
    "print(f'Dominant keywords: {dominant_keywords} \\n\\n Document:{document}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T09:46:19.862202Z",
     "start_time": "2021-01-23T09:46:19.847189Z"
    }
   },
   "source": [
    "In the above document, the dominant keywords reflect the document with purchasing a GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most representative document for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:49.935443Z",
     "start_time": "2021-01-26T00:19:49.889151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6234</td>\n",
       "      <td>3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...</td>\n",
       "      <td>[3090, simply, titan, titan, driver, basically...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>price, card, nvidia, people, time, buy, money,...</td>\n",
       "      <td>[edit, opinion, x200b, know, teaser_rate, car,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>game, vram, gpu, 4k, year, 1440p, gaming, good...</td>\n",
       "      <td>[plenty, depends, singeplayer, multiplayer, ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.6234   \n",
       "1        1.0              0.7326   \n",
       "2        2.0              0.6444   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  3080, 3090, ti, amd, 3070, rtx, 2080, upgrade,...   \n",
       "1  price, card, nvidia, people, time, buy, money,...   \n",
       "2  game, vram, gpu, 4k, year, 1440p, gaming, good...   \n",
       "\n",
       "                                 Representative Text  \n",
       "0  [3090, simply, titan, titan, driver, basically...  \n",
       "1  [edit, opinion, x200b, know, teaser_rate, car,...  \n",
       "2  [plenty, depends, singeplayer, multiplayer, ba...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format the columns\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most representative document for Topic 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:49.951458Z",
     "start_time": "2021-01-26T00:19:49.936444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a helper function to display the most representative documents for a topic\n",
    "def display_representative_document(topic_n, df):\n",
    "    dominant_keywords = df['Keywords'].loc[topic_n]\n",
    "    document_topic = \" \".join(df['Representative Text'].loc[topic_n])\n",
    "    \n",
    "    print(f'*******Topic {topic_n}********\\n\\nDominant keywords: {dominant_keywords} \\n\\nDocument:{document_topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:49.967472Z",
     "start_time": "2021-01-26T00:19:49.954461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Topic 0********\n",
      "\n",
      "Dominant keywords: 3080, 3090, ti, amd, 3070, rtx, 2080, upgrade, 2080ti, wait \n",
      "\n",
      "Document:3090 simply titan titan driver basically titan mind 2080 ti increase vram 1080 ti previous gen doubled respectively x70 class 8gb 1070 previously doubling gen prior 28gb 570 2gb 670 2gb 770 680 rebrand 4gb 970 8gb 1070 staying 8gb similarly x80 class doubled gen staying 8gb 1080 2080 receiving minor capacity upgrade 10gb 3080 supposed believe 10gb 3080 upgrade path 11gb 2080 ti compute 3090 titan driver actual titan\n"
     ]
    }
   ],
   "source": [
    "display_representative_document(0, sent_topics_sorteddf_mallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document talks about the price and performance of AMD's 6800xt and 6900xt which fits the topic of the `price` and `performance` of the card."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most representative document for Topic 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:49.983486Z",
     "start_time": "2021-01-26T00:19:49.968473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Topic 1********\n",
      "\n",
      "Dominant keywords: price, card, nvidia, people, time, buy, money, series, release, day \n",
      "\n",
      "Document:edit opinion x200b know teaser_rate car advertised insanely price dealership told sold cost little 699 3080 teaser_rate nvidia hyped insanely hint 3080 wanted insanely cheap price announced wanted problem nvidia stock 3080 place retailer stock place know run merchandise tracking system retailer nvidia hype knowing stock satisfy basic demand release day come nvidia counted bot ebay taking 3080 actually available blame bot nvidia overselling hype delivering card bot responsible retailer nvidia hype train knew sufficient stock satisfy basic demand retailer scam seriously believe retailer know stock send 14 99 deliver moon someday guarantee 1000 year offer valid entire universe send money backlash swift betting nvidia shat pant reading forum pissed consumer oh look pre_order delivery october november soon december year nvidia placate consumer come hey worse ussr ordered car year advance x200b nvidia destroyed marketing plan generate hype oh look mystery nda nvidia release video showing massive improvement sort falling card 2x limited release teaser_rate form bait switch car dealer time noted work lucky generate hype hear 10 people friend mention 10 people 10 people know person word mouth advertising lucky managed teaser_rate expire true price dollar higher especially nvidia tax 3rd_party manufacturer nvidia blame rising price demand created initially teaser_rate restricted supply lucky spreading word mass 3080 x200b nvidia f ck bot check ebay card sold public actually ended planned hype marketing machine bolstered lucky consumer spreading gospel seemingly army nvidia nvidia bragging demand price rise realistic level coming month bot destroyed yes bot evil nvidia forced pre_order delivered oct nov soon december probably year maybe nvidia actually pay lot money jump head manufacturing line pissed lot people nvidia know placate consumer x200b marketer heavily psychology 1920 far longer alive honed art 100 year passed knowledge method work new method today merely time tested true method rebranded buy thing know consumer button one push madison avenue screw count bot nvidia count exposed bot bot owner ebay market massive miscalculation nvidia given incident economy people desperate money way 3080 opportunity scammer target bot nvidia retailer caught pant pulled bot scammer nvidia payed played crumb wait awhile crumb fork cash pre pay pre_order october 31st coming soon sale number ceo board member upper management need bonus rich investor want dividend new normal good luck lucky managed card fantastic\n"
     ]
    }
   ],
   "source": [
    "display_representative_document(1, sent_topics_sorteddf_mallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T01:39:13.797937Z",
     "start_time": "2021-01-24T01:39:13.790930Z"
    }
   },
   "source": [
    "The document does not make sense as it's talking about HTML syntaxes which the model poorly interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most representative document for Topic 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:49.999501Z",
     "start_time": "2021-01-26T00:19:49.984488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Topic 2********\n",
      "\n",
      "Dominant keywords: game, vram, gpu, 4k, year, 1440p, gaming, good, high, pc \n",
      "\n",
      "Document:plenty depends singeplayer multiplayer battle royale dog obviously apex legend br duty sp mp br battlefield sp mp br counterstrike mp pubg br doom sp mp rainbow 6 siege mp wolfenstein sp mp fortnite br outlier borderland looter shooter warframe space ninja looter shooter ton grind left dead want shoot zombie deep rock galactic coop experience hardcore simulation shooter arma squad insurgency\n"
     ]
    }
   ],
   "source": [
    "display_representative_document(2, sent_topics_sorteddf_mallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document discusses about [ray tracing](https://www.techradar.com/news/ray-tracing) which gives more lifelike shadows and reflections, along with much-improved translucence and scattering in games. This fits the topic in which it has the keyword `ray_tracing`, `performance`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most representative document for Topic 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:22:51.800212Z",
     "start_time": "2021-01-26T00:22:51.768183Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\mlbook2\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 3 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-84ec89d13b81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay_representative_document\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent_topics_sorteddf_mallet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-939d13c96a00>\u001b[0m in \u001b[0;36mdisplay_representative_document\u001b[1;34m(topic_n, df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create a helper function to display the most representative documents for a topic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_representative_document\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdominant_keywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Keywords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtopic_n\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdocument_topic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Representative Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtopic_n\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlbook2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlbook2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlbook2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlbook2\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3736\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3737\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3738\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3740\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlbook2\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    351\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "display_representative_document(3, sent_topics_sorteddf_mallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document talks about the pre ordering AMD's 6800xt which fits the topic on purchasing a GPU during the GPU's launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most representative document for Topic 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.032531Z",
     "start_time": "2021-01-26T00:07:31.302Z"
    }
   },
   "outputs": [],
   "source": [
    "display_representative_document(4, sent_topics_sorteddf_mallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document compares Nvidia's GPUs, the 3070, 3080 and the 3090 against AMD's GPUs, the 6800, 6800xt and the 6900xt which adequately matches the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most representative document for Topic 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.033533Z",
     "start_time": "2021-01-26T00:07:31.304Z"
    }
   },
   "outputs": [],
   "source": [
    "display_representative_document(5, sent_topics_sorteddf_mallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unable to intrepret the document well as it discusses about the turing complete machine, whereas the topic discusses about the PC and gaming consoles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic distribution across documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.034533Z",
     "start_time": "2021-01-26T00:07:31.306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts().sort_index()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num = pd.Series(sorted(df_topic_sents_keywords['Dominant_Topic'].unique()))\n",
    "topic_keywords = sent_topics_sorteddf_mallet['Keywords']\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num, topic_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.034533Z",
     "start_time": "2021-01-26T00:07:31.307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sort the Percentage of documents in descending order\n",
    "df_dominant_topics.sort_values(by='Perc_Documents', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.035534Z",
     "start_time": "2021-01-26T00:07:31.309Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "\n",
    "plt.figure(figsize=(11,7))\n",
    "sns.barplot(x='Dominant_Topic', y='Num_Documents',data=df_dominant_topics, palette=cols)\n",
    "\n",
    "plt.title('Distribution of documents by their topics')\n",
    "plt.xticks(np.arange(6),[x for x in range(6)])\n",
    "plt.xlabel('Dominant Topics')\n",
    "plt.ylabel('Number of documents');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 3 has the been assigned the most often to the documents with close to 3000 documents being assigned while making up 20% of the topics assigned.\n",
    "Stock availability during the launch of the GPUs is the most discussed for the AMD's subreddit with Topic 4 coming in second, which goes into comparing the price and performance of the AMD and Nvidia's GPUs. \n",
    "\n",
    "The least discussed is Topic 5 which discusses about the [RDNA 2 GPUs](https://www.pcworld.com/article/3528861/what-the-new-xbox-series-x-specs-tell-us-about-nvidias-next-gen-radeon-graphics-cards.html) powering the new gaming consoles, Xbox X series and the PS5. It seems that most of the subreddit users are PC gamers given the least number of Topic 5 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Distribution of Word Counts in Documents by dominant topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.035534Z",
     "start_time": "2021-01-26T00:07:31.311Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "\n",
    "fig, axes = plt.subplots(3,2, figsize=(14,11), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):    \n",
    "    df_dominant_topic_sub = df_dominant_topic.loc[df_dominant_topic.Dominant_Topic == i]\n",
    "    doc_lens = df_dominant_topic_sub.Document.map(lambda token: len(token)).tolist()\n",
    "    #ax.hist(doc_lens, bins = 100, color=cols[i])\n",
    "    ax.tick_params(axis='y', labelcolor=cols[i], color=cols[i])\n",
    "    sns.histplot(doc_lens, bins=50, color=cols[i], kde=True, ax=ax) # ax.twinx()\n",
    "    # Mean\n",
    "    ax.axvline(np.mean(doc_lens), color='red', label='mean')\n",
    "    # Median\n",
    "    ax.axvline(np.median(doc_lens), color='yellow', label='median')\n",
    "    ax.legend()\n",
    "    ax.set(xlim=(0, 1000), xlabel='Document Word Count')\n",
    "    ax.set_ylabel('Number of Documents', color=cols[i])\n",
    "    ax.set_title('Topic: '+str(i), fontdict=dict(size=16, color=cols[i]))\n",
    "\n",
    "# fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.90)\n",
    "# plt.xticks(np.linspace(0,375,9))\n",
    "plt.xlim(0,100)\n",
    "fig.suptitle('Distribution of Document Word Counts by Dominant Topic', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the distributions shows a right tailed skewed graph in which the mean and median are quite close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clouds of Top N Keywords in Each Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.036535Z",
     "start_time": "2021-01-26T00:07:31.313Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(STOPWORDS).union(stopwords.words(\"english\")) # Combines gensim stopwords and nltk's stopwords\n",
    "stop_words = stop_words.union(['http', 'www', 'youtube' 'get', 'like', '1', '2', '3', '5', 'got'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.037536Z",
     "start_time": "2021-01-26T00:07:31.314Z"
    }
   },
   "outputs": [],
   "source": [
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = optimal_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Counts of Topic Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.037536Z",
     "start_time": "2021-01-26T00:07:31.318Z"
    }
   },
   "outputs": [],
   "source": [
    "data_flat = [word for word_lst in data_trigrams for word in word_lst] # Creates a list of words \n",
    "counter = Counter(data_flat) # Counts the frequency of the tokens and stores in a dictionary\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.038537Z",
     "start_time": "2021-01-26T00:07:31.319Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = [[word, i , weight, counter[word]] for i, topic in topics for word, weight in topic]\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.039537Z",
     "start_time": "2021-01-26T00:07:31.320Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16,14), sharey=True)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Weights')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Word Count')\n",
    "    ax.set_ylabel('Weights', color=cols[i])\n",
    "    ax_twin.set_ylabel('Word Count', color=cols[i])\n",
    "    # Sets the ylimits for the axes\n",
    "    #ax_twin.set_ylim(0, 0.030)\n",
    "    #ax.set_ylim(0, 3500)\n",
    "    ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticks(np.arange(10))\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'].tolist(), rotation=30, horizontalalignment= 'right', fontsize=12)\n",
    "    ax_twin.legend(loc=[0.80,0.82])\n",
    "    ax.legend(loc=[0.80,0.90])\n",
    "    \n",
    "\n",
    "fig.tight_layout(w_pad=2)    \n",
    "fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrepreting the topic word frequency and their weights\n",
    "\n",
    "Topic 0:\n",
    "* Equally distributed weights\n",
    "* The frequency of the words have little correlation with the weights\n",
    "\n",
    "Topic 1:\n",
    "* Equally distributed weights\n",
    "* nvidia has the highest word frequency\n",
    "* gpu is more favoured to gpus\n",
    "\n",
    "Topic 2:\n",
    "* Performance has the highest frequency, but the weights are not that high\n",
    "* Gaming features: dlss has a higher weight and frequency compared to ray_tracing, which possibly means a more favoured feature among gamers.\n",
    "* Resolution: Surprisingly, 4k resolution has a higher frequency and weight compared to 1440p resolution, which is not so main stream yet. 1440p resolution is reaching mainstream crowd.\n",
    "\n",
    "Topic 3:\n",
    "* Relating to GPU purchase during the launch\n",
    "* card seems to appear often, possibly could include in the stopwords\n",
    "* lol, yeah seems to make little sense here, could add to stopwords\n",
    "\n",
    "Topic 4:\n",
    "* The GPU models have a relatively higher word count compared to their frequency\n",
    "* Nvidia's RTX 3070 and 3080 seems to be favoured over the other GPU models\n",
    "\n",
    "Topic 5:\n",
    "* Compared to the other topics, the weights are equal to or higher than their word count.\n",
    "* good and great share a similar meaning, could potentially add one of the to stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most discussed topics in the documents (Possibly remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It'll take **more than an hour** to run if all the documents are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.039537Z",
     "start_time": "2021-01-26T00:07:31.323Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sentence Coloring of N Sentences\n",
    "# def topics_per_document(model, corpus, start=0, end=1):\n",
    "#     corpus_sel = corpus[start:end] # Obtain a slice of nth documents\n",
    "#     dominant_topics = []\n",
    "#     topic_percentages = []\n",
    "#     for i, corp in enumerate(corpus_sel): # For each document\n",
    "#         doc = model[corp] # Gets the nth document\n",
    "#         dominant_topic, topic_percs = sorted(doc, key = lambda x: x[1], reverse=True)[0] # Gets the dominant topic and topic percentage by sorting the topic percentage prob in descending order\n",
    "#         dominant_topics.append((i, dominant_topic))\n",
    "#         topic_percentages.append(topic_percs)\n",
    "#     return(dominant_topics, topic_percentages)\n",
    "\n",
    "# dominant_topics, topic_percentages = topics_per_document(model=optimal_model, corpus=trigram_corpus, end=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.040538Z",
     "start_time": "2021-01-26T00:07:31.324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of Dominant Topics in Each Document\n",
    "# df = pd.DataFrame(dominant_topics, columns=['Document_Id', 'Dominant_Topic'])\n",
    "# dominant_topic_in_each_doc = df.groupby('Dominant_Topic').size()\n",
    "# df_dominant_topic_in_each_doc = dominant_topic_in_each_doc.to_frame(name='count').reset_index()\n",
    "\n",
    "# Total Topic Distribution by actual weight\n",
    "# topic_weightage_by_doc = pd.DataFrame([{t} for t in topic_percentages])\n",
    "# df_topic_weightage_by_doc = topic_weightage_by_doc.sum().to_frame(name='count').reset_index()\n",
    "\n",
    "# Top 3 Keywords for each Topic\n",
    "# topic_top3words = [(i, topic) for i, topics in optimal_model.show_topics(formatted=False) \n",
    "#                                  for j, (topic, wt) in enumerate(topics) if j < 3]\n",
    "\n",
    "# df_top3words_stacked = pd.DataFrame(topic_top3words, columns=['topic_id', 'words'])\n",
    "# df_top3words = df_top3words_stacked.groupby('topic_id').agg(', '.join)\n",
    "# df_top3words.reset_index(level=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.040538Z",
     "start_time": "2021-01-26T00:07:31.326Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_top3words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.041540Z",
     "start_time": "2021-01-26T00:07:31.327Z"
    }
   },
   "outputs": [],
   "source": [
    "# from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# # Plot\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), dpi=120, sharey=True)\n",
    "\n",
    "# # Topic Distribution by Dominant Topics\n",
    "# ax1.bar(x='Dominant_Topic', height='count', data=df_dominant_topic_in_each_doc, width=.5, color='firebrick')\n",
    "# ax1.set_xticks(range(df_dominant_topic_in_each_doc.Dominant_Topic.unique().__len__()))\n",
    "# tick_formatter = FuncFormatter(lambda x, pos: 'Topic ' + str(x)+ '\\n' + df_top3words.loc[df_top3words.topic_id==x, 'words'].values[0])\n",
    "# ax1.xaxis.set_major_formatter(tick_formatter)\n",
    "# ax1.set_title('Number of Documents by Dominant Topic', fontdict=dict(size=10))\n",
    "# ax1.set_ylabel('Number of Documents')\n",
    "# ax1.set_ylim(0, 1000)\n",
    "\n",
    "# # Topic Distribution by Topic Weights\n",
    "# ax2.bar(x='index', height='count', data=df_topic_weightage_by_doc, width=.5, color='steelblue')\n",
    "# ax2.set_xticks(range(df_topic_weightage_by_doc.index.unique().__len__()))\n",
    "# ax2.xaxis.set_major_formatter(tick_formatter)\n",
    "# ax2.set_title('Number of Documents by Topic Weightage', fontdict=dict(size=10))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE Clustering Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:19:50.042541Z",
     "start_time": "2021-01-26T00:07:31.329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get topic weights\n",
    "topic_weights = []\n",
    "\n",
    "for row_lst in optimal_model[trigram_corpus]:\n",
    "    lst = []\n",
    "    for topic_id, topic_perc in row_lst:\n",
    "        lst.append(topic_perc)\n",
    "    topic_weights.append(lst)\n",
    "    \n",
    "\n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, perplexity=30, verbose=1, random_state=42, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "n_topics = 6\n",
    "mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), \n",
    "              plot_width=900, plot_height=700)\n",
    "lgd_label = np.array(['Topic 0', 'Topic 1', 'Topic 2', 'Topic 3', 'Topic 4', 'Topic 5'])\n",
    "\n",
    "source = ColumnDataSource(dict(\n",
    "    x=tsne_lda[:,0],\n",
    "    y=tsne_lda[:,1],\n",
    "    color=mycolors[topic_num],\n",
    "    label=lgd_label[topic_num],\n",
    "))\n",
    "\n",
    "plot.scatter(x='x', y='y', color='color', source=source)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-Distributed Stochastic Neighbor Embedding (t-SNE) is an unsupervised non-linear learning technique used for data exploration and visualizing higher dimensional data. It gives a sense of how the data is arranged in a high dimensional-space. As t-SNE preserves small pairwise compared to Principal Component Analysis (PCA), we can see that the Topic 0, 2, 4 and 5 are close together which shows their relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyLDAVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T00:25:16.011654Z",
     "start_time": "2021-01-26T00:25:13.398117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1290027835742341605772061659\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1290027835742341605772061659_data = {\"mdsDat\": {\"x\": [-0.09994819686019732, -0.2757858552289673, 0.37573405208916477], \"y\": [-0.3650197875048462, 0.2665051850004943, 0.09851460250435179], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [33.62215125817759, 33.37400330674761, 33.00384543507481]}, \"tinfo\": {\"Term\": [\"3080\", \"3090\", \"game\", \"card\", \"price\", \"nvidia\", \"people\", \"vram\", \"time\", \"ti\", \"buy\", \"amd\", \"3070\", \"rtx\", \"4k\", \"2080\", \"upgrade\", \"2080ti\", \"gpu\", \"1440p\", \"gaming\", \"titan\", \"memory\", \"high\", \"series\", \"release\", \"cpu\", \"super\", \"pc\", \"money\", \"margin\", \"nvme\", \"27\", \"absolutely\", \"unlike\", \"picture\", \"skip\", \"specifically\", \"large\", \"op\", \"excuse\", \"stable\", \"mod\", \"g_sync\", \"hardware_unboxed\", \"lg\", \"admit\", \"doom\", \"maxing\", \"nah\", \"broken\", \"showed\", \"navi\", \"dude\", \"maximum\", \"editing\", \"vr\", \"55\", \"open\", \"valve_index\", \"game\", \"vram\", \"4k\", \"1440p\", \"gaming\", \"high\", \"pc\", \"lot\", \"work\", \"monitor\", \"gen\", \"play\", \"run\", \"fps\", \"issue\", \"setting\", \"console\", \"4\", \"1080p\", \"gb\", \"fine\", \"difference\", \"dl\", \"resolution\", \"running\", \"graphic\", \"100\", \"video\", \"driver\", \"gpu\", \"good\", \"year\", \"odd\", \"preorders\", \"wanna\", \"850w\", \"page\", \"tend\", \"google\", \"corner\", \"loop\", \"cost\", \"mid_tier\", \"supply\", \"noticed\", \"originally\", \"group\", \"delivery\", \"customer\", \"watch\", \"em\", \"blame\", \"supply_demand\", \"plug\", \"build\", \"sooner\", \"pushed\", \"regret\", \"haha\", \"manufacturer\", \"iphone\", \"day\", \"card\", \"nvidia\", \"people\", \"price\", \"time\", \"buy\", \"series\", \"release\", \"fe\", \"month\", \"sell\", \"stock\", \"power\", \"gonna\", \"worth\", \"long\", \"feel\", \"waiting\", \"buying\", \"scalper\", \"market\", \"pay\", \"product\", \"psu\", \"generation\", \"bought\", \"30\", \"aib\", \"launch\", \"money\", \"end\", \"year\", \"point\", \"3080\", \"didnt\", \"rear\", \"closed\", \"myth\", \"digit\", \"16gb\", \"saturate\", \"strong\", \"angle\", \"realm\", \"mini\", \"cover\", \"hop\", \"120mm\", \"road\", \"rate\", \"safely\", \"liquid\", \"phase\", \"sata\", \"pcie_4\", \"calculation\", \"slim\", \"conscious\", \"dy\", \"dirt\", \"soooo\", \"6900_xt\", \"wouldnt\", \"3090\", \"ti\", \"amd\", \"3070\", \"rtx\", \"2080\", \"upgrade\", \"2080ti\", \"titan\", \"memory\", \"cpu\", \"super\", \"case\", \"1080ti\", \"10gb\", \"pretty\", \"1080\", \"benchmark\", \"3080ti\", \"faster\", \"20\", \"bit\", \"big\", \"review\", \"fan\", \"increase\", \"8gb\", \"guess\", \"reason\", \"wait\", \"10\"], \"Freq\": [2545.0, 1889.0, 1437.0, 1371.0, 1374.0, 1309.0, 1279.0, 1252.0, 993.0, 975.0, 908.0, 814.0, 793.0, 745.0, 701.0, 631.0, 602.0, 583.0, 871.0, 559.0, 553.0, 496.0, 483.0, 479.0, 463.0, 451.0, 445.0, 440.0, 434.0, 487.0, 43.98959152524436, 43.98959152524436, 21.99479576262218, 100.71301217621735, 21.99479576262218, 39.359108206797586, 21.99479576262218, 39.359108206797586, 49.77769567330283, 19.679554103398793, 19.679554103398793, 49.77769567330283, 47.46245401407944, 24.310037421845568, 19.679554103398793, 19.679554103398793, 19.679554103398793, 19.679554103398793, 24.310037421845568, 40.51672903640928, 24.310037421845568, 40.51672903640928, 48.620074843691135, 84.50632056165364, 19.679554103398793, 21.99479576262218, 285.93234491408833, 19.679554103398793, 61.35390396941976, 21.99479576262218, 1437.7650703777235, 1252.5457376398526, 701.5182227446865, 559.1308607024481, 553.3427565543897, 479.2550234592412, 434.1078111043851, 413.27063617137463, 410.95539451215126, 407.4825320233162, 380.8572529422472, 375.0691487941888, 369.2810446461303, 369.2810446461303, 362.33531966846016, 327.6066947801093, 305.61189901748713, 298.666174039817, 298.666174039817, 282.45948242525327, 280.14424076602984, 274.3561366179714, 250.04609919612582, 246.5732367072908, 243.1003742184557, 236.15464924078552, 230.36654509272705, 222.2631992854452, 215.31747430777503, 761.7145058844944, 547.5546524063311, 568.3918273393416, 21.62063544579653, 21.62063544579653, 43.24127089159306, 21.62063544579653, 67.13776270010501, 21.62063544579653, 21.62063544579653, 21.62063544579653, 21.62063544579653, 360.72323349039476, 21.62063544579653, 86.48254178318612, 21.62063544579653, 21.62063544579653, 21.62063544579653, 21.62063544579653, 67.13776270010501, 73.96533178825129, 21.62063544579653, 43.24127089159306, 21.62063544579653, 21.62063544579653, 160.4478735714374, 21.62063544579653, 21.62063544579653, 21.62063544579653, 73.96533178825129, 43.24127089159306, 21.62063544579653, 421.0334271023535, 1371.2034585360432, 1309.7553367427267, 1279.0312758460686, 1373.4793148987585, 993.4113023252828, 908.0666887234544, 463.13676981258885, 451.7574879990118, 418.757570739638, 402.82657620063014, 364.13701803446787, 362.9990898531102, 322.03367532423255, 298.1371835157206, 290.1716862462166, 273.10276352585095, 270.8269071631355, 266.2751944377046, 265.13726625634695, 253.7579844427698, 252.62005626141212, 252.62005626141212, 252.62005626141212, 237.82698990376184, 325.4474598683057, 223.0339235461116, 223.0339235461116, 221.8959953647539, 385.7576534802644, 473.37812344480824, 273.10276352585095, 366.4128743971833, 252.62005626141212, 2545.465782572243, 20.55557832494409, 5.709882868040024, 6.8518594416480285, 3.4259297208240143, 10.277789162472045, 125.61742309688054, 10.277789162472045, 27.407437766592114, 10.277789162472045, 6.8518594416480285, 10.277789162472045, 25.123484619376107, 3.4259297208240143, 7.993836015256035, 17.129648604120074, 34.25929720824015, 3.4259297208240143, 12.561742309688054, 3.4259297208240143, 13.703718883296057, 6.8518594416480285, 13.703718883296057, 3.4259297208240143, 3.4259297208240143, 13.703718883296057, 10.277789162472045, 3.4259297208240143, 7.993836015256035, 25.123484619376107, 1889.971229321248, 975.2479938612363, 814.2292969825075, 793.6737186575634, 745.7107025660272, 631.5130452052267, 602.9636308650266, 583.5500291136905, 496.75980951948213, 483.0560906361861, 445.37086370712194, 440.8029574126899, 405.4016836308418, 399.69180076280173, 362.00657383373755, 359.72262068652157, 359.72262068652157, 326.6053000518894, 306.04972172694534, 301.4818154325133, 293.4879794172573, 284.3521668283932, 269.50647137148917, 260.3706587826251, 248.95089304654508, 247.80891647293709, 245.52496332572107, 230.679267868817, 229.53729129520897, 582.4080525400825, 262.65461192984117], \"Total\": [2545.0, 1889.0, 1437.0, 1371.0, 1374.0, 1309.0, 1279.0, 1252.0, 993.0, 975.0, 908.0, 814.0, 793.0, 745.0, 701.0, 631.0, 602.0, 583.0, 871.0, 559.0, 553.0, 496.0, 483.0, 479.0, 463.0, 451.0, 445.0, 440.0, 434.0, 487.0, 43.98959152524436, 43.98959152524436, 21.99479576262218, 100.71301217621735, 21.99479576262218, 39.359108206797586, 21.99479576262218, 39.359108206797586, 49.77769567330283, 19.679554103398793, 19.679554103398793, 49.77769567330283, 47.46245401407944, 24.310037421845568, 19.679554103398793, 19.679554103398793, 19.679554103398793, 19.679554103398793, 24.310037421845568, 40.51672903640928, 24.310037421845568, 40.51672903640928, 48.620074843691135, 84.50632056165364, 19.679554103398793, 21.99479576262218, 285.93234491408833, 19.679554103398793, 61.35390396941976, 21.99479576262218, 1437.7650703777235, 1252.5457376398526, 701.5182227446865, 559.1308607024481, 553.3427565543897, 479.2550234592412, 434.1078111043851, 413.27063617137463, 410.95539451215126, 407.4825320233162, 380.8572529422472, 375.0691487941888, 369.2810446461303, 369.2810446461303, 362.33531966846016, 327.6066947801093, 305.61189901748713, 298.666174039817, 298.666174039817, 282.45948242525327, 280.14424076602984, 274.3561366179714, 250.04609919612582, 246.5732367072908, 243.1003742184557, 236.15464924078552, 230.36654509272705, 222.2631992854452, 215.31747430777503, 871.3442569508629, 744.4162277812153, 979.3417881072371, 21.62063544579653, 21.62063544579653, 43.24127089159306, 21.62063544579653, 67.13776270010501, 21.62063544579653, 21.62063544579653, 21.62063544579653, 21.62063544579653, 360.72323349039476, 21.62063544579653, 86.48254178318612, 21.62063544579653, 21.62063544579653, 21.62063544579653, 21.62063544579653, 67.13776270010501, 73.96533178825129, 21.62063544579653, 43.24127089159306, 21.62063544579653, 21.62063544579653, 160.4478735714374, 21.62063544579653, 21.62063544579653, 21.62063544579653, 73.96533178825129, 43.24127089159306, 21.62063544579653, 421.0334271023535, 1371.2034585360432, 1309.7553367427267, 1279.0312758460686, 1374.6212914723665, 993.4113023252828, 908.0666887234544, 463.13676981258885, 451.7574879990118, 418.757570739638, 402.82657620063014, 364.13701803446787, 362.9990898531102, 322.03367532423255, 298.1371835157206, 290.1716862462166, 273.10276352585095, 270.8269071631355, 266.2751944377046, 265.13726625634695, 253.7579844427698, 252.62005626141212, 252.62005626141212, 252.62005626141212, 237.82698990376184, 326.6050806979174, 223.0339235461116, 223.0339235461116, 221.8959953647539, 388.0416066274804, 487.26957340014854, 383.0767423389618, 979.3417881072371, 427.4208015327779, 2545.465782572243, 20.55557832494409, 5.709882868040024, 6.8518594416480285, 3.4259297208240143, 10.277789162472045, 125.61742309688054, 10.277789162472045, 27.407437766592114, 10.277789162472045, 6.8518594416480285, 10.277789162472045, 25.123484619376107, 3.4259297208240143, 7.993836015256035, 17.129648604120074, 34.25929720824015, 3.4259297208240143, 12.561742309688054, 3.4259297208240143, 13.703718883296057, 6.8518594416480285, 13.703718883296057, 3.4259297208240143, 3.4259297208240143, 13.703718883296057, 10.277789162472045, 3.4259297208240143, 7.993836015256035, 25.123484619376107, 1889.971229321248, 975.2479938612363, 814.2292969825075, 793.6737186575634, 745.7107025660272, 631.5130452052267, 602.9636308650266, 583.5500291136905, 496.75980951948213, 483.0560906361861, 445.37086370712194, 440.8029574126899, 405.4016836308418, 399.69180076280173, 362.00657383373755, 359.72262068652157, 359.72262068652157, 326.6053000518894, 306.04972172694534, 301.4818154325133, 293.4879794172573, 284.3521668283932, 269.50647137148917, 260.3706587826251, 248.95089304654508, 247.80891647293709, 245.52496332572107, 230.679267868817, 229.53729129520897, 720.0973624843657, 405.0419739720795], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.0928, -7.0928, -7.786, -6.2645, -7.786, -7.2041, -7.786, -7.2041, -6.9692, -7.8972, -7.8972, -6.9692, -7.0169, -7.6859, -7.8972, -7.8972, -7.8972, -7.8972, -7.6859, -7.1751, -7.6859, -7.1751, -6.9928, -6.44, -7.8972, -7.786, -5.221, -7.8972, -6.7601, -7.786, -3.6059, -3.7439, -4.3235, -4.5504, -4.5608, -4.7046, -4.8035, -4.8527, -4.8583, -4.8668, -4.9344, -4.9497, -4.9652, -4.9652, -4.9842, -5.085, -5.1545, -5.1775, -5.1775, -5.2333, -5.2415, -5.2624, -5.3551, -5.3691, -5.3833, -5.4123, -5.4371, -5.4729, -5.5047, -4.2412, -4.5713, -4.534, -7.7957, -7.7957, -7.1026, -7.7957, -6.6626, -7.7957, -7.7957, -7.7957, -7.7957, -4.9813, -7.7957, -6.4094, -7.7957, -7.7957, -7.7957, -7.7957, -6.6626, -6.5658, -7.7957, -7.1026, -7.7957, -7.7957, -5.7914, -7.7957, -7.7957, -7.7957, -6.5658, -7.1026, -7.7957, -4.8267, -3.6459, -3.6918, -3.7155, -3.6443, -3.9682, -4.0581, -4.7314, -4.7562, -4.8321, -4.8709, -4.9719, -4.975, -5.0947, -5.1718, -5.1989, -5.2595, -5.2679, -5.2849, -5.2891, -5.333, -5.3375, -5.3375, -5.3375, -5.3978, -5.0842, -5.4621, -5.4621, -5.4672, -4.9142, -4.7095, -5.2595, -4.9656, -5.3375, -3.0162, -7.8351, -9.116, -8.9337, -9.6269, -8.5282, -6.025, -8.5282, -7.5474, -8.5282, -8.9337, -8.5282, -7.6344, -9.6269, -8.7796, -8.0174, -7.3243, -9.6269, -8.3276, -9.6269, -8.2406, -8.9337, -8.2406, -9.6269, -9.6269, -8.2406, -8.5282, -9.6269, -8.7796, -7.6344, -3.3139, -3.9755, -4.156, -4.1816, -4.2439, -4.4101, -4.4564, -4.4891, -4.6501, -4.6781, -4.7593, -4.7696, -4.8533, -4.8675, -4.9666, -4.9729, -4.9729, -5.0695, -5.1345, -5.1495, -5.1764, -5.208, -5.2616, -5.2961, -5.341, -5.3456, -5.3548, -5.4172, -5.4222, -4.4911, -5.2874], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 1.09, 0.9555, 0.7828, 0.5459, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0966, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0974, 1.0938, 1.0974, 1.0974, 1.0974, 1.0915, 1.0685, 0.759, 0.1143, 0.5715, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 1.1085, 0.8963, 0.6754]}, \"token.table\": {\"Topic\": [1, 3, 1, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3, 1, 1, 1, 3, 2, 3, 1, 1, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 2, 2, 3, 2, 3, 3, 3, 1, 2, 2, 3, 3, 2, 2, 2, 3, 1, 3, 3, 1, 1, 1, 1, 3, 1, 2, 1, 2, 1, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 3, 1, 2, 3, 2, 1, 1, 3, 3, 2, 1, 1, 2, 3, 1, 3, 2, 2, 1, 2, 1, 2, 1, 1, 3, 2, 3, 1, 1, 2, 1, 2, 3, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 3, 2, 3, 1, 1, 2, 1, 2, 2, 2, 3, 2, 3, 2, 2, 2, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1, 1, 3, 3, 3, 2, 2, 2, 1, 1, 1, 3, 2, 3, 1, 1, 2, 3, 3, 2, 2, 2, 3, 2, 3, 1, 3, 1, 1, 1, 1, 2, 3, 2, 2, 2, 1, 2, 3, 1, 2, 3], \"Freq\": [0.35058094993826094, 0.6493154213645256, 0.9984088614404513, 1.0007710922180793, 1.0011177226924215, 1.0007710922180793, 0.999981840568065, 1.0007710922180793, 0.9997659569312921, 1.0030455719731204, 0.9983373103790274, 1.0007710922180793, 1.0007710922180793, 1.0002366122165438, 0.999847899612883, 1.0004111026165619, 0.9998170147972791, 0.9998375370947414, 1.0000152228130808, 1.0011177226924215, 1.0006867637071901, 1.0162831888831192, 1.0007710922180793, 1.017546410934801, 1.0019347795346119, 1.0028495605243195, 1.0162831888831192, 1.000468708933098, 0.9997183877031233, 0.9729718952120214, 1.0012084921709719, 1.0018312310869544, 0.9987615117116173, 0.9944203561408282, 0.999847899612883, 0.9872465263436015, 0.9972086038819454, 0.9999265596632025, 0.9994822822974487, 1.0216204899726227, 0.9998516204617363, 0.9990091712810755, 1.0216204899726227, 0.8756747056908195, 1.0012699145018913, 1.017546410934801, 1.0007672544596786, 0.9950848928304765, 0.9991672923908066, 0.9979480594144851, 0.9999206070107459, 1.017546410934801, 1.0216204899726224, 0.9987019185269134, 0.9729718952120214, 0.9729718952120214, 0.9998156372114021, 1.0162831888831192, 0.9985255525182261, 1.005841923243909, 1.0216204899726227, 1.0002366122165438, 1.017546410934801, 0.28714872985598155, 0.7126509386425725, 1.0162831888831192, 1.000197255582633, 0.9984018424732447, 1.0005789250805275, 1.0006391271778627, 0.9994851196453819, 0.9992389410444839, 0.9872465263436015, 1.0001633991721712, 0.9993805709926991, 0.9983732802265725, 1.0003748046194474, 0.0030618017266085245, 0.9950855611477705, 0.9995398644539977, 0.7361473051619957, 0.26463689619874664, 1.017546410934801, 0.8745108422089146, 0.12624172262858346, 0.9993451357350672, 1.017546410934801, 1.0013903812602933, 1.000468708933098, 1.0162831888831192, 0.9994678752506329, 0.8756747056908195, 1.0007710922180793, 1.017546410934801, 0.9990745598061845, 1.0044659425007574, 0.9947386914376933, 0.005154086484133126, 1.0162831888831192, 1.0348882885436956, 0.999623718469472, 1.017546410934801, 0.9993451357350673, 0.9944203561408282, 1.0002366122165438, 1.0015040125642072, 1.0162831888831192, 0.9872465263436015, 0.9998838838029922, 1.017546410934801, 0.9729718952120214, 0.9902564242897711, 0.028731529248396392, 0.9707152381779638, 0.9988158215741906, 1.000430517273725, 0.8756747056908195, 1.0119276895021916, 1.0078141623090933, 1.017546410934801, 1.0001868007332435, 1.0002366122165438, 1.017546410934801, 1.0162831888831192, 0.9942317611998064, 1.017546410934801, 0.9979480594144851, 1.0015040125642072, 0.9997516490106205, 1.0216204899726227, 0.9999755472390244, 0.8756747056908195, 0.9908761091610413, 0.999815637211402, 1.017546410934801, 0.4094325764502589, 0.5919225248109456, 0.9998954291839242, 1.017546410934801, 1.0007710922180793, 0.9988205540810227, 0.0007274730911005263, 1.0015040125642072, 1.0007274619937299, 1.017546410934801, 0.9924313331162619, 1.0216204899726227, 1.0508096468289834, 1.0020158323825297, 1.017546410934801, 1.0005368189956572, 1.001730777023525, 0.9985764187702325, 0.9924313331162619, 1.0003879486146268, 0.9992389410444839, 0.9995871079228965, 0.8756747056908195, 1.0216204899726227, 0.9729718952120214, 1.0009537258808294, 0.9996237184694721, 0.9997046880716377, 1.001200540850225, 1.0119276895021916, 1.0002366122165438, 0.8756747056908195, 1.017546410934801, 0.8756747056908195, 0.9908761091610413, 1.0044659425007574, 1.000002507297994, 0.9851340439021719, 1.0004470083151589, 0.9944203561408282, 1.017546410934801, 1.017546410934801, 0.9997457120006426, 0.9995859697546021, 1.0004835143180166, 1.0002366122165438, 1.000060317294629, 1.0002366122165438, 0.9988158215741906, 1.0002366122165438, 1.0003626712753846, 0.19164075191706617, 0.8082240406937139, 0.9989665036644297, 0.9944203561408282, 1.000468708933098, 1.0001085409473738, 0.9994083287434498, 0.9950848928304765, 0.5799813782048117, 0.3737203951108469, 0.04594922890707134], \"Term\": [\"10\", \"10\", \"100\", \"1080\", \"1080p\", \"1080ti\", \"10gb\", \"120mm\", \"1440p\", \"16gb\", \"20\", \"2080\", \"2080ti\", \"27\", \"30\", \"3070\", \"3080\", \"3080ti\", \"3090\", \"4\", \"4k\", \"55\", \"6900_xt\", \"850w\", \"8gb\", \"absolutely\", \"admit\", \"aib\", \"amd\", \"angle\", \"benchmark\", \"big\", \"bit\", \"blame\", \"bought\", \"broken\", \"build\", \"buy\", \"buying\", \"calculation\", \"card\", \"case\", \"closed\", \"conscious\", \"console\", \"corner\", \"cost\", \"cover\", \"cpu\", \"customer\", \"day\", \"delivery\", \"didnt\", \"difference\", \"digit\", \"dirt\", \"dl\", \"doom\", \"driver\", \"dude\", \"dy\", \"editing\", \"em\", \"end\", \"end\", \"excuse\", \"fan\", \"faster\", \"fe\", \"feel\", \"fine\", \"fps\", \"g_sync\", \"game\", \"gaming\", \"gb\", \"gen\", \"generation\", \"generation\", \"gonna\", \"good\", \"good\", \"google\", \"gpu\", \"gpu\", \"graphic\", \"group\", \"guess\", \"haha\", \"hardware_unboxed\", \"high\", \"hop\", \"increase\", \"iphone\", \"issue\", \"large\", \"launch\", \"launch\", \"lg\", \"liquid\", \"long\", \"loop\", \"lot\", \"manufacturer\", \"margin\", \"market\", \"maximum\", \"maxing\", \"memory\", \"mid_tier\", \"mini\", \"mod\", \"money\", \"money\", \"monitor\", \"month\", \"myth\", \"nah\", \"navi\", \"noticed\", \"nvidia\", \"nvme\", \"odd\", \"op\", \"open\", \"originally\", \"page\", \"pay\", \"pc\", \"pcie_4\", \"people\", \"phase\", \"picture\", \"play\", \"plug\", \"point\", \"point\", \"power\", \"preorders\", \"pretty\", \"price\", \"price\", \"product\", \"psu\", \"pushed\", \"rate\", \"realm\", \"rear\", \"reason\", \"regret\", \"release\", \"resolution\", \"review\", \"road\", \"rtx\", \"run\", \"running\", \"safely\", \"sata\", \"saturate\", \"scalper\", \"sell\", \"series\", \"setting\", \"showed\", \"skip\", \"slim\", \"sooner\", \"soooo\", \"specifically\", \"stable\", \"stock\", \"strong\", \"super\", \"supply\", \"supply_demand\", \"tend\", \"ti\", \"time\", \"titan\", \"unlike\", \"upgrade\", \"valve_index\", \"video\", \"vr\", \"vram\", \"wait\", \"wait\", \"waiting\", \"wanna\", \"watch\", \"work\", \"worth\", \"wouldnt\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1290027835742341605772061659\", ldavis_el1290027835742341605772061659_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1290027835742341605772061659\", ldavis_el1290027835742341605772061659_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1290027835742341605772061659\", ldavis_el1290027835742341605772061659_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2     -0.099948 -0.365020       1        1  33.622151\n",
       "1     -0.275786  0.266505       2        1  33.374003\n",
       "0      0.375734  0.098515       3        1  33.003845, topic_info=       Term         Freq        Total Category  logprob  loglift\n",
       "4      3080  2545.000000  2545.000000  Default  30.0000  30.0000\n",
       "10     3090  1889.000000  1889.000000  Default  29.0000  29.0000\n",
       "295    game  1437.000000  1437.000000  Default  28.0000  28.0000\n",
       "15     card  1371.000000  1371.000000  Default  27.0000  27.0000\n",
       "18    price  1374.000000  1374.000000  Default  26.0000  26.0000\n",
       "..      ...          ...          ...      ...      ...      ...\n",
       "714     8gb   245.524963   245.524963   Topic3  -5.3548   1.1085\n",
       "266   guess   230.679268   230.679268   Topic3  -5.4172   1.1085\n",
       "937  reason   229.537291   229.537291   Topic3  -5.4222   1.1085\n",
       "134    wait   582.408053   720.097362   Topic3  -4.4911   0.8963\n",
       "194      10   262.654612   405.041974   Topic3  -5.2874   0.6754\n",
       "\n",
       "[216 rows x 6 columns], token_table=       Topic      Freq              Term\n",
       "term                                    \n",
       "194        1  0.350581                10\n",
       "194        3  0.649315                10\n",
       "803        1  0.998409               100\n",
       "263        3  1.000771              1080\n",
       "277        1  1.001118             1080p\n",
       "195        3  1.000771            1080ti\n",
       "721        3  0.999982              10gb\n",
       "3113       3  1.000771             120mm\n",
       "575        1  0.999766             1440p\n",
       "3171       3  1.003046              16gb\n",
       "213        3  0.998337                20\n",
       "31         3  1.000771              2080\n",
       "81         3  1.000771            2080ti\n",
       "2657       1  1.000237                27\n",
       "493        2  0.999848                30\n",
       "9          3  1.000411              3070\n",
       "4          3  0.999817              3080\n",
       "196        3  0.999838            3080ti\n",
       "10         3  1.000015              3090\n",
       "812        1  1.001118                 4\n",
       "450        1  1.000687                4k\n",
       "2682       1  1.016283                55\n",
       "10506      3  1.000771           6900_xt\n",
       "598        2  1.017546              850w\n",
       "714        3  1.001935               8gb\n",
       "903        1  1.002850        absolutely\n",
       "3990       1  1.016283             admit\n",
       "13         2  1.000469               aib\n",
       "163        3  0.999718               amd\n",
       "3158       3  0.972972             angle\n",
       "284        3  1.001208         benchmark\n",
       "228        3  1.001831               big\n",
       "108        3  0.998762               bit\n",
       "6788       2  0.994420             blame\n",
       "130        2  0.999848            bought\n",
       "4045       1  0.987247            broken\n",
       "781        2  0.997209             build\n",
       "345        2  0.999927               buy\n",
       "285        2  0.999482            buying\n",
       "3215       3  1.021620       calculation\n",
       "15         2  0.999852              card\n",
       "259        3  0.999009              case\n",
       "3176       3  1.021620            closed\n",
       "3302       3  0.875675         conscious\n",
       "327        1  1.001270           console\n",
       "1152       2  1.017546            corner\n",
       "581        2  1.000767              cost\n",
       "3130       3  0.995085             cover\n",
       "457        3  0.999167               cpu\n",
       "1972       2  0.997948          customer\n",
       "639        2  0.999921               day\n",
       "1968       2  1.017546          delivery\n",
       "3205       3  1.021620             didnt\n",
       "1032       1  0.998702        difference\n",
       "3172       3  0.972972             digit\n",
       "3293       3  0.972972              dirt\n",
       "167        1  0.999816                dl\n",
       "3993       1  1.016283              doom\n",
       "1195       1  0.998526            driver\n",
       "2412       1  1.005842              dude\n",
       "3294       3  1.021620                dy\n",
       "5328       1  1.000237           editing\n",
       "2304       2  1.017546                em\n",
       "525        1  0.287149               end\n",
       "525        2  0.712651               end\n",
       "5225       1  1.016283            excuse\n",
       "232        3  1.000197               fan\n",
       "169        3  0.998402            faster\n",
       "132        2  1.000579                fe\n",
       "191        2  1.000639              feel\n",
       "599        1  0.999485              fine\n",
       "1012       1  0.999239               fps\n",
       "1223       1  0.987247            g_sync\n",
       "295        1  1.000163              game\n",
       "458        1  0.999381            gaming\n",
       "200        1  0.998373                gb\n",
       "273        1  1.000375               gen\n",
       "533        1  0.003062        generation\n",
       "533        2  0.995086        generation\n",
       "348        2  0.999540             gonna\n",
       "224        1  0.736147              good\n",
       "224        2  0.264637              good\n",
       "2547       2  1.017546            google\n",
       "369        1  0.874511               gpu\n",
       "369        3  0.126242               gpu\n",
       "641        1  0.999345           graphic\n",
       "4327       2  1.017546             group\n",
       "266        3  1.001390             guess\n",
       "1296       2  1.000469              haha\n",
       "2539       1  1.016283  hardware_unboxed\n",
       "614        1  0.999468              high\n",
       "3124       3  0.875675               hop\n",
       "216        3  1.000771          increase\n",
       "1228       2  1.017546            iphone\n",
       "1065       1  0.999075             issue\n",
       "989        1  1.004466             large\n",
       "538        2  0.994739            launch\n",
       "538        3  0.005154            launch\n",
       "5160       1  1.016283                lg\n",
       "3083       3  1.034888            liquid\n",
       "819        2  0.999624              long\n",
       "3178       2  1.017546              loop\n",
       "176        1  0.999345               lot\n",
       "417        2  0.994420      manufacturer\n",
       "3304       1  1.000237            margin\n",
       "951        2  1.001504            market\n",
       "3844       1  1.016283           maximum\n",
       "2503       1  0.987247            maxing\n",
       "235        3  0.999884            memory\n",
       "2741       2  1.017546          mid_tier\n",
       "3141       3  0.972972              mini\n",
       "3958       1  0.990256               mod\n",
       "57         1  0.028732             money\n",
       "57         2  0.970715             money\n",
       "396        1  0.998816           monitor\n",
       "474        2  1.000431             month\n",
       "10574      3  0.875675              myth\n",
       "2465       1  1.011928               nah\n",
       "2428       1  1.007814              navi\n",
       "1962       2  1.017546           noticed\n",
       "74         2  1.000187            nvidia\n",
       "1024       1  1.000237              nvme\n",
       "1251       2  1.017546               odd\n",
       "3904       1  1.016283                op\n",
       "409        1  0.994232              open\n",
       "3397       2  1.017546        originally\n",
       "75         2  0.997948              page\n",
       "616        2  1.001504               pay\n",
       "329        1  0.999752                pc\n",
       "3073       3  1.021620            pcie_4\n",
       "49         2  0.999976            people\n",
       "3192       3  0.875675             phase\n",
       "945        1  0.990876           picture\n",
       "1042       1  0.999816              play\n",
       "1102       2  1.017546              plug\n",
       "548        1  0.409433             point\n",
       "548        2  0.591923             point\n",
       "442        2  0.999895             power\n",
       "743        2  1.017546         preorders\n",
       "650        3  1.000771            pretty\n",
       "18         2  0.998821             price\n",
       "18         3  0.000727             price\n",
       "553        2  1.001504           product\n",
       "428        2  1.000727               psu\n",
       "3398       2  1.017546            pushed\n",
       "3106       3  0.992431              rate\n",
       "3144       3  1.021620             realm\n",
       "3182       3  1.050810              rear\n",
       "937        3  1.002016            reason\n",
       "1157       2  1.017546            regret\n",
       "651        2  1.000537           release\n",
       "1348       1  1.001731        resolution\n",
       "90         3  0.998576            review\n",
       "3111       3  0.992431              road\n",
       "78         3  1.000388               rtx\n",
       "154        1  0.999239               run\n",
       "238        1  0.999587           running\n",
       "3096       3  0.875675            safely\n",
       "3211       3  1.021620              sata\n",
       "3166       3  0.972972          saturate\n",
       "1052       2  1.000954           scalper\n",
       "342        2  0.999624              sell\n",
       "79         2  0.999705            series\n",
       "1043       1  1.001201           setting\n",
       "1173       1  1.011928            showed\n",
       "5267       1  1.000237              skip\n",
       "3309       3  0.875675              slim\n",
       "1073       2  1.017546            sooner\n",
       "3286       3  0.875675             soooo\n",
       "962        1  0.990876      specifically\n",
       "1015       1  1.004466            stable\n",
       "600        2  1.000003             stock\n",
       "3159       3  0.985134            strong\n",
       "208        3  1.000447             super\n",
       "1580       2  0.994420            supply\n",
       "7511       2  1.017546     supply_demand\n",
       "2543       2  1.017546              tend\n",
       "35         3  0.999746                ti\n",
       "3          2  0.999586              time\n",
       "209        3  1.000484             titan\n",
       "939        1  1.000237            unlike\n",
       "54         3  1.000060           upgrade\n",
       "3557       1  1.000237       valve_index\n",
       "468        1  0.998816             video\n",
       "841        1  1.000237                vr\n",
       "211        1  1.000363              vram\n",
       "134        2  0.191641              wait\n",
       "134        3  0.808224              wait\n",
       "162        2  0.998967           waiting\n",
       "386        2  0.994420             wanna\n",
       "3435       2  1.000469             watch\n",
       "400        1  1.000109              work\n",
       "318        2  0.999408             worth\n",
       "3272       3  0.995085           wouldnt\n",
       "227        1  0.579981              year\n",
       "227        2  0.373720              year\n",
       "227        3  0.045949              year, R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 2, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics for the trigram model\n",
    "pyLDAvis.enable_notebook()\n",
    "# Creates the filepath to save the html file\n",
    "LDAvis_data_filepath = os.path.join(os.getcwd()+'\\\\visualization\\\\'+ 'nvidia_' + 'trigram_' +'mallet_ldavis_prepared_'+str(num_topics))\n",
    "\n",
    "optimal_model_lda = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(optimal_model)\n",
    "trigram_mallet_vis = pyLDAvis.gensim.prepare(optimal_model_lda, trigram_corpus, trigram_id2word)\n",
    "\n",
    "# Saves the graph as a html file to the LDAvis_data_filepath\n",
    "pyLDAvis.save_html(trigram_mallet_vis, os.getcwd()+ '\\\\visualization\\\\' + 'nvidia_' + 'trigram_' + 'mallet_ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "trigram_mallet_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bubbles are spread further apart compared to the LDA's pyLDAvis with the exception of topic 3 and 4. This shows that the topics are distinguishable from one another. Also, it seems that the bubbles are of similar sizes which means that the documents are evenly distributed across the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 474.4,
   "position": {
    "height": "496.4px",
    "left": "1156px",
    "right": "20px",
    "top": "120px",
    "width": "360px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
