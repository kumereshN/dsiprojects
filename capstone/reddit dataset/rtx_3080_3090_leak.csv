Reddit comments,tag
"Can't believe I have to make this stickied post but yet another reminder:

1. Wait for benchmark
2. VRAM does NOT equal performance. 
3. Wait for benchmark
4. Wait for benchmark
5. Wait for benchmark
6. You cannot compare core count across generations
7. Wait for benchmark
8. Wait for benchmark
9. Wait for benchmark
10. Bait for Wenchmark",rtx_3080_3090_leak
Meanwhile theres people still trying to sell a gtx 1080 ti for 700 dollars. I also see people trying to sell their 2080 ti's for more than they actually paid for them. This crap makes no sense.,rtx_3080_3090_leak
"I can already see ""Should I wait for 20 GB 3080 or buy 3090 now."" post flooding this sub lol.",rtx_3080_3090_leak
"8GB again for the 70 series.

On top of that, non-X GDDR6 :/",rtx_3080_3090_leak
"memory config a bit underwhelming on the 80, 70 :( probably see ""super"" variants next year with more memory perhaps.",rtx_3080_3090_leak
"""Alright, 1080ti. Looks like another tour.""",rtx_3080_3090_leak
3070 with 8GB is kick to my nuts,rtx_3080_3090_leak
So @kopite7kimi was right that they failed to achieve 21gbps with the 3090: https://twitter.com/kopite7kimi/status/1288444657345560576,rtx_3080_3090_leak
7nm?? Holy did they really bamboozle us again lmaooo,rtx_3080_3090_leak
"As a 1080Ti owner for 3.5 years now i realy hate these options. I want to upgrade for Cyberpunk 2077

I sure af wont do a VRAM downgrade, so 3080 and 3070 are out. The 3090 will be 1500€+ here in germany, so i wont do that either, i already skipped the 2080Ti because i dont do 4 digit cards.

3080 20GB TBA, so i guess they come in 2021

Its like Nvidia wants people like me to get big Navi in november instead one of their cards.",rtx_3080_3090_leak
"4 more days everyone, 4 more days.",rtx_3080_3090_leak
Where's the DP 2.0?,rtx_3080_3090_leak
"I think everyones getting a bit caught up in the difference between the Vram on the 90 and the 80. Looking at those specs, there really arent a lot of things that gamers will do to max out the 10GB (potentially in certain circumstances but i would imagine few and far between) Nvidia really cant launch the 3080 with 20GB (10 or 20 is only option at 320 bus i believe) as its just gonna be way too close to the 3090. Looking at the size of the 3090 it seems to me like Nvidia know the performance difference between these two cards isnt actually going to be that great so they shoved the VRAM up massively, stuck a massive cooler on it and threw a load more electricity through it in the hope to justify the price tag. I think the 3080 may surprise people here and will be the better buy, even if i dont agree with the prices of any of them. If it turns out the 10GB isnt enough can probably sell in 2-3 months for a 20GB AIB and lose £50-£100",rtx_3080_3090_leak
"The high TDP of the new cards makes a lot more sense now. If these specs are true, the most likely culprit of the high TDP on the new cards isn't the GPU itself, but the GDDR6X memory. The difference in TDP between the 3070 and 3080 is massive compared to the 2070 and 2080. The RTX 2070 had a TDP of 175, the 2080 a TDP of 215w, a 40w difference. The 3070 has a TDP of 220w and the 3080 of 320w, but the 3080 is using GDDR6X and the 3070 uses GDDR6.

The 3090 having 24GB of VRAM and pushing near 1TB/s bandwidth is going to be extremely power hungry, wouldn't be surprised if this is eating up near 100w of power by itself.",rtx_3080_3090_leak
Will PCIE 3.0x16 decrease the performance of those cards?,rtx_3080_3090_leak
The human eye can’t see 24 gigabeans anyways,rtx_3080_3090_leak
I guess DisplayPort 2.0 isn’t ready yet? Was hoping these cards would be the first with it.,rtx_3080_3090_leak
"So... I initially saved up for the 3090 back when it was expected to be $2000. The closer I got to the release dates, the more I was thinking I probably didn't need a $1,400 card and I'd stick with a 3070 or 3080. But now, I feel like the 3090 is the only card (as of now) that's really worth getting, and it still seems way too expensive to me. I'll wait for benchmarks of course before I make any decision, but this news saddens me :(",rtx_3080_3090_leak
Just give me that sweet sweet HDMI 2.1,rtx_3080_3090_leak
"Just a casual question: if you play games at 1440p, why would you need more than 10 gbs of VRAM?",rtx_3080_3090_leak
Underwhelmed at least in my price tier(s). Hope amd can get their driver issues sorted.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Got a FE1080 the day it came out, this time I want to wait for third party. How long does it usually take for those models to come out after the FE release?",rtx_3080_3090_leak
"Unless if u are buying the 3090, anything lower should wait for amd announcement.

Either Nvidia drop price on its 3070 3080 or come out another super version.",rtx_3080_3090_leak
"Ok, real talk... is 10Gb really ""not enough"" VRAM? I'm currently only gaming at 1080p/144hz, but I'm going to upgrade to 1440p/120hz, and looking at many videos and articles, 6-8GB is the sweet-spot for gaming at that resolution. Granted, in terms of future-proofing, who the heck knows? But for the forseeable, it should be ok, right?",rtx_3080_3090_leak
"Remember wait for benchmarks, so I can buy one at launch.",rtx_3080_3090_leak
"Bait for wenchmarks?

Guess I'll wait for the benchmarks then",rtx_3080_3090_leak
3080 320 watt TDP and only 10GB? What a joke.,rtx_3080_3090_leak
I'm more interested in the 3070 tbh.,rtx_3080_3090_leak
Getchu a card that has more ram than most computers,rtx_3080_3090_leak
Damn...will see what Big Navi offers or maybe will just stick it out with my 5700XT for the meantime.,rtx_3080_3090_leak
10gb on the 3080 is not very future proof imo.,rtx_3080_3090_leak
I'll wait for second iteration of 3080 and benchmark reviews. I can wait another 6 months or so.,rtx_3080_3090_leak
"Going for 3090 would be insane from financial pov (it costs almost as much as average income after tax for 2 months in this country) , going for 3080 10gb would be insane for futureproofing for next 3-4 years, especially for someone who will love to play heavily modded open world games with RT on ultra.

Meh. Hoping for 20gb models of 3080, or im without upgrade this time again.",rtx_3080_3090_leak
"Imagine the impact that would have if, in the middle of the rtx 3000 presentation, right in the moment when overprices are revealed, everybody leaves the stream. 0 viewers. And nobody buys a single gpu for the next 24hours. 

I think that nvidia would drop prices. It would also be epic.",rtx_3080_3090_leak
7nm? I thought it was samsung 8nm.,rtx_3080_3090_leak
bench for the waitmarks,rtx_3080_3090_leak
so what will happen to 2080tis on used markets. will they drop in price drastically or remain the same or increase? should i sell mine now or wait till the specs are talked about more.,rtx_3080_3090_leak
The vram is disappointing. I have a 5 year old GTX 980 with 4GB. I thought a reasonably priced card like a 3070 would have at least 12GB by now.,rtx_3080_3090_leak
"3070 getting 8GB probably means 3060 is still on 6. I will laugh.

Specs are a buzzkill, hope at least performance is not.",rtx_3080_3090_leak
"I had planned to go 3090 despite the price, but hoo boy is that going to be cutting it close with a 750w and 10900k.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"At 3440 x 1440 I have maxed out my 8 gb VRAM many times. Just saying that I'll reserve judgement but am rather pessimistic about this. For my specific use case, and the use case of people running 4K and 5120 x 1440, this should be a serious caution flag.",rtx_3080_3090_leak
I just bought a corsair rm750x - did I screw myself if I was planning on getting a 3080?,rtx_3080_3090_leak
So much for the Sammy 8nm LPU rumors,rtx_3080_3090_leak
970 gang,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"I clearly remember  that there was a variant with  5,376 cuda cores . I am hoping that this will be the titan",rtx_3080_3090_leak
"I had a 1070 that had 1920 CUDA cores, would 1920 Pascal CUDA cores run the same as 1920 CUDA cores from Ampere or Turing, if both of them are at equal frequency? I'm hoping for a great bump in performance from the 1070!!",rtx_3080_3090_leak
"Sitting on a 1070ti and have been looking at the 3070 as an upgrade for the ray-tracing and much better performance (more frames at higher settings)  


currently sitting on 1080p 144hz but looking into upgrading to 1440p 144hz, i'm gonna have the same vram but i'm not sure if that will be a problem since i don't care about 4k?",rtx_3080_3090_leak
AMD is time to shine on video board,rtx_3080_3090_leak
I hope AMD pulls a sneaky and announces big Navi 2 weeks after NVIDIA with gold performance and forces NVIDIA to add this 3080 20gb or adjust pricing,rtx_3080_3090_leak
Leak the fucking price,rtx_3080_3090_leak
"It’s not a rumor if it’s leaked, kids",rtx_3080_3090_leak
320w 1710mhz boost uhh what?,rtx_3080_3090_leak
"It looks like the TDP is only \~9% higher on the 3090 vs the 3080 despite having over 20% more cores and twice the memory. Is this evidence that the 3090 is on the 7nm process?

Edit: and the 3080 is on a different process. I'm not referencing 20 series cards at all, I don't know why people are confused or downvoting",rtx_3080_3090_leak
Pcie 4.0? Daddy x570 wants you sweetie!,rtx_3080_3090_leak
3090 it is then.,rtx_3080_3090_leak
"Glad I didn’t wait. I think I’ll be fine with my 2070 Super for a few years. My CPU seems to be the bottleneck (i5 9600k), I’ll upgrade their instead.",rtx_3080_3090_leak
"It's seriously wild to see people comparing the VRAM from GDDR5/6 to GDDR6X....

""Well I can't go backwards in VRAM number!!!!"" That is not at all how it works lmao.",rtx_3080_3090_leak
Might be time to switch to AMD,rtx_3080_3090_leak
"ITT: “But muh VRAM”

Y’all don’t even know what you need or how it’s used on the new line, but smaller is automatically worse.",rtx_3080_3090_leak
"I'm so confused with this obsession of 10gb of vram vs 11gb.   Like I run at 1440p and never come anywhere close to using 11gb of vram on any game.   I guess people are worrying about 4k future proofing?  The truth is buying a card for ""future proofing"" is never going to leave you satisfied.",rtx_3080_3090_leak
"Curious if there’s room for a TITAN variant (more vram, more bandwidth) in the future?",rtx_3080_3090_leak
Im just patiently waiting to see what the custom water cooling support is gonna look like,rtx_3080_3090_leak
For gaming on 3440x1440 144hz would a 3080 do? Ultra/RTX on? I know the FPS will vary depending on the game.,rtx_3080_3090_leak
Not surprising.. nvidia has forever been gating performance with bit bus.,rtx_3080_3090_leak
So would now be the time to buy a 2070 super lol since people will buy 30 series. I'm still on a 1060 6gb trying to run 1440p :(,rtx_3080_3090_leak
"OOH HDMI 2.1 Nice. My LG C9 OLED needs 4K 120fps at MAX Settings in Cyber Punk. All these numbers mean nothing to me. At Least HDMI 2.1 is there for a possible 4K120fps, G-sync VRR ALLM eARC etc full fat 2.1 experience. Let's hope they give it all the HDMI specs 2.1 has to offer.",rtx_3080_3090_leak
",c",rtx_3080_3090_leak
Bait for wenchmark,rtx_3080_3090_leak
Will 10gb be a problem? Seems stupid when i had 11 on my 2080ti? Is it actually necesary for games?,rtx_3080_3090_leak
Legitimate question here. Don’t get upset with me pls. Why do yall need all these crazy good 20GB graphics cards? I got a 2060S in my PC and I feel like I can literally run anything I want on Max settings at 1080p. Do you guys need these super high end cards for 4K gaming? Also should I be upgrading this gen?,rtx_3080_3090_leak
"Ah that tpd for the 3080, is a sff 600w gold paired with a ryzen 2600 gonna be ok?",rtx_3080_3090_leak
So basically wait for the Super variants (or buy older GPU’s in the meanwhile) unless you’re financially able to get the 3090.,rtx_3080_3090_leak
"Man, these specs are leaking everyday!",rtx_3080_3090_leak
"Hmm, I would probably rather have a 12GB 3090 than a 20GB 3080.

Think I might wait and see if there'll be a 3080 Ti Super or something to slot in between the two.",rtx_3080_3090_leak
So if I'm going from a 1080 to a 3080 would/should I replace my 650w PSU as well?...,rtx_3080_3090_leak
"Been saving up for the 3090 for years, this time I'm going in for the killshot on my wallet.",rtx_3080_3090_leak
Read my flair,rtx_3080_3090_leak
Keeping my power-hungry Vega 64 💪🏾,rtx_3080_3090_leak
"I don’t know shit about the technical sides of these things, don’t even know what most of this stuff means... but can someone tell me if a 3080 will be a big improvement over my 2070super or if I should just get a 3090 or wait for the new Ti version to drop for some huge boost? I would like to get into 4K gaming soon, especially when CP77 drops",rtx_3080_3090_leak
"I have no idea what to do at this point. I am gathering parts for my first build, I think I have settled on the 3700X CPU and I had originally planned to do the 2070 Super. Then I decided to wait for the announcement, which I guess I am still doing, but for a \~$1500 max budget build the 3090 and 3080 are probably out of my price range (I don't need monitors, keyboards, etc) and I'm not sure how long I can justify waiting on a 3070.

I can get a 2070 Super for $499 at Best Buy right now. I'd for sure wait for the 3070 if it was going to be available first thing at the leaked prices, but I'm not sure that'll be the case and I'm also not sure I want to be first in line either. This is going to be a work machine (self-employed contractor) in addition to a gaming machine so I can't really afford much down time.

Anyone in the same position or have any ideas?",rtx_3080_3090_leak
With the prices I've seen they can go fuck themselves.,rtx_3080_3090_leak
"Fuck yeah, shoot my NVIDIA stock up.",rtx_3080_3090_leak
"If I were to upgrade to any of these cards, would I have to replace the TR2 600 power supply I have right now for my GTX 1060 ssc 6gb?",rtx_3080_3090_leak
so i got a 2080super if i upgrade to 3080 will i have to upgrade from my new 750watt power supply im also running ryzen 9 so that takes alot of power,rtx_3080_3090_leak
what is the best CPU to go with the Nvidia 3080?,rtx_3080_3090_leak
Im still confused are the 3000 series PCIe 3.0 compatible?,rtx_3080_3090_leak
Cant wait until they release 3080 so 2080 will be cheaper so I can buy 1080,rtx_3080_3090_leak
Fuuuuuck my 650w PSU isnt going to cut it for a 3080 at 320w TDP...,rtx_3080_3090_leak
"Thank god they want to make a 3080 with 20GB. Or at least there are rumors. I dont want to spend an additional 1000€ just for 12GB more VRAM.

Still man, 24GB sounds good.",rtx_3080_3090_leak
So 750w PSUs like RMx series are still enough for this. Good.,rtx_3080_3090_leak
"Cant believe some people in the comments are defending the outrageously high prices. Where the hell is the Nvidia I grew up with giving us a good price to performance ratio. Granted AMD was the king of that for a long time, But in 2014 with the Maxwell cards they finally pushed back and won me over with the new cards up until Pascal, I started losing interest when the prices for the RTX cards started to release because they were hardly worth the upgrade just for ray tracing, I was already gaming at 130+ FPS with my GTX 1070 so there wasnt a reason for me to upgrade. Now with ampere the reach seems so far away, I can barely even afford to be a PC gamer anymore. Big Navi is looking sweeter and sweeter at this point, I might be going back to the red team.",rtx_3080_3090_leak
I suppose ill be in the 70 tier cuz even if the performance is there i have a hard time speniding 500+ on a gpu. I got a refurb 1080 FE for 391 a couple years ago,rtx_3080_3090_leak
"I sincerely hope this is just a pre-emptive measures of specification setup against the AMD line up, AMD is silently waiting on Nvidia's announcement, and Nvidia know that AMD is silently waiting.

Hope it is just that Nvidia is expecting AMD will have a line up of 10GB 12GB 16GB etc, to make Nvidia look bad. And Nvidia will reveal their actual line up, otherwise if these specification from leak are real, then they are super underwhelming, 6 and 8GB are a norm for high end cards several years ago, you can't be serious that in 2020 you are still selling cards that provide 8GB only, those will not be futureproof at all.

Whether you call it high-end, or mid tier, does not matter, as this classification is getting stupid nowadays where people call a $500-600 card mid tier. $500-600 could buy you a decent entry gaming PC, spending that kind of money just to realize in 3 years significant amount of AAA title you won't be able to run max setting. Might as well just use GeForce Now instead.",rtx_3080_3090_leak
"Look at them gimping on the vram again for the 80 and 70. 
Kick rocks nvidia",rtx_3080_3090_leak
"I was considering the 3070. Now I'm not considering the 3070.  That artificial segmentation is nuts.  

Sigh.  Here's hoping the PS5 has some exciting launch day games.   Nvidia seems to have lost the point entirely.",rtx_3080_3090_leak
Still not sure which one to go for as a successor to my previous 2080 Ti? I have a 1440p 165Hz G-Sync monitor.,rtx_3080_3090_leak
"""VRAM does NOT equal performance""

...Not until you run out of it. Which is why people are rightfully worried. 

Outb4 more airheaded claims that the VRAM being really really ridiculously fast will somehow cancel out the fact that you're going to be running textures at High or lower on $800+ video cards...",rtx_3080_3090_leak
"Holy shit that power usage, looks to me like they are compensating for their falling out with tsmc and are now having to push their cards way farther, producing more heat, and needing some extreme cooling solution..  

Which makes me wonder what the temps and performance will be like if vendors decide to stick to conventional cooling  

I hope my gut is wrong, but I'm at the very least going to hold off to see what amd can come up with this time, if only for the fact that if their drivers are stable (which would be surprising in itself), and they're even somewhat competitive without having to push their cards as hard, nvidia might drop prices, 400 for a 3060 is insane, and might be worth jumping ship this time",rtx_3080_3090_leak
I just built a new system with a 750W PSU. I am running i7 10700k and plan to get the RTX 3080 or 3090. Will my PSU be ok?,rtx_3080_3090_leak
"I have a 1080ti and was wondering if a 3080 with 1GB less VRAM would be a downgrade? (I'm still somewhat new to this stuff so excuse the ignorance)

I think Red Dead Redemption 2 at 4K could use a lot of VRAM (iirc).  I'm guessing more and more games will use more VRAM so I am confused that why would they go backwards in amount of VRAM?

I play in 1440p@165hz or 4K@60hz if that matters.  I would prefer to one day get a monitor for 4K@144hz",rtx_3080_3090_leak
"So whats it looking like for 100+ fps, 1440p on a 3070?",rtx_3080_3090_leak
"220Watts for a 3070 card, LOL

Oh boy this is gonna be a one *hot* mess.",rtx_3080_3090_leak
same salt as last time,rtx_3080_3090_leak
"Why on earth would they bother releasing a 10GB 3080 lmao. This card is bought by people who play on 1440p/4k and/or want future proofing to some extend. I’ll be waiting for the 20GB 3080. Don’t wanna get fucked by buying a 10GB 3080, when a month or two or so later the 20GB version can be bought.",rtx_3080_3090_leak
"Wouldn't be surprised if the 7nm is Samsung 8nm with a marketing twist (which is actually a marketing twist of 10nm). If this is Samsung 7nm EUV, the yields musn't be great if the 3080 has a 320w board power with less than half the memory and less activated shaders.",rtx_3080_3090_leak
"You know whats worst? All reviews will show how 3080 have more than enough VRAM, how well Nvidia memory compression technology works.

But they wont be able to take into account what will happen in a year after console generation switch. At least i hope somebody will review BF5 eith 4k RTX ultra, heard it eats alot of memory",rtx_3080_3090_leak
"I mean, honestly, why are people complaining about 10 Gigs of Vram?
The RTX 3080 is a card for gaming, it's not beeing marketed nor sold as something else, it's not meant for super complex scenery, ""Avatar 2"" renders and such.
10 Gigs should more than enough for the upcoming few games in 4K res. And it also has a substantially higher bandwidth.

Sure, it is weird that a better card, about to replace its predecessor the RTX 2080(Ti) has less Vram but I personally don't see this as a huge letdown",rtx_3080_3090_leak
"Considering that the 3070 is 8gb and GDDR6 non X, is it better to buy a 2070s at a lower price?

PS: pure speculation because we dont know the actual performance of the 3070.",rtx_3080_3090_leak
Can we expect 8GB for the 3060?,rtx_3080_3090_leak
Those boost clocks seem very conservative for the 3080. If it is indeed on tsmc 7nm then it should be able to hit 2.1ghz easy.,rtx_3080_3090_leak
Is it alreasy confirmes when the 3070 drops?,rtx_3080_3090_leak
Is the PCI Express 4.0 connector different to the PCI Express 3.0 connector?,rtx_3080_3090_leak
Damn I don't think I will be able to get the rtx 3080 with my 650w psu :(,rtx_3080_3090_leak
I would like to know more about this Wenchmark mentioned by the mod in the sticky post....,rtx_3080_3090_leak
will the 3070/80 have the same cooler as the leaked 3090? Any info on that? Cause the 3090 looks massive...,rtx_3080_3090_leak
Interesting. what about the rumor that the 3090 is a 3-slot GPU? That is thicc!,rtx_3080_3090_leak
i have a 650w psu will a 3070 be okay?,rtx_3080_3090_leak
Presumably there will also be a 3090 Ti? :),rtx_3080_3090_leak
"If you already have a 2060 super or 2070 super, what kind of % performance increase do you look for before warranting an upgrade over to the same tier 3000 series cards?

Or just how many % performance icrease from the gpu you are using before you would want to upgrade? I'm thinking in the mid tier level only. 

I know typically, the xx70 series of the previous gen gpu will be matched by the xx60 series of the new gen.",rtx_3080_3090_leak
"So.. to get the new VGA, I have to replace my brand new 750W PSU...?",rtx_3080_3090_leak
God this is so stressful. I was gonna buy a 2070 super to upgrade my currently bottlenecked to death 780. Knew these cards were coming out soon so I've waited. Now I'm about to be caught in this horrible game lol,rtx_3080_3090_leak
"Will 650w be enough for 3080? RTX Titan on NVIDIA's page says 650w is recommended, but it's only like 280w TDP.",rtx_3080_3090_leak
"I'm looking at this, wondering if I should be mad or excited, then I realised it all means bugger all until I've seen actual footage of the card running games and can see the FPS, settings, frametimes, memory utilisation etc.",rtx_3080_3090_leak
"I'll wait for the supers. 

👍",rtx_3080_3090_leak
Will we see benchmarks at the event?,rtx_3080_3090_leak
Damn I’d consider the 3080 for me but gotta wait for benchmarks.,rtx_3080_3090_leak
I really hope we are getting more than one hdmi 2.1 port.,rtx_3080_3090_leak
"Anyone wanna ELI5 the major differences between GDDR6 and GDDR6X, along with the differences for gaming, VR, ML and other workloads ?",rtx_3080_3090_leak
I was planning on buying a 3080 should I hold out or is 10GB enough ?,rtx_3080_3090_leak
What's the price on the 10 Gb version???,rtx_3080_3090_leak
bruh I'm still going strong with my 970,rtx_3080_3090_leak
Did I read it wrong or did they mention 7nm???,rtx_3080_3090_leak
"Brah.

wut.",rtx_3080_3090_leak
I am in the market for a 400-550€ card. Three years ago I bought a 1080 with that amount but it looks like that I can only get a 3070 this time around.,rtx_3080_3090_leak
Will it have HDMI 2.1?,rtx_3080_3090_leak
What is  the TDP equivalent  for 350 TGP?,rtx_3080_3090_leak
Maybe I need to wait on this. I want to max out flight simulator 2020 at 4k.,rtx_3080_3090_leak
I think I’m going to nab a heavily discounted second hand 2080 ti instead.,rtx_3080_3090_leak
No matter what we can be sure that this card will not run Star Citizen when it releases in 2030,rtx_3080_3090_leak
"Ugh, that power draw. Wonder how much hotter my case is going to get going from a 1070 to 3070, especially considering it's SFF.",rtx_3080_3090_leak
Can someone please fill me in on how these will compare to current 20 series? Like I’m looking at Vram and clock speeds which look similar so what am I looking at in terms of upgrades?,rtx_3080_3090_leak
When are they supposed to come out?,rtx_3080_3090_leak
***Scenes if these are actually 7nm.***,rtx_3080_3090_leak
Im really hoping the 3070 is the same price as the 2070 super at $500.,rtx_3080_3090_leak
People talk about how casual people dont need this like its casual users that actually need the latest stuff anyway. I use my gpu for procedural work and im hopeful for these but its not purely about the specs themselves. a 1070 -2070 was  a massive performance leap but neither looks different on games to me.,rtx_3080_3090_leak
Oof that 3070.,rtx_3080_3090_leak
With the new leaks would a 450w psi be enough for a 3060? I know the 3060 isn’t mentioned but I would expect it to be similar to the 3070?,rtx_3080_3090_leak
"As someone with a 1080 @ 1440p, it seems tempting to go up to the 3080 if the prices are in the same ballpark as the 1080 was (~$700).",rtx_3080_3090_leak
"I was waiting until now to upgrade from 980 era system.  Looks like I have to wait... again, to see if they do a super version.  And by that time I'll be waiting for the 4000 series I guess.  Looks like I'll just keep my money and see if AMD pulls off something",rtx_3080_3090_leak
When will Ti be out?,rtx_3080_3090_leak
My 3D visualizations will love the (rumoured) 3090 with 24gb VRAM.,rtx_3080_3090_leak
So will a 3080 be able to run 4K at like 100+ FPS?,rtx_3080_3090_leak
"I'm with moddy boy here: Bait for wenchmarks, fellas. Nahh who are we kidding? This thing is thing to be a beast. Beasty McBeastFace.",rtx_3080_3090_leak
Thoughts on the 3070 being only 8gb?,rtx_3080_3090_leak
My 1080 Ti still gives me 60 FPS at everything I throw at it. I'll probably just wait another two years or go with AMD if they manage to pull it together.,rtx_3080_3090_leak
"Okay so I’m looking at 4K at 60 FPS as my target area for a new card. I know we need to wait for the benchmarks. That makes all the sense in the world. 

But what does you gut tell you? 3080 or 3090?",rtx_3080_3090_leak
"I've got a 1080, got it for 4 years. The plan is to go for 3080, I don't care about benchmark because I'm sure to be good for at least 4 years again",rtx_3080_3090_leak
will there be a TI variant for 3080? I am super excited but def need to restrain myself.,rtx_3080_3090_leak
No where in the article does it state how many kidneys i have to sell to afford this ^obviously ^not ^mine ^cause ^where ^would ^all ^the ^salt ^go,rtx_3080_3090_leak
Looks good as long as there isn't a price increase. I don't think they need to increase vram until their next generation of cards. Games will start taking advantage of more memory with the new consoles but it will take a couple years for multi-platform devs to leave this current gen of consoles behind.,rtx_3080_3090_leak
and heres me still thinking that the 1080 TI is new.. yet it's 4 years old...,rtx_3080_3090_leak
Does Nvidia usually release benchmarks when they announce a new series? I’m assuming they would,rtx_3080_3090_leak
"At the moment I think the price point is more important, as I think we can all have a general pretty good guess at what the specs will be anyway.",rtx_3080_3090_leak
I might buy one if the jump it's comparable to the one with the 10xx cards,rtx_3080_3090_leak
"3060, my poor ass an only afford a 3060. WHERS THE 3060!",rtx_3080_3090_leak
Very good news! Maybe I’ll be able to afford a secondhand 2060 in a couple decades now!,rtx_3080_3090_leak
When’s this beast getting released? I hardly game but I want to experience graphics like this.,rtx_3080_3090_leak
Good thing I don't need to upgrade for Crusader Kings 3.,rtx_3080_3090_leak
what ? no dp 2.0?,rtx_3080_3090_leak
"Not waiting, getting a 3090 and thats that.",rtx_3080_3090_leak
"what kind of psu will i need for that 3080?

i have a 700w right now.",rtx_3080_3090_leak
"Any idea how many ray tracing cores RTX 3000 will have?

I saw a video a couple years ago about how ray tracing will increase exponentially YoY and that got me pretty hyped.",rtx_3080_3090_leak
I guess the generations are just going up and up and up,rtx_3080_3090_leak
I was about to build a pc using a 2080 ti - how long to wait?,rtx_3080_3090_leak
Why do these new releases never drop prices for old cards 1060s are still as expensive as they were a year or two ago,rtx_3080_3090_leak
So the 3070 is just a 2070 rebranded....,rtx_3080_3090_leak
"Youtubers spamming the specs for two weeks, specs don't matter where the real world benchmarks at!? 24GB memory, call bullshit on that, that's a Titan card.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
I'm so excited to buy this so that my CPU-bound games are even more CPU-bound.,rtx_3080_3090_leak
Wish amd will do like they did in the r9 390/gtx 970 area and give people way more vram for the same price,rtx_3080_3090_leak
"What is the website I go to to buy a 3090 on launch day, is it literally just like Nvidia.com?",rtx_3080_3090_leak
Not the most interesting launch as a 1080TI user... Guess we have to wait for something like a 3080TI mid/end 2021 with 16-18gb then. My wallet says thank you for now...,rtx_3080_3090_leak
"I’m a newb, can someone tell me how well my 980 TI actually is these days",rtx_3080_3090_leak
"What kind of power supply would one need for the 3080? I’ve got a 750 W, would I need an upgrade?",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Considered waiting for the 3070, but ended up getting a good deal on an EVGA 2060 Super.

Looks like I made the right call.

My goal was 1080p High. 60fps AAA Single player and 144hz multiplayer games. So far I'm incredibly happy.",rtx_3080_3090_leak
"Oh no 10gb vram whatever will we do..

Its only slightly more than an RX580, must be shit then.",rtx_3080_3090_leak
So is the 1080 ti still good or?,rtx_3080_3090_leak
Samsung node ?,rtx_3080_3090_leak
1080 going another year then LOL. How disappointing,rtx_3080_3090_leak
So it’s about to be a really good time to upgrade to a 2060.,rtx_3080_3090_leak
I'd love to get that RTX 3090.,rtx_3080_3090_leak
When a graphics card has twice the memory than your whole pc,rtx_3080_3090_leak
"How long before we can realistically see the mobile versions for laptops?  I was in a spot where I needed to replace a dying laptop and purchased at a less than ideal time, but was afraid to wait considering how long it took mobile versions of Turing to hit the market (looks like it was similar for Pascal as well).  Otherwise I would have considered waiting it out (fwiw building a desktop wasn't an option).  Also, with the 3080 going to 320W is that going to make the performance gap to a max p laptop even bigger than it already is (and further yet for max q)?  As it is the gap is pretty stark. Even with a maxed out 200W 2080 Super I'm probably at best like a 2070 desktop (if not lower) nevermind the lower limits of a laptop CPU.",rtx_3080_3090_leak
Tbh I jusy hope the 3060/3070 is good enough to justify upgrading from my 1060. I can still run Destiny 2 at 1080p / 90fps (wpuld prefer 144 but whatever) on low,rtx_3080_3090_leak
"How about a 3060 super variant, without RTX, with the fast version of the memory (+x)?  1660 super is already one of the best value cards for 1080p.

I assume 3070 will be 2070 equivalent, and 3090 is more expensive than a 2080.  But who knows?",rtx_3080_3090_leak
I’m hopping on board this 3090 the day it’s announced. Building a new pc around it. Excited.,rtx_3080_3090_leak
"If they release at these prices and these specs, they have just opened the windows for AMD to make a comeback. I was almost going to insta-buy a 3080, but now I'm waiting to see how competitive AMD is.",rtx_3080_3090_leak
Personally I am really excited for the 3090. I do a lot of cg work and lots of photogrammetry so being able to bake high poly stuff easier is going to save me loads of time and let me bake wayyyy higher poly stuff,rtx_3080_3090_leak
So just wondering how long after NVIDIA launches the FE editions of these cards will it be before say EVGA releases their version of one of them. Two months? Three?,rtx_3080_3090_leak
For the price we are about to pay I don’t understand why 12GB or 10GB isn’t the standard. Talking about 3070,rtx_3080_3090_leak
The pinned mod comment has basically been me through this whole year,rtx_3080_3090_leak
"kind of annoying really, i expect 2x,3x performance and effiencey of 1080 ti, 30c temps, 12gb+vram,  phone sized sub-£600..    but noooo lets jack it up to £1400 dolla   i'll likely just settle for a laptop in the future i cant ever really see myself cranking out a 3k PC tower again, its 2020 the world is ending

&#x200B;

forget it nvidia i'll hold on to my 980 ti 5yrs old now",rtx_3080_3090_leak
"I’ll wait for the benchmarks, but looks like I’m rocking my 1080 for another year. I was just playing DOOM 2016 on Ultra everything 1080p@100+ FPS. 

Probably upgrade my CPU instead since those seem to be priced appropriately.",rtx_3080_3090_leak
So how much are the 20xx series cards expected to drop in price once the new ones are released?,rtx_3080_3090_leak
"3090s are architecturally far closer to Quadros than GeForce (sans ECC). If you need NVLink for its shared VRAM pool, specifically in Data Science and ML applications, go for it - otherwise these are not  gaming cards unless you have money to waste. Comparing price by FP32 performance without considering NVLink as a  (invaluable or worthless, based on your use case) feature for 3090s is silly.

**TLDR: Unless you're buying 2x 3090s and need \~40GB VRAM, it's not worth.**",rtx_3080_3090_leak
"I hope the 3060 will be a good bang for the buck card. Coming from a 960 2gb, looking to crank up msfs2020 and play games at 1080p 144hz",rtx_3080_3090_leak
Still rocking my 1080 and want to upgrade. Im playing at 1440p/144hz,rtx_3080_3090_leak
"Wanting to get a HP Reverb G2, and currently gaming at 1440p, I probably either have to stretch for the 3090, or wait for a 20GB edition of the 3080 I am guessing.  

Ugh.  I hope the AIBs launch those right away",rtx_3080_3090_leak
"I got my 1080ti used last year after the price took dump after it was no longer relevant to crypto miners. I paid $300-$320 from what I recall.

After people realized RTX was a dud feature and Nvidia is raping them on new card prices, the price of the 1080ti shot back up.

Glad I upgraded last year, it's one hell of a card.",rtx_3080_3090_leak
I have a 2080ti since day one and i have 0 interest in the 3000 series,rtx_3080_3090_leak
Time to get a new psu,rtx_3080_3090_leak
Wonder what it’ll cost me to upgrade my 2080ti with 3090ti,rtx_3080_3090_leak
wake me up when rtx 4080 release.,rtx_3080_3090_leak
Any predictions on what their RTX 3060 will be equivalent too ? Maybe the RTX 2070?? Or is that pushing it?,rtx_3080_3090_leak
Fail,rtx_3080_3090_leak
so. wait for the supers?,rtx_3080_3090_leak
I just pre-ordered the HP Reverb 2 and will need a new gpu to get the most out of it since I'm rocking a 970 currently. I was planning on getting one of the new mid level Nvidia cards coming out but the vram is disappointing. It doesn't seem like a good future proofing decision. Maybe I'll just wait until after the info is released next week and hopefully the used 2000 cards will drop a bit in price.,rtx_3080_3090_leak
I remember when 600 dollars used to buy you the flagship cards. But sadly those days are over. What the hell happened to the PC GPU market. I'm not saying that the r&d and technology behind the new ampere cards didn't cost anything. But Nvidia needs to understand that not all is PC gamers have very deep pockets. I usually just buy whatever graphics card cost $400 and I'm almost always fine for 5 years. Im still using the good ol GTX 1070. So if I upgrade to the 2060 I'll basically have a 2070,rtx_3080_3090_leak
"Feeling better about my recent 5700xt purchase, especially with how much I paid for it",rtx_3080_3090_leak
"My first PC build was a Pentium 166mhz, I think we had 8meg ram and a 420meg hdd, 56k modem, I do believe the 3dFx Voodoo graphics card was out at the time. It could run Quake in 30-40 frames per second. Quake, the great, great grandfather of 3D gaming written by one of the most amazing software companies in the world, at the time, id Software.



Daamn. Tech is crazy.",rtx_3080_3090_leak
🐑,rtx_3080_3090_leak
"What a cokndjcence, I don’t know much anything about this computer stuff but I was wondering about the XSX’s capability with the 2080. I was wondering about the new NVIDIA graphics card and surprise there is a new post about its specs, it also made it on /r/all",rtx_3080_3090_leak
So it's just quadro. Only meant for gaming,rtx_3080_3090_leak
Wait I'm using pentium with hd graphics 128mb😑,rtx_3080_3090_leak
"Would the 3090 fully saturate a PCIe 3.0 x16?

Basically when plugging in the card to a 3.0x16 slot, would I see any performance degredation ?",rtx_3080_3090_leak
"Am i the only one not hype of this..once it release, confirm sold out..and it will be resell with markup price..",rtx_3080_3090_leak
Can't wait for the 2500$ 4090,rtx_3080_3090_leak
Meanwhile my 970 runs just about everything on ultra. Whats the point of updating?,rtx_3080_3090_leak
is there a rtx or gtx 3060? looking forward to that ahahaha,rtx_3080_3090_leak
"I’ll never understand graphics card models numbers.

I’ve just given up on it at this point",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Neckbeard gonna neckbeard.,rtx_3080_3090_leak
Not knowing a damn thing about GPUs. Planning to buy a graphics card for cyberpunk. How big of a jump from my current 1060 3GB to 3070? I am trying to not invest in another graphics card for another 4 years.,rtx_3080_3090_leak
I need to sell my kidneys.,rtx_3080_3090_leak
I'm a little OOTL here can someone explain? I thought 3080 series was dropping soon? Why won't that mean most people can upgrade to 2080 from their 1080 at least? Thats what I've been hoping for.,rtx_3080_3090_leak
Is 7nm instead of the Samsung 8nm practically confirmed by now on the 3080 and 3090 models?,rtx_3080_3090_leak
 And here's me still using my ole faithful GTX 970.,rtx_3080_3090_leak
do we need another titan at this point,rtx_3080_3090_leak
"will my 9 year old 650W antec power supply be ok  with these cards? It only has 1 8 pin and 1 6 pin. Anyone know exactly what the 12 pin adapter will require?   I have no magnetic disks in the machine, just two SSDs and a i5-6600k, so not really pulling a lot of power other than the GPU",rtx_3080_3090_leak
How do these specs compare to the cards in the next gen PS5 and Xbox?,rtx_3080_3090_leak
I will try to sell 1070 for 300-350 Australian dollar and buy 3070/3080 depending on price.,rtx_3080_3090_leak
How long until after market cards come out? I'm looking for the EVGA models.,rtx_3080_3090_leak
"This all looks confusing to me and I don't understand the difference, everyone kept telling me to hold off to upgrade my RX580, so what looks to be the one most people should be getting? The 3090?",rtx_3080_3090_leak
I just wait for the haiku bot to reply to my comment down here.,rtx_3080_3090_leak
And 50 minutes till presentation hahahahahaa,rtx_3080_3090_leak
"The 10g on the 3080 is not future proof enough for me.
   I have 8g on my 1080.👀",rtx_3080_3090_leak
Anyone know how to get their hands on one of these when they come out at the MSRP price?,rtx_3080_3090_leak
" [https://stockx.com/nvidia-nvidia-geforce-rtx-3080-graphics-card-founders-edition](https://stockx.com/nvidia-nvidia-geforce-rtx-3080-graphics-card-founders-edition)  


Looks like they have some other models too  
[https://stockx.com/search?s=3080](https://stockx.com/search?s=3080)",rtx_3080_3090_leak
Well looks like AMD is gonna have to come and save the day!,rtx_3080_3090_leak
"People complaining about the VRAM, read the sticky posts ffs. *Wait for benchmarks.*


 That, of course, also means we shouldn’t jump on the bandwagon, either.",rtx_3080_3090_leak
"7nm isnt right with those low clocks and high wattage, thats gotta be samsung 8nm",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Read quite a few comments. Holy the people are really hard to please and it shows.

The 10GB of VRAM of thje 3080 may seem as a small amount but it will be sufficient for 95% of the cases. For the other 5%, you'll most likely wait for the 3080 20GB model.

And the TDP is no surprise yet people are pikachu cosplaying left & right. GDDR6X is in no way a joke. Else the 3070 should have sucked at least 50W more than it does in this leak.

Plus. It's a leak people... calm down.",rtx_3080_3090_leak
"Unimpressed. Not selling a kidney for 3090. Not getting shammed with 10gb card. Will stick with what I have for another gen. 

I did the math. The lowest rumored price is 1300 for the 3090. You could buy a PS5, Xbox Series X both and still have $300 left. Nvidia has become a meme.",rtx_3080_3090_leak
Yeah is not hard to see the 3080 ti happening. I am busy enough with school to think I can get away waiting for that.,rtx_3080_3090_leak
I have an EVGA 650w with RTX 2080 + 8700k. No OC. Will I be fine upgrading to the 3080 or do I have to upgrade my PSU as well?,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Looks like a 750W PSU will be enough for the 3090, phew!",rtx_3080_3090_leak
"Damn I wanna buy a 3090 but  
1. I have a 750W PSU so if it draws 400+ W it's not enough  
2. It may not even fit in the case (both bc of length and width)  
3. It will also serve as a room heater",rtx_3080_3090_leak
I can't wait to get the big boy and some ln2 :D,rtx_3080_3090_leak
sounds like ps5 for me,rtx_3080_3090_leak
But how will it compare to my GTX 970?,rtx_3080_3090_leak
"I just want a reasonably priced 3060, is that so hard?!",rtx_3080_3090_leak
"I like how these things are always labeled as “leaked” instead of released, because they know it’s more grabby of a headliner.  People think they are seeing something they shouldn’t, but they just tricked you into giving a shit by changing the phrasing.",rtx_3080_3090_leak
"Why is everyone freaking out that it's ""only"" got X amount of VRAM, its going to handle it differnetly for all we know 10GB of this new VRAM = 20GB of the old",rtx_3080_3090_leak
Could somebody estimate prices for me doesn't have to be exact just want an idea,rtx_3080_3090_leak
"Knew this was going to happen, the only reason people are disappointed is Becuase they got all hyped up for rumours. People thinking this gen will make the 20 series obsolete. Since when is a next gen that much better where it makes the previous gen or 2 completely obsolete?",rtx_3080_3090_leak
"I know its all rumours until details are confirmed in a few days. But if the leaks are real, then I think I will stick with my 1660Super and skip another generation.",rtx_3080_3090_leak
How important do you all think having a board and cpu that supports PCIe 4.0 is for these cards?,rtx_3080_3090_leak
You guys are all complaining about the RTX 3080 having 10gb VRAM meanwhile I'm just sitting here with my GTX 1060 3gb...,rtx_3080_3090_leak
"I have a 3840 x 1600 175hz ultra wide monitor and most games I play atm bounce between 110 - 130fps with an OCed 2080ti at medium / high settings.

I don't care what the 3090 RTX costs, I will be buying one. I need it.",rtx_3080_3090_leak
"Lol people saying 10 GB of vram is not enough, stop gaming in 8K 🤣",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
oh nvidia such a dick move tbh if this all true lmao,rtx_3080_3090_leak
Will a 750 watt power supply be enough for a 3080?,rtx_3080_3090_leak
"So glad I bought an Asus Dual Evo RTX 2070 just recently, despite redditors telling me I should have waited a month for a next gen card that was going to be MUCH more powerful, meaning the 3070",rtx_3080_3090_leak
"I know everyones hyped for the high end but there is nothing but leaks. Like 200 fucking leaks of these two meant for people who have probably over 1200-3000$ ready to go and no rush sell their cards with no worry. Meanwhile the people I know are asking when they can get a 3060 or a 3070 at a good price compared to the current high end for nvidia now. Looks like I'm gonna tell em to go bstock and wait for a deal cause I ain't spending shit for nvidia if they wanna screw the mid and low end AGAIN. 

I'll stick with my 5700xt and I'll wait for Navi 21 cause it doesn't look good for nvidia this coming year.",rtx_3080_3090_leak
Based on what we know of the 3900 would a ryzen 7 2700x bottle neck it?,rtx_3080_3090_leak
ffs videocardz.com and their cloudflare firewall page.,rtx_3080_3090_leak
Idk abt specs but does the 3070 beat the 2080 (super)?,rtx_3080_3090_leak
Ok so I've got a 970sc that I really want to upgrade for cyberpunk. Sounds I just get a lesser model than these?,rtx_3080_3090_leak
soo how big of an upgrade are any of these coming from a 1070 for 1440p 144hz,rtx_3080_3090_leak
"8 gb non-X VRAM for 3070? Again? Wtf

Brb ordering a 2070s",rtx_3080_3090_leak
"\*cries in 1060\*

It feels like the tech progresses so quickly these days. Tbf I've had the card a few years and it paid itself off several times over (got it a little before mining went insane). Hopefully this pushes the price of the 2080 down to a point I can afford in time for Cyberpunk.",rtx_3080_3090_leak
There's no way the 3090 will be able to run the Crysis re-master on maximum settings.,rtx_3080_3090_leak
$2k for gpu is too much.,rtx_3080_3090_leak
Lol no thanks.,rtx_3080_3090_leak
I'm most interested in how much it's gonna cost...it takes time to sell a kidney.,rtx_3080_3090_leak
First I had to swallow the fact that the 3070 would likely be $600. Now it seems it might only have 8GB of VRAM. Upgrading from a $350 970 and this is just frustrating lol,rtx_3080_3090_leak
Someone should cross post this to wall street bets,rtx_3080_3090_leak
1080ti till it dies!!!!,rtx_3080_3090_leak
* pats 1080 ti ftw3 *,rtx_3080_3090_leak
1080ti is the one true King of graphics cards.,rtx_3080_3090_leak
Mark my words the 3080 is and under are not news if you have a 1080ti or 2080ti just keep them another go around or two unless you want and need 4k high refresh AAA play. 1440p forever! Anywho by time 4k 120hz ultra AAA is a $500 card game 3 years from now 8k will be out (as in regular enough but still enthusiast) and you will need $1500-2000  catdfor 8k 40-80fps lol.,rtx_3080_3090_leak
"I saw the specs for the RTX 3070 today. Only 8gb ram. Same as previous generation. It said that with no overclock, it’s as fast as a 1080ti.",rtx_3080_3090_leak
"There has to be a model they're holding back to launch against Big Navi.

24gigs to 10gigs is such a wide window it almost seems intentional. $1400 vs $800 in that same vein.

IMO they're looking for BN to drop somewhere in between at like 12-16gigs @$1000 and then Nvidia will drop their SUPERS to match.",rtx_3080_3090_leak
Am I the only person who still runs GTX 260 core 216 since it's been released and doesn't play other games other than wow and CS? I wouldn't even fall for new games out new standard upgrade pay $2000 for a graphics card.,rtx_3080_3090_leak
"Still running a 1070 OC at 3440 x 1440.

Excited to upgrade to the 3090 and upgrade my Am4 2700x to 4th gen Ryzen when they drop.

Not looking forward to getting fucked by the ""Australia Tax."" I do work that benefits from more CUDA cores, so the 3090 is going to be a massive upgrade for me. Wonder if the 850w will be enough now, with 1TB NVMe, 1TB SATA SSD, 3TB HDD and 64GB RAM :\",rtx_3080_3090_leak
"NVIDIA just going to refresh these in less than a year- it worked last time and they know it. Unless you're buying a 3090 you mise well wait. Looks like the 3070 will be the most worthless purchase on launch just like previous gen.

I'll hold out for final pricing though if 3060 looks good.",rtx_3080_3090_leak
Ps5 > PC 2,rtx_3080_3090_leak
"LMFAO. And I'm just glad I bought RTX 2070 super a month ago. There were people saying  ""JuSt wAiT tHe NeXt GeN, YoU wIlL nOt ReGrEt"".",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Chillax, they already announced that AIBs can make cards with custom RAM. I bet Asus and the like will make a 16GB 3080.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
3090 for 1080p yay or nay?,rtx_3080_3090_leak
Is it worth trying to Step-Up a recently bought EVGA 2070 Super to a 3070? I know it's all speculation right now but it looks like the 2070 super may be better in some ways.,rtx_3080_3090_leak
"Jesus Christ - 20GB DDR6...

I know it will probably be 5 years from now to be able to afford a card of that power but what will the next gen consoles gonna do, honestly? This is insane.",rtx_3080_3090_leak
At this stage they might as well build a cpu onto the board...,rtx_3080_3090_leak
is 10gb of vram enough for 1440p 120hz+?,rtx_3080_3090_leak
Fuck I just got a new gpu,rtx_3080_3090_leak
I wonder if the RTX 3090 will saturate a PCIE 3.0 x16 slot seeing as the 2080ti saw performance detriment from a 3.0 x8 slot,rtx_3080_3090_leak
"320 Watts for the 3080, and 350+ watts for the 3090.

The good news is that the 2020 Almanac is calling for a long cold winter. The bad news, ...ah who we kidding, there's no such thing as bad news. We're going into Palpatine mode, UNLIMITED POOOOOOOOWAAAH.",rtx_3080_3090_leak
This is the most disgusting and disappointing thing I’ve seen. Leakers have been preaching how this year was going to be a “generational leap”...my a**!!! This was just like the super series upgrade. Prices will be the same as the past generation it’s over. Please AMD...PLEASE DO SOMETHING,rtx_3080_3090_leak
"Same shit, bigger. Woho surprise!",rtx_3080_3090_leak
I'd wait for the 20GB Zotac card,rtx_3080_3090_leak
Will these be faster than my 1060?,rtx_3080_3090_leak
"This release looks like a real shitshow, i'll look again when they do the 4 or 5000 series (2080 ti here)",rtx_3080_3090_leak
"Yup, I don’t think anyone falls for that? I’ve seen 1080tis for €350-400 used now here and meanwhile some try to sell their 1070 for €280 and 1070ti for €350 lmao",rtx_3080_3090_leak
"Damn $700? Even $500 is absolutely ridiculous. 2080 ‘Tis  are still going for $900 though, the current flagship cards have a lot of prestige.",rtx_3080_3090_leak
Whistles and twiddles thumbs in 1060.....,rtx_3080_3090_leak
I have a gtx 1080. Works pretty ok for me.,rtx_3080_3090_leak
I freaked out for a second just bought one for 700 dollars. Then realised youre probably american and aud is in the shits rn,rtx_3080_3090_leak
The market is messed up. I upgrade my friends fx series and CPU and sold it for like 150 bucks. (Just the cpu) someone paid for a ryzen 5 and got 1/10th the performance..,rtx_3080_3090_leak
Im selling my 2080ti at 500 bucks. TOPS. Whoever does more than that is an idiot,rtx_3080_3090_leak
"Not really that many people keep up with hardware news or upcoming product launches.

Those that do often try to time their purchases/sales so they lose the least amount of money by price gauging, which will be much more difficult once the 3X series and is widely aviable. Particularly the old 2X cards, and the 1080ti will quickly lose resale value.",rtx_3080_3090_leak
980ti's go for about 150 on ebay. Amazing deal if you ask me considering i was doing some high end vr on one a while back before buying a new pc,rtx_3080_3090_leak
I plan on selling my 1080Ti for 350 when the 3090 comes out,rtx_3080_3090_leak
Lol its wack I was actually considering buying a 1080 but I found the 2070 to be like 200-300 dollars cheaper lol. Speaking of this isn’t the price inflation for older cards mainly due to nvidia stopped manufacturing them as they focus on the new ones. I read somewhere they are going to discontinue producing the current gen nvidia once the new 30xx ones come out but not sure.,rtx_3080_3090_leak
Interested in buying my 980 ti for $1500?,rtx_3080_3090_leak
I'm not pc master race so I have no clue whats what........ I am pre ordering ps5.,rtx_3080_3090_leak
I legit just bought a 2080 ti for 800. It's ridiculous what people are trying to get for used cards.,rtx_3080_3090_leak
2080s on Newegg are going for 1300. I just got a 2080 super 2 months ago for 739 and that same card is 1299 on Newegg right now. The fuck is going on? New cards will be out in a month.,rtx_3080_3090_leak
I bought my 1080 2 years ago for $325,rtx_3080_3090_leak
come to australia where you’ll be very lucky to find a secondhand 1080ti for that much,rtx_3080_3090_leak
I've already lined up a buyer for mine. $450 for the card and a waterblock post release. Cant imagine trying to sell it for $700,rtx_3080_3090_leak
My friend got sold a computer for a fair price but he thought it was like 6-700$ off; somehow people can get PCPartPicker to show 489$ for a 1060 3gb. Crazy the shit people try to pull.,rtx_3080_3090_leak
"in my area, people are selling 1080Tis for $400 Canadian",rtx_3080_3090_leak
"Who cares? The market will determine if these guys can get that kind of money for those cards. If I place my iPhone 11 on the market for 25,000 dollars, should anyone actually be angry with me? Just laugh it off.",rtx_3080_3090_leak
1080ti is history... if you want to buy a GPU now .. then go for newest ones ...always.,rtx_3080_3090_leak
Sold my 1080 ti today for 400,rtx_3080_3090_leak
I know... I'm thinking of selling mine because I see them being sold for $600 and then I could easily upgrade. Plus it's an FE with hybrid cooler installed.,rtx_3080_3090_leak
Couldn't agree more!!! Graphics card pricing makes zero sense!,rtx_3080_3090_leak
Just sold my 2080ti FE I got at launch for the same price I paid for it. I threw my 1080ti in the rig and it’s like it never missed a beat.,rtx_3080_3090_leak
"Buy 3090 now, get mad that 20 GB 3080 comes out.",rtx_3080_3090_leak
"Buy 3090. #nopoors.

Edit: No, wait. Don't buy it immediately so I have stock to buy mine. Buy it a bit later. Thanks.",rtx_3080_3090_leak
"As much as I want a 3090 I will probably wait for a more reasonable 20Gb 3080 from some AIB. NVIDIA can go screw themselves for forcing us to choose between 10Gb 3080 and 24Gb 3090. This is outright dirty, they are charging premium for 3090 and not its honest price (which should cover development costs and modest return on investment).",rtx_3080_3090_leak
"With the info we have now there seems to be a HUGE gap between the 3080 and 3090. Looks like this will be a theme until the launch day. If the 3090 is priced super high, and there is nothing in between the two, I expect chaos in here.",rtx_3080_3090_leak
I might need that answer lmao,rtx_3080_3090_leak
"Personally, the actual prices are gonna determine what I do. 

I’ve seen pricing rumors from $1400 to somewhere around $2500 for the 3090. 

If pricing is closer to $2500, I’m gonna wait ride with my 2080 Super until we see how things shake out with a 20GB 3080 variant. 

But if the 3090 is priced closer to $1400, I might just jump on that.",rtx_3080_3090_leak
fools still don’t know how to abuse warranty,rtx_3080_3090_leak
8gb is plenty for 1440p which the majority of people buying that card are probably using,rtx_3080_3090_leak
I just want 1440p High settings at 120Hz. Is that too much to ask?,rtx_3080_3090_leak
"I don't remember the exact details, but it has been mentioned somewhere that those cards may use some form of compression utilising tensor cores. If this is the case, then 8GB on Turing  != 8GB on Ampere.

We'll see in just a couple of days.",rtx_3080_3090_leak
Why are people harping on this so much? Have we actually seen performance issues from only having 8 GB of VRAM?,rtx_3080_3090_leak
Looks like my 2070 Super FE was a good buy a few months back.,rtx_3080_3090_leak
"And at 600 dollars thanks Nvidia. Seriously hope these come at 500 or under, 70 series usally have the same ram amount as the 80 series, the fact they gave only 8GB is bad enough, but also not offering GDDR6X is just a scam.",rtx_3080_3090_leak
"Agreed. 8GB is a discrace for a 3070 in 2020.

For those that are saying it's ""plenty"", then try running Mankind Divided at 1440p on ""Ultra"" with MSAA on. Go look at afterburner and see how much ram is being used. Well over 8GB.

Guru3D also has shown that MFS2020 will just about use up 8GB completely for ""1440p Ultra"", but as soon as you turn on ""dense terrain"" it will shoot up several more GB.

When VRAM runs out, you will get piss junk performance. Typically meaning unplayable. The 3070 @ the anticipated $600 deserves more than 8GB. Can we at least get 10-12GB?",rtx_3080_3090_leak
"How to make a new 1000's series video card:

* Make the best card you can and call is the --80.

* Trim down quality to get the --70 and --60 line.

* Limit vram of the --70 and --60 to ensure easy upgrade options for the the super variant. 

* big ole profit time.",rtx_3080_3090_leak
I really thought they would have gone with more Vram considering the 1070 has 8GB. Oh well,rtx_3080_3090_leak
"That or AIBs will have models with 20GB but will probably cost $100-200 more than base model.

EDIT: It will be best to carry some restraint going into the Nvidia announcement. Don't panic buy if you are not happy with the VRAM amount. Wait and see what the AIBs do.",rtx_3080_3090_leak
AIB 20GB model coming as well for 3080,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"There will absolutely be higher variants, but next years ""Super or Ti"" launch will be the most exciting I think.",rtx_3080_3090_leak
"no we wont, there would need to be headroom with the die itself. 3070 wont get more than 8gb simply because the 104 die is 256bit bus. Thats either 8gb or 16gb.",rtx_3080_3090_leak
"Don't worry, it well compensated by TDP of 320 and 220 watt",rtx_3080_3090_leak
"Yeah, might as well wait till the 4000 series. 

/s",rtx_3080_3090_leak
That's kind of annoying that we basically have to wait again to not get ripped off.  Hopefully AMD pulls out something good,rtx_3080_3090_leak
"Totally talking out of my ass here, but there still is that rumor about Tensor VRAM compression. If that technology is coming with the cards and the 20-40% decreased use of VRAM is true, nvidia might cleverly use it for its marketing to praise the cards to actually have 20-40% more vram than physically availible.

Something about the 10gb on the 3080 make so little sense, that i feel like that rumor might actually be true.",rtx_3080_3090_leak
"I mean what games realistically need more than 10 though, every game I've run at max settings at 4k doesnt really come close to 10gb, the only game Ive seen come close to 10 is a heavily HEAVILY modded skyrim with 200 texture mods mostly at 4-8k res and even that only hit 9.8gb at 4k",rtx_3080_3090_leak
Comment on unreleased product and speculate too. Thanks for being useful,rtx_3080_3090_leak
"I never understand Nvidia, why cant they do half of the memory chips as double capacity. They did it back in GTX550, it doesnt have that weird memory issue like GTX970.

15GB for 3080 is more than fine & not overkill. 12GB 3070 is decent too.",rtx_3080_3090_leak
"This 1080 has been a fine investment. I was too late to the cheap Ti party, but this chip will remain usable at 1440p 144Hz for a while yet.",rtx_3080_3090_leak
"If you purchased a 1080ti around the time that thing launched, the value is unreal. It was reasonably priced for the highest end card and is still a top performer almost 4 years later. Best card Nvidia ever made. Will likely still be really solid for a while. Legendary",rtx_3080_3090_leak
"Haha, have an upvote.
Same feelings here.",rtx_3080_3090_leak
GOAT GPU,rtx_3080_3090_leak
"the 970 looks at me. looks *through* me.. its thousand yard stare cold and lifeless... begins to speak..falters...again it tries...  

""when?"" it whispers..

""when? what do you mean?"", i say

""i have given your more, so much more than i was meant to. than any of us were *meant* to"",  it says. 

i consider this for a moment. the overclock was an effective but limited means of prolonging its lifespan, even these two generations past. Its faithful service from the days of the triple A has slowed, in time, to pixel art. 

it continues...""i have served to the best of my ability, faithfully, without falter, all these years past. i have watched my sons and grandsons come and go..so i ask again: when? When will it be enough?""

i look at the 970. i look at it's faded glory and dim RGB and see the truth of it. it lays in the ghost of its predecessor, the 560ti...

""a while more....a while more...""",rtx_3080_3090_leak
"Yeah, at this point the 1080ti might just be the greatest value GPU ever released. I use to buy GPUs ever year or 2, but Nvidia hasn't seriously sold a good product in almost 4 years",rtx_3080_3090_leak
Might have to upgrade my 970 finally.,rtx_3080_3090_leak
"Rright? At 3440 x1440p, 120hz i still cant find a reason to replace this card. Absolute fantastic investment.",rtx_3080_3090_leak
"Don't give up yet, we still haven't seen benchmark and price.",rtx_3080_3090_leak
"Yeah I'm thinking the same, altho I have a Titan XP 12GB (Pascal). Its still rocking but two recent games have made it struggle on my Samsung G9, Horizon Zero Dawn and MS Flight Sim 2020.

Was thinking a 20GB RTX3080 a must, as both of those games use 11.5GB of VRAM on ultra settings :(

Getting a 10GB 3080 makes zero sense for me.

So I'll be joining the other folk for another tour with a Pascal card...


...if the 3090 is £1400+, there is no chance!",rtx_3080_3090_leak
"o7 to that, sir.",rtx_3080_3090_leak
Yep. I need to figure out how to replace the thermal paste on mine,rtx_3080_3090_leak
Got 1080ti at launch since 780ti needed upgrading.  Haven’t looked back since.,rtx_3080_3090_leak
"When I went from 980 twins to 1080ti it was a leap in performance.

When my 1080ti died a horrible death with the rest of my PC, the 2080ti I bought is basically equal to the 1080ti. I don't see a difference in any of my games except when I played with Minecraft RTX for a week.",rtx_3080_3090_leak
Best card investment I've ever made,rtx_3080_3090_leak
My 980ti served many tours but sadly didn't make it to the end of this current one.,rtx_3080_3090_leak
Lol.  R9 fury.,rtx_3080_3090_leak
If the rumors that next year we are getting a new gen are true i'd keep the 1080ti too,rtx_3080_3090_leak
"nope, 1080 ti is sayonara bye bye. Hello 3090.",rtx_3080_3090_leak
1050ti here💀 didnt know they shit these things out every year,rtx_3080_3090_leak
"So i have a base 1080, would it be worth it for me to upgrade to a ti since i got a 4k monitor? Or is there not much of a difference",rtx_3080_3090_leak
I got a 1080 in both of my computers and I'm at least waiting until the second iteration of the 3 series hits.,rtx_3080_3090_leak
"The most beast-mode workhorse video card ever created. 

Not only is its power overwhelming despite its age, but the value ratio of cost to power/longevity is staggering.",rtx_3080_3090_leak
I felt pretty foolish spending the money and time applying a Raijintek to my 1080ti. Welp,rtx_3080_3090_leak
"Yeah... nobody's gonna buy these till AMD makes them drop prices. Near-$500 for a xx60 series is insane, and I'd say the same thing about 2060 pricing. Remember the 970 at $300? Competition was nice.


Oh, and another thing... For those saying hurr durr 2060 performs like a 1070 and it's the same price or whatever... *performance is supposed to get cheaper with time.*",rtx_3080_3090_leak
"I bought my 1080ti for $1100CAD with a free game and mouse mat in 2017, and just resold it for $800. Best investment ever.",rtx_3080_3090_leak
"But I use a 4k monitor, so my 1080ti is barely hanging on. He's been a champ so far.",rtx_3080_3090_leak
Right?! What is the deal with the HUGE gap in between the 3080 and 3090?!,rtx_3080_3090_leak
"3090 is looking to be double 1080ti performance. He’s had a good run, but it’s time for a new performance king",rtx_3080_3090_leak
"Calling it now, they be gimping that card so they can release a Super Variant with 12GB, 500mhz boost and GDDR6X in about a year down the line.",rtx_3080_3090_leak
It not having GDDR6X memory surprises me the most to be honest.,rtx_3080_3090_leak
"If that's what keeps the price down, I will happily buy a 3070 with 8GB. But to be honest, I have a 1060 now so this is still ~~an upgrade~~ a major upgrade

edit for emphasis",rtx_3080_3090_leak
"Probably almost as fast as a 2080Ti, but reusing the same memory configuration as the RTX 2070. That GPU is powerful enough for 4K gaming and raytracing, but the memory won't allow it :(",rtx_3080_3090_leak
"Yup, pretty bummed to see that. Was really hoping for 10-12GB 3070 and 16GB 3080. Looks like I'll be holding out til 4000 series. Can't justify an upgrade from my 8GB 2060 Super even with the 10GB 3080. Hopefully RDNA2 provides a decent option.",rtx_3080_3090_leak
Wonder how this will play out with console ports which are developed for next gen consoles.,rtx_3080_3090_leak
"8gb is nothing. And the moderator saying that vram isn't everything is bs. With the increase in resolutions and textures, 8 gb is not enough. My 1080Ti from far 2017 has more Vram.",rtx_3080_3090_leak
My 970 with 4GB laughs at your problems.,rtx_3080_3090_leak
Remember this is just based on a rumor not officially confirmed yet. I wish it doesn't ends being true though..,rtx_3080_3090_leak
16gbps and potentially NVcache would make it as fast as a 2080Ti,rtx_3080_3090_leak
"On the other hand, 3070 in September is music to my ears.  Thought I'd have to wait a bit longer.  Upgrading from RX580, so will still be massive for me.",rtx_3080_3090_leak
It's the 3080 only having 10gb for me,rtx_3080_3090_leak
"8GB is enough for up to 3440x1440 even with GDDR5x, its all good man. Put down the pitchfork.

Hell, you could even game at 4k, but your milage is gonna vary depending on the title.",rtx_3080_3090_leak
"Do we *need* more than that 8GB* for most games? I'm pretty sure most of us don't even measure the amount we're currently using, ~~probably because Task manager doesn't show.~~ **[it does](https://i.imgur.com/Qx71QCa.png)**, I just never used it before.

Yes, we're likely going to need more in the future, but the future isn't now, yet.",rtx_3080_3090_leak
I think I just opted out of buying a new card,rtx_3080_3090_leak
Bro I just want 60 FPS ;__;,rtx_3080_3090_leak
Is 8gb enough for 1440p?,rtx_3080_3090_leak
He's usually right. He kept saying 19.5Gbps for a few weeks now,rtx_3080_3090_leak
The 21gb/s is probably Microns target which means the Super refresh next year will have 21gb/s,rtx_3080_3090_leak
"Kopitie7kimi was damn certain on 8nm Samsung but was right on downgrading the GDDR6X to 19.5 from 21: https://twitter.com/kopite7kimi/status/1288444657345560576

I suspect we'll be getting a 3080 Ti 12GB 21 Gbps soon if Navi 21 has very good performance.",rtx_3080_3090_leak
Can someone explainlikeI’m5 this comment?,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
We don't know if It's TSMC's 7nm or Samsung's 8nm rebranded as Nvidia custom 7nm.,rtx_3080_3090_leak
I can’t believe it.... I don’t think anyone saw this coming... I was completely expect 7nm to be on their refreshes some time after initial launch,rtx_3080_3090_leak
"No they didn't. Jensen literally said that TSMC would be getting the majority of their 7nm orders. Nvidia wasn't going to completely redesign their entire GPU just to work on 10nm.

This 8nm rumour was complete unsubstantiated crap from leakers who just make shit up half the time.",rtx_3080_3090_leak
"This is the big news here. Makes it much more tempting to get the 3090 since the card is now truly a ""no holding back"" step in video cards. With Samsung 8nm you were never gonna feel that great buying something power hungry and inefficient while and was working on the better node.",rtx_3080_3090_leak
what is nm,rtx_3080_3090_leak
"I'm really confused if they are using TSMC 7nm why do they need this insane cooler. It should be an efficient node. This doesn't add up to me. Also, this doesn't seem like a confirmation, and it doesn't mention TSMC at all.",rtx_3080_3090_leak
I get the feeling the 20GB variant of the 3080 will cost you 1k at the minimum.,rtx_3080_3090_leak
"Yikes, I'm here with a 970  with effectivly 3.5gb of vram. Im only finally deciding to upgrade this generation. Since high-ultra setting at 1080p as nowhere near as attainable as it used be and I want cyberpunk in all its next gen setting.

Im also planning on picking up an ultrawide 1440p 144hz montior so thats a factor. Especially with their cost coming down to about 400 lately",rtx_3080_3090_leak
"Basically on the same boat. I won't change my 1080TI for a, what? 800€ card that has less VRAM? Right now that the new consoles are going to bring higher requirements?

That and according to what I read, the new consoles bring AMD RTX technology. Knowing how lazy companies are with PC ports, it might even be a bit of a problem with nvidia RTX cards, even if they were supposed to be faster on paper.

I am way more interested at this point in what AMD shows. Looks like nvidia cards aren't catering to me these last years.",rtx_3080_3090_leak
"There's got to be a release between 3090 and 3080.
If 3090 is the new titan, a 3080ti will come out later on.

Hopefully.",rtx_3080_3090_leak
">3080 20GB TBA, so i guess they come in 2021

It's not. It'll come after this launch period. Otherwise it makes no sense",rtx_3080_3090_leak
"> As a 1080Ti owner for 3.5 years now i realy hate these options.

Gotta agree. Who asked for 24GB of VRAM anyway. I sure as hell didn't. It gives the card such an unncessary huge cost and price increase. It's kinda dumb.",rtx_3080_3090_leak
"I'm in the same boat, exactly the same. I'm sorta hoping AMD helps push the prices down.",rtx_3080_3090_leak
"but on the other hand, you're really getting your 1080Ti money's worth",rtx_3080_3090_leak
"Considering the 3080 has a rumored memory bandwidth of 760GB/s vs 484.4 GB/s on the 1080ti, I wouldn't sweat that 1GB of VRAM too much. In benchmarks it'll probably outperform the 1080ti by a good margin.

Depending on benchmarks I might still get it but I feel my 1080ti is still great at 1440p. Might want to wait a bit longer for the inevitable SUPER or whatever bullshit NVIDIA comes up with.",rtx_3080_3090_leak
Bold of you to assume Big Navi is going to beat 3080. Either way no harm in waiting to find out?,rtx_3080_3090_leak
"Yea we are all here basically being forced to wait for a 3080 20gb version, but guarantee that wont come before cyberpunk, as as a UK consumer I really have to purchase a GPU before we crash out of the EU in January and prices here skyrocket.

Really not looking forward to the announcement now because it either means I will have to bankrupt myself with a 3090 (probably new power supply needed for that too) or get a downgrade in Vram amount given I am gaming at 4k I think my fps might actually take a hit in some games from the 1080ti.",rtx_3080_3090_leak
yup - i'm not spending $800 for less VRAM. If i'm spending that much money on a card I should know it's going to be good for 4 years at least.,rtx_3080_3090_leak
"If you “don’t do 4 digit cards” you’re never going to upgrade from your 1080Ti, unless you shop used. GL.",rtx_3080_3090_leak
If you think ultra cyberpunk is going to use more than 10GB VRAM then you’re nuts.,rtx_3080_3090_leak
"This isn't a downgrade, holy fuck are people dumb. A game using up 8 GB of VRAM on your 1080 Ti will use less than 8 GB of VRAM on a 3080. Completely different architecture and different speeds.",rtx_3080_3090_leak
The 3080 will probably run laps around your 1080ti.  Ram isn’t everything.,rtx_3080_3090_leak
"I'm in the same boat as you. Marketing wise the difference between 3080/3070 and 3090 is insane, it makes no sense.",rtx_3080_3090_leak
"Erm, sorry while I crawl from under my rock...but how solid is that we get big navi in november?",rtx_3080_3090_leak
Yeah it's all down to pricing right now. If the 3090 is over $1400 I'll be waiting even longer. Hell even if it's over $1200 I'll still have to think hard about it. The 1080ti is still a beast in 2020.,rtx_3080_3090_leak
"I bought a 2080 TI from EVGA, b stock, for around $900 and change a while back. Comes with 1 year warranty and EVGA makes good stuff. Might be worth aiming for that.",rtx_3080_3090_leak
I have a 1080 and i feel i will still have to wait for the 4000 series to see anything worth upgrading. Right now the cards are way overpriced.,rtx_3080_3090_leak
1080ti will probably still kick ass at 4K 60 tho,rtx_3080_3090_leak
"1080Ti still performs very well anyway, right?",rtx_3080_3090_leak
Why do you want to upgrade for Cyberpunk ? unless you wanna play 4k 120hz?,rtx_3080_3090_leak
Sprich Deutsch du Grafikkartensohn!,rtx_3080_3090_leak
"At this point I'm considering selling my 1080 Ti and PG279Q and getting one of the upcoming AMD cards and an Ultrawide Freesync monitor. Naturally it won't be the performance of a 3090, but if I can just get a decent performance boost with ray tracing capabilities to boot, I think I'd be cool.",rtx_3080_3090_leak
"Nvidia is in full control of the market since AMD fails to provide adequate competition. Anyone expecting them to not pull off the usual bullshit that every single company does when they're on the top is an idiot. The PC gaming market is downright garbage right now with these prices. With new consoles coming up, I bet lots of people who would otherwise upgrade are just gonna get a ps5 or xbox and be done with it.",rtx_3080_3090_leak
What’s a 4 digit card?,rtx_3080_3090_leak
">	I sure af wont do a VRAM downgrade, so 3080 and 3070 are out. 

That’s what they’re banking on for all the current 1080 Ti owners now starting to get that upgrade itch. As soon as you decide to base your decision on a single spec number instead of actual real-world performance, you’ve played yourself right into their funnel.

They *want* you to turn your nose up and scoff at the mere thought of an 8GB or 10GB card, because now you’ve just convinced yourself that your only reasonable upgrade path is their high margin halo product. The best part is that you’ve already made this internal choice based on leaked specs and they didn’t even have to spend a penny convincing you.

Games are built to run on mainstream hardware configurations. Historically parts with abnormally high VRAM configurations for the era have rarely seen much if any benefit outside of a few niche use cases. Most of the time what you see is that by the time you might find an actual difference, the actual performance of the core itself can’t keep up anyway. It mattered slightly more in the past when multi-GPU setups were more common, as the frame buffer had to be shared.

Ignore the specs and look at what the products actually deliver for performance and features to decide whether it makes a sensible upgrade for you. A 2070 Super edges out a 1080 Ti even at high resolutions with just architectural and clock speed improvements, despite the numbers on paper showing spec deficits across the board in comparison.",rtx_3080_3090_leak
I'm the same with 1080ti. Gaming at 3440x1440 160hz on monitor and 4k 120hz tv once HDMI 2.1 is here. I don't want to be going backwards on vram,rtx_3080_3090_leak
"Yeah I was looking at this for my 1070Ti upgrade - looking more towards team red now, since this is stupidity - I want future proofing; and I don’t want to rob a bloody bank to achieve this. 

I mean, I already use an AMD cpu - might as well throw a GPU in there if the performance warrants it.",rtx_3080_3090_leak
"Yes sir, 1080TI for life. If these mofos think I'm spending 1k+ for less than 50 percent performance its a no go.",rtx_3080_3090_leak
Why would you even need to upgrade from a 1080ti?,rtx_3080_3090_leak
It’ll be fine don’t overthink things...,rtx_3080_3090_leak
They probably have some fancy compression to make the downgrade a non issue. Y’all need to chill with the fixation on specs before the cards are even announced,rtx_3080_3090_leak
"Saying ""I don't do 4 digit cards"" while also aiming for the best performance is like walking in a Lamborghini showroom with 50,000$ in your pocket looking to make a purchase.

Also, if you're brave enough to get an AMD card after the disastrous launch of the RX 5700 XT, go right ahead. The fact that it took that company over 1 year to offer a stable GPU that doesn't showcase some form of issue in some way just proves the company's incompetency in the driver support area.",rtx_3080_3090_leak
"I'd hold out till Big Navi. 

But I bet there will be disappointment with it. At that point a 20gb 3080 or potentially a 3080 Ti may come out.",rtx_3080_3090_leak
"As someone who has been a loyal Nvidia fan for years, this may be the first time I buy AMD instead...(I skipped Turing all together). What a sad time to be a PC gamer.",rtx_3080_3090_leak
"The VRAM throughput is much higher, your jumping the gun caring it a downgrade. 

Don't focus on the cover of the book here, let's see the results.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
AMD might interest you,rtx_3080_3090_leak
Just sold my 2080Ti for 800€. Can't wait!,rtx_3080_3090_leak
Do you know what time it will go live on Monday?  I live in UK,rtx_3080_3090_leak
"Four more days, me Johnny, four more days, me Johnny,

Oh rock and roll me ooo-hooover, four more days!",rtx_3080_3090_leak
Wait I'm out of the loop..four more days to what?,rtx_3080_3090_leak
"4 more years for me, just bought a RTX 2070.  Not going to be suckered in by the hype.  Will just get a 4000 series at non-launch.

Went from a GTX 970 to the 2070, so even getting a 4070 next won't be that huge a leap, what to say of a 3070",rtx_3080_3090_leak
I really hope it will be included or they can issue a firmware update to enable it. I don’t think it’s acceptable to not include it.,rtx_3080_3090_leak
On the super refreshes of course /s,rtx_3080_3090_leak
That ...,rtx_3080_3090_leak
"Use HDMI 2.1, unless you need 16k of course, or 8k90fps

But monitors with DP 2.0 don't even exist yet",rtx_3080_3090_leak
The real question is if EVGA step up program would let you step up from a 10gb to a 20gb 3080....,rtx_3080_3090_leak
Thank you for the most logical comment in this entire thread.,rtx_3080_3090_leak
"Regardless, I think many 1080ti owners won't feel good spending 800 euros to go from 11 to 10GB.

3090 will most likely be way too expensive.

I hope Big Navi can compete.. 16GB sounds nice, and we need a competition to get prices back to normal again.",rtx_3080_3090_leak
"As a PC rookie, looking to build his first PC, thanks for making me feel a bit better about a likely 3080 purchase, haha.",rtx_3080_3090_leak
"> Looking at the size of the 3090 it seems to me like Nvidia know the performance difference between these two cards isnt actually going to be that great

What are you talking about the cooler on the 3090 is CONSIDERABLY bigger than the one one the 3080. That indicates it will be much more powerful in my book.",rtx_3080_3090_leak
"Yes I believe the 3090 is just to hold the top card title, but the real battle will be the 3080 vs 6700XT (Or whatever they call it). The 2080 super and 2080ti is a 12% FPS difference for 400 dollars, which doesn't make sense other than owning 'the best of the best' for the 1%ers of PCGaming (or 4k addicts like myself)

So it's also funny funny to me (assuming rumors are accurate) that they hot-rodded the card to run at 350-400 watts, which meant they had to slap a $150 cooler on it, raise the price to $1400, then ask 'hmm how do we justify this... ah yes 24GB ram it is, then we short the lower tier cards, ha so smart'

I predict the real value will be in owning a 3080 and then selling for 5nm Hopper.",rtx_3080_3090_leak
">there really arent a lot of things that gamers will do to max out the 10GB

But they do exist.  Tomb Raider at 4K, max graphics can use over 10GB VRAM.  Having a next gen 4K card with only 10GB VRAM is not enough.",rtx_3080_3090_leak
Won’t raytracing take up a huge amount of vram?,rtx_3080_3090_leak
"> there really arent a lot of things that gamers will do to max out the 10GB

On *current* games that are (like it or not) made for *current* consoles with 8GiB of shared RAM/VRAM. This is such a ridiculous argument.

Just before this generation of consoles got released, I'm sure you were there telling us that there aren't a lot of things that gamers will do to max out 4GiB, and that no one could ever possibly need 8GiB of VRAM.",rtx_3080_3090_leak
Did you really expect anything different?most people don't really know what they are talking about,rtx_3080_3090_leak
"Wish more people could see this, everyone’s commenting the same shot and it’s fucking annoying seeing them everywhere saying “muh VRAM downgrade NVIDIA bad money machine go brrr” like there was mechanical reasoning behind it, they didn’t just do it to make the gap between the cards bigger.",rtx_3080_3090_leak
"> there really arent a lot of things that gamers will do to max out the 10GB

today.",rtx_3080_3090_leak
How does the memory bus effect the possible VRAM configurations? Why wouldn't they be able to just slab 12GB on it instead?,rtx_3080_3090_leak
"Only reason games don't max out it because they're built for consoles that have 4-5 GB max of usable memory. 

The upcoming consoles that games will be designed around are working with at least 12GB, not to mention their use of the SSD beyond faster storage. 

It makes no sense to drop Down in vram when we know for fact that the requirements are only going to go up.",rtx_3080_3090_leak
"I am pretty sure that people planning to buy the top end cards want to keep it for years.

8GB now might be okay but is crap if you are planning to keep your GPU for years.",rtx_3080_3090_leak
"Spoken like someone who hasn’t played flight simulator 2020, I have a 1080ti and I’m using 11gb almost always",rtx_3080_3090_leak
"I currently have a 2070 super.  Getting average 47fps on 3840 x 1600 maxed settings.  Warzone

You think I can expect 100fps gaming at maxed out settings with this 3080?",rtx_3080_3090_leak
And people said you don't need to worry about how many cores you have on your CPU and when a year later core counts started massively increasing and games changed to accommodate that those people had to upgrade earlier than they expected to get reasonable performance.,rtx_3080_3090_leak
I think the 3089 will have the same cooler and it just costs way too much so they had to skimp on the ram where it doesn't affect gaming performance all that much most of the time. The AIBs can offer a 20gb model since they aren't using the Uber expensive cooler and potentially offer a better prices 10gb aib 3080 when big Navi rolls around (alongside a refreshed 3080 super),rtx_3080_3090_leak
But why does the 3080 use 320w at 10gb of memory and the 3090 use 350w with over twice the amount of memory? Memory alone can't be the only reason for high TDP,rtx_3080_3090_leak
It will probably consume around 400 watts with a full OC. 350 watts stock. That's my guess with the information that is out currently.,rtx_3080_3090_leak
A 3070 at 220W would run on a 550W power supply right?,rtx_3080_3090_leak
Is tdp the power supply? I'm sorry I don't know lingo and I'm a smoothbrain,rtx_3080_3090_leak
"Nooblet here, what is TDP and how does it affect graphics cards?",rtx_3080_3090_leak
I'm really puzzled by the power usage of the new cards. It suggests performance per watt won't increase much if at all. I don't think it can be just the memory. 7nm should of brought the power usage right down,rtx_3080_3090_leak
Probably not,rtx_3080_3090_leak
Curious as well as something with a 9900k PCI 3 and considering a 3090.,rtx_3080_3090_leak
"No, watch the video hardware unboxed made. Pci-e 8x vs 16x gave some difference in some games but it was small for the 2080ti. Means there is more than enough bandwidth for the 2080ti in pcie 3.0x16. You probably need a card twice as fast to make any difference.",rtx_3080_3090_leak
Highly highly unlikely,rtx_3080_3090_leak
Very weak chances unless the game really needs it.,rtx_3080_3090_leak
They should be backward compatible with 3.Xx 16 slots. This was the case back when the 3.x slots were new and 2.x were common. 4.x slots are new and almost no motherboards have them.,rtx_3080_3090_leak
"No, that's likely only to be an issue for compute-heavy workloads sending lots of data back/forth between GPU and CPU.

The vast majority of work & IO overhead happens on the GPU itself.",rtx_3080_3090_leak
Hopefully not. I have a 7820x and I'm eyeing the 3090. I really don't want to upgrade my CPU as well.,rtx_3080_3090_leak
Probably a few percent. Not by a lot.,rtx_3080_3090_leak
Likely by a few percent. I think this combined with ryzen 4000 is spelling some doom for intel,rtx_3080_3090_leak
"Lol that would fuck over Intel users, so I wouldn't bet on it.",rtx_3080_3090_leak
Can't tell 1 bean from 2 and that's coming from a space force pilot.,rtx_3080_3090_leak
That is a bummer. Is DP 2.0 needed for 4K 144hz?,rtx_3080_3090_leak
There aren’t even any monitors that exist that have it. The next flagship stuff will still have 1.4.,rtx_3080_3090_leak
"I REALLY hopes that's wrong. HDMI 2.1 is nice, but no DP 2.0 is a huge mistake IMHO.",rtx_3080_3090_leak
"DP 2.0 test tools don't exist yet, they are in development. high data rate means relatively expensive equipment as well; obviously for amd/nvidia that doesn't mean much but overall adoption will take a while. don't expect to see DP 2.0 in stuff until late 2021, more likely 2022.",rtx_3080_3090_leak
"Because of the Vram? Everyone was saying the same about the 2080TI and the vram, this time you have GDD6X wich is way faster. Wait for the reveal , it is also rumored that AIB partners will increase the Vram of those cards.",rtx_3080_3090_leak
">but this news saddens me :(

Nvidia, saddening gamers since 2018.",rtx_3080_3090_leak
"Worth waiting for news on other cards, incl. AIB models",rtx_3080_3090_leak
SAMEEEEEEEEEEEEEEEE,rtx_3080_3090_leak
Yasssss. 4k 120hz gsync HDR OLED is calling,rtx_3080_3090_leak
First we need monitors with hdmi 2 1,rtx_3080_3090_leak
VR or flight sims.,rtx_3080_3090_leak
Because current Games already max out 11GB of VRAM at 1440p. E.g. Warzone.,rtx_3080_3090_leak
As games get bigger and textures get high quality the file size gets bigger. Game words are also getting larger with further LOD. Seeing less and less gaming tricks like the fake fog games always had in the distance so you couldn't see very far and essentially not render the rest of the world,rtx_3080_3090_leak
I don’t know how old you are but amd has had gpu driver issues for decades now (ati). The fact this has been going on as long as I can remember leads me to think you probably shouldn’t hold your breath. You can go back to the 90s and find all the known issues for games on their cards. It put me off then and it puts me off now. I don’t even care what their raw performance is because I know I’ll have to deal with all sorts of amd specific issues in games that wouldn’t be worth it.,rtx_3080_3090_leak
"Big Navi's supposed to be like two months from now, they're not doing to do a refresh after such a short time.  IF a refresh on this gen happens it'll be some time in 2021.",rtx_3080_3090_leak
But you're kingpin. Gotta break them records,rtx_3080_3090_leak
Nearly a month.,rtx_3080_3090_leak
Last time I ordered a palit 2070 super on launch week so hopefully will be same again,rtx_3080_3090_leak
Theoretically they're going to launch at the same time. However the 3080 20GB (if it will be a thing) will launch a month or two later.,rtx_3080_3090_leak
Game developers don't work in a vacuum. They target the hardware that is available on the market and budget their assets and game engines accordingly.,rtx_3080_3090_leak
"People are just circlejerking. For the next couple years, it's more than enough.

I have 2080 Ti with 11GB VRAM running 1440p/120 just fine on all games maxed out.

Of course more VRAM is good for future proofing (maybe) but by then your GPU performance will severely fell off the pack anyway and you'll probably want to upgrade.",rtx_3080_3090_leak
"It depends, VRAM isn't everything. I have an RX580 8gb in my old machine and some games, yes, that 8gb is tied directly to my frames. Others, it's largely irrelevant. No rhyme or reason at surface level. 

I would honestly not bother until the beginning of next year if your current GPU isn't in it's death throes. I bought a new machine and chucked a 2060 Super in it since I was planning on buying an Ampere Q1 2021. Now I'm skeptical because the 3080 is looking underwhelming and I refuse to buy a 4 digit GPU. Wait for benchmarks and Big Navi to make an informed buying decision.",rtx_3080_3090_leak
"It's legit a lot more than enough. Unless you're running the very latest games at the max textures setting (and the game is unoptimized) you can do just fine with 10GB.

8GB was the perfect amount for 1440P. 10GB is just another breath of fresh air.

But people being people (and the subreddit being plagued with AMD fanboys at the moment) obviously everybody is going to behave like this gen is going to be tragic or tragically underwhelmed.",rtx_3080_3090_leak
"Ummm,, I'm using a 1440p ultrawide, and Microsoft Flight Simulator 2020. It consistently uses around 18GB is RAM and it can max out my 11GB VRAM (1080Ti). So it's definitely a valid concern.",rtx_3080_3090_leak
If you're gaming at 1440p then 10 GB of vram is overkill. I think the reason that it has 10 gigs is because it's for 4K resolutions since texture memory is much higher at those resolutions.,rtx_3080_3090_leak
Warzone needs over 11GB VRAM at 1440p and high textures.,rtx_3080_3090_leak
"Yes, I had a 2080Ti until recently and never went over 8300-8400 mb of vram. You’ll be just fine, plus NVcache might help the situation even more.",rtx_3080_3090_leak
From what I can tell the improved efficiency will mean 10GB + 16GB will be good enough to run 4K maximum specs on most games. You may run into issue on 4K on some top of the line games down the line but I think the 3080 should be enough to run anything in 4K that exists right now at/near max settings. To be honest it not being 12GB really fucking grinds my gears. I think it’s a marketing stunt and I hate them for that but regardless 3080 will be a powerhouse for the vast majority of gamers.,rtx_3080_3090_leak
10GB is definitely not enough for next gen games. 1080Ti is from 2016 and has 11.,rtx_3080_3090_leak
Imagine doing this with the 2080 at launch. Only to find out from the benchmarks you got a more expensive 1080ti,rtx_3080_3090_leak
Yeah I'm waiting for benchmarks and for amds cards. Not gonna jump right into a purchase.,rtx_3080_3090_leak
"It's 10GB with 760GB/s bandwidth, which is anything but a joke. The 2080ti is 11GB with 616GB/s for comparison and can do anything you'd want to do with a 3080 just fine from a VRAM perspective. It'll be a while yet before you'd rather have more VRAM with a lower bandwidth rather than a higher bandwidth for the same price/less VRAM. I believe that 20GB models are rumoured, but you'll pay the premium for them for potentially questionable benefit and an even higher TDP.        
  
People are bringing up the new consoles, but while they might have 16GB of shared memory (not all of it will be for graphics) they also only have a memory bandwidth of 448GB/s. I kind of wonder about the 3070 if these specs are real due to that, but I think the 3080 will absolutely crush any ports.",rtx_3080_3090_leak
Just immagine one of that 320W chip in a laptop.... and we tought a GTX 1070M beating an RTX 2070M was bad....,rtx_3080_3090_leak
AIB 20GB model coming as well.,rtx_3080_3090_leak
"LOL, you’re a clown.",rtx_3080_3090_leak
"2080 Ti 11 GB VRAM <<<<<< 3080 10 GB VRAM

If you only look at the numbers and believe you understand the whole picture you're not prepared to make a purchase of such a magnitude.",rtx_3080_3090_leak
10gb is a slap to the dick,rtx_3080_3090_leak
I'm definitely interested in what AMD has to offer this round. Great times we're living in.,rtx_3080_3090_leak
I was planning on getting 3090 until I read this article this morning. I don't trust Nvidia after the crap they tried to pull with Turing. Went ahead and pulled the trigger on an 5700xt to tide me over until all new cards are out and benched since I sold my 1080ti already. How do you like your 5700xt?,rtx_3080_3090_leak
There is a 20gb version that is going to be released later this year,rtx_3080_3090_leak
"Why not just sell 3080 at the new variant launch, or use EVGA step up?",rtx_3080_3090_leak
Which country?,rtx_3080_3090_leak
Or hoping for a 16GB 3070. Only 8GB for the 3070 makes 0 sense to me. We already had fcking 6GB models of the GTX780 7 years ago? Also the 1070 already had 8GB of vram. I was eyeing the 3070/3080 but with these kinda of memory amounts I will either get the 16/20GB version or just wait for AMD.,rtx_3080_3090_leak
I fail to see how going for the 3080 is insane... AFAIK there are zero games that come close to using 10GB of vram.,rtx_3080_3090_leak
Left to mash f5 buttons to preorder lol,rtx_3080_3090_leak
They bamboozled us all maybe with 8nm. We'll see,rtx_3080_3090_leak
Is one better than the other?,rtx_3080_3090_leak
"This leak could be wrong, or maybe the 3080 and 3090 are 7nm while the rest are on 8nm. It makes sense to do that for me. Use the higher performance 7nm for the expensive cards and the cheaper 8nm for the midrange and low end cards.",rtx_3080_3090_leak
"Definitely sell yours, 3070 will be very close at 600$, so you would lose about 300-400$ in about one month compared to what you can get now.",rtx_3080_3090_leak
Well we'll  have  to wait to see if the 3070 is going to end up  *reasonably* priced,rtx_3080_3090_leak
"I would no worrie, You probably will be able to undervolt it without losing performance, Pretty sure it will be able to undervolt and have the TDP lowered from 350W to 300W +-

My 5700 xt Was consumming 240W +- full load, and after I undervolted it, it now consume 200W +- full load",rtx_3080_3090_leak
In a similar boat but not as severe. My advice? Buy the 3080 and then sell when the 20GB variant comes out. It will probably cost you a $100 bucks in resale and whatever the price increase on the 20GB but that’s going to still be my move most likely.,rtx_3080_3090_leak
"1070ti is pretty recent. If you usually upgrade in similar increments as between 1070 and this, 10gb will be far more than enough for the timeframe until the next upgrade.",rtx_3080_3090_leak
Too soon. Holding my 1070 Ti close to my chest =),rtx_3080_3090_leak
Gonna wait till 4000 series for 5120x2160 144hz. You need Display port 2.0 to even run the bandwidth requirements.,rtx_3080_3090_leak
"How are you managing to eat up 8gb of vram at 3440x1440 at all, let alone ""many times""?",rtx_3080_3090_leak
"That's and absolute top end use case that isnt relevant to 99.99% of the market. And frankly with such requirements, you're the crazy one for even looking at anything but top end gpu either.. A 3080 wont be enough for your needs just in terms of pure performance, long before any vram issues come into play.",rtx_3080_3090_leak
"Your total system will probably drain 500-550W total, it should be more than enough.",rtx_3080_3090_leak
You’d be fine with a 650w at this tdp,rtx_3080_3090_leak
"The 2080Ti has a recommended PSU of 650W and a TDP of 250W , the 3090 has a TDP of 350 so that would be a recommended PSU of 750W. They propably will play it safe and will recommend a PSU of like 800 or something.",rtx_3080_3090_leak
No,rtx_3080_3090_leak
Easily could power a 3090 presuming you don't have anything like a Cascade Lake or Threadripper CPU & motherboard as well.,rtx_3080_3090_leak
I have a 750w EVGA PSU and was wondering the same. I just upgraded to a 10700k. Hoping thats enough for the 3080.,rtx_3080_3090_leak
Not a chance unless you go mental on overclocking but even then I would say 600max total for the system.,rtx_3080_3090_leak
I'm running a 8600k not overclocked and a 1070 with the same PSU but the 550W version. I guess I'm fucked as the plan is to buy the 3080 :(,rtx_3080_3090_leak
"Depending on your CPU, you'll be fine.

Unless you got some OC'd 3950X with a lot of storage, you'll be good to go.

(reminder that PCs today barely go over 400W, let alone 500-600W unless it's enthusiast grade)",rtx_3080_3090_leak
Wondering this as well. I have an i7-8700k. I’ll get a new PSU if I really need it but I really hope I don’t have to.,rtx_3080_3090_leak
You should be fine. 3090 is the only one that might need more (although I doubt it). And certainly the next series will be more power efficient.,rtx_3080_3090_leak
"I have a bequiet pure power 11 500w PSU (80 plus gold) with a 2700x. Do you guys think that is enough power for a 3080?

I bought it a year ago :(",rtx_3080_3090_leak
"LMFAO

I couldn't make dual 570s consume more than 615w on my power supply going balls to the wall overclock on the CPU and GPU. What a ridiculous question. No one makes consumer gaming GPUs that require anything more than a 650w power supply and even then they assume you're using 50 fans and 10 hard drives and a 16 core intel server CPU at 6GHz.",rtx_3080_3090_leak
Can't wait to upgrade to a 3080 to appease my 1440p 140mhz monitor!,rtx_3080_3090_leak
960 gang,rtx_3080_3090_leak
680 gang,rtx_3080_3090_leak
"Tell that to people saying ""2gb will be fine for years!"" before last console hardware switch.",rtx_3080_3090_leak
Tell that to GTX 770/960 2GB users. :),rtx_3080_3090_leak
You sound like someone who defends 40% generational performance improvement with a 40% price increase,rtx_3080_3090_leak
"NVIDIA be like ""FINE, HAVE TWICE THE MEMORY OF A 2080 Ti YOU CUCKS""",rtx_3080_3090_leak
"""When people are wrong about something in the past, it means they can't be right about anything ever again."" - Idiot in this comment section",rtx_3080_3090_leak
Ain't that the truth...,rtx_3080_3090_leak
"Yea no, lots of use cases needs vram these days, it’s not just a gaming card anymore",rtx_3080_3090_leak
"As someone that uses them professionally, I've been waiting for more ;-;",rtx_3080_3090_leak
tell that to 2gb 680/770/960 and 3gb 1060,rtx_3080_3090_leak
"The biggest booboo of idiots yelling ""not enough ram"" is the fact that they don't understand just how much some games today pre-load.

This basically started because AMD had poor ram management on their cards and they threw a shitload of it on their cards. Nvidia has very good memory compression on their boards. So they don't realistically need 16GB and 32GB cards today for gaming purposes especially.",rtx_3080_3090_leak
3080 10gb for 4k isnt enough but for 1440p its perfect.,rtx_3080_3090_leak
"This may be the Titan because of the fact that it's called a 3090 (unless it sporadically gets called a 3080 Ti last minute).

And the unlocked Ampere core is reserved strictly for DGX stations.",rtx_3080_3090_leak
"Best is to wait for benchmark but RTX 2060 has 1920 and it runs quite a bit faster than 1070 (\~15-20% or so?)

So yeah comparing cuda cores is fools' errands",rtx_3080_3090_leak
similar situation with a 1060 at 1080 60 wanting to make the jump to 1440 144. 3080 is a little more than I want to spend but not really considering AMD options. Should I bite the bullet and get the 3080 and possibly sell and get the 20gb one if/when it releases?,rtx_3080_3090_leak
"It depends on the rest of your system. 3070 is a jump for you, but it doesn't look like a good investment for the future.

These cards are so expensive that I'd rather go with more powerful card and upgrade less often (maybe better 5 year-warranties). 

I think we'll start making systems based on resolutions you want to run. 3080 20gb feels like the CARD for anything 1440p. 3090 isn't worth it yet for 4k - better to wait till 4000 series and displayport 2.0.",rtx_3080_3090_leak
"Lol, how desperate are you to count on ATI to save the day.  AMD basically put all their Alpha engineers on Ryzen and ATI get the Beta team.",rtx_3080_3090_leak
"Its just 2 more days to wait until the confirmation, but the prices have been leaked a few times, stating  that the 3070 will be 700$, the 3090 1400/2400$, and the 3080 will be 800$, allegedly",rtx_3080_3090_leak
Thank you for clarifying  fellow child,rtx_3080_3090_leak
GDDR6X most likely culprit,rtx_3080_3090_leak
Do you know anything about Nvidia cards? The thing will likely boost up to almost 2GHz out of the box.,rtx_3080_3090_leak
"No, the 3090 could just be clocked lower",rtx_3080_3090_leak
Huh? 3090 has 350w TDP which is about 25% higher than 280w of 2080 Ti,rtx_3080_3090_leak
You can't mafs.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Everyone and their mom.  How hard do you think it'll be to snatch one of these puppies?,rtx_3080_3090_leak
Let me know if you have an extra kidney I can use to buy the 3090.,rtx_3080_3090_leak
"In the past, I’ve always purchased my graphics cards from third parties. Do you think I will regret it if I buy straight from Nvidia this time around? Is it worth waiting to get it from Asus or MSI or EVGA or whomever?",rtx_3080_3090_leak
That card will probably be $1600 or more here in Canada.,rtx_3080_3090_leak
If you have sparse kidney,rtx_3080_3090_leak
Good call. Watch me pick up a used 1080Ti.,rtx_3080_3090_leak
Remember 4GB HBM > 16GB GDDR5 meme?,rtx_3080_3090_leak
4k isn't really future proofing. It's here now and probably a fair number of people considering dropping $800 on a gpu in 2020 already have 4k,rtx_3080_3090_leak
"Ummm,, I'm using a 1440p ultrawide, and Microsoft Flight Simulator 2020. It consistently uses around 18GB is RAM and it can max out my 11GB VRAM (1080Ti). So it's definitely a valid concern.",rtx_3080_3090_leak
What games are you playing at 1440p and not maxing out ram? Hell this shortens the list of cards being future proof for vr or large wide screen monitors. Imagine even trying to play Microsoft's new flight simulator with any of these options. The last game that didnt max out 11gb of ram was resident evil 2/devilmay cry v. Metro exodus and control are prime examples of why 10gb isnt cutting it..,rtx_3080_3090_leak
"Same. I mean, there's pretty much nothing that will stop me from buying a 3090 (or 3080ti, or whatever the 3000 series non titan flagship is) at this point. I got a 1080 in 2016 and it served me well for 1080p high refresh rate. Only reason why I'm upgrading is because I want to step up to 1440p high refresh rate. The 3090 just makes more sense than buying a 3070 this generation and then buying a 4070 next generation for around the same cost. 

However, it would be nice if Nvidia would at least stick to the 2000 series pricing strategy, with maybe an inflation increase. Because it's ridiculous that, in 4 years, we've gone from $700 buying the best card to $700 being the price for a bottom of the barrel mid tier card.",rtx_3080_3090_leak
I think the 3090 is the new titan,rtx_3080_3090_leak
"There are rumors of a Titan with 48GB VRAM, but it will have less bandwith than the 3090.",rtx_3080_3090_leak
You can bet your house on that ...for only $2999.,rtx_3080_3090_leak
"Hopefully not a mess... if the rumor that most AIBs are designing their own PCBs is true, it could be a train wreck.",rtx_3080_3090_leak
"Hard to tell, RTX is implemented differently by each game. I would just wait for benchmarks.",rtx_3080_3090_leak
"No, you'd want to wait until the 30 series releases, though I don't know how much the price will drop or anything.",rtx_3080_3090_leak
does the LG C9 support GSYNC?,rtx_3080_3090_leak
"Only at 4k. I've had no issues at 1440p with a 1080. I get good frame rates, just not 144 on a lot of games which is my goal for this new series.",rtx_3080_3090_leak
"Yes, 4K and VR. High Resolution and ray tracing all use vram. 

I’d upgrade your monitor first.",rtx_3080_3090_leak
AI mostly,rtx_3080_3090_leak
CUDA / deep learning.,rtx_3080_3090_leak
"Maybe, maybe not, PSU are more efficient when they run at about 50% of their capacity, the GPU only is already higher than that lol",rtx_3080_3090_leak
650w is gonna be tight,rtx_3080_3090_leak
Read my username,rtx_3080_3090_leak
You're just gonna have to wait for benchmarks for sure. Chances are 3080 will be slightly better than 2080ti. Luckily a big gap between GPU release and CP2077,rtx_3080_3090_leak
3070 is expected before end of the year.  But you're always racing to get new cards before other people.  Wide availability can sometimes take 2-3 months after launch.,rtx_3080_3090_leak
"What parts are you looking at?  I'm building a similar box and I'm looking at the 3700x and a 3080.  Right now, I'm $560 in on a phanteks p400 case, evga 650w gold psu, 16gb of 3200 crucial ram, b450 tomahawk, 970 evo 500gb, and a 3200g (using onboard video while I wait for the 3080).  

My plan is to sell the 3200g for around $80, moving my total back down to $480 then dropping ~$800 on the 3080 and trying to hopefully pick up a 3700x on black Friday for $200.  That would leave me right around $1500, maybe a little more with taxes.",rtx_3080_3090_leak
"I'm curious how their stock is looking for the rest of the year.  I can't believe how high it is now.  

Bought at $60, $90, and $250",rtx_3080_3090_leak
Yes,rtx_3080_3090_leak
"Unfortunately, you probably do :(",rtx_3080_3090_leak
"No, 750w for 3080 and ryzen 9 is good enough",rtx_3080_3090_leak
For gaming or work?,rtx_3080_3090_leak
PCIE is bacwards and forwards compatible,rtx_3080_3090_leak
"Let me explain this better, 4.0 cards will work in 3.0 slots, but 3.0 slots wont become 4.0 without new hardware.  To get pci4 you're gonna need the processor and motherboard that supports it.",rtx_3080_3090_leak
You could undervolt it but yeah :/,rtx_3080_3090_leak
"What are the rumoured prices? 

I agree though, it’s absolutely ridiculous",rtx_3080_3090_leak
Good thing the leaked prices were wrong,rtx_3080_3090_leak
"> I suppose ill be in the 70 tier cuz even if the performance is there i have a hard time speniding 500+ on a gpu.

So you think the 3070 will stay around $500? [How cute](https://blackandyellowotakugamers.com/2019/02/19/o-kawaii-koto-kaguya-sama-mid-season/kaguya-sama-how-cute-8/)",rtx_3080_3090_leak
"if the price is right, u can look past almost anything. and the price will surely fluctuate if rdna2 is competitive",rtx_3080_3090_leak
"Considering the 3080 will have a 20gb option, it’s very possible the 3070 will have a 16gb option as well. Granted, I also don’t know if I want that. I was already struggling to justify a $600 card, and this would push it to $700, and being an aftermarket card would add another $50 or so. The PS5 sounds pretty good at that point.",rtx_3080_3090_leak
"Same here as well, I was bracing for $500 dollars, but hey its new tech.

Now im seeing its 600 and artificially gimped? No thanks, ill stick with my 970 a little longer and hope Big Navi 2 will compete (I think it will at a much lower price point)",rtx_3080_3090_leak
Why are you not considering the 3070 now?,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Lol. I’m not trying to be a dick but why upgrade? 2080ti is a tank of a card. Wouldn’t it be better wait till at least another generation. I guess to each their own.,rtx_3080_3090_leak
"im yet to see a game use more than like 8 gigs at 1080 or 1440, 10 should be ok IMO. if at 4k you're in the 3090 market anyway",rtx_3080_3090_leak
Bandwidth is so fast the textures are just being replaced so quickly you won't notice it /s,rtx_3080_3090_leak
The article does explicitly mention 7 nm which is TSMC. My guess is 7 nm for the high end and 8 for the lower end.,rtx_3080_3090_leak
"Re power and heat - there is no way an AMD card with equivalent performance is going to have any significant difference in heat and performance per watt vs this 3000 series

5700xt 7nm has worse perf per watt than 12nm 2070super.. not sure why people think there's going to be a drastic shift",rtx_3080_3090_leak
"Incorrect. The TDP discrepancy between the 3070 and 3080 renderds your statement as being wrong.

Why? Because the 3070 is using 220W and the 3080 has a huge punch to 320W of power usage. The culprit here is GDDR6X which without a doubt is a power hog.",rtx_3080_3090_leak
ur total power draw will probably be 500-550 if you have 1 cpu and 1 gpu in ur rig,rtx_3080_3090_leak
Yes!,rtx_3080_3090_leak
You'll be fine.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
">I have a 1080ti and was wondering if a 3080 with 1GB less VRAM would be a downgrade? (I'm still somewhat new to this stuff so excuse the ignorance)

No. I have 2080 Ti and 3080 even with 10GB VRAM will still be rumored to be about 20-30% faster than 2080 Ti. 

The VRAM situation only matters if you are maxing out and exceeding the capacity which is rare in gaming workload.",rtx_3080_3090_leak
"In terms of actual fps the 3080 will win easily given it is supposed to be faster than the 2080 ti

I play at 1440p and I've never hit 8GB of VRAM usage, currently most games will do  4k without hitting 8GB VRAM, there are some.

But the way i think of it is this:

Play at 4k with 11GB VRAM at 60fps max settings with a 1080ti with usage at 10GB

Play at 4k with 10GB VRAM at 100fps with AA turned down one setting using a 3080.

I'd pick option number 2, besides factoring in DLSS the chance you actually go over 10GB is very unlikely",rtx_3080_3090_leak
"It is rumored that AIB partners will propably increase the VRAM of the 3080 , offering 3080 20gb cards propably.",rtx_3080_3090_leak
"No, it won't be a downgrade.",rtx_3080_3090_leak
"No, even with only 8gb the 2080 is already an upgrade from the 1080 Ti.",rtx_3080_3090_leak
Maybe,rtx_3080_3090_leak
The best salt is the 2080ti guys bitching about not being able to play everything at 8k 240fps,rtx_3080_3090_leak
"Because, as others have stated, 10GB is still enough. People are overreacting a lot and are not understanding it's good even for 4K gaming (true, not balls to the wall texture size wise but still enough especially with that speed and Nvidia's compression).

the 20GB version is indeed a better buy but don't be amazed if it costs a hefty 300 bucks more than the 10GB variant. GDDR6X is expensive as shit.",rtx_3080_3090_leak
"That's just laughable.. The people who play on 1440/4k dont future proof, not for a console gen lengths of time anyway. The hardcore users that can justify such price upgrade at most every 2 gens and for that time 10gb will be *more* than enough. Hell 8gb will be enough just because most games for that time will be multigen and developed with old consoles in mind...",rtx_3080_3090_leak
It's not enough my 1080ti with 11gb vram uses 10.3gb in the recent horizon new dawn game and about same in metro exodus all with ultra settings at 4k60hz. I'm sure newer AAA games in 4k will surpass that shortly.,rtx_3080_3090_leak
"Because the new consoles will likely push games to use over 10GB since they have 16GB and 2-4 will likely be reserved so 12GB+ for games.

Sure it will be fine for now, and look great on release benchmarks, but what about games in 6 months @ 4k?",rtx_3080_3090_leak
10 GB isn't going to be enough at all.  New console are 16 GB and the newest games will be made to take advantage of that 16 GB.,rtx_3080_3090_leak
"No, 3070 is rumored to be around 2080ti level of performance.",rtx_3080_3090_leak
probably saving that for the super cards in 6 months.,rtx_3080_3090_leak
nope,rtx_3080_3090_leak
PCIe 4.0 has double the throughput of PCIe 3.0,rtx_3080_3090_leak
I pull about 480 watts from the wall when gaming with a 8700k at 1.46v and a heavily oced 1080ti hitting the 300w limit. If you're just running games you'll be supprised with what psu you can get away with. Especially if it's a decent psu.,rtx_3080_3090_leak
i would almost certainly say no,rtx_3080_3090_leak
Yes,rtx_3080_3090_leak
Who knows but I would actually bet on there not being a 3090Ti.  I would bet on there being a 3080Ti at some point due to the massive price gulf between the 3080 and 3090.  I think timing will depend on what Big Navi turns out to be.,rtx_3080_3090_leak
No.,rtx_3080_3090_leak
"I guess anything worse than a 2080 Ti is a no go, but it depends on RTX performance and also DLSS 3.0 availability, this can turn tables dramatically.",rtx_3080_3090_leak
"Depending on your other specs, I very much doubt it. 750 will have plenty of head room.",rtx_3080_3090_leak
Good to see another 780 who has been down with the struggle the last few years,rtx_3080_3090_leak
yes it will be unless your cpu is +300watt,rtx_3080_3090_leak
Yea right. Everyone here will cave once the benchmarks are out.,rtx_3080_3090_leak
"nvidia likes to release performance charts. Always take these with a grain of salt, they are (for the most of the time) a bit too high in performance gain and they obviously like to shine their own products in a good light. 

Wait for indipendend benchmarks by techyoutubers like Gamersnexus , Linus or Bitwit or someone like that. They will get the cards first to review them.",rtx_3080_3090_leak
GDDR6X is literally brand new and no one knew it existed until it was leaked for this card. No one knows the performance characteristics of them. The only thing we can kind of gleam is that they use a lot of power.,rtx_3080_3090_leak
"id buy the 10 gb 3080 now, use it , and then sell it and buy the 20gb when that comes out.",rtx_3080_3090_leak
"Honestly, imo, you'd be pretty insane to not at least wait and see what AMD's big navi cards look like.

But to answer your question yes 10gb will be enough for the next 3-4 years.  If you keep cards longer than that without upgrading (which you might, I certainly keep mine for at least 3 years) then maybe there is a little bit of concern?

I sure wish they would have standardized somewhere in the 12-16 gig range tho....",rtx_3080_3090_leak
"No idea.  The conference is September 1st, but rumor is 800 MSRP with +100 for FE.",rtx_3080_3090_leak
Yes,rtx_3080_3090_leak
"It's stupid but...

Nvidia's TGP is Total Graphics Power (AMD's equivalent is TBP) 

For Nvidia, ""TDP"" is just the GPU Power. So in this case it's lower than 350w.",rtx_3080_3090_leak
"3070  = 2080Ti In non RT games, 3080 beats 2080ti by ~30%.

3090 beats 3080 by ~20%",rtx_3080_3090_leak
"Faster memory, more cuda cores, better ray tracing. Clock speeds tends to stay similar between generations, and cant really be used to gague performance. Cuda cores also cannot really be directly compared between generations either.",rtx_3080_3090_leak
"announcement on sept 1, rumors of early/mid september.",rtx_3080_3090_leak
I'm guessing 600-700 USD. I'm Canadian so I see this card being sold for like 1000. Not good,rtx_3080_3090_leak
"Depends on the rest of your system, but 450w is pretty anemic for most gaming systems in 2020. Everything is a rumor at this point, you have to consider that a 3060 might pull \~200W on it's own under load based on this speculation.",rtx_3080_3090_leak
980ti here. Also wait g to see what amd has in store.,rtx_3080_3090_leak
"Sure, because every game is the same and is programmed the same. Sure man. 
Oh all settings are also the same in all games.",rtx_3080_3090_leak
Probably 3090 but wait for benchmarks,rtx_3080_3090_leak
"3090, unless there’s a 20 GB 3080.",rtx_3080_3090_leak
The 3090 is \*probably\* a 3080ti replacement because the ti branding is too confusing,rtx_3080_3090_leak
Reviewers will publish benchmarks. Take manufacturer benchmarks with a grain of salt.,rtx_3080_3090_leak
x60 always come later than the high end cards.,rtx_3080_3090_leak
September,rtx_3080_3090_leak
What CPU you have? I think it should be enough in most cases,rtx_3080_3090_leak
"Even with these 300 watt cards you’re probably looking at 500-600 power draw with the rest of the system, there’s no way you should be worried unless you have a threadripper or something that draws an absurd amount of power.",rtx_3080_3090_leak
"I’ve got an Evga 750w Platinum. I’m hoping to go for a 3090, but will most likely get a 3080. I have no concerns about my PSU. I won’t be upgrading it. I’m running 8700K processor.",rtx_3080_3090_leak
Probably a few weeks into September for full benchmarks,rtx_3080_3090_leak
Because they don't manufacture them anymore.,rtx_3080_3090_leak
RTX 2080 to 3080 is going from 2944 cuda cores to 4352 cuda cores. RTX 3070 should see a similar uplift in processing bandwidth.,rtx_3080_3090_leak
"You are ahead for 6 next generations, should be ok.",rtx_3080_3090_leak
We won't really know till next week. It will be better but you can't compare core counts/speeds across architecture changes let alone cards that are on a new process node.,rtx_3080_3090_leak
"nvidias website is the place to be, stream is at 10am pacific time so be on the website refreshing during the stream until a 3000 series thing comes up",rtx_3080_3090_leak
"Just go off benchmarks 

[Here's a vid of it in some recent games](https://www.youtube.com/watch?v=IH5U8aK0ClM)  


Remember that not a single person in this thread has actually seen performance of the 30XX series. Your 980ti card will not perform worse in new games just because there is something better",rtx_3080_3090_leak
"I think you should be fine. It has a TGP of 320W which definitely is higher than the previous gen but that's the limit of power it will draw at stock, and a normal CPU (3600x for example) draws less than 100W, and it's highly unlikely everything else in your PC will draw more than 50-75W",rtx_3080_3090_leak
"Nah I think you should be good. It's rated at 220W which is usually at the high end of actual power draw, and your 3600x won't surpass 100W.",rtx_3080_3090_leak
"9700KF at 5.1ghz and a 1080ti overclocked with afterburner to max.

My setup pulls 500w under full load (OCCT avx load and furmark). During most gaming sessions I'm more like 400-450w. My CPU pulls way more power and my GPU is at least as much as a 3070. You'll probably use at least 50-75w less than my setup.

You should be fine.",rtx_3080_3090_leak
it will still game fine but consider upgrading,rtx_3080_3090_leak
3070 equivalent to a 2070? In what sense?,rtx_3080_3090_leak
Rumors are they are ready to go same day.  Various versions like Kingpin and Copperblock will probably be some time though.,rtx_3080_3090_leak
They arnt going to drop price at all,rtx_3080_3090_leak
ML is useless meme. But you can use 24gb for actual work like rendering.,rtx_3080_3090_leak
"Oh, if i were you i wouldve waited for the amd cards being released in late October/early November, but the 5700x is a great value card undoubtedly. What cpu are you pairing it with?",rtx_3080_3090_leak
"Oh yeah, definitely",rtx_3080_3090_leak
"Well,the founders edition will be sold out pretty quickly i imagine, but some AIB partners are going to release their cards at around the same time as nvidia",rtx_3080_3090_leak
So you only want to buy half of a 4090?,rtx_3080_3090_leak
games newer than 1990?,rtx_3080_3090_leak
"If you want to upgrade monitor to something beyond 1080/60hz
Or if you want to have hw ray tracing support. (You aren't really gonna be ""ultra"" on future games without it)",rtx_3080_3090_leak
"Not this year, but most likely will be released in the future",rtx_3080_3090_leak
"?

It's been the same system for generations. xx30 piece of shit for HTPC's...or something I don't even, xx50 is low tier entry level gaming, xx60 is mid tier, xx70 is entry level high tier, xx80 is high tier, xx80ti is very high tier",rtx_3080_3090_leak
"Depends on your budget and the final pricing of the cards, that wont be truly confirmed until the reveal, but if youve got the money, you should probably go for the 3080",rtx_3080_3090_leak
"I'm going the same. Running a AMD 7770 HD since 2013 and pricing out new PC's now. Waiting until these release as honestly, I've never had a high end graphics card and the AMD 7770 is about as good as I've ever had in any gen.....It's about time.

I can't afford the 3090 though...it's too much. I'm eyeing the 3070 or maybe the 3080 if it makes sense to spend  a bit more.",rtx_3080_3090_leak
"*pretty huge jump*, my guy it will definitely  be worth the upgrade :)",rtx_3080_3090_leak
"And your liver, dont forget about the new PSU you might have to buy :D",rtx_3080_3090_leak
"You can, most likely there will be some stock clearance sales as RTX 2080 production ends, but you might be better off upgrading directly to 3080 as skipping a generation gives you better gain.",rtx_3080_3090_leak
"You'll be fine, it adapts 8 pin",rtx_3080_3090_leak
"**Should be** ok, but your PSU is gonna run at like 80% charge and the PSU fan may get loud (never tried antec ones so IDK if the fans are loud but a 80% charge the fan will spin fast)",rtx_3080_3090_leak
"In terms of VRAM the 3080 is similar in terms of usable VRAM, 3090 is much more. But in terms of performance, new consoles are like a 2070 super. These crush them. VRAM may be an issue also other shit comes with console optimisation and the PS5 has some interesting SSD tech so don't expect this gen of GPUs to be massively better than PS5 or series X off the bat. But yes, these are more powerful, NVIDIA is really flexing it's muscles here",rtx_3080_3090_leak
Looks like it's going to be the same time this time around. Last time it was within the month.,rtx_3080_3090_leak
"wait for amd, otherwise if the 3060 has 8gb, it would be an awesome upgrade from your 580 im sure, no need for the 3090 if you came from rx 580 haha ! What resolution do you play on? Which refresh rate? What is your PSU/CPU?",rtx_3080_3090_leak
"Wait for *next AMD cards* meme is still alive and well. 

They have disappointed me ever since Fury's release.

It's all hype and then they disappoint",rtx_3080_3090_leak
What? If this low amount of vram is true benchmarks won’t say anything! 8/10GB for a $600-800 card is NOT future proof. No benchmark will change that.,rtx_3080_3090_leak
What's the point of your post. You are just repeating what is in the stickied comment. What do you think people will see first?,rtx_3080_3090_leak
That’s not actual clocks and the memory is energy hungry.,rtx_3080_3090_leak
Rip. Refresh in half a year with more vram and 7nm? I hope Amd can bring something to the table.,rtx_3080_3090_leak
"I mean you can also look at the 3080. 

Hence wait for benchmark.",rtx_3080_3090_leak
"Yeah I am shocked at the amount of people freaking out, especially about vram! My 1080 has 8GB vram and if I were to get the 3080, that's 2 more than what I have. Right now I feel fine playing games at 1440P, just not able to max games and get 100+ consistently at that frequency. I can't imagine 10GB VRAM being too little anytime soon.",rtx_3080_3090_leak
"But PS5 and Xbox can't Zbrush, photo, programming etc...",rtx_3080_3090_leak
"Idk being a 320bit bus means that memory will either be 10gb or 20gb, and I can't see NVIDIA making a 20gb version as that's a bit too similar to the 3090 and they'd rather push people to spend the extra money to buy that",rtx_3080_3090_leak
If its a premium plat/gold you'll be okay with no OC's,rtx_3080_3090_leak
320W is about as much as my OC 980ti on 650W corsair gold. Should be just fine as long as it’s the high end EVGA range. :),rtx_3080_3090_leak
If it’s a high rated EVGA you’ll have plenty of room at 650w. Your probably looking at a total system draw of 470-520w (with a 3080) depending on other components.,rtx_3080_3090_leak
"> I think there’s something wrong about it to them hence making a huge dive in their new lineup.

The 3070 is rumored to be 2080 Ti performance. Not sure what dive are you talking about

Your 2060 will perform like some low end 3000 cards",rtx_3080_3090_leak
"AMD's upcoming card will barely out perform 2080ti. If that. The 3070 will probably be better than Big Navi. I pay for quality and performance, so Nvidia it is.",rtx_3080_3090_leak
"How are you determining this? (Not being rude, genuine question)",rtx_3080_3090_leak
"Try not being a caselet, that'll help.",rtx_3080_3090_leak
970 still better,rtx_3080_3090_leak
"NVIDIA: Hey ""PhysicalSecurity1"" fork over $600 for a 3060",rtx_3080_3090_leak
"Prices are decided literally  just before Jensen walks onto the stage and even then can change before release.
 I would wait for AMD to announce or release before making a decision. Only competition will bring down prices.",rtx_3080_3090_leak
"Both Pascal and Maxwell rendered the older generations obsolete.

Besides, just because the vRAM is quite disappointing, doesn't mean the performance increase isn't good, especially in RTX.",rtx_3080_3090_leak
"970 was faster than a 780 Ti in majority of new games.

1070 became as fast as a 980 Ti right out the gates.

20 series was a flop that only succeeds at raising the pricing threshold for every tier of GPU. Ie - 2060 tier is 1070, 2070 tier is 1080, 2080 became 1080 Ti and the 2080 Ti became the old Titan. Instead of being more efficient and costing the same or less like past generations, it simply went with bigger and more expensive chips for each tier. It was a colossal ripoff for what you got. The 30 series is built on a new process and will actually deliver colossal gains over the 20 series similar to what we saw in the past. Yes, the 20 series will absolutely be made obsolete.",rtx_3080_3090_leak
Why? There will be lower end card obviously. This is just initial launch with the high end.,rtx_3080_3090_leak
What do you mean skip another gen? 1660 super is current gen lol,rtx_3080_3090_leak
">How important do you all think having a board and cpu that supports PCIe 4.0 is for these cards?

I'd imagine it has about 0 importance, give or take.  If you're trying to do heavy compute with them, then *maybe*.  But for general gaming and/or editing: 0 importance.",rtx_3080_3090_leak
"Maaaayyyybe on 3090 at very high resolution on some specific games you can see a difference that is above the noise floor of normal variance.

So, no, not at all important.",rtx_3080_3090_leak
Your 1060 didn't cost 800$ though.,rtx_3080_3090_leak
">I really don't see the point of having RTX 3000 when raytracing still won't let me play > 100FPS in 1440P and the GPU has almost the same performance as last-gen with same memory amount

The fuck are you smoking?

3070 is rumored to have 2080 Ti performance and will run circles around your 1070. You're ridiculous.

Also wait for Benchmark.",rtx_3080_3090_leak
even the 400 dollar -ish cards will be a decent upgrade from ur 1070,rtx_3080_3090_leak
"yeah, i know..

imagine releasing newer, more powerful, cards eh? MADNESS!

# 🙄",rtx_3080_3090_leak
Yes,rtx_3080_3090_leak
lmao,rtx_3080_3090_leak
"What a crap logic. Just because the vRAM is the same, doesn't mean the card won't be significantly faster.

You did bad for buying a 2070 recently nonetheless, you will see soon.",rtx_3080_3090_leak
You really should've waited for 3070 because you could've gotten it for maybe $100 or so more and it'll perform like 2080 Ti.,rtx_3080_3090_leak
Maybe a bit,rtx_3080_3090_leak
3070 is rumored to be 2080 Ti in performance,rtx_3080_3090_leak
"Wondering myself. I cant see buying a 3080 and getting everything maxed out of it with 10gbs of vram, people max out 11gbs now..",rtx_3080_3090_leak
VRAM isnt everything. But yeah do order a 2070s its definetly the most value-card you can get.,rtx_3080_3090_leak
"Interesting point of view. Now that Moore's law is dead, people usually think it progresses slower than it used to",rtx_3080_3090_leak
It'll be nowhere close to that.,rtx_3080_3090_leak
"I have an 850w and AMD 3700x, 32GB RAM, 1TB NVMe, 1 TS SATA and 3TB SATA and cpu calculation web site said 850W PSU was still more than enough for RTX 3090 and it's max 350W usage.",rtx_3080_3090_leak
"Nvidia makes new gaming silicon once every 2 years.  The initial 3000 series cards will be the biggest jump in (non-ray tracing) performance per dollar in at least 4 years.   Sure, in about a year they may refresh the stack with ""new"" cards that are slightly better, but it's same silicon, just slightly different sku marketed differently for cheaper. 

For most people it doesn't make sense to wait for that",rtx_3080_3090_leak
"The VRAM is disappointing but the 3070 may be as powerful as a 2080ti. If you had the ability to wait, it was sound advice.",rtx_3080_3090_leak
So memory size == performance?,rtx_3080_3090_leak
right. i think people forget u can play anything u want within reason on a 500$ 2070 super.,rtx_3080_3090_leak
Same boat here man and I'm assuming the same thing. Nothing would be worse Than a faster card releasing a few months after buying a 3090.,rtx_3080_3090_leak
It will be yes,rtx_3080_3090_leak
"3090 will 90% remain the flagship card.  Also, a 3080 ""Super"" refresh is more likely that is placed halfway between 3080 and 3090 than a 3080 Ti.  Or even a 12 GB variant of the 3090.",rtx_3080_3090_leak
You can only have 10GB or 20GB 3080 since it's using 320bit bus,rtx_3080_3090_leak
its on a 320bit bus. Next step up from 10 is 20.,rtx_3080_3090_leak
"3070 super maybe at 16gb, but  the 3080 need denominations of 10, 3090 needs denominations of 12",rtx_3080_3090_leak
">The 3080 and 3070 seem DOA. These aren't next-gen cards.

3070 is rumored to perform like 2080 Ti...

That's pretty in line with normal gen to gen upgrade",rtx_3080_3090_leak
In what terms? How do you have any basis for performance comparison?,rtx_3080_3090_leak
It’s likely going to be much faster and on par with the 2080/2080s VRAM isn’t everything.,rtx_3080_3090_leak
3070 is rumored to be 2080 Ti in performance.,rtx_3080_3090_leak
Way overkill. Absolutely nay.,rtx_3080_3090_leak
$1400 GPU for a $120 monitor?,rtx_3080_3090_leak
nothing about the 2070 super is better than the 3070.,rtx_3080_3090_leak
yeah but it has to be in stock.  you only have 90 days to buy it,rtx_3080_3090_leak
I would be shocked if the 2070 Super was better than the 3070. That would seem like a major screw up for Nvidia.,rtx_3080_3090_leak
yeah,rtx_3080_3090_leak
If it's EVGA you might be able to upgrade,rtx_3080_3090_leak
"If 3070 beats or matches a 2080 Ti, it is similar to pascal which was praised. Definitely a bigger leap in performance than the super cards",rtx_3080_3090_leak
What are you even talking about rumors have the 3080 at or above 56% better than the 2080ti without even factoring in RT or DLSS...,rtx_3080_3090_leak
AMD will drop RDNA2 and consumers will spend 6 months beta testing the drivers for them.,rtx_3080_3090_leak
nah they are going to be slower with each generation,rtx_3080_3090_leak
no,rtx_3080_3090_leak
bro youre on a 2080ti no shit you skip a gen or two,rtx_3080_3090_leak
I have a friend who is a dumbass just go out and pay 700 for a new 1080 ti lol they still fall for it haha,rtx_3080_3090_leak
"1080ti for 400? Gimme a link pls, I need one",rtx_3080_3090_leak
Just paid 170€ for a 1070. Felt like a fine price,rtx_3080_3090_leak
People get caught up buying things online for the thrill. They don't care if there is a deal. If you look up things on eBay that where won by bid often the price difference on 500 dollar items (new) sell for like 480 (used) while bidding. People get to caught up in winning they don't pay attention to the fact they shouldn't even buy it at the price.,rtx_3080_3090_leak
For real I recently got a 1080 Ti for $400,rtx_3080_3090_leak
Sold my 2070 Super about 5 weeks ago for $200 more than I paid new.,rtx_3080_3090_leak
"I sold the 2080 Ti yesterday for 1050 euro, got it for 1200 at launch. No idea why people buy them this close to launch. Also, 1080 Tis here cost 250 euro lol",rtx_3080_3090_leak
The 2080Ti I get. People are impatient and have too much money. I am curious how much my 2060S would sell for once 30s are out,rtx_3080_3090_leak
"LOL, prestige.",rtx_3080_3090_leak
I saw a 2080Ti new on Amazon today for $1800. Absolute wtf moment.,rtx_3080_3090_leak
"A 2080ti founders edition, *used*, on Amazon, is going for $1700.


[Sauce](https://imgur.com/dzy5QXr)




Scarcity perhaps? I have no clue, but these people are insane.",rtx_3080_3090_leak
"I also had a 4790k that I got to something like 4ghz (or 5,I really don't remember) all cores without any extra voltage and it passed a 24 hour stability test. I sold it for slightly more than I paid for it a few years after launch. I remember because I was told ""no one will pay that much for that CPU"" and it was sold an hour later on eBay.",rtx_3080_3090_leak
Shit hit me up when you decide to do that,rtx_3080_3090_leak
1080 ti or 2080?,rtx_3080_3090_leak
Bro you just had a 1080ti sitting around?,rtx_3080_3090_leak
I will willing to wait till Nov 18th for when Cyberpunk 2077 comes out.  That's probably the only new game I will need a new card for.,rtx_3080_3090_leak
">This is abusive or harassing

>It's targeted harassment

>At me",rtx_3080_3090_leak
Not unless you're going for the max VRAM available... Us 3D artists crave VRAM!,rtx_3080_3090_leak
"Or get even madder when the 3080ti drops in like January of next year costing 900 bucks and having 16GBs of memory which is more than enough while also only being like 5% slower than the 3090.

That one will really piss off the community big time and rightfully so.",rtx_3080_3090_leak
They gonna have start selling these will installation plan they do with phones lol.  $60 a month for 24 months lol.,rtx_3080_3090_leak
New to this scene. Do they sell out that fast?,rtx_3080_3090_leak
Top end flagship are never priced fairly.  Just look at phone/laptops for example.,rtx_3080_3090_leak
"In contrary. Rumor from a few days ago showing a relatively small gap between 3080 and 3090 (around 20%).

So unless you REALLY need the VRAM and want the best of the best, 3080 will be good enough.",rtx_3080_3090_leak
"Really depends on how many games adopt dlss 2.0.  10 GB isn't enough for 4k AAA gaming and gamers are dying to move up to 4k from 1440p.  If dlss 2.0 made 1440p look as good as 4K, then 10 GB might be good enough.",rtx_3080_3090_leak
"I'm already running 1620p on a GTX 1070 TI. I fully expect 4k performance out of the 3070 and have concerns about how Nvidia is marketing these.

I'm already expecting ""ti"" or Super variants to come later and the thought is disappointing.",rtx_3080_3090_leak
8gb is plenty for old gen games. Next gen games will use much more VRAM. Can't wait to set my textures settings to medium on a brand new 700-800$ GPU. Awesome.,rtx_3080_3090_leak
"Why would you say that? FS2020 on 1440p uses 9GB+ just on the high preset. 

Upcoming AAA titles will demand more than 8GB.",rtx_3080_3090_leak
"To be honest, most people will probably still use 1080p.
I have a 2070 Super and a 1080p 180Hz monitor and I'm very happy with it, 8 gigs of VRAM should be enough for years.",rtx_3080_3090_leak
"It's not great for VR though, VRAM is already being maxed out in games like half life alyx",rtx_3080_3090_leak
Most games I play max my 8gb gpu currently (VR).,rtx_3080_3090_leak
playing dead by daylight at max settings maxes out 8gb,rtx_3080_3090_leak
The 70 series can already push 4K so why not give them more VRAM? I'm disappointed because I was specifically looking to buy a 3070 for my 4K display. There is no way I am paying over one grand for a stinking 3080 just for more VRAM.,rtx_3080_3090_leak
Which card should I take to use with a HP Reverb G2 ? Would the 3070 be enough or a 3080 will be mandatory for a good experience? Can we compare a 3070 to an actual 2080Ti ?,rtx_3080_3090_leak
So if I plan to chill on 1440p for awhile do I not need to stress about 3080 only being 10GB? Currently at a 1070ti but do want to upgrade prior to Cyberpunk.,rtx_3080_3090_leak
But with DLSS 2.0? 3070 should do 4k with it,rtx_3080_3090_leak
"No. The majority of the ram needed by the gpu is to save the models and the shader files(they are usually just a few megabyte). When you want to display a flower you first have to load the shader files wich are most common the vertex and fragment shader. Then you load the object into the storage of the gpu. The only thing a gpu needs for high quality screens is processing power(shure it needs a bit more storage but the bulk is to save the coordinates of the triangles). The first processing stage is the vertex shader there you render the whole world and the screen resolution is unimportant at this stage. Then it comes to the fragment shader. THERE is where the screen resolution is relevant. Now it renders the color for every picture but keep in mind the triangles are already processed this stage is only for the color.

To conclude you need a higher processing power for a higher screen resolution but not as much more storage. 8gb is not good for the future.",rtx_3080_3090_leak
Is ray tracing memory bound though? I thought the more rays/bounces the bigger the search tree,rtx_3080_3090_leak
I use my 2080ti for professional modeling and rendering and I've only ever maxed out VRAM a few times.  My 980ti would get maxed out on some more complicated renders.  24GB is way too much for the average joe.,rtx_3080_3090_leak
3070 should fall close to 2080 ti so thats ideally the 1440p card this generation,rtx_3080_3090_leak
Even e-sports titles like Apex Legends can easily exceed 8GB on texture streaming alone at the highest preset.,rtx_3080_3090_leak
Its really not. Some triple A games are already pushing 8gb at 1080p. Nevermind 1440p.,rtx_3080_3090_leak
It is but shouldn't it have more since its a a new line of gpus? My rtx 2070 super has 8gb so why wouldn't the 3070 have 10gb?,rtx_3080_3090_leak
Lolloll,rtx_3080_3090_leak
"When I buy a GPU, I expect to get 4 years out of it. 8GB doesn't sound like much now, let alone several years from now. I've been waiting for the 3000 series to upgrade, so by the time I get one, it will have been 5 years  with my GTX 980 which has 4GB. I was expecting 12GB to the minimum on a 3070 and 16GB on the 3080, so this is disappointing.",rtx_3080_3090_leak
It isn’t. Some games eat up all the graphics memory they can. COD MW eats up 10+ GB on my 2080ti,rtx_3080_3090_leak
I just wanna play modded Skyrim with no compromises. 8 GB VRAM is not enough for that.,rtx_3080_3090_leak
Yeah but considering rumors are the new consoles will have equivalent 16gb vram. It's worrying about future proofing,rtx_3080_3090_leak
"honestly, 8gb is gonna be enough for many 4k games because even when the geometry is rendered at 4k a lot of the textures aren't actually be 4k....",rtx_3080_3090_leak
"Stop making excuses for this bullshit. No, 8GB is NOT going to be sufficient for 1440p going forward. Red Dead Redemption 2 at 1440p and Ultra textures (which is the setting Xbox One X uses) is already peaking 9GB of VRAM usage on my 1080 Ti. And note that this is with the game swapping textures in and out as you roam the map and it loads them in as needed. That means if you had even less VRAM, you'd either be getting stutters or even worse texture swap and LOD quality issues.

What do you think happens a year from now when next gen games start coming out? You think Ultra textures is still going to be possible at 1440p with only 8GB? That number is a fucking joke and we should not be brushing it to the side as easily as you are.",rtx_3080_3090_leak
"What does AIB stand for? I’m assuming makers like gigabyte, Asus, etc. but I can’t find the words to put there",rtx_3080_3090_leak
"Thank you for telling me this. I was on the fence  about preordering at launch, but  now you talked me out of it.",rtx_3080_3090_leak
I want the 3080 20 gig model.,rtx_3080_3090_leak
It would be great if someone like GamersNexus does a video on VRAM vs performance for few AAA games to give people like me an idea of how important 5 million GB of VRAM is.,rtx_3080_3090_leak
"
>Wait and see what the AIBs do.


Probably charge more than MSRP again....",rtx_3080_3090_leak
I'm more then happy with the current rumored VRAM amounts since I have a 970. Just built a new rig am just waiting for the 3070 to go on sale so it will finally be complete.,rtx_3080_3090_leak
"Nope, won't happen",rtx_3080_3090_leak
Dont tell me how to PANIC! I will panic buy and complain about it all i want!,rtx_3080_3090_leak
"Videocardz said that for the moment there is no info about a 20GB AIB model. And that if it exists, it won't we launched anytime soon. So they probably will launch it next year as 3080 Super.",rtx_3080_3090_leak
"I wouldnt be so sure about that for various reason:

1-  kopite7kimi didnt say anything about a 20GB model and he is proven the most reliable leaker.

2- I dont know if there are any precedent about Nvidia allowing AIB partners to modify internal parts of the PCB

3-  First buyers will be turbo mad if they release a 20GB model just 1 month after the 10GB one. Its a hard shitty move... even for Nvidia",rtx_3080_3090_leak
"Given everything we know about Nvidia and AIBs, I don't understand why they'd allow them to make a variant with 2x the VRAM of their Founders card and still call it a 3080. They've allowed strange versions in the past but I have a hard time believing this.

It makes a lot more sense to me that this would be the 3080ti with a wider bus and they'll adjust the overall specs depending on what AMD puts out. The fact this has already been floating around as a rumor makes me suspicious it's primarily to pressure AMD.

This puts Nvidia in a position to release a 3080ti and even a 3090ti (or super cards) to take control if AMD gets too competitive.",rtx_3080_3090_leak
"Even though I would want a 20GB model, allowing AIBs to release one near the time of the initial release doesn't make sense as it'll under cut the revenues of the 3090.",rtx_3080_3090_leak
"So, it looks like, from the last 2 years at least, they will look to release upgraded boards for the original boards MSRP to an extent. 3080 super will replace 3080 and take that price, plus $100 probably. But, again, if AIBs can release 12, 15 GB 3080 variants now, kind of strange but possible, then the upgraded 3000 Supers will have to be quite a bit faster next year.",rtx_3080_3090_leak
Might be a good idea to hold off and see what the competition brings. Could potentially impact 3000 series and what variants they release. If you can't wait just buy the best for your budget.,rtx_3080_3090_leak
"3080 Super would be the same price as the 3080, but it would come out next year.",rtx_3080_3090_leak
"I doubt the 3080 super would be as much as the 3090 anyway. However, going off of the 2000 series super variants, it’ll be a while before they release a 3080 super. If you really want to “future proof” your vram count and have the money to spend then go with a 3090 now if you are in need of an upgrade. There are plenty of other benefits of a flagship card besides just the vram amount.",rtx_3080_3090_leak
"> what is your speculation for a 3080 SUPER's price

Same as the whole 30 series: somewhere between dirt cheap and obscenely unaffordable.",rtx_3080_3090_leak
"I wonder, will there actually be a 3090 Ti at some point?",rtx_3080_3090_leak
"But if you wait a year after that you get the 40xx series.

Which will be the most exciting I think. 

...",rtx_3080_3090_leak
If we had a die for 32bit that could have a lot of performance difference with the die.,rtx_3080_3090_leak
"Wouldn't put too much faith in compression tech since it will affect read / write speeds.

Thought it might be another thing that helps explain the high power draw.",rtx_3080_3090_leak
"I have the same setup. Couldn't be more happy considering the card is 4 years old and still handles most games at 1440p ultra. Also glad I ignored those saying ""a 4 cOre i5 WiLl aLwAyS bE eNouGh fOr gAmInG"" and went for an i7 6700k.

Just like people are saying ""8gb oF vRaM wILl aLwAys bE eNoUgh"" about the 3000 cards",rtx_3080_3090_leak
Keyword is *usable* not necessarily optimal.,rtx_3080_3090_leak
"I’ve been blown away by the performance of my 1080. I plan on upgrading to a 3080 when they release, but I’ve had this card for a few years now and it’s been a good ride.",rtx_3080_3090_leak
"""Usable"", that means all RT games are going to go by while you play games like they were made in 2010 with fixed shadows and no color bouncing. That 144hz 1440p is not gonna hold, you might be going down to 100hz or even less.",rtx_3080_3090_leak
Huh my 2070 super can't even maintain 1440p144hz,rtx_3080_3090_leak
"I got lucky, my 980ti broke after having it for 2.5years, reached out to EVGA and they replaced it with a 1080 for free, no charge, I was shocked. Still rocking it today and it is great",rtx_3080_3090_leak
"love my 1080. I also play at 1440p 144hz but i finally installed a game i cant run at max 60fps+ and cant even utilize raytracing and that is Control. Control is gorgeous, and it is begging me to uograde.",rtx_3080_3090_leak
I got one for damn near free from a hardcore gamer friend and damn if that thing still holds up.,rtx_3080_3090_leak
What to do for Ray Tracing with 1080ti?,rtx_3080_3090_leak
"Same. I'm still getting plenty of life out of my 1070 on a 144hz monitor. It's probably gonna be a few more years before I start to see it stall on the kinds of games I've been playing. It's not top performance, but at least it's not tripping the breaker every time I turn it on.",rtx_3080_3090_leak
Same one I currently have.  I may upgrade to the 3080ti if I can use pimax 5k on VR sim games.  I will wait for hard results first as that is a lot of cash to be putting out for two products.,rtx_3080_3090_leak
My 1080 / 4790k gets roasted on 4K / VR,rtx_3080_3090_leak
Yeah. The people who got a 1080 Ti on release got the best GPU value in history. I only got into PC gaming later and made an all AMD build and I can still see that. Im excited to see if Big Navi will cause problems for Nvidia considering how extravangantly priced this 3000 series is.,rtx_3080_3090_leak
"I wish I'd have gotten that card. I think I'd could be holding out on an updated for 2 years or longer, since I'm still content with the 980. 1080ti had turned out to be such a good value performance card.",rtx_3080_3090_leak
"unfortunately, 3060 will shit on 1080ti... rip",rtx_3080_3090_leak
"No kidding... I picked it up right at launch for an i7-5930k build. I don’t think I have touched it in 3 years for any reason. Oh and got like $300 off mining when the market was nuts  for like 5 months.

I can’t believe the value I got out of it. Probably can still sell today and walk away as a 0 sum affair.",rtx_3080_3090_leak
How was it originally priced,rtx_3080_3090_leak
I did and it has.,rtx_3080_3090_leak
I got the founders edition when it launched for like 700 bucks,rtx_3080_3090_leak
Lol at the people who got persuaded by marketing into waiting for Vega,rtx_3080_3090_leak
I bought the 1080 online instead of the 1080ti by mistake and was pissed beyond belief.  It’s served me well and I have no complaints but man was I mad,rtx_3080_3090_leak
"Hopper is gonna be insane, I’m definitely holding onto my 1080 Ti.",rtx_3080_3090_leak
Its a good thing your feelings dont indicate reality.,rtx_3080_3090_leak
Wow really because half this sub is people jerking off to the 1080 ti,rtx_3080_3090_leak
I agree.,rtx_3080_3090_leak
"I open my case and stare at the 2 980ti's brought to their knees by COD @ 1440p 144hz.... they look at me and ask ""Is it time to sleep now?""... I just dust them off and close the case again.",rtx_3080_3090_leak
My mummified 580GTX can't even see me. It's probably the dust though if I'm being honest,rtx_3080_3090_leak
"Same for me here, and my SLI is being useless with time, less and less game support it.. But still, the 970 keep doing the job pretty well.",rtx_3080_3090_leak
"Meanwhile my 950 says to me...

“I can count to potato!”",rtx_3080_3090_leak
Enjoying the 3.5 gigs of VRAM?,rtx_3080_3090_leak
The GeForce 8800 would like to have a word with you.,rtx_3080_3090_leak
I have a 1080 (no TI). Im a bit out of the loop why wouldn't it make sense for me to update to 2080 when they hopefully drop in price soon?,rtx_3080_3090_leak
"I mean probably the 3070+ will really make the 1080Ti look like nothing

But, that doesn't means the 1080Ti will be a card that runs at 720 low every game, it just won't hold well or run newer settings that won't be available for some time.

For 4K? 1080Ti and equivalents (5700XT, 2070S only if the game doesn't have DLSS) will definitely suffer at even low settings , for 1440P depends of how much FPS are you aiming? probably for 60 you will have to town some settings

For 1080p? They will handle newer games for some years at least",rtx_3080_3090_leak
i dont think nvidia is doing a gen per year. only amd is maybe,rtx_3080_3090_leak
"Here here. My 1070ti is  anxiously waiting to be put in retirement, it's served me well but it's time for a 3090 upgrade.",rtx_3080_3090_leak
"I'll be waiting forever if I keep waiting for the next hump.

Looks like 3080 is replacing my 1080ti.

I think the cost/performance will offer me a solid improvement for a year or two; it's going to be a little bit into the console cycle before we see more than a handful of games using that VRAM. There are 3 or 4 now, but honestly I only buy 2 or 3 AAA titles a year.",rtx_3080_3090_leak
"That would need to be an entirely different die to accommodate a different memory bus.  

And 500Mhz boost is just fantasy land.",rtx_3080_3090_leak
And then 12-18 months later they’ll release hopper. They seem to be aiming for a yearly release,rtx_3080_3090_leak
"Doubt it. They did the Super cards solely because the original line of 20xx cards was wildly overpriced and practically nobody bought them, causing Nvidia's revenue and stock price to both tank. They want the sales now, not a year from now after a shitload of additional R&D spending.",rtx_3080_3090_leak
"The horrible thing is it might not even be a year. The cards might be designed and ready to hit production, Nvidia are just waiting for the big Navi release so they can shift their performance and pricing segments.",rtx_3080_3090_leak
"> Calling it now, they be gimping that card so they can release a Super Variant with 12GB, 500mhz boost and GDDR6X in about a year down the line.

Is it too unrealistically to ask for a RTX 4xxx-generation in end of 2021? (just like when a new generation came out every year in the past... 6800, 7800, 7900, 8800, 9800, 280, 480, 580, 680, ....)?",rtx_3080_3090_leak
What's gddr6x? Is it an upgrade to gddr6?,rtx_3080_3090_leak
RemindMe! 1 year,rtx_3080_3090_leak
"Wait for amd to come out with a Navi Card at that price with 16GB of ram and 56 CUs above 2GHZ. Then Nvidia will come out with some real competitive cards, if it’s 8GB I hope no one buys it, consoles are going to offer 16GB of ram and they’re literally complete computers with mb cpu and everything else.",rtx_3080_3090_leak
Yep I’m over all these dumbass marketing tricks that screw you over. Might look at Amd,rtx_3080_3090_leak
Wow brave gamer thank you for saying what no one else would!,rtx_3080_3090_leak
"The 3080 being sold with 10GB of VRAM, the 3070 with 8GB ***AND*** without GDDR6X memory just makes the divide between the 3070/ 3080 and the 3090 ridiculous.",rtx_3080_3090_leak
3070Ti...,rtx_3080_3090_leak
3080 uses only 1gbps faster memory. It just happends to be G6X. Most of the difference is actualyl in the bus width not in the memory speed.,rtx_3080_3090_leak
"WTF do I actually do?


Watch them price the 3070 at $600MSRP. Clowns.

Was hoping for a £450-£520 3070 GPU, but Nvidia have literally shafted anyone who won't buy a 3080/3090.",rtx_3080_3090_leak
Maybe they add it with Super edition.,rtx_3080_3090_leak
Do we evem have an official tech for gddr6x anywhere by anyone? Like what is this gddr6x that suddenly came up? Because that 8gb gddr6 for 3070 could be at 16 or even 18gb/s that samsung showcased about 2 years ago.,rtx_3080_3090_leak
And yet it will sell like crazy.,rtx_3080_3090_leak
"There’s no point in me buying one because of this. The change in memory speeds and bus width make a huge difference for scientific computing which is what makes me interested these cards, and I’m not interested enough in scientific computing to pay for a 3080.",rtx_3080_3090_leak
I mean the 3070 will probably perform +-5% faster/slower than 2080Ti. Going from a 1060 to a 2080Ti is a gigantic upgrade.,rtx_3080_3090_leak
"If the 3080 performance leaks are correct, (33 percent over 2080ti) probably a good 10% faster than the 2080ti. Which makes things all the more weird. 

Nvidia almost certainly has to be confident in NVcache, or there are some very interesting bandwidth efficiency changes.",rtx_3080_3090_leak
8gb is enough for 4k. And with VRAM compression and 16gbps it'll be even better.,rtx_3080_3090_leak
"Assuming the price is right, wouldn't this be good for people that don't care about 4k and just want high FPS gaming though? Like, I haven't moved up to 1440p yet, if the price is good i'd love to have 2080ti performance for games at 1080p.",rtx_3080_3090_leak
">Probably almost as fast as a 2080Ti, but reusing the same memory configuration as the RTX 2070. That GPU is powerful enough for 4K gaming and raytracing, but the memory won't allow it

I have no idea what makes you think this, cuz it's just not true.  The 2070 is a fairly balanced card in terms of raw horsepower versus its memory setup.",rtx_3080_3090_leak
"What you on mate? I've never even came close to maxing out 8GB of VRAM in video games, and I play in 4k.

&#x200B;

Only game that surpassed 8GB was Resident Evil 2 & 3, but they all ran above 70-80 FPS regardless..",rtx_3080_3090_leak
">Probably almost as fast as a 2080Ti... That GPU is powerful enough for 4K gaming and raytracing

lolwut?",rtx_3080_3090_leak
"I'm into IL-2 & starting to get into racing sims, I just want the video card to be able to run max detail on my pimax 5k.  

At $1300, it's a lot of cash to fork out for a video card.",rtx_3080_3090_leak
Why are people so upset about the memory? I have not seen a single instance where a game's performance suffers because of VRAM usage.,rtx_3080_3090_leak
"> 16GB 3080

320 bit bus. Can only be 10 or 20.",rtx_3080_3090_leak
"honestly people with a 2060s shouldnt be considering an upgrade anyways, unless you demand the best. ithink people have forgetten that you can play anything within reason on a 400$ card",rtx_3080_3090_leak
Aftermarket 2080s may come with 20gb,rtx_3080_3090_leak
Only way that was happening is that is if GA104 was 384-bit memory bus & GA102 was 512-bit memory bus with various cut downs. But Nvidia hasn't done 512-bit memory buses since GF110 powering the 580 & 570.,rtx_3080_3090_leak
I will unwillingly upgrade just for the hdmi 2.1,rtx_3080_3090_leak
I'm still impressed they can't give a XX70 more than 8GB VRAM lol,rtx_3080_3090_leak
"Jesus how fucking retarded are you people, the message really got lost on you lmao",rtx_3080_3090_leak
*3.5,rtx_3080_3090_leak
I work with screenshots that big,rtx_3080_3090_leak
Yeah he leaked the full Ampere chips in May 2019. Kind of crazy.,rtx_3080_3090_leak
"But didn't he mention that they doubled the amount of CUDA cores? According to this leak, isn't he wrong?",rtx_3080_3090_leak
Or maybe 3080 Ti when Navi 21 comes out perhaps. Especially if the 800 for the 3080 & 1400 for the 3090 holds and Navi 21 is very competitive (basing on the XSX hot chips presentation it seems it will be).,rtx_3080_3090_leak
Maybe just G102 is 7nm and the rest 8nm. We will see I guess.,rtx_3080_3090_leak
"> I suspect we'll be getting a 3080 Ti

I think (and hope) they're doing away with the ""Ti"" models for ""SUPER"" models. I actually don't care which one they'd use, but having them both in the same generation is stupid--especially if the top consumer card isn't going to be a Ti model. 3060/S, 3070/S, 3080/S, 3090/S(?) just looks much cleaner.",rtx_3080_3090_leak
I feel like Kopite is still correct because he was right on GDDR6X,rtx_3080_3090_leak
Sliding a card into the supposed 19% gap between the 3080 and 3090 would be an interesting move for sure... I'ma still go full on 3090 though.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"It could be Samsung 8nm renamed as 7nm for marketing, videocardz does not say if they are using TSMC or Samsung. They already did that with Turing, renaming the 16nm process (optimized for Nvidia) as 12nm.",rtx_3080_3090_leak
"Basically there was a lot of speculation that due to capacity concerns, most of if not all of the new cards would be on Samsung 8nm, which would be a little worse and a little hotter. This leak confirms (if it's to be trusted) that the 3090 and 3080 are in fact on TSMC's 7nm which is a good thing.",rtx_3080_3090_leak
Basically TSMC 7nm is better,rtx_3080_3090_leak
"My limited knowledge, 7nm TSMC is proven to be really Good. Other companies have used them to be very good (Apple, AMD (Ryzen, RX 5xxx))",rtx_3080_3090_leak
"Less power for same performance, meaning if you do same power for 7nm and 8nm, 7nm will be better. And usually this number is meaningless. Is like when apple claiming their shitty numbers.",rtx_3080_3090_leak
Smaller equals more cores to put in a processor equals more power and performance.,rtx_3080_3090_leak
More power usage and more heat meaning lower cap on performance. Nvidia could make a more powerful card if they could get on TSMC.,rtx_3080_3090_leak
8nm Samsung is actually 10nm,rtx_3080_3090_leak
True,rtx_3080_3090_leak
Only TSMC fabs 7nm. It is their sales pitch. Samsung might have 7nm in the next couple of years. I doubt the 3090 will be that great for games. I expect it to be underwhelming.,rtx_3080_3090_leak
This was always up in the air.,rtx_3080_3090_leak
"> Nvidia wasn't going to completely redesign their entire GPU just to work on 10nm. 

You're implying a redesign was required, when no one knows what was designed originally. For all we know they had working silicon on both processes.

Also

> This 8nm rumour was complete unsubstantiated crap from leakers who just make shit up half the time. 

This came from the same person that said they'd be using GDDR6X before Micron or Nvidia had said anything. I'm not saying they're right, but to blow them off as someone who ""make shit up half the time"" feels a little unjustified.",rtx_3080_3090_leak
">I'm really confused if they are using TSMC 7nm why do they need this insane cooler. It should be an efficient node. 

 The node does not determine power used. It only determines power efficiency. The two are not the same thing whatsoever. 

For example in an imaginary scenario a 350 watt GPU would be very power efficient on TSMC's 7nm vs a different node. On Samsung's node the GPU could use 400 watts or more. Power efficiency and power used are totally separate concepts.",rtx_3080_3090_leak
Man a $300 boost on all 3 of the higher end cards MSRPs would be insane.,rtx_3080_3090_leak
"Well, 1st there has to be a 3080 20GB for me to buy in november, because i will upgrade immediately after the AMD big Navi launch.

If there is no 20GB card and big navi turns out at least on 3080 performance level i will go with team red, because i assume AMD will price the cards very similar (<1000€)

If there is a 20GB card i get the one with the better overall perf/€",rtx_3080_3090_leak
They're starting to sell to corporate clients now. These cards look like someone a business would use and not a gsmer. I see why they're going to sell it at 1000.,rtx_3080_3090_leak
Then they'll watch their revenue and stock prices drop like a rock just like they did after the overpriced 20xx cards released.,rtx_3080_3090_leak
"I would be willing to pay a £100 premium for 20gb, no more. If it's more I'm better off just going 10gb and upgrading again to Hopper.",rtx_3080_3090_leak
"Nah, I guess it will be $780 for a 3080, $900 for the 20 GB version.",rtx_3080_3090_leak
"Yes brother! The 970 has lasted me such a long time, but I’m stoked to finally upgrade.",rtx_3080_3090_leak
"I'm on the same boat as you. The 970 has served so well throughout all the years for 1080p, but I'm finally ready to upgrade to the 3080 and I don't care if it's ""just"" 10Gb, that's enough for 1440p and I'll be more than happy with the purchase.",rtx_3080_3090_leak
I just upgraded my 2016 asus strix gtx 970 oc to an Asus Dual Evo RTX 2070 oc.  No regrets about not waiting for the Next Coming Messiah rtx 3070,rtx_3080_3090_leak
"In the same boat with my 960 4gb. It’s still working fine-ish for now, but I also haven’t made the move to 1440 144hz for exactly the reason you mentioned. 1080 60hz isn’t quite as taxing.",rtx_3080_3090_leak
Yeah this time wait to be sure it's not a scam and it's the good amount of vram xD,rtx_3080_3090_leak
"Laughs in 760 that stutters when playing Factorio.

Anything I buy will be a massive upgrade.",rtx_3080_3090_leak
"I upgraded from a 970 to an rtx 2060 super a couple of months ago for 440 euros. Plays anything you throw at it on max on 1080p. My flight simulator is on high end on two screens at 60fps stable.

Dont buy into the hype and buy what you need, not what is newest.

People are still thinking prices will go down with new 3 series release, but it's a dream. 

I had heard the same when 1070's released and they didn't come down in price at all.",rtx_3080_3090_leak
"The 970 paired with a G-sync monitor is surprisingly awesome. I'm running a fully modded Witcher 3 in ultra mode with 4k textures, framerate drops down to 40 at times but it's still super smooth. Upgrading this gen is still a no-brainer, sadly the choices aren't as nice as I had hoped.",rtx_3080_3090_leak
Team 950 what what,rtx_3080_3090_leak
"AMD RTX will be probably more limited and not as fast as NV's. Not to mention their drivers will probably suck ass for the next year or so.

It's not like RTX is that important tho. It's still mostly a gimmick and will be relevant from 2020 at earliest. It's a luxury techdemo as of now.",rtx_3080_3090_leak
">I won't change my 1080TI for a, what? 800€ card that has less VRAM?

Does it matter if it's faster? do you really need more VRAM?  
If it's faster (and it will) it means 1GB less isn't so much of a problem, otherwise it wouldn't be faster.

Just wait for benchmark and remember that console have to share RAM with both GPU and CPU while on PC you something like 16GB of system RAM + 10GB of really fast VRAM",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"I'm sure a 3080S will be released, but how long is it going to take and how much is it going to cost? I'm in the same boat, I'm rocking my GTX 1080 Ti FE that I've had since its launch. I skipped the 20xx series because of no HDMI 2.1 but I'm ready to upgrade to a 3090 at this point since I've been holding onto the budget for a few years at this point. 

At the very least, the 1080 Ti's are still holding their price and I'm hoping to get around $350 after I upgrade which helps offset the cost of the 3090. Then again, if people wait for the SUPER variant of the $799 3080, I'd expect to pay *at least* $999. But again, how long's the wait going to be? It *probably* won't launch before CP2077.",rtx_3080_3090_leak
Gotta just endlessly wait. By the time the 3080ti comes out it'll be better to just wait for 40xx,rtx_3080_3090_leak
What does it mean to come after this launch period? As in how long will that take typically?,rtx_3080_3090_leak
Let's hope that it'll make sense.,rtx_3080_3090_leak
"It's replacing the Titan series. They've changed the name of the Titan series and dropped Ti because it supposedly confused consumers, however this new naming scheme is exponentially worse. The 3090 isnt a consumer card, at minimum it's a prosumer card. Based on specs I'd say it's geared towards professional use for people that dont want to drop the money on a Quadro but still need a large amount of VRAM",rtx_3080_3090_leak
"the other thing is that it’s sucking down a lot of power whether or not you’re utilizing it all, memory power is a significant part of the TBP increase on these new cards.",rtx_3080_3090_leak
"indeed :D

best card i ever bought",rtx_3080_3090_leak
Now that Nvidia isnt giving me a reason to immediately jump for the 3080/3090 i will definitely wait,rtx_3080_3090_leak
Bung some savings into an international account as Euros if you want to buy after the crash without losing out as much.,rtx_3080_3090_leak
"Also consider that next gen games are coming, 4k will definitely require more then 10 gb.",rtx_3080_3090_leak
At 4k it definitely could,rtx_3080_3090_leak
"It’s kind of genius subconscious marketing by Nvidia if you think about it. There’s a big chunk of current 1080 Ti owners who are starting to get that upgrade itch now. All of those people who blindly proclaim they would never upgrade to a card with less VRAM have just convinced themselves their only viable upgrade option is to just shell out for the top end halo card, completely taking the lower cards out of consideration even if they offer a much more compelling value. I would not be surprised at all if the eventual reviews and benchmarks put the 3070 just under the 2080 Ti, or roughly 35-40% faster than the 1080 Ti.",rtx_3080_3090_leak
"This sub is so fixated on this, I don't get it at all.  11gb of GDDR5X vs 10gb of GDDR6X - they aren't even the same type of ram and it's only 9% less ram.

None of this translates at all to performance numbers.   If performance is better who cares about the 9% less ram number.",rtx_3080_3090_leak
"Maybe the 3090 is the new ""titan"" and they left the gap between 3080/3090 so they can launch a 3080ti when big navi launches?  In any case, i'm waiting for big navi just to see if it triggers prices drops and/or a ti/super release.",rtx_3080_3090_leak
"The rumors are that big navi will launch in november, because AMD said the RDNA2 cards will launch before the new consoles.",rtx_3080_3090_leak
"I want all the eyecandy i can get. The 1080Ti is starting to struggle in newer games in 3440x1440 if i dont lower some settings to medium. I play Horizon Zero Dawn atm and many settings are high or medium to get at least 70+ FPS most of the time. Not to mention that the 11GB VRAM arent enough in this game in this resolution, so i have a lot of VRAM stutter.",rtx_3080_3090_leak
https://imgur.com/a/pgVXjOS,rtx_3080_3090_leak
1000+ GB vRAM,rtx_3080_3090_leak
"I will definetly hold out for Big Navi.

Lets just hope AMD was able to harvest some of that RYZEN mojo and feed it to the RADEON team, because competition is good for us customers",rtx_3080_3090_leak
"Ah yes, i forgot theres a difference between the US and germany with , and . 

I bought the 1080Ti in march 2017 on release day for 819€",rtx_3080_3090_leak
Yikes,rtx_3080_3090_leak
"Ya I got a 2080ti with an AIO I bought for 1400 new. Dunno what I’ll get out of selling it, but I bet it’ll be enough to cover a good chunk of the upgrade! Lol",rtx_3080_3090_leak
https://www.nvidia.com/en-us/geforce/special-event/,rtx_3080_3090_leak
yeeeeeeeeeehaw,rtx_3080_3090_leak
The 30xx series of cards are to be announced on the 1st. Or so the rumors say anyways,rtx_3080_3090_leak
"im excited because im finally upgrading from  a 980ti, I'm probably sticking to 1080p+240hz though so this works out incredibly well for me. I've never tried 1440p but I mainly play esports titles.",rtx_3080_3090_leak
"> monitors with DP 2.0 don't even exist yet

...and it will stay that way as long as Nvidia refuses to adopt it.",rtx_3080_3090_leak
Why wouldn't it? As long as it comes out within 90 days of your purchase and you registered in the first 14 days.,rtx_3080_3090_leak
Is the step up program US only? UK based here and never come accross it.,rtx_3080_3090_leak
I dont envy you this time of year! haha,rtx_3080_3090_leak
"The overall sentiment of ‘nvidia should stop messing with the pricing and product stack’ is fair, imo. Everything FEELS extremely expensive, even if when you ignore the numbering the improvements are sort of acceptable.",rtx_3080_3090_leak
"This is my point though. You have no idea what 10GB actually means. It's not going from ""11 to 10"". It's going from 11GB DDR5x to 10GB DDR6x. We have no idea what that actually means yet in raw performance until we see the benchmarks - I can say all 1080ti owners would feel super happy upgrading if there was a 100 percent performanace improvement....so why does the number of VRam matter? It's just been ploughed in to your head by Nvidia/AMD that more VRam = better. There are other things at play....",rtx_3080_3090_leak
But they'll be fine spending 800 euros for a big performance boost.,rtx_3080_3090_leak
Who cares about that tiny group? I went from 11-8gb and didn’t miss a thing. If wankers love that card so much they can stick with it this gen as well.,rtx_3080_3090_leak
"Are you planning on getting a pre-order? If you can wait for some benchmarks and hold out for a few weeks you'll get a lot of peace of mind knowing that you've got yourself a great card, or indeed steered clear of something thats been slammed.",rtx_3080_3090_leak
"What i mean by that is that inherently I dont think the actual GPUs are THAT different. However, if you whack a load of extra ram in and a load of extra electricity it'll do more and run hotter and need a bigger cooler. You can stick more electricity through a 2080ti, overclock it and cool it down loads with a massive cooler if you wanted do. Doesn't make it particularly innovative or exciting.",rtx_3080_3090_leak
Completely agree,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Will it use over 10GB of DDR6x on a 3080?,rtx_3080_3090_leak
Potentially yes.,rtx_3080_3090_leak
"Except Nvidia, the ones who make GPUs for a living/massive profit havent seen fit to increase the actual VRAM in 2 generations...doesn't that tell you something? As i said, they're releasing a 20GB version too....so whats the problem and why are you so angry at what I said which boils down to ""wait and see the benchmarks before getting angry"" and ""If you believe you'll need the RAM and are worried about the future then buy the 20GB version""",rtx_3080_3090_leak
"To be honest, my only thought on the matter is it' basic common sense. Why complain about the numbers if we don't know what the numbers mean yet? We'll find out in like 3 days....everyone just needs to chill.",rtx_3080_3090_leak
"So how long do you think until there will be games that easily max out the 10 GB? How do you know these cards arent going to handle other things decidely better than previous generations? The truth is nobody knows exactly how this architecture is going to handle amything and we won't know for sure until we see the benchmarks which will happen in the next few weeks. If the 3080 underperforms and it turns out it cant run Flight sim the way people want it to and it needs more ram then fine, complain then, but to complain about potential issues that might be encountered in two/three/four/five years, especially when you have no idea if said problems might be fixed elsewhere other than ""MORE VRAM"" all while not having seen any benchmarks is just being silly.",rtx_3080_3090_leak
"No. Today there arent many things gamers do to max out even 6gb... 8gb on current day hardware will be plenty for atleast the next 4-5 years, let alone 10..",rtx_3080_3090_leak
"Afraid i can't give a proper technical answer on this, it was just something I was reading about. IF anybody else is around to either correct me or explain that would be great.",rtx_3080_3090_leak
"I am not sure of the technical answer.. I assume it's physically connected to the actual gpu... therefore, more vram ICs equals more bandwidth.. which is why bit bus increase with more chips.  Basically, it would have the same bit bus as the 3090 and performance would be too close.  Nvidia has been gating performance with bit bus like this for YEARS..",rtx_3080_3090_leak
"Maybe, wait for benchmarks",rtx_3080_3090_leak
Of your GDDR5X RAM? Cool. Wait for benchmarks,rtx_3080_3090_leak
"No idea, wait for benchmarks",rtx_3080_3090_leak
"That's a load of hilarious bullshit. It took literally a fuckin decade for core counts to start mattering at all, and even today only in a small handful of games does it make a big difference. Just because you got fooled by AMDs marketing bullshit (not that their cpus are bad, just not because of core count) doesnt mean anyone was wrong.",rtx_3080_3090_leak
"And if that's the case then sell the 10gb and get a 20gb version when theyre released (potentially even a couple weeks later). All i'm saying is at this point in time theres not much that needs 10GB and if it benchmarks really well comparatively then great, the majority of people wont need to worry about the VRAM anyway. If you're not one of those people then thats fine too and there'll be a 20GB version later if you need it. Everyone complaining about the Vram seems to be forgetting that they're releasing a 20GB version too....",rtx_3080_3090_leak
"Could be lots of reasons. The 3090 is almost certainly binned better, so it'll likely have better power characteristics. The 3080 is also clocked higher according to this leak, so even more power consumption as well.

There's also a chance the TDP listed leaves some thermal room for the 20GB 3080 models that AIB's are apparently going to be shipping.",rtx_3080_3090_leak
">It will probably consume around 400 watts with a full OC.

It will consume as much as they arbitrarily limit us to. If the max power limit is only +14% that's going to suck.",rtx_3080_3090_leak
My 392W full spectrum LED grow lamp which covers a 2x4 foot growing area with the power of sunlight for some vegetables.  Or I can crank up Microsoft Flight Simulator haha.,rtx_3080_3090_leak
"Definitely, assuming you don’t have some crazy OC on your CPU",rtx_3080_3090_leak
"Yes, easily",rtx_3080_3090_leak
"TDP is how many watts the specific component draws at max load. You need a power supply with enough wattage to cover all your components, plus a little headroom for efficiency losses. Most GPUs are <200 W TDP so the jump to 300+ W is a significant increase.",rtx_3080_3090_leak
"> If you want to be specific, TDP stands for thermal design power which refers to the heat generated by the component. Usually you see it mentioned with cpus when you choose a cooler for them. Here it's TGP which stands for total graphics power, which is the power draw of the gpu (not sure why everyone calls it TDP here) assuming you run it at stock without overclocks. 
TGP and TDP aren't usually the same because I know my cpu draws more power than its TDP suggests when it's under load.

Copy pasting my answer to someone else above.",rtx_3080_3090_leak
"4x8 without dropping any performance in bifurcation would be pretty sweet though in an SM560 or similar case

edit: assuming the appropriate riser cable gets made for 4.0",rtx_3080_3090_leak
"DP 1.4 will do it if the monitor supports display stream compression. 

But HDMI 2.1 will do it natively so it’s not the biggest deal.",rtx_3080_3090_leak
"Yes, if chroma subsampling is to be avoided.",rtx_3080_3090_leak
What about DSC? I thought that is new tech that lets you hit 4k 10bit 144hz without chroma subsampling?,rtx_3080_3090_leak
DP 1.4 can drive that and can power even 5120x1440 @ 240Hz with Display Stream Compression that is only featured on Turing so far.,rtx_3080_3090_leak
No. You can use lossless data compression.,rtx_3080_3090_leak
Chicken and egg...,rtx_3080_3090_leak
I’ve seen a few comments that point out Nvidia released a firmware update for Pascal that upgraded the DisplayPort. Maybe that can happen again.,rtx_3080_3090_leak
Does speed actually reduce the amount of vram needed? If the game throws the mem full of textures full = full right? Even with higher speed mem?,rtx_3080_3090_leak
"The 3070 according to this doesn't even have GDDR6X, and the 3080 has less than half the VRAM. I know VRAM isn't everything and I do plan on waiting for benchmarks, but this news at face-value is just kind of disheartening. I'm also still waiting to see what AMD has up their sleeve but it seems like they're gonna be a bit late to the party.",rtx_3080_3090_leak
Huh? Computer monitors have DP so it’s irrelevant. This is for purposes of playing on a large LG OLED and the like that don’t have DP connections.,rtx_3080_3090_leak
How to vr increase ram requirements?,rtx_3080_3090_leak
I had 5 amd and 4 nvidia gpus . Neither of them had game breaking problems. Both of them had bugs or some issues but nothing serious .,rtx_3080_3090_leak
"Every device has driver issues. And I've been dealing with one particular Nvidia issue relating to how they deal with texture transparency *for 15 years*. AMD cards can filter them just fine but every generation of Nvidia cards since 2005 messes it up, in the name of optimization.",rtx_3080_3090_leak
Except this time round AIB's are preparing to launch the same time as FE.....,rtx_3080_3090_leak
"Oh cool, that's not bad at all.",rtx_3080_3090_leak
"With multiple water block manufacturers stating that they will have new products at launch, I highly doubt it will take as long as it did the last time around.",rtx_3080_3090_leak
Arkham Knight flashbacks,rtx_3080_3090_leak
"Yes, they almost always target console hardware. So it's a mystery as to how pc games will perform in the coming years with the new generation",rtx_3080_3090_leak
4K or VR sucks up VRAM like it's nothing..,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"next console generation VRAM specifications are still uncertain, but 10 gb is nowhere near enough for AI and machine learning.",rtx_3080_3090_leak
">and the subreddit being plagued with AMD fanboys at the moment)

Seems more like broke college students shitposting in between their zoom classes",rtx_3080_3090_leak
Then I could have turned around and sold it online for a profit as the 2080 was sold out for months.,rtx_3080_3090_leak
"Congrats for you...
I'm locked into gsync with my monitor :(",rtx_3080_3090_leak
All the 20GB will offer is some future proofing. Which at the expected price point would be nice.,rtx_3080_3090_leak
How do I know if my PCIE on my Mobo will support these higher speeds? I have a Z370-P but can't really find any info unless I'm looking for the wrong thing,rtx_3080_3090_leak
"Yeah I don't get people, are you looking to be burried with your next graphics card? Are you gunna marry it? If you upgrade every 2-3 years 8 GB will be fine. Future proofing is stupid. Buy it, use it a couple years, sell it buy the next thing.",rtx_3080_3090_leak
"That 760GB/s is irrelevant when you are limited to PCIE 3.0 or 4.0 16x to load that missing 1GB of ram from system ram.

We call that a stutter.",rtx_3080_3090_leak
"Yeah I would wait for the 20GB models 100%

EDIT: To clarify I would wait if you game at higher resolutions like 4K and VR.",rtx_3080_3090_leak
"That's what I'm probably getting, hopefully we don't have to wait too long.

If by some miracle the 3090 is reasonably priced I'll get that but I have a feeling that it's going to cost as much as a decent second hand car.",rtx_3080_3090_leak
yeah but that'll be next year.,rtx_3080_3090_leak
The 5700XT is great for my needs right now since I only game in 1440p. I was planning to get the 3090 to play 4K but now I am not sure.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Isn’t step up within 30days of new cars coming out?,rtx_3080_3090_leak
"I'm not OP but in my country (Chile) is *even worse*, like x3 or x4 of average income for a 3090 after tax lol",rtx_3080_3090_leak
"Croatia for example. The average salary here is \~1000USD / month.  
The main market here are the x60 cards and even they are quite are becoming way to expensive.

There are also huge markets with even less money available like Russia or China.",rtx_3080_3090_leak
If you're not at 4k above 60 you'll be fine,rtx_3080_3090_leak
Happy fantasies crushed by sad truths.,rtx_3080_3090_leak
"I won't pay more than 399$ for the rtx 3070, even more, if it only have 8gb, i wont even pay 300$ for it.

Overpriced gpu = me going for a console.",rtx_3080_3090_leak
"They literally never said they were using 8nm. ""Leakers"" made it up.",rtx_3080_3090_leak
I don't know. It was just a technical difference to me that I noticed.,rtx_3080_3090_leak
"In theory, a smaller die should be more power efficient and generate less heat than a larger one. I don't know what the real world difference is between 7 and 8 nm though.",rtx_3080_3090_leak
"TSMC's 7nm is better. It can fit more transistors in a smaller area, (likely) clock higher and use less power. However, it is in high demand and as such costs lot of money per wafer: on the order of \~10k USD. The SS 8nm process is a iteration on their 10nm node, which is dramatically cheaper per wafer, however there is no confirmation that they're using either one.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Why, when a 2070 Super is just fine for my use case today?",rtx_3080_3090_leak
">That's and absolute top end use case that isnt relevant to 99.99% of the market. And frankly with such requirements, you're the crazy one for even looking at anything but top end gpu either.. 

3440x1440 is nowhere near a ""top end"" use case. Pretty common higher end enthusiast resolution. But it also does not need more than 10gb of vram.",rtx_3080_3090_leak
Thanks!,rtx_3080_3090_leak
"So I have a 6700k and want to get a 3080. Only temporary until zen 3 release. Then I’ll build whole new comp. 

I have an sf600

You think I’m pushing it? 

Currently running a 1080ti. 

Thank you",rtx_3080_3090_leak
I also have a 750w PSU. Would that be enough to support a 3090 with an overclocked 8700k?,rtx_3080_3090_leak
"You can run a 2080ti and a 9900k at like 400-450w.

This is not a big deal.",rtx_3080_3090_leak
"It's the TGP that is 350w -- not the TDP.

[Graphics Cards: TDP and TGP](https://www.geeks3d.com/20190613/graphics-cards-power-tdp-tgp/)",rtx_3080_3090_leak
Those recommended stats are overkill.,rtx_3080_3090_leak
Just a 3700x - whew!,rtx_3080_3090_leak
damn this guy has a 140mhz monitor while we're stuck in 2020 with our 144hz monitors,rtx_3080_3090_leak
"2gb was already not enough for bf4 at 1080p at ultra. So I don't think that held for too long, we were already close to hugging the limit back then. Now it's sometimes getting close to 8gb at 1440p if the game is terribly optimized, but most of the time my vram usage stays below 4 gb...",rtx_3080_3090_leak
"So? It was. Not for 10 years, but for a few, 1-2 gpu gens definitely. Not to mention that this gen the console ram increase isnt 10-16 times either..",rtx_3080_3090_leak
That wasn't the majority pardunk,rtx_3080_3090_leak
You sound like a pilly legged swamp monkey,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"""I'm a motherfucking monkey""

-You",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Do you have any evidence of the poor ram management? I googled AMD poor VRAM management but didn't find anything,rtx_3080_3090_leak
"Thank god.  
I saw that 3080 as the same amount of cuda cores of the 2080ti and I was scared.  
In your opinion the jump between turin and ampere will effect RT and TC performance?  
So we have better rasterization, better ray tracing and dlss?",rtx_3080_3090_leak
"I think the 3080 20GB will carry most people thru 1440p gaming for the next 4 years. But if your on the fence, I'd wait for AMD Navi news to see their offerings. It's only a couple months away. 

The 3070 looks like something you'll be forced to upgrade in 2 years. It also just seems like a trap at $600+. If it goes on sale for like $480 or less then it's a good buy. 

If anything definitely buy a power supply now if you are upgrading. They are going to be massively limited in early spring 2021.",rtx_3080_3090_leak
"20 gb is too much and they'll probably charge too much for it, you don't need 20 gb of vram just wait, maybe amd will have a gpu for the same price with 12gb of vram instead of 10 which for me is the sweet spot for futurproof",rtx_3080_3090_leak
"*Help me AMD Kenobi, you're my only hope*",rtx_3080_3090_leak
Do we have any info on base clocks for both of them? Their boost clocks seem marginally different,rtx_3080_3090_leak
this is 3090 vs 3080,rtx_3080_3090_leak
"You must have misread what I said then, thanks for the downvote though.",rtx_3080_3090_leak
Doesn’t hurt to try. You might need an entire new house to cool and power it anyway. /s,rtx_3080_3090_leak
PayPal credit.,rtx_3080_3090_leak
"Credit card has entered the chat. If you only had the balance of a 3090 and made minimum payments, then you'd probably be financing it for \~5 years and pay \~$700 more than it's sticker price. Or get new credit card with 0% intro for the first year, then pay \~$110/mo for 12 months and avoid interest, and thus overpaying for it; take the $700 you would have paid if you financed for 5 years and invest it in \[almost anything\] for 5 years. Win!

Edit: not actually advising this",rtx_3080_3090_leak
"If you don't care about the money, just buy a pre-built from Dell (Alienware) and throw away the rest of machine. They will guaranteed have stock.",rtx_3080_3090_leak
"No idea man but I'll be waiting with the store page up and my wallet ready, really hoping the preorders are available for atleast an hour. Better not be no 30 seconds and it's sold out bullshit.",rtx_3080_3090_leak
at those prices probably easy,rtx_3080_3090_leak
"Gotta save a little over time friend. I have a fun money account that I auto deposit $50 every Friday into. So when it comes time to buy a new gun, game, computer part, etc... It doesn't hurt my pocket. Also selling your previous Gen gpu helps a ton. My 1080ti that I had for 2 years sold for $500 the other day. That's $500 off the 3090.",rtx_3080_3090_leak
"It'll be my first nvidia FE card as well. I've been with evga for over 10 years and would prefer to stay that way. Rumors point to partner cards launching same day, so my plan is to preorder a 3090 FE then try to order an evga card at the same time. If I can snag an evga card I'll cancel my FE card. But in the past evga cards sell out extremely fast, I really hope they have preorders available but I'm not sure.",rtx_3080_3090_leak
Oh dude it's gonna be $2200-2500 probably.,rtx_3080_3090_leak
F ya. Lot of people still rocking that card.,rtx_3080_3090_leak
"I bought a 1080 ti refurbished from Zotac for $413.99 I replaced my 1070ti which I resold for $265.  My 8600k is now at \~90% utilization in 1440p   
 Warzone. I imagine if I upgrade to the 3000 series ill actually be bottlenecked by my processor. Seems like the 8600k and 1080ti are a perfect pairing.",rtx_3080_3090_leak
"And it will be the best consumer card for 4k.

End of discussion there.",rtx_3080_3090_leak
">Metro exodus and control are prime examples of why 10gb isnt cutting it..

Neither of those games use 10gb, even at 4k ultra RTX on etc",rtx_3080_3090_leak
CSGO at Ultra settings,rtx_3080_3090_leak
"I’m expecting a Titan with fully enabled GA102 with 48GB VRAM, at around $2999",rtx_3080_3090_leak
Wonder if less bandwidth means is a prouser GPU then,rtx_3080_3090_leak
Bro thats a damn used car. Nvidia is seriously getting out of hand,rtx_3080_3090_leak
If thats the case then they are probably just making waterblocks for FE models at first and AIB cards will probably come months later. Either way im still in a wait and see mode. Dont plan on buying until rdna 2 drops and i can actually compare both cards. Though the way my savings is going i may end up with enough for the 3090 by the time rdna 2 drops so its already tempting,rtx_3080_3090_leak
It’s gsync compatible. So yea kinda,rtx_3080_3090_leak
"On HDMI 2.0b:
2560x1440 @ 120Hz for a 40-120Hz Variable Refresh Rate range
3840x2160 @ 60Hz for a 40-60Hz Variable Refresh Rate range
On HDMI 2.1
4K 40-120fps.",rtx_3080_3090_leak
"Yeah that's my concern. Between that and a coupon I need to use that will probably cover any future price drop of the 2070S after the 3000s are announced, I might as well go that route. Guess I can wait a few days just in case though.",rtx_3080_3090_leak
"I was looking at the same B450 and SSD, but two of them because I'm likely going to try to dual boot so I want an OS on each drive. I was going up to a 750w PSU and 2x16 3600 ram (brand tbd). I actually considered doing exactly what you're thinking about, just do everything \*but\* a GPU while I wait but I would be worried about putting something together and then having a 3000 series GPU just be an energy whore and then need to redo do the PSU and cooling and just need to rip it all apart and put it back together again anyway. Have not decided on a case yet, but likely something mid size.

I also already have a dual 1440p monitor set up that I run off of my docked MacBook Pro so I'd be sacrificing a screen for a while if I went onboard GPU since I think most only have a single output. I really don't know. My local Best Buy actually has the 2070S in stock which is tempting as hell. I'm worried about waiting until Nvidia announces the 3000s and then realize they'll either be priced out of my range or the 3060 or 3070 won't be out for months. Can't really wait that long. My MBP is slowly dying and I just can't have the down time.",rtx_3080_3090_leak
The forecast is that it will rise 46~% in the next 5 years. Which seems pretty good.,rtx_3080_3090_leak
"I assumed it would do fine, but I guess not. What power supply would I need to go for?",rtx_3080_3090_leak
"for gaming: League of Legends and work: deep learning, and photo and video editing.",rtx_3080_3090_leak
I eat my words.,rtx_3080_3090_leak
Probably the same as me because its only 8GB GDDR6,rtx_3080_3090_leak
"Because people are kneejerking and making absolutely no sense. 

VRAM means fuck all if the performance is not there. Most important thing is still how the GPU performs.

The VRAM is only an issue if you're running into certain scenario that maxes out your VRAM.",rtx_3080_3090_leak
Because I'm getting 6900xt now with 16gb of TSMC memory and will be more than comfortable for the generation without worrying if memory pools will exceed 10gb (which they will). Same thing happened with Intel fan boys excusing 4 cores.(That turned out well),rtx_3080_3090_leak
"People think they **have** to get the best possible thing on paper otherwise their e-peen will shrink into nothingness. Some of the things I've seen people bitching about only make a minimal difference unless you are going for 4k at high refresh rates. 

And in that case they are just entitled retards for bitching about it anyway because it's like saying they want to do 300km/h on a racetrack but only want to buy a ford fiesta.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Such an unnecessarily stupid comment.,rtx_3080_3090_leak
"Rumours point to a decent performance bump, especially in ray tracing, so that's what got me interested.

Also I sold my 2080 Ti a couple weeks ago so I literally have no choice now, I've already committed!",rtx_3080_3090_leak
"Eh, if I had a 2080ti I'd be selling it TODAY.  There are still people paying more than 3080 (rumored) prices.  And 3080 > 2080ti, plus probably have some money left over.",rtx_3080_3090_leak
"Assuming a person has money to burn, it can be worth it. 2080ti is powerful, but it *juuust* isnt quite there for some games 60fps@4k or 144@1440p. And rumors are that the 3xxx ones will have much better rtx performance too.",rtx_3080_3090_leak
Because a 3080 at $800 will probably beat it (Judging by the rumours) by about 10-15%.,rtx_3080_3090_leak
Consoles didn't have 16gb until now.,rtx_3080_3090_leak
"Samsung does have 7nm, only it's yields aren't great....",rtx_3080_3090_leak
"Nvidia is the King of GPU's absolutely no argument here.


But with all the Ryzen Money, and the new RDNA Foundation and Zen like Roadmap AMD may surprise us.


Keep in Mind that the Xbox Series X GPU with 12 tflops of RDNA 2 and 52 CU's (with over 10 GB of Ram) is merely using around 170 Watts.


AMD might ultimately lose on performance but efficiency might be great.",rtx_3080_3090_leak
"Because RDNA 2 is going to have a 50% increase in power efficiency compared to RDNA 1, as confirmed by AMD already. RDNA 1 already added 50% power efficiency as well compared to Vega, which was a big jump. I wouldn’t be too surprised if that would finally be enough to close the efficiency gap with Nvidia.",rtx_3080_3090_leak
"Hmwell apparently we're partly both right, if I look at the 2080 with 215w tdp, and the 3080 at 320w tdp, that's nearly a 50% increase, gddr6x however according to micron only has about a 25% increase in power consumption compared to gddr6  
If what this says is true in practice https://www.anandtech.com/show/15978/micron-spills-on-gddr6x-pam4-signaling-for-higher-rates-coming-to-nvidias-rtx-3090  
  
Nevertheless I have a feeling that this time around it might a good idea to just wait and see, so we can compare some hard numbers first, at least I know I will, I like nvidia's stability, but they're starting to become nearly unaffordable",rtx_3080_3090_leak
Wtf no. He will be absolutely fine with 750w.,rtx_3080_3090_leak
Lol I’ll have some of what’s he’s smoking..,rtx_3080_3090_leak
"Why is this guy getting downvoted? best Power efficiency for a psu is generally around 50-60% usage, so if a 3090 system is using 500w his numbers make sense.",rtx_3080_3090_leak
"ok thank you, I was more worried about future games because I would eventually play with a 4K@144hz monitor.  Not expecting to get max frames even with the new cards tho.",rtx_3080_3090_leak
"good way to look at it, thank you for the info",rtx_3080_3090_leak
most of my games hit +7gb of vram at 1440p.,rtx_3080_3090_leak
"interesting, that's an odd decision",rtx_3080_3090_leak
okay thank you,rtx_3080_3090_leak
is that because the newer VRAM is faster?  + you got rtx too,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
And your 1080ti isn't on 6x with memory streaming improvements. Wait for benchmarks.,rtx_3080_3090_leak
"That 16gb of memory for the XSX is not just dedicated to graphics. It will be used as system ram as well, meaning the OS will also take up a portion of it.",rtx_3080_3090_leak
"Holy shit, thats a lot of performance. Unfortunately I might afford it and I dont know if I can wait until the release of the 3060.",rtx_3080_3090_leak
Then its rtx 2000 for me,rtx_3080_3090_leak
I have a i7 8700 and a corsair rm650x. This brings me hope :),rtx_3080_3090_leak
"Because? A good 650W psu can output 650W on 12V consistently and peak power to 750W ish. If your gpu uses 320W you have 330W left for the rest. Cpu =150W OC, rest uses like 100W max or other rails. Total = ~570W peak. This will run easily on a good 650W unit.",rtx_3080_3090_leak
thanks!,rtx_3080_3090_leak
"I'm on a 3600 now, waiting for AMD 4000 series to go to whatever equivalent to either 3700x or 3900x but still that's like 65 to 105 TDP so shouldn't make a big difference.",rtx_3080_3090_leak
How much time since the launch until the youtubers get the cards?,rtx_3080_3090_leak
"Damn 
Just finished saving $500usd for a new card this month 
Gotta waits few months",rtx_3080_3090_leak
Not sure where you're getting your information but rumors have 3080 at near 56% above the 2080ti right now.,rtx_3080_3090_leak
Damn I really hope it doesn’t but I’m not surprised if it does sell that high because nvidia loves raising their prices every generation...,rtx_3080_3090_leak
"Which is still alright, since the entire system shouldn't go over 300W.",rtx_3080_3090_leak
I’m guessing you don’t have very many friends.,rtx_3080_3090_leak
"Sure, I more want to know if those would be available before preorders go up or after",rtx_3080_3090_leak
imma cry now,rtx_3080_3090_leak
WHEN THE WINGED HUSSARS ARRIVED,rtx_3080_3090_leak
It’ll probably be like $1500 right?,rtx_3080_3090_leak
"That'd be fine with me, thank you",rtx_3080_3090_leak
Haha thanks buddy,rtx_3080_3090_leak
"Thank you so much!

Edit: website says 9am PT",rtx_3080_3090_leak
Thank you,rtx_3080_3090_leak
"Forgive my ignorance , if things are drawing so little power, why do they make such large power supplies? Just got into pc gaming",rtx_3080_3090_leak
I don’t have it as considering to buy,rtx_3080_3090_leak
"Judging by what they said, I assume they mean in relation to price.",rtx_3080_3090_leak
So theoretically the 3080 FTW3 should be ready at launch?,rtx_3080_3090_leak
"When I got into ML before it was ""hype"" a decade ago, 99% of people and 95% of businesses thought as you do. Making far north of 6 digits a year from it, 95% of individuals still think as you do. Except that less than 5% of F500 companies agree. Industry changes do be funny.",rtx_3080_3090_leak
"I’ve got a Ryzen 7 3700 I think, not exactly sure.",rtx_3080_3090_leak
want to go halfsies with me,rtx_3080_3090_leak
Ty. What’s 90?,rtx_3080_3090_leak
Thank you!,rtx_3080_3090_leak
"TBH im not paying 1k+ for the newest card out there when I wont even see a difference in gaming with a 2080(ti) for half that. If I could actually see a crazy difference then I would consider it....but its just my personal opinion that spending that much on a brand new card is purely a status thing and not an intelligent move for my household. 

Thanks for clearing it up tho I can't wait till the 20 series comes on sale soon and I can snag a whole new series upgrade!",rtx_3080_3090_leak
"I was planning to do a full upgrade prior to Cyberpunk 2077 in November, my PC is from 2016. I have a 4690k and I think a 750W PSU.  

Well, hopefully AMD releases something before November.

I play on 1080p a 240hz, was thinking of going 1440p at 144hz.",rtx_3080_3090_leak
"It's because of AMD that nvidia released their super series, my 5700 xt didnt disappointed me in any way and because of it people had a 2070 super for the same price as an 2070",rtx_3080_3090_leak
watch navi 2 having a card beating the 3070 for 10-15% less cost and having 10 gb of vram instead of 8 and after that watch nvidia releasing a 3070 super to counter,rtx_3080_3090_leak
"There’s no such thing as future proof, at least on the hardware level.",rtx_3080_3090_leak
"Yep, defo reckon the refreshes will all be on tsmc 7nm like big navi will be. Navi will beat the 2080ti, its just by how much",rtx_3080_3090_leak
So you think it's acceptable that over 4 years and at the start of a new console generation they only give you an extra 2 GB at the same tier and higher price? Idk about that,rtx_3080_3090_leak
But those aren't gaming purposes...,rtx_3080_3090_leak
"It all depends on price. ""Extra money"" is subjective, but $2000 vs $800 is absolutely insane.",rtx_3080_3090_leak
"You're assuming the 3080 ti would have the same memory bus as the 3080. If history is any guide, it probably won't.",rtx_3080_3090_leak
There is literally no way rdna2 only barely beats a 2080Ti. Zero chance.,rtx_3080_3090_leak
Based on the power specs that were leaked. A high quality 750W PSU should have enough headroom to run a modest system with this card.,rtx_3080_3090_leak
Sorry obsolete wasn't the right word I guess. But people claiming the 20 series won't be good as soon as amphere comes out is kinda lame. People are still using 980s 4 years after the fact. Just don't like the idea of a gen old card not being good anymore becuase the new one is better. It's like buying a new model of a car only 3 or 4 years old. Even though it's still a great car people will buy will trade up just to have the newest one,rtx_3080_3090_leak
1440p 60 FPS ray traced and the 20 series is obsolete? Literally every pascal and anything else has been obsolete years ago,rtx_3080_3090_leak
">Maaaayyyybe on 3090 at very high resolution on some specific games 

Which resolutions would those be?  Bear in mind that a PCI-E 3.0 x16 bus has 128Gbits/sec bandwidth available to it.  When it comes to graphics, that's an insane amount of bandwidth.  So, do the math when you come up with a resolution (and refresh) and see if it even comes close to 128Gbits/sec.

Horizontal dots \* vertical lines \* refresh \* 32 (bit rate for the colors) == bandwidth needed.  It's simple math.  If we take a 4K/144FPS example, which is ""high end"" today, that hits about 38Gbits/sec or so.  Or roughly 1/3 of a PCI-E 3.0 x16 slot.  An 8K/60 doesn't even double that to \~65Gbits/sec.  Still about half a PCI-E 3.0 slot.

For gaming graphics, PCI-E 3.0 is way more bandwidth than we need at the moment.  PCI-E 4.0 is unnecessary for the time being.  It shines for things like storage, and NICs that have 2 x 100Gbits/sec interfaces on them (think: data center compute).  But for day to day end users?  Nothing else can come close to needing it.",rtx_3080_3090_leak
"That is a very good point, I actually got it for $200 during the 2017 GPU mining crisis. I use it on a 1080p 60hz display and honestly its still a good GPU. I could only imagine what having 8gb of VRAM is like... Must be godly to be able to run high texture settings.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"No I won't, as I'll be bypassing the 3000s, and buying a 4000.  You'll see",rtx_3080_3090_leak
See the long explanation I just wrote to the other poster,rtx_3080_3090_leak
"No it isnt, but it’s a significant factor that’s getting no improvement whatsoever",rtx_3080_3090_leak
"I wasn't aware we'd hit the Moore's law peak, interesting. I guess it was bound to happen as there's only so far you can go in terms of miniaturisation before van der waals forces make it impossible, when you have transistors that are literally a few atoms wide.

My personal prediction (armchair-as-fuck, I have no training in physics but follow tech advances closely) is that we're on the cusp of enough advances to make silicon yesterday's news. EG light-based / quantum computing. I'm reading a book atm called 'Physics of the Impossible' by Michio Kaku, there's a great chapter about that in there.",rtx_3080_3090_leak
"I'm not ready to pull the trigger on 8Gb and 10Gb cards at those prices, I think it makes plenty sense for most people to wait.",rtx_3080_3090_leak
"Yeah and add 100$, and wait for how long? This was my first PC, so I didn't want to wait any longer. P.S. I am from third world country, so the availability would also be an issue.",rtx_3080_3090_leak
It does when you run out.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Sorry right. So custom 3080 with 20GB and 3090 with 30GB maybe.,rtx_3080_3090_leak
He is the greatest hardware armchair expert,rtx_3080_3090_leak
"Sorry, I miss worded that a bit. Thanks anyways",rtx_3080_3090_leak
"Yeah sorry, I miss worded that a bit. But that makes sense thanks.",rtx_3080_3090_leak
"But 1070 was 60% better than 970 and it also offered twice the vRAM (well, even more when you consider the 3.5GB thing), while 3070 would only be about 45% faster than 2070, which was also only about 25% better than 1070.

Sure, you got RTX and DLSS though.",rtx_3080_3090_leak
Only 6 months? That's very optimistic. I would have bought an AMD GPU long ago if not their shit drivers.,rtx_3080_3090_leak
Make him return it?,rtx_3080_3090_leak
Big uffff,rtx_3080_3090_leak
But it has more RAM! it will be future proof... ;),rtx_3080_3090_leak
"Friends don't let friends buy overpriced used GPUs...

/s",rtx_3080_3090_leak
"For anyone wondering. I told my friend i would help him with his build and he never came to me until after he had spent 4000 dollars on one. He got a good cpu imo. He bought a ryzen 3950x with nice ram but i told him 700 for that gpu was way to much. However, itll be a good build but only at a somewhat fair price. I could of built the same pc for around 2200 for sure. Oh well",rtx_3080_3090_leak
Man he want another one lol.    I just sold one of mine for 405 free shipping.,rtx_3080_3090_leak
"I mean a 1080ti is within 20% of a 2080ti if you ignore raytracing and dlss.  In a lot of areas a 2080 super is $900 so its honestly not a bad deal for a brand new card. 

People seem to forget that the 2000 series was BARELY an increase over the 1000 series, 
And in some cases it had far worse fps due to bad drivers that STILL HAVEN'T BEEN FIXED.",rtx_3080_3090_leak
Get a 5700xt for $400. Wins in literally like 80 percent of games. The higher vram only helps so much when a game is optimized on current stuff,rtx_3080_3090_leak
"Is there actually a market for $400 1080 Ti's?


I have two under water-cooling so once I slap the original heat sink back on them their fans have effectively 0 use


I've also been holding on to try RMAing them to EVGA for _________ reason to hope they send me something back that's better (I still have like 2.5 years of extended warranty and I'm hoping they don't have equivalent cards on their shelves anymore, it's a pipe dream, I know - but I have heard of it)",rtx_3080_3090_leak
I need one too,rtx_3080_3090_leak
I can sell you my gigabyte 2070 super oc windforce white for $450? Not even a month old if your still looking for an upgrade,rtx_3080_3090_leak
"> rence on 500 dollar items (new) sell for like 480 (used) while bidding. People get to caught up in winning they don't pay a

Oh wow that is crazy! In my experience people online usually severely underbid. I got bids of €200-250 on a PG348Q ultrawide by 3 people within 1 day. In the end sold if for €420. Honestly people have a hard time guessing the real worth of used products?",rtx_3080_3090_leak
"Yeah that's a great price! €400/$400 is a good price for a 1080ti, but let's remember it got no raytracing, no DLSS and usually Nvidia support kinda fades after 3-4 years. Also rumors say the RTX3070 is ~2080ti level for $600. 1080ti worth must come down to $300 within 4 months if this is true, since the 2080ti will soon sell for $500-550 used if this would to become true.",rtx_3080_3090_leak
"That is crazy haha, did you get a good deal for your 2070S new? I have not seen them under €500 here new in the Netherlands. Can't imagine someone paying up towards $700 for a 2070S. I've seen a new 2080S for €600..",rtx_3080_3090_leak
"What that is crazy. Yesterday I saw someone selling an Asus 2080ti for €899. Good price right now, but if the RTX3080 launches for $800 the Asus RTX3080 will probably cost like €950 making it a superior offer. I don't understand why people don't wait literally 3 months for a card they might use for 4 years.

I always say either buy directly at launch, or buy at a major discount. Usually prices stay flat for the next 12 months after launch (unless AMD RDNA2 will be awesome and beat the RTX3080).",rtx_3080_3090_leak
"That's the price set up by a third party hoping to score big on some sucker. HWS prices are roughly $900-1000, as well as on Ebay.",rtx_3080_3090_leak
That’s nutty... I’ll end up selling my 2080ti for around $700 when the 3090 drops I was thinking.,rtx_3080_3090_leak
"I am in Russia, so...sorry 🤷‍♂️",rtx_3080_3090_leak
1080ti,rtx_3080_3090_leak
I had it in another PC that wasn’t being used.,rtx_3080_3090_leak
Bold of you to assume Cyberpunk will release on time,rtx_3080_3090_leak
"You probably won't need a new card because it will have DLSS 2.0 and DLSS is actually amazing now. On Control, my rtx 2060 super on ultra with full raytracing and DLSS on gets the same performance a 2080ti gets with the same settings but no DLSS. To top it off, the latest update to it actually makes it the miracle that was promised. Rendering in 720p and upscaling to 1080p with DLSS manages to look better than native 1080p due to the anti aliasing it adds as part of the tensor cores upscaling. I only play in 1080p but I'm expecting to get a pretty good experience out of it with DLSS on on my $400 card",rtx_3080_3090_leak
Will you need a better card than an RTX 2080 for cyberpunk??,rtx_3080_3090_leak
You'll be able to see you hat the 4000 series is like before you look at older tech.,rtx_3080_3090_leak
This is the only reason why I'll upgrade my 980 ti sc. Witcher 3 played flawless on it but it struggled. I'm sure CP77 will play well but I want to see it in all its glory.,rtx_3080_3090_leak
3080ti will be probably $999 with 20 GB.,rtx_3080_3090_leak
Don't give them ideas...,rtx_3080_3090_leak
"First shipment inevitably does. Of course they'll make them as fast as they can, so the problem goes away in weeks.",rtx_3080_3090_leak
Agreed. Perhaps I am wrongly seeing GPUs as an enthusiast market where geeks are making hardware for geeks. Better get out of this mindset.,rtx_3080_3090_leak
I find that hard to believe with the core counts of each. I know it doesn't scale perfectly but there seems to be a lot of space between those two cards not even considering the VRAM counts. Time will tell though and soon enough!,rtx_3080_3090_leak
"The only concern is that you then would be relying on most things having DLSS 2.0. I hope so, but time will tell.",rtx_3080_3090_leak
"The top of the line ""Ti"" or ""Titan"" cards have BARELY been suitable for 4k at release the past 2 generations. Don't get your hopes up that a xx70 card will be a 4k crushing machine.",rtx_3080_3090_leak
"Wish they'd quit wasting the silicon, and mass produce more top tier cards at a reduced price.",rtx_3080_3090_leak
Wtf is 1620p? Do you mean 2160?,rtx_3080_3090_leak
This generation is 1440p my friend.,rtx_3080_3090_leak
"I get where you're coming from, but do you really think Nvidia, the company who literally works with the largest AAA companies (like working with cyberpunk to release DLSS 2.0 support on launch) would not have a better idea of VRAM usage for future titles than the average person on reddit?",rtx_3080_3090_leak
This is a controversial statement somehow. Amazing how many people don't understand this.,rtx_3080_3090_leak
"FS2020, the new game that looks insane and is being considered a ""next gen"" game, doesn't even use more than 6 GB of VRAM most of the time for me when using DSR at almost 1440p.

Very few games actually saturate 8 GB of VRAM, and it's not even a problem if they do. We haven't seen games that lose performance or stutter (things that happen when you run out of VRAM.

It's like how Windows and other programs use more RAM now that I have 32 GB, but it worked fine at 16 GB. It only became a problem when it was actually maxed out from running multiple programs.",rtx_3080_3090_leak
Nvidia drivers for dx11 anyway allow you to overallocate vram and the driver will deal with the memory sorting. I played siege on ultra with a 980 with 4gb vram while 6.6gb was allocated.,rtx_3080_3090_leak
"Not really. Depends on what platform dev uses as a base. Console optimised games tend to use more vram, because of the nature of console using sys ram and vram as one.",rtx_3080_3090_leak
"What next gen games? The next gen consoles don't even have that much VRAM.   


Flight sim is next gen, it uses under 6gb at 1440p.",rtx_3080_3090_leak
That's not how it works. Read a bit through this thread.,rtx_3080_3090_leak
"look at steamsurvey - no one is even playing 1440p yet.


Edit. Obviously there are people who play above 1080p,me including. But VAST majority is on 1080p.  Damn.",rtx_3080_3090_leak
Buy a 3090 if that's what you think.,rtx_3080_3090_leak
Flight Simulator uses a shitton more textures than any other game though. I can't imagine many games that need to hold 8GB+ textures in memory for 1440p at all times.,rtx_3080_3090_leak
"Just because you see 9 GB being ""used"" on a card while playing, that doesn't mean at all that the game ""demands"" it. Just like with normal RAM, games will use caching opportunities if they present themselves. (Or rather, they'll just throw unused assets out less aggressively.)

Case in point: On FS2020, 1440p, Ultra Quality preset, the 2080 Super, 2080, and 2070 Super (which all have 8 GB VRAM) all perform equal or better than the 1080 Ti (11 GB VRAM) and all perform significantly better than the Radeon VII (16 GB VRAM), so clearly VRAM isn't an issue. The RX 5700 with 8 GB VRAM even performs exactly the same as the Radeon VII. In fact, even at 2160p there is no indication that having more than 8 GB VRAM actually does you any good in FS2020, as the relative performances stay largely the same.",rtx_3080_3090_leak
No it doesn’t. I run it on almost Ultra @ 1440p and it uses about 5GB of RAM on my 2070 Super. GPU sits around 60% util while the game is limited by “MainThread” (CPU) @ around 36fps.,rtx_3080_3090_leak
"AMD Ram utilization is sub par compared to what Nvidia does. Hence less VRAM on many of their cards (especially for lower end).  
While RX cards were basically unusable for their 4gb variations, Nvidia 6gb cards performed quite well.  
Games do not require specific VRAM on GPU's. Its up to each vendor to develop a way to utilize the VRAM in the most efficient way.  
AMD clearly goes for ""more is better"" especially with the R VII featuring 16gb VRAM while coming short of a RTX 2070 and on the same level as 5700XT and both of them have ""only"" 8gb VRAM.",rtx_3080_3090_leak
9gb+ on what card? Uses or caches?,rtx_3080_3090_leak
"I play at 1080p 144 Hz and am looking to get a 3070. Even at 1080p, 144 Hz isn't a joke and I expect with more games having more forms of RT that it might start to struggle at max settings some point over the next 5 years.",rtx_3080_3090_leak
My 2070 super is dope on my 1440p 144hz panel. I love it. Not a chance in hell I'll be upgrading.,rtx_3080_3090_leak
I think most people are more casual gamers who prefer resolution and high quality graphics and not pretend pro call of duty players who think they need 180hz...,rtx_3080_3090_leak
Which monitor,rtx_3080_3090_leak
Most people are causal gamers and this is reflected on steam hardware survey among users. A lot of people play games which isn't taxing on the system. They play csgo or GTA.,rtx_3080_3090_leak
"I upgraded to 1440p ultrawide and don't want to go back. I agree with the sentiment though, 4k is overkill, but if anyone is going to notice it's PC gamers and not someone playing consoles/watching TV on a couch far away.",rtx_3080_3090_leak
"I have a 2070 super as well with a 4k monitor. I run everything on max in 4k, even multiplayer games, without lag or tearing. It's beautiful. I'm definitely not upgrading.",rtx_3080_3090_leak
"Yeah man, people are scaring me and my 2060 :(",rtx_3080_3090_leak
"not really, 4k as a term is the increasing norm. when people buy televisions, they look at 4k options. Graphic designers, 4k.. shit even 8k.

&#x200B;

1080p is outdated, when you’re used to higher resolutions that exist in our own smart phones, average television, and then switch to a quad HD 144hz monitor, the difference is massive. I can understand for players in a competetive type fast paced less graphical commitment and more performance, 1080p is fine. but most people want the graphics being offered and developed by producers with huge efforts, 1440p+....

&#x200B;

just because its cool for you doesnt mean the general market shares your situation",rtx_3080_3090_leak
No offense but isn't that overkill? I have a 1070 and I can't imagine using it on 1080p after seeing what it can do on 1440p.,rtx_3080_3090_leak
"Yep, I have a 2060 Super OC, and have a 4K monitor. 1080p is the perfect setting for the limited gaming I do, and detailed work I do the other 95% of the time.

That said, I have a Quadro P600 as I run often a bunch of transcoding jobs and other media, and the 2060 with stutter and other like crazy if using at the same time. Offloading those tasks to a separate GPU and it's unoticeable.",rtx_3080_3090_leak
max doesnt mean used and you would know if you were running out. Maxing  your VRAM usage would cause massive stuttering.,rtx_3080_3090_leak
"The best one you an afford. Supersampling will take care of any ""overkill"" very quickly 😂",rtx_3080_3090_leak
Either card would be fine. VR games have high resolutions but the textures aren’t very high resolution. I’ve yet to see my vram maxes on a 2080. Just get the card you can afford.,rtx_3080_3090_leak
"You will have zero issues considering I am running 8gb without issue. We aren't even close to using the 8gb.

The thing about ram is that your system will cache it before it needs it and if you have more available itll cache more. So people with 2080ti see high vram 'usage' but its really just cached. 10gb is PLENTY at 1440p",rtx_3080_3090_leak
Dlss renders at a lower resolution you’d need less vram,rtx_3080_3090_leak
Ray tracing has hardware it runs on its own. Not sure it’s impacts to vram,rtx_3080_3090_leak
They really arent.,rtx_3080_3090_leak
Games cache more ram when there’s more available. It’s the same with any memory. Doesn’t mean it’s using that much.,rtx_3080_3090_leak
"The full specs of both new consoles are officially announced.

You must have missed it.

16GB of total shared RAM, and SSDs with custom access stack to allow RAM caching at similar to DDR2 speeds. PS5's SSD is significantly faster than Xbox's though.

And then both have CPUs and GPUs which put them in the ballpark of an R7 3700X + 2080 Super.

The Xbox SX should be ~10% faster than the PS5 in practice, but the inferior SSD could make a difference. Though probably only in 1st-party games.",rtx_3080_3090_leak
"That's the ticket! AIB = Add-in Board partners like Gigabyte, Asus, Msi, etc. :)",rtx_3080_3090_leak
"I'm 90% sure it stands for Add In Board. Probably along the lines of makers like gigabyte and asus using their own custom boards to make the video cards, usually also adding in their own cooling system to said cards.

Please correct me if I'm wrong, though.",rtx_3080_3090_leak
You could also just say '3rd party' instead.  I dont like the term AIB.  Just seems like a poor descriptive term even though it's accurate industry speak.,rtx_3080_3090_leak
"AIB ist add in Board, which refers to everything that comes in a board form factor. GPUs , soundcards and so on.

This subreddit uses it as ""3rd party manufacturer"" which is just plain wrong...",rtx_3080_3090_leak
I thought it was associate in board for some reason,rtx_3080_3090_leak
It means add in board...as opposed to integrated graphics on the CPU.,rtx_3080_3090_leak
Add In Board,rtx_3080_3090_leak
"lol I'm kind of writing it to myself as well. I will just have to see how the launch goes and decide then but hype-buying is rarely a good thing so yeah let's practice restraint together! Also, the people needing the most VRAM are the ones playing at high resolutions and sims in VR. So if you don't think that will be an issue then do whatever. Also Nvidia might come out with some compression that will require less VRAM but I'm alwasy skeptical of things like that. The most prudent approach will always be ""wait and see"". :)",rtx_3080_3090_leak
"Agreed I would love to see an in depth video on VRAM speed and allocation usage relating to graphics performance at 1080p, 1440p, and 4k.",rtx_3080_3090_leak
I thought that was only due to shortages cause by bitcoin miners. Time will tell I suppose...,rtx_3080_3090_leak
[maximus91 on launch day](https://media.tenor.com/images/71bd5e05ee7129477716182e6789d424/tenor.gif),rtx_3080_3090_leak
"It shouldn't. It'll be launched soon as AIB only model. 

This launch is all about the GPU and FE models so technically the 20GB doesn't ""exist"" in FE world.",rtx_3080_3090_leak
"> Videocardz said that for the moment there is no info about a 20GB AIB model. 

What? Did you read the article?

Videocardz:

> We have learned that board partners are also preparing a second variant of the RTX 3080 featuring twice the memory (20GB).",rtx_3080_3090_leak
"> 1- kopite7kimi didnt say anything about a 20GB model and he is proven the most reliable leaker.

He actually said it. That's where I get this from - https://twitter.com/kopite7kimi/status/1298575248283992064

and https://twitter.com/kopite7kimi/status/1295602053260038146

and https://twitter.com/kopite7kimi/status/1295522577788465153",rtx_3080_3090_leak
I think the 320 bit memory bus on the 3080 only allows for 10 and 20GB configs. The 3090 has a 384 bit bus allowing for 12 and 24GB variations.,rtx_3080_3090_leak
"Because bus width is Nvidia-specified, it is unlikely you will see VRAM in a format that isn't doubled from original numbers.",rtx_3080_3090_leak
Thanks for the info!,rtx_3080_3090_leak
Yeah I'm waiting to see what AMD brings to the table. I'd caution people against preordering cards. It can be a very frustrating experience... Or great. But you're full on gambling if you just preorder before reviewers compare the cards.,rtx_3080_3090_leak
This is probably the best and simplest answer there is.,rtx_3080_3090_leak
"Lol, that's what I was afraid of.  Probably going to splurge on that 3090, unless there is a healthy competitor.",rtx_3080_3090_leak
"I truly think the Ti days are over. I could totally be wrong, of course, but I think the era of the ""Supers"" is here and they are not going to abandon a new naming scheme that made them a BOATLOAD of money. The ""90"" series is back, it looks like, though. It remains to be seen if the 3090 is... the Ti, or the Titan. Once we know more about that, we will know what next year will bring.",rtx_3080_3090_leak
"Yeah, I know the feeling. I traded an 8700k system for a 3700x system (Actually made a profit, thanks Microcenter) since I figured the additional cores would help more long term. Hyperthreading saved my 3770k and allowed it to live as long as it did, so I'm a big proponent of SMT.

I recently went and got a quality 3600MHz 32GB kit of RAM... figured I would be sticking with AM4 for the long haul. 32 gigs is a little harder to justify at the moment, but modded Minecraft was pushing about 19 gigs on a medium sized modpack when I last checked. Sound investment.",rtx_3080_3090_leak
Oh hey my dashing friend,rtx_3080_3090_leak
"8gb isn’t enough unfortunately, when DLSS and a stable 4K at high/medium/didn’t bother going less on Assetto Corsa Competezione renders smooth at a beautiful 60hz then boom bitch: *terribly sorry sir it’s appears that “not enough vram, please try adjusting your settings. I hope the 10 seconds of beautifully rendered UHD was fun though”.*",rtx_3080_3090_leak
"Yeah, pretty much. I've been looking forward to the RTX 3000 series. If I can get ~50% perf uplift and a good deal I'll definitely hop on the Ampere bandwagon.",rtx_3080_3090_leak
"I mean, I typically really play older games from 2016 or before. I can't really name a game I play past that point, any ways. It's just a conventional horsepower increase would help a lot with what I do.",rtx_3080_3090_leak
What titles do you play?,rtx_3080_3090_leak
Suffer I guess. 1080Ti won't be able to do RTRT in a very playable framerate.,rtx_3080_3090_leak
Got my FTW3 for 680$ such a good buy.,rtx_3080_3090_leak
"if it comes in with similar stats, but has displayport 2.0 capability, it will shit all over nvidia.",rtx_3080_3090_leak
">	The people who got a 1080 Ti on release got the best GPU value in history

Not quite. The 8800GT was quite a bit of a better value in its day.",rtx_3080_3090_leak
Radeon R9 290 gang rise up !,rtx_3080_3090_leak
"> The people who got a 1080 Ti on release got the best GPU value in history

My £200 Launch GTX 970 thats still here begs to differ!",rtx_3080_3090_leak
I thought this 30 series was considered cheap compared to previous generation,rtx_3080_3090_leak
"I got my evga ftw3 1080ti for $900CDN, so happy I made the plunge. I was very hesitant, but now 4 years later its still a beast.",rtx_3080_3090_leak
"And my electric bill is gonna shit on the entire rtx3000 line. 

Three hundred and fifty goddamn watts? Sweet christ, I'm gonna need four radiators. Maybe I'll bake a potato in there while I'm at it. Even the 3070 eats as much juice as a 1080ti.

Nah, I'm just gonna hold onto my 1070 and wait until they make some GPUs that won't dim the power grid.",rtx_3080_3090_leak
Nvidia accidentally made a card that was too good,rtx_3080_3090_leak
Hopper?,rtx_3080_3090_leak
"Reality is that nearly no launch day reviews will let us know how will perform in 2 years or even 1, because we're about to have a major console hardware swap, and on top of it RT significantly increases VRAM consumption, and we'll have more developed RT going forward thanks to RT processing power increase on these new GPUs.

&#x200B;

9xx, 10xx and 20xx series card didn't face this problem because they didn't have immediate console hardware switch incoming.

As for 7xx... 770 2gb ""will be enough for 1080p for years to come"", half a year before the consoles landed in 2013-14. Remember that?",rtx_3080_3090_leak
"And what's the alternative?

3090 will cost like 2 average monthly net wages in this country's capital (Eastern EU, Latvia), 3080 comes with 10gb memory right before next console generation introduction, and with improved RTX performance on top of it (and playing with RT also increases VRAM usage)  


And if you mean why I was talking about upvote - i found his comment when it only had 1 or 2.",rtx_3080_3090_leak
8600 gt was even better value imo,rtx_3080_3090_leak
"The 8800 GT wasn't a top end card though. The 1080 Ti was THE top end card to own, even beating the Titan Pascal when overclocked nicely in many games. For the cost of that card, the value was unparalleled in the history of Nvidia releases. What a stark difference that shitter 2080 Ti is, doubling the price for a paltry 35% gain.",rtx_3080_3090_leak
"This, the biggest jump in graphics card history.",rtx_3080_3090_leak
"Go look up the side by side comparisons of the 1080ti vs the 2080, the 2080 is only going to net you about 10% extra fps on any given game vs the 1080ti and about at the cost difference of about $200+

So it follows that you can generally save yourself about $200 by just selling your gtx 1080, for about $300 and buying a 1080ti for $500ish, meaning you net about a 30%-50% power increase for $200 (1080ti) instead of a  40%-60% increase for $400 (2080super)

At this point, if you're going to go through all that, I'd say sell your 1080 and buy a 3080 at least then you'll net some real performance gains of probably around 70%-80% for $500ish",rtx_3080_3090_leak
"2080 is about the same as 1080ti and it's not a bad idea if you can get a used one for cheap. However, buying used means less warranty and less next gen features and it can be hard to find used cards that offer better perf/$ compared to just upgrading to say, a rtx 3070.",rtx_3080_3090_leak
Well his flair does say amd. That or he's expecting a super/ti refresh.,rtx_3080_3090_leak
"I mean the 1080Ti will even survive the next 1-2 years at 1080p.

But yes, as your flays, at 4K that's practically impossible lol, already at 30FPS at 4k on ultra in MSFS 2020 is an indicator",rtx_3080_3090_leak
I would just wait until you get a game you can’t run how you’d like. We don’t really know how demanding next gen games will be on current hardware until cyberpunk is out really,rtx_3080_3090_leak
I'm right there with you. Going 3080 to replace my 1080ti. If VRAM ends up being an issue I'll sell it down the line for the super.,rtx_3080_3090_leak
"Y'all have already made up your minds that Ampere is getting a refresh next year even though there's literally no indication of that whatsoever.  

There's no 'pattern' here that suggests they're going for yearly releases.  The Super Turing refresh was a complete one-off for all we know, there's no reason to think it was anything else.  It's not part of some pattern.  

Anyways, RDNA3 on 5nm could be out *well* before Hopper in late 2022(going by your expected schedule).",rtx_3080_3090_leak
"There is a 1 hour delay fetching comments.

I will be messaging you in 1 year on [**2021-08-29 00:47:46 UTC**](http://www.wolframalpha.com/input/?i=2021-08-29%2000:47:46%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://np.reddit.com/r/nvidia/comments/ii6179/nvidia_geforce_rtx_3090_and_geforce_rtx_3080/g370zpm/?context=3)

[**CLICK THIS LINK**](https://np.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fnvidia%2Fcomments%2Fii6179%2Fnvidia_geforce_rtx_3090_and_geforce_rtx_3080%2Fg370zpm%2F%5D%0A%0ARemindMe%21%202021-08-29%2000%3A47%3A46%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://np.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%20ii6179)

*****

|[^(Info)](https://np.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://np.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://np.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://np.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|
|-|-|-|-|",rtx_3080_3090_leak
No u,rtx_3080_3090_leak
"Yea, I usually got 260, 660, etc. 60s. I got a 1070 and liked it. I was hoping for a 3070 but yes, the jump from 3070 to 3080/3090 is almost like a whole gen.",rtx_3080_3090_leak
8GB VRAM is what I expected for the 3060. This is depressing...,rtx_3080_3090_leak
"Perfect gap for a 3070 super to slot into, with 10gb gddr6 or 8/10gb gddr6x, next year..",rtx_3080_3090_leak
"3090 350W, 3080 320W and 3070 220W. Seems that the 3070 does focus on more efficiency. GDDR6 does use less power vs GDDR6x I would say, not saying efficiency was the reason",rtx_3080_3090_leak
"A bit of a disappointment in terms of VRAM at least. Looks like it wasn't so bad to get a 2070S a few months ago as I did, probably gonna wait for a potential 3070 Super with more VRAM...",rtx_3080_3090_leak
"And all reviewers, you tubers, tech sites should absolutely blast Nvidia for this horseshit.  It is so obvious this is done so they can release these cards at whatever damn price they want, essentially forcing a vast majority people to the much more expensive 3080 and finally the gap in ram is so obviously so that they can release ""supers"" in 8 months or whenever AMDs GPUs come out, which likely is the best time to buy a 3000 GPU, hopefully the AIB manufacturers pull through with a 20GB 3080. I was never planning to buy the top end card, but definitely the one below it., the fact that the 3080 has 10GB is odd. wait for benchmarks, wait for benchmarks. also proud NVDA shareholder so I'm not trying to be a dick or anything.",rtx_3080_3090_leak
"I'm not sure what things mean here, mostly. But I'm hoping for 8K at least 30 FPS on the top end 3090. I'm trying to learn, but I don't have a computer engineering background so it's hard to follow people like Moore's Law is Dead. I nod along like I understand, but it's difficult.",rtx_3080_3090_leak
Sounds like all the secondary sellers will offer 20GB variants so this is another FE tax.,rtx_3080_3090_leak
Me thinks this is to help sell a markup for the 3080 _and_ to keep it from being better than a 2080ti.,rtx_3080_3090_leak
"Question. I'm planning on doing a new PC build (I've built a few already), but I'm not usually one that gets into the nitty-gritty specifics of utmost efficiency and capability. Let's say the 3070 releases at like 600-700 price range. Would it be worth to grab a 3070 or would it be better to grab a 2070S especially if it price drops. And then wait until the 4000 series releases in some years. Or.. I guess upgrade to a 3080/3090 in a year or two.",rtx_3080_3090_leak
And the 3090 is a triple-slot card making it completely unworkable for smaller form factor builds.,rtx_3080_3090_leak
I totally agree with you. I would even say that this makes the whole price discussion more interesting because if the 3070 is lets say priced 100-150$ higher than a 2070 on release this will definitely cause some raised eyebrows.,rtx_3080_3090_leak
"I mean, it all comes down to the price and fps / $ right?",rtx_3080_3090_leak
"You'll sell your least favorite kid to afford the 3090 and you'll like it!

In all seriousness, I'm still on a 1080 and a 3080 is still going to be a massive upgrade for me so I'm buying one so long as the price isn't crazy. I'm hoping it will align with the 2080 prices and I can snag one for around $730.",rtx_3080_3090_leak
"I'm incredibly interested in this specific tier, the 3070Ti/Super. Can anyone pls give the realistic and possible dates for such a thing? I'd assume it would come right after Big Navi as a usual counter.",rtx_3080_3090_leak
"It's a bigger difference than that.  :/  

3070 is 16gbps + 256 bit bus = 512GB/s

3080 is 19gpbs + 320 bit bus = 760GB/s

With the same GDDR6X, the 3070 could be 608GB/s.",rtx_3080_3090_leak
Music to my ears,rtx_3080_3090_leak
What's the comparison to my 970?,rtx_3080_3090_leak
What about 980ti,rtx_3080_3090_leak
"Nah i'm thinking the difference in performance between the 3070 and the 3080 is going to be bigger than usual. I mean looking at the TGP here, you have the 3080 and the 3090 having respectively 320W and 350W, pretty close to each other, meanwhile the 3070 comes at a much lower 220W, while still possibly using a worse node.",rtx_3080_3090_leak
if they were confident they wouldn't release a GPU with 24 GB vram I think.,rtx_3080_3090_leak
Interesting take.,rtx_3080_3090_leak
"33% in 1 benchmarks, plenty of other leaks pointing to more reserved numbers. I will be shocked if the 3080 averages 30% faster than the 2080ti in 1440p gaming numbers.",rtx_3080_3090_leak
2080ti@1080 is ridiculous,rtx_3080_3090_leak
"Yeah that's my hope. I'm still at 1080p and just want frames. Seeing these ""modest"" specs make me hope the pricing won't be too absurd.",rtx_3080_3090_leak
"Next gen consoles are 16gb, part dedicated to OS and part shared with CPU, so under 4K you'll likely be fine with 10gb for 99% of games depending on features.

I'd say 8GB is pushing it these days considering raytracing eats up a decent amount of ram even at 1080p, but generally it looks like next gen GPUs will have enough RAM for 1080p.",rtx_3080_3090_leak
But why would you EVER need a 2080ti for gaming at 1080p???? You can easily play any game 1440p 144Hz with a 2070 super,rtx_3080_3090_leak
"Battlefield V with RTX on (raytracing has always been extremely memory demanding) and MFS 2020 are two examples where 8GB is not enough anymore. You need to also take into account that thanks to the new consoles, games are going to start using high-quality textures. Yes, they have Sampler feedback in DX12\_2 that may help with that, but who knows if developers will take the time to implement the lastest DX12 technologies in their games.

If I'm paying 800-1200$ for a 3080 I want a futureproof GPU, I am definitely not buying a GPU with less than 16Gb at that price range.",rtx_3080_3090_leak
MFS 2020 needs around 10 GB VRAM at 4K i think,rtx_3080_3090_leak
Horizon uses more than 8gb.,rtx_3080_3090_leak
"FS 2020 has been seen using over 12.5GB VRAM, and it will not be the last game to do this over the next year or two.  [https://www.guru3d.com/articles-pages/microsoft-flight-simulator-(2020)-pc-graphics-performance-benchmark-review,4.html](https://www.guru3d.com/articles-pages/microsoft-flight-simulator-(2020)-pc-graphics-performance-benchmark-review,4.html)

Game VRAM requirements will only increase as their sophistication and graphical fidelity increases.",rtx_3080_3090_leak
"> What you on mate?

Microsoft Flight Simulator",rtx_3080_3090_leak
">What you on mate? I've never even came close to maxing out 8GB of VRAM in video games, and I play in 4k.

I mod my games and this happens even at 1080p. Actual VRAM stutter. Not just low performance.

Too bad I have a 4K monitor so I cant mod my games as much nor enable max textures in games like Wolfenstein 2 for example.",rtx_3080_3090_leak
He's just circlejerking with the other know it alls,rtx_3080_3090_leak
"There's probably not many games that will allow it since there's only been 2 consumer GPUs >8 gb of any real note (I imagine the Radeon VII probably didn't even sell as much as any of the $1000-$1200 titans and AMD dropped support for it *fast*).

But hey... https://i.imgur.com/XvAfgql.jpg

That game's not one of the ones you mentioned, is *only* at 1440p, and nearly ever setting is at low.  Sure there's 100 fps in that screenshot, but that's totally ignoring that every time the VRAM actually went up and hit 8 gigs proper it stuttered *because unlike you I actually have an 8GB card.*",rtx_3080_3090_leak
"Makes more sense then, didn't think about the bus size. Would have been nice to get a 320 bit bus on the 3070 for 10GB and a 384 bit on 3080 for 12GB. I'd have to think hard about the 3080 at that point.",rtx_3080_3090_leak
Can you explain this to me in English please?,rtx_3080_3090_leak
"Can you explain this? Fairly new to PC gaming, so interested to learn more. Thanks.",rtx_3080_3090_leak
But we didn't know it was a 320 bit bus.  There's nothing wrong with somebody hoping it was more.,rtx_3080_3090_leak
There are also rumors AIBs will release 20 GB versions of the 3080.,rtx_3080_3090_leak
Totally agree. Just Because a new series comes out doesn't mean its necessary.,rtx_3080_3090_leak
"Yeah, it's a solid card for sure but my goal is 1440p 165hz on Med/High no RTX (or 1440p 100+ w/ RTX for Cyberpunk) and my 2060S already has trouble getting there. Getting a high refresh rate monitor has ruined me, lol...",rtx_3080_3090_leak
"Do you mean 3080? And if so, do you have a source for the info? Would be interested to see the article for sure.",rtx_3080_3090_leak
Solid argument,rtx_3080_3090_leak
He said he's not sure about the FP32x2 thing. Thing about Kimi is that he is honest and he tells accurate stuff on things he knows and he will admit when he doesn't know or things are unclear.,rtx_3080_3090_leak
"That would be very difficult on the development side, I heard if they are using different foundries (ie tsmc and samsung) the teams have to be under nda and so the team working on tsmc can't be the same as the one working on samsung so things get much more complicated.",rtx_3080_3090_leak
">everyone is gonna be like ""oh well uh it's not on 8nm so I guess it's worth the upcharge... take me monies."" 

You reddit monkeys love to imagine these scenarios that are unrealistic and treat them as reality. Most people don't give a motherfuck about 8 vs 7nm or even know/care what that means. Benchmarks matter, that's it. Stop circlejerking broke bitch",rtx_3080_3090_leak
But Samsung already has a 7nm process though. Would be problematic to present 8nm as 7nm when the foundry it's being fabbed on actually can do their version of 7nm.,rtx_3080_3090_leak
Samsung 8nm is just renamed SS 10nm.,rtx_3080_3090_leak
"NVIDIA didn't rename anything, Turing just used a customized process NVIDIA was already using for Volta and Tegra Xavier",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"What I don't quite understand is that the TDP still seem high and clocks seem low. For Samsung 8nm that makes sense but on TSMC 8nm that's even more disappointing. Is there something about 7nm that would inherently just make them perform better outside of numbers like core count, clockspeed and TDP?",rtx_3080_3090_leak
He meant that Samsung/Nvidia can just rename 8nm to 7nm. Its a made up name anyway,rtx_3080_3090_leak
"Everywhere I looked (Moore’s law is dead, graphically challenged, gamers nexus) thought it was Samsung 8nm",rtx_3080_3090_leak
"A redesign is required. Samsung 8nm and TSMC 7nm are not compatible without redesign.

""Person guesses that cutting edge GPU uses cutting edge memory"".",rtx_3080_3090_leak
Didn't they just do that with the 20xx?,rtx_3080_3090_leak
#prayforbignavi,rtx_3080_3090_leak
"You’re assuming AMD has a card that competes with these cards though yeah? 

Do you know if you’re currently even using that much VRAM? 11gb is quite a bit, and if cyberpunk doesn’t even utilize that it’s not like “downgrading” to 10 will harm it.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
I am in a similar situation but its worse for me since im currently sitting with an unstable 1080 Ti. Was going to opt for AMD but then my G-sync monitor would go to waste. Maybe will have to give in to the 3080 10GB if there is no 20GB card soon.,rtx_3080_3090_leak
Nvidia is doing better than ever financially.,rtx_3080_3090_leak
Hooper?,rtx_3080_3090_leak
"Team 970 up in this bish! I'm so stoked for a 3080. I've waited this long, tho, so I am completely fine to hold out for the 20gb variant.",rtx_3080_3090_leak
"Even a 2060 at this point is double or more fps than the 970.

3080 will be massive upgrade, easily close 3 times the power.",rtx_3080_3090_leak
"Raytracing shouldn't be a gimmick if 3000 series bring in required RT performance uplift.

2000 series was a beta test, it got clear in first months.",rtx_3080_3090_leak
Sure AMD’s might be limited - but it sure as hell will be supported considering this upcoming console generation.,rtx_3080_3090_leak
"No one thinks this. They're rightfully concerned about the fact that consoles will have more vram, and the wave of ports we always get will be more demanding on vram as a result. Paying almost $1k for a card that would theoretically chug at ultra texture settings shouldn't be a thing.",rtx_3080_3090_leak
"3090 is way to exp. But the step down is too drastic. 

Maybe they will announce something that hasn't been leaked lmao or the 3090 might not be 1 billion $",rtx_3080_3090_leak
1080ti is still performing well even with the 2080 series. Game companies are using last gen tech for their games. It will be a few years until the 2080 series will be truly outmatched by games.,rtx_3080_3090_leak
"I'm in a pickle too. Want to build my first PC, but all this 10GB chat for the 3080 (which I had my eyes set on) has questioned all my plans... If the Super variants (with 20GB VRAM) come just a few months after, I know I would be kicking myself. I will wait for Big Navi to be released too and see how they compare. Lots to think about towards the end of this year!",rtx_3080_3090_leak
"I just buy it a few months to halfway through the life cycle every single time

That's what I've done since the 980 ti.

I mean, if you're going to keep wanting the best on release you deal with a bunch of bullshit issues (supply issues, hardware issues), not all the best versions of the cards are even out, and no option to buy second hand.

You're only upgrading your own computer. Who cares if /U/Overclocker69erXoXo gets 20 fps more than your 150fps for like 4 months.

Oh and yeah the ti versions usually come out later anyway, so there's that too. Plus now there's super versions as well.",rtx_3080_3090_leak
I thought the Ti versions won't be released anymore?,rtx_3080_3090_leak
isn't the 3090 considered the 3080ti? lol,rtx_3080_3090_leak
Probably within a month or two if i were to guess,rtx_3080_3090_leak
"I'm aware of that, but the fact that they are then not launching a 3085 or 3080 Ti or 3080 Super or whatever inbetween the 3080 and 3090 is wat baffles me. I will bet my kidney that it's coming, but it's dissapointing to see that it won't be a launch card. Give it 16-20GB of VRAM, 3080 Ti naming or whatever, and I wouldn't be as dissapointed.",rtx_3080_3090_leak
"I can still see NVIDIA releasing a Titan RTX 3000 card for like 3000USD with 48GB VRAM.

I mean, probably not, but I wouldn't be surprised if that happens",rtx_3080_3090_leak
And want to play games. Last I checked the Quadro isn’t really optimized for gaming.,rtx_3080_3090_leak
What you explained towards the end is literally what the Titan cards used to be. How is naming it more like a gaming card going to clear up any confusion?,rtx_3080_3090_leak
"Nvidia now makes more money selling to businesses for cloud, AI, and editing. 3090 is not marketed for gamers but for B2B. The gamer one is the 3070. You're better off with the 20xx series for gaming. But the leap from 10xx to 20xx wasnt that big.",rtx_3080_3090_leak
"> It's replacing the Titan series. 

It's already been confirmed the GA102-300 chip is the 3090 and there's also a GA102-400. That doesn't mean that there will be a Titan released though.

Like someone else said, the only real move they could make there from what we know of the two chips (so far) would be doubling the VRAM to 48GB.",rtx_3080_3090_leak
Not a bad point! Assuming I have savings :D. But shipping from the EU is going to be a nightmare also it seems.,rtx_3080_3090_leak
"I suppose its possible there is new tech that lowers vram requirements in games, but we will have to wait and see.",rtx_3080_3090_leak
"People obsess about VRAM way too much, this VRAM is a lot faster and who knows what technology Nvidia has in store to make it even faster.",rtx_3080_3090_leak
"Yea, it's like men with penis size... it goes well beyond reasonable concerns",rtx_3080_3090_leak
"A free upgrade to a 3080, I see no issue",rtx_3080_3090_leak
"Thank you, calendar reminder added.  Wallet primed!",rtx_3080_3090_leak
"Oh great. Do you know if it's rumored to also include prices, or if it's something that usually comes later along the way?

I'm really trying to see if I can and should get something from the new series in time for cb2077, instead of a 2060, but it seems unlikely lol",rtx_3080_3090_leak
"Not really, for example HDMI 2.1 has existed on TVs for over 2 years now, and we're only getting HDMI 2.1 sources this year",rtx_3080_3090_leak
Not all GPUs are available for step up,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
I have never done a step up through them so I have no idea if there are restrictions on the same model or something.,rtx_3080_3090_leak
"According to their website its US, CA and EU, which is even more of a reason to get a GPU before we crash out of the EU because who knows if they mean Europe as a continent (Switzerland gets a specific mention also so my guess is no) or the EU as a trading block. Other UK people have commeneted on other threads saying they were able to step up, personally I would call EVGA and find out before sinking such insane amounts of money on a gpu from them.",rtx_3080_3090_leak
"Hahaha it's a bit crazy! Also regarding your comment, I think there might be 20GB model of 3080 but it's only AIB according to the rumor.

But yeah, initial launch with FE cards, no 20GB.",rtx_3080_3090_leak
"I agree, I'm guessing they will demo their new memory compression technique, and try to convince this gen needs less memory.

That said, you can say the same thing about the future: you don't know how things will progress (esp. with new consoles coming) and/or higher res monitors becoming more availalble. Maybe you will start running into hard limits in Cyberpunk or Squadron 42 who knows.

People like to think they are more future proof. I can imagine going from 11 to 10 or 8 to 8 (1070>3070) could feel off, is all I'm saying.",rtx_3080_3090_leak
"In current games, sure.",rtx_3080_3090_leak
"I'll definitely wait. I was planning to buy the Xbox Series X, but both that and the PS5 look incredibly underwhelming so far. It's time I switch to the dark side! I will for sure wait until Big Navi is released and compare the two. Plus, I'm very cautious about dropping around £800 on a single component, so will wait for reviews of the various AIB models.",rtx_3080_3090_leak
The rumored core count on the 3090 is considerable higher than the 3080. That is where most of the extra wattage/heat would be coming from. Yes more VRAM would increase it but not nearly as much as the core count.,rtx_3080_3090_leak
https://ctee.com.tw/news/tech/266203.html,rtx_3080_3090_leak
"It will if it can't use NVidia's shiny new compression tech, or if their shiny new compression tech isn't what they've hyped it up to be.  Bytes are bytes.  If they don't compress it, it will use over 10GB, regardless of the type of RAM it's on.",rtx_3080_3090_leak
"Yeah we dunno the benches yet but why you gotta be so combative about people who are upset with 10GB of RAM?

I'm expecting the first generation of these cards to have a short lifespan for people who like having a modern PC kit, 'cause I'd expect a 30xx Super or TI line in a year or less. That's *okay*. It's okay to expect more out of a new line of cards, and it's okay to not want to buy them. It's okay to think they're going to be a good upgrade, too! You don't have to get upset with people thinking differently than you, and try to sway them to your point.

Learn to let things lie. Save your energy for things that matter, man.",rtx_3080_3090_leak
"What you don't understand is that there is a feedback loop that must be broken: 

GPU has little vram -> developers develop for little vram -> GPU vendor noticed little vram is still ok (but it isn't) -> new GPU has little vram 

And that's how you end up with xx70 having 8GB for 3 generations now.",rtx_3080_3090_leak
Yeah if you stay gaming at 1080p or 1440p. I game at 4K and will be in VR 4K headset soon. This low VRAM IS disappointing.,rtx_3080_3090_leak
"Yeppers, and 24-27gb of total ram consumed of 32gb in a high texture area.

First “game” by a long shot that truely has gobbled vram",rtx_3080_3090_leak
It took a decade.....from when? What a nonsensical statement.,rtx_3080_3090_leak
"The only reason they're still not fully using it is all the people still holding onto their outdated quad cores.  Battlefield V uses 12 threads.  Keep that in mind.  Hardware will always limit the software, but it shouldn't be imposing false limits by simply not upgrading certain parameters.",rtx_3080_3090_leak
Truth...I'm just guessing and on the high end for that matter.,rtx_3080_3090_leak
Thank you very much dude or dudette,rtx_3080_3090_leak
Oh are the 3000 cards coming with HDMI 2.1 or is that the expectation?,rtx_3080_3090_leak
DSC is already in 1.4a Display Ports.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Not to mention with HDMI 2.1 we waited literally years (and are still waiting) to get literally any capable output device whatsoever.

I'd be pretty fucking pissed if that happened again with DP 2.0

Not to mention, VR",rtx_3080_3090_leak
"I do remember that on Maxwell(?) I believe, so as long as the hardware is good than yeah that'd be nice.",rtx_3080_3090_leak
">Does speed actually reduce the amount of vram needed?

No. There's no substitute for it. Grabbing textures out of system RAM when VRAM runs out is quite slow and will stall the GPU pipeline, causing severe performance problems.",rtx_3080_3090_leak
If the AIB partners have control over the vram of the cards we can propably expect they tinker with the 3060 and 3070 VRAM aswell.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Not sure if dp 1.4 is capable of 4k 144hz with 10bit color,rtx_3080_3090_leak
You need to render everything twice at a very high framerate,rtx_3080_3090_leak
"You aren't playing the games with issues or just not noticing them/got lucky. Known issues in games pertaining to AMD hardware is as old as time. I've been PC gaming since the 90s and I've seen countless games over the years with issues specific to AMD hardware to the point I actively avoid them. It's been pretty easy since they don't have the performance these days, but even if Big Navi shows up and is somehow faster than a 3090, it won't matter to me because I don't trust 'em on drivers.",rtx_3080_3090_leak
"Ah it's *this* comment.

It doesn't represent the reality of the situation as the 5700XT issues plagued users left & right all the time.",rtx_3080_3090_leak
ok,rtx_3080_3090_leak
Source?,rtx_3080_3090_leak
There has been some rumors about AIB partners launching alongside the FE cards. This could be true cause of covid and wanting to get ahead of potential stock shortages but just take everything with a grain of salt and wait and see.,rtx_3080_3090_leak
If you’re on a 4K 120hz+/ serious vr you’re already spending tons on your monitor/vr rig alone and you’re likely the target market for the 3090 not the 3080.,rtx_3080_3090_leak
"VR is not limited by vram at all right now.

And sure okay the small % of 4K gamers have a good reason to complain",rtx_3080_3090_leak
Fair point about 4K but remember that GPU memory compression is also getting better every generation. Hence we gotta wait for benchmarks! :),rtx_3080_3090_leak
"No it doesn't. You're only saying that because HL:A can take up to like 9GB... that's it, not a single other VR game.",rtx_3080_3090_leak
VR Porn brah. I want my 6k teddies.,rtx_3080_3090_leak
"> You really think people should be buying a new GPU every couple years

Depends on the kind of performance you need. RT is in its infancy and this upcoming card and the generation after that will most likely boost performance way more (since we're starting so low). So if you'd like to keep up with the ever increasing RT enabled games, you'll probably have to upgrade more often than the last couple gens.

I agree that 10GB might be small if people are using mods and stuff so maybe the rumored 20GB model is the sweet spot.",rtx_3080_3090_leak
Well these GeForce cards were never for AI and machine learning. That's where 3090 and Titan came in.,rtx_3080_3090_leak
Why the fuck is this so accurate?,rtx_3080_3090_leak
"Me too technically, but I'm looking getting a new one. My current gsync one has a lot of artifacting.",rtx_3080_3090_leak
time to upgrade the monitor as well!,rtx_3080_3090_leak
"Never know, might be cheaper to buy an AMD card + a monitor",rtx_3080_3090_leak
Should be listed in the manual,rtx_3080_3090_leak
You have pcie 3 I believe,rtx_3080_3090_leak
"No, we call that a dumb circlejerk stemming from monumental ignorance on how games are designed... And ""missing 1gb"" lol? 2080 has 8gb..",rtx_3080_3090_leak
You're being downvoted but you're right. Nvidia is selling cards with tiny VRAM sizes for planned obsolescence. The consoles' advanced storage architecture should make anything under 24GB of VRAM completely useless in a few years' time.,rtx_3080_3090_leak
Lets take a moment and consider the price of an extra 10gb of g6x. This adds over  $100 usd to the price at cost. It could realistically add $200 with markup.,rtx_3080_3090_leak
Eh... I'm using 2080 Ti right now and 11GB is plenty. I'll be okay with 3080 10GB probably as long as it performs right (+30% faster vs 2080 Ti or so). Need it to drive my LG C9 TV to its potential!,rtx_3080_3090_leak
Any guess on how long it would take for those to be available?,rtx_3080_3090_leak
Why?,rtx_3080_3090_leak
Im more concerned about the cooling solution and size. I do plan to eventually cool whatever card I wind up getting but having a leaf blower for a few months doesn’t sit well with me,rtx_3080_3090_leak
Damn I bought a shite second hand car for £1200 :/,rtx_3080_3090_leak
"Same here. I game at 1440p and I have a 144hz monitor. I just hope between both companies, there's a decently priced card that will do the job.",rtx_3080_3090_leak
"The information isnt confirmed, it was a leak from a good source (from what i hear), so its most likely true, but nvidia can change the release to whenever they want to. But i wouldnt get it unless your brother is either really into 4k gaming or does renders and such on his PC, 10GB is more than enough for most games at 1440p and 1080p on max graphics. Most games take up to 8GB max, some less and a handful go above 9GB, besides the 3080 is using a new GDDR6X memory which  is (according to Nvidia) much faster than GDDR5 and considerably faster than GDDR6",rtx_3080_3090_leak
">Isn’t step up within 30days of new cars coming out?

I think it only applies to the Tesla cars though.",rtx_3080_3090_leak
"You need to register within 14 days of purchase and you can upgrade within 90 days of purchase, so long as this better variant comes out in October or November you can step up",rtx_3080_3090_leak
"Yeah but it is possible that this is some sort of enhanced 8nm being marketed as 7nm

But we all can confirm this on the Xtor count when they released it!",rtx_3080_3090_leak
Yeah if it was 12GB I would be ironclad on the purchase. The only thing giving me pause is the 10GB. 20GB will honestly be overkill I think. It could be two generations of cards before you start needing that or more. At least in gaming.,rtx_3080_3090_leak
"Isn't
 > ""top end"" use case. 


The same as
> higher end enthusiast resolution.

?",rtx_3080_3090_leak
"600w should be enough, unless you go for like a 32 core zen 3.",rtx_3080_3090_leak
"Yes, more than enough. The CPU isn't as power hungry as the GPU and the high wattage PSU are mostly for people using multi GPU or high powered CPUs with ton more cores.",rtx_3080_3090_leak
So me with an 8700k and looking to get a 3080 should be fine on 650w?,rtx_3080_3090_leak
"Is there a way I can actually measure my current power draw? I’ve got all my components overclocked including ram so it’ll be nice to know how much headroom I have. 

I actually had a 650w psu with a 9600k and 2070 super(both overclocked) and I kept getting blue screens, swapping to a 850w solves the issue even though apparently 650w should have been well enough for my hardware I’ve never known how to check",rtx_3080_3090_leak
You’ll be fine. 3700x is a 65w cpu. Much less power draw than 3800x and up that are 95w or any late intel cpu.,rtx_3080_3090_leak
How else are you going to display 1000fps Doom?,rtx_3080_3090_leak
Another brain dead consumer,rtx_3080_3090_leak
Stupid donkey,rtx_3080_3090_leak
"No idea, I just like the thought of some angry businessman at NVIDIA throwing his arms in the air and saying this in a boardroom xD",rtx_3080_3090_leak
"Rebut me, bitch",rtx_3080_3090_leak
"Not at all, since pro cards exist at a completely different price point. Indie studios and hobbyists simply cannot afford it. This is my current reality tbh",rtx_3080_3090_leak
Don't need any evidence. It's just performance counters. I got the privilege of seeing both the R9 290X and the 780 Ti head to head and the 780 Ti was using less ram than the R9 290X in a lot of games.,rtx_3080_3090_leak
"Don't worry he's just dumb, trying to say that a 3gb card use less vram than a 4gb one which is normal lol",rtx_3080_3090_leak
Well... wait for benchmark. I'm no reviewers!,rtx_3080_3090_leak
Great point. Never thought of that.,rtx_3080_3090_leak
Lmao you changed your whole comment. Nice try bro,rtx_3080_3090_leak
"> just buy a pre-built from Dell (Alienware) and throw away the rest of machine

But they're going to put a shitty plastic blower version in there with a single 8pin power connector.",rtx_3080_3090_leak
if i had money like that I'd wake up and go down a water slide to my infinite pool every morning xD,rtx_3080_3090_leak
Biggest worry is bots. Im ignorant of that world.  Big time Streamers Plus huge business maybe needing the High end cards.  I'm just a small fish in this huge ocean >_>!,rtx_3080_3090_leak
Nah that thing will sell out,rtx_3080_3090_leak
"I am just joking man. I will personally be waiting for reviews and what amd brings to the table because as of right now, nvidia is jacking prices up. Supporting it would mean it will just keep going up. I think it’s best for us consumers to stand our ground and say enough is enough. 

Maybe that’s just me but of course this is an nvidia sub so people will support it no matter what.",rtx_3080_3090_leak
"Well, just because you save some money doesn't automatically mean you have to spend it on videocards, you can for instance invest them in an index fund or something - unless you already do that. :)",rtx_3080_3090_leak
"I agree, people want bleeding edge but also want to pay less than last gen for some reason. Some things just aren’t for everyone. Its like working min wage and wanting a ferrari... if you dont have the expendable money from saving or wages then dont buy the best out",rtx_3080_3090_leak
"I’m coming from an EVGA card myself.  I’ve never bought a card at launch before, so this is all new to me.

I like your idea and may try that myself, actually.",rtx_3080_3090_leak
"Um, no. The 3090 with 24gb will be the best card.  People are complaining that the second best launch card is 10gb in comparison.",rtx_3080_3090_leak
Welp that would be a no for me lol. No way I could justify that kind of cash.,rtx_3080_3090_leak
We can meet here 4 months from now to see how it pans out ;-),rtx_3080_3090_leak
"As long as whales keep throwing away money, Nvidia will keep raising the prices.  I wonder if all the pandemic  economic issues will end up backfiring on them or not",rtx_3080_3090_leak
"That's a shitbox 99 corolla, dumbass",rtx_3080_3090_leak
The b9 also I think ?,rtx_3080_3090_leak
What hdmi port does my gtx 2080 have ?,rtx_3080_3090_leak
"Well, you would need to get a pretty high emd PSU, because you need the hugh wattage, but more importantly  efficiency  and reliability, i would go for the seasonic Focus PX-850, or even the Aorus Gigabyte GP-AP850GM, wich is a surprisingly  good psu, but generally  anything over 800 watts with an 80+ Gold certification",rtx_3080_3090_leak
"Ryzen 9 3900x or 3950x


Edit: Or a threadripper  if you have that kind of money :))",rtx_3080_3090_leak
"Yeah I understand that and you can’t deny that. Based on benchmarks tho we’ll know more about how they actually perform. I have a 2070 and it’s probably not me upgrading. Was thinking about selling mine to offset an upgrade, but it’s probably not worth it.",rtx_3080_3090_leak
Right that’s where my head was at. Just because they’re both 8GB card doesn’t mean the 3070 isn’t gonna destroy the 1070.,rtx_3080_3090_leak
"So I'm kneejerking because I don't accept 8gb of standard Gddr6 as an exceptional value?  Even if I *don't* have exact performance figures,  I understand the implications of that decision. I'm not replacing a gpu every 2 years just because *nvidia.*",rtx_3080_3090_leak
"I wouldn’t buy an $800+ GPU with 10GB VRAM in 2020 for the same reason that I wouldn’t buy a 4 core Intel CPU in 2018.

I’m not an idiot",rtx_3080_3090_leak
"For me it’s not the amount of VRAM amount, it’s the bus width and speed. The scientific applications I run benefit greatly from better memory speeds but use almost no memory relative to gaming requirements.",rtx_3080_3090_leak
"When’s that scheduled to come out? Also, are you okay with shitty drivers for the first few months?",rtx_3080_3090_leak
"""almost the same spec"" except double the speed..

ok then",rtx_3080_3090_leak
How much you get for yours? I'm thinking about selling mine before the 3000s drop. Mine still has over two years warranty left on it too. should sell pretty quick I'm thinking.,rtx_3080_3090_leak
Good point. Thanks,rtx_3080_3090_leak
It can be risky though.  The buyer could file on ebay/paypal for a return.. buyers can return anything for any reason up to 6 month on there due to credit card chargebacks.,rtx_3080_3090_leak
Ah okay that makes more sense. Yeah sell the 2080ti and get the 3080. Makes sense. Thanks!,rtx_3080_3090_leak
"I doubt more than 12 of that will be used for games, also i doubt such a drastic increase in game VRAM usage will happen, more like next gen games slowly start using more and more until they're using 12 in the second half of the generation.",rtx_3080_3090_leak
"In manufacturing it's all about the cost per usable chip.

3080 is basically made from broken dies from 3090, so bad yield matters less.

Samsung's node is a lot cheaper too - if they yield half as many but pay Samsung half the money, that's the same price as far as Nvidia is concerned.",rtx_3080_3090_leak
"People are way too delusional about the whole ""Ryzen Money"" thing. Its hype is mostly on tech sites and reddit, not the general population. For all the supposed superiority of Ryzen, intel lost very little market share so far. Not to mention that Ryzen is sold for significantly cheaper too meaning the profits arent that amazing either. AMD may not be in a somewhat dire situation like they were before, but lets not pretend they're rolling in money or anything. Especially when they need to keep putting that money in the cpu segment too.",rtx_3080_3090_leak
"I wouldnt hold my breath until it actually comes out. Every bit of AMD hype every gen, atleast for gpus, have turned out to be bullshit for many *many* years so now.",rtx_3080_3090_leak
"Maybe they will close the gap..But there are so many comments that NVIDIA is going to be worse off somehow.
I don't see it happening. The 3090 might use a lot of power but if AMD have anything that performs similar , they will have the same power/heat issues",rtx_3080_3090_leak
"This is the law. Unless you're without a doubt sure of spending this money, you always wait for proper results.",rtx_3080_3090_leak
"Sooooooo will his computer turn on and work. YES. I’m not saying it won’t work. For maximum efficiency, longevity, and piece of mind he should upgrade.",rtx_3080_3090_leak
I read the Johnny guru article the other day and the difference between 50-75% is literally 1%. 89% vs 90%,rtx_3080_3090_leak
Hahaha wow. Didn’t think I’d get downvoted on this. Let’s see how many I can get! 😂,rtx_3080_3090_leak
Yeah and performance at worst matches the 1080 Ti. But in popular titles like RDR2 its a full generation leap ahead at 30% faster.,rtx_3080_3090_leak
For 1440P it's absolutely enough even for future games.,rtx_3080_3090_leak
"I already mentioned that saying 2-4 will likely be reserved so games can use 12GB+, do you honestly think the OS will need 6GB+?",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"If you look on the seasonic 12 pin connector boxes they recommend 850+. You are making lots of assumptions, theses cards are rumored to draw 400w. Wait for the official announcement to know for sure but like I said in my post, based on what we know probably not.",rtx_3080_3090_leak
"They get press samples. There will be reviews before or at the same time cards are released, usually",rtx_3080_3090_leak
That's 3090,rtx_3080_3090_leak
The previous guy is probably closer to the real number.,rtx_3080_3090_leak
"Where? No, they don't.",rtx_3080_3090_leak
I'm gonna assume 650 at the maximum,rtx_3080_3090_leak
"You should have a little overhead for upgrading, overclocking and such.",rtx_3080_3090_leak
You can generalize games like that man 🤣 that makes no sense. What is up with the stupid dislikes.,rtx_3080_3090_leak
Most likely after,rtx_3080_3090_leak
NVIDIA decide on final pricing right before the announcement,rtx_3080_3090_leak
Apologies,rtx_3080_3090_leak
"Because other components need power as well SSD, Mobo, Ram, fans with RGB LEDs.",rtx_3080_3090_leak
"No worries! if you go back even 5-7 years ago, having more than one GPU in a system was quite common as more games supported it and individual GPUs were cheaper, therefore 2 GPUs in an enthusiast system was common.  This combined with some GPUs like the GTX 480 easily reaching over 350W (the 3090 is rated for a 350W power limit, i.e won't go above that at stock) meant overall system load could go above 750W for enthusiast systems. Even back then, a 1000W power supply was overkill in most cases, but of course when you're spending that much on a system anyway, it's unlikely an enthusiast would mind shelling out the extra $50-100 on a fancy 1000W power supply. Old habits die hard hence why 1000W power supplies are still around, and proper workstation computers for 3D design and machine learning can have many many GPUs in them.   


Oh also, power supplies are both quietest and most efficient when they are at 50% load, so people wanting the ""best system"" even if it's not particularly powerful will go for a high rated PSU to get the best efficiency",rtx_3080_3090_leak
And still it is a meme as there is no usefull application. It is nothing more than a new toy for megacorps. Same for AI and data science,rtx_3080_3090_leak
Thats a pretty good pairing,rtx_3080_3090_leak
"xx90 is either the new name for what has been called ""TI"" up until now, or the new name for the Titan series. We'll probably know on Tuesday.",rtx_3080_3090_leak
"xx90 hasnt been a used for years. The last one to use x90 IIRC  was a dual-GPU on one PCB card.  
The word is they want to avoid confusion with the ""ti"" naming, as it insinuates only a small difference in power.  I'm not sure I buy that. There will probably be ""ti's"" and Supers to come along with the 3090, so folks will be just as confused as ever.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Why? I have an 5 year old 980ti which is just fine with 6GB atm. GTX1070 also lasts a long time already. However a card like the 3GB 1060 wasn’t future proof at all: if a newer game releases and uses a bit too much vram you’re done for.,rtx_3080_3090_leak
">ane from financial pov (it costs almost as much as average income after tax for 2 months in this country) , going for 3080 10gb would be insane for futureproofing for next 3-4 years, especially for someone who will love to play heavily modded open world games with RT on ultra.

But there is such thing of short-proof, and the best examples were R9 380/GTX 960 with 2GB. Remember that you have to pay 600-800$ for these cards, you are supposed to keep them for years, not throw them in the bin after a few months.",rtx_3080_3090_leak
I don't think so.  They would need to redesign it.  You can't just jump to a node from a different foundary.  So we are talking about a year+ of work and testing for a simple refresh.  The only chance of that would probably rest on if Big Navi surprised everyone and blew Nvidia entire lineup out of the water.  Otherwise there's no need for that huge expenditure of money.  More likely is they just do what they did with Super cards and place the SM count somewhere between the current card and next card and higher factory clocks.,rtx_3080_3090_leak
"True, but this is a reason why it costs more. I feel that 3090 is for ""content"" creators to render or stream and indie game devs. Titan was too pricey and it was weird product. If you are professional 3D artist you want quadro. If you want to play it is geforce. Probably 3090 is attempt to be that product to clash game hobby and creative hobby and cooler might indicate it. But it is only three days left, lets see how Nvidia will market it.",rtx_3080_3090_leak
"I'm sorry you must be new (or trolling) but core count means fuck all when comparing different generations of GPU.

2070 Super (2560 Cores) has less cores than 1080 Ti (3584 Cores) but performs similarly.

2070 Super (2560 Cores) has the same cores as 1080 (2560 Cores) and it outperformed 1080 by approx 30-35%

Specs... means... nothing.

Look at benchmark and actual testing.",rtx_3080_3090_leak
"Just because you bypass it doesn't mean you shouldn't have waited one month or two to get at least 40% better performance for not much more money.

By getting 3070 you could have bypassed 4000 series.",rtx_3080_3090_leak
3070 is rumored to be 2080 Ti performance so your 2070 Super will be be way behind in performance despite the same amount of VRAM,rtx_3080_3090_leak
"But if you wait a year, now you're only a year away from even better cards. You get the most value when you by the new generation when it is released, and use that card for 2-4 years until you decide to jump to a new generation.   The mid cycle cards are fine if you happen to be buying on the off year, but it's certainly not the most efficient",rtx_3080_3090_leak
"These are fair points and we currently don't know the 3070's exact price, availability or your personal reasons for not being able to wait. This is why I specifically mentioned ""if you had the ability to wait"" because most people here did have the ability to wait a month or two for 2080ti performance around a $500 price point.



That being said I hope your enjoying your first pc! The 2070 is still a great card and should serve you well.",rtx_3080_3090_leak
"Really, you think I would've been better future proofed had I gone with a 4GB 670 GTX instead of my 2GB version?",rtx_3080_3090_leak
Especially with CP2077 coming out just 2 months after these cards drop.,rtx_3080_3090_leak
No 3090 at 24GB is probably it. They could do 48GB but that's probably reserved for Quadro.,rtx_3080_3090_leak
RTX is a new technology and most likely will get a big bump from Turing.,rtx_3080_3090_leak
It’s still a solid card. But I’m going to replace mine because it can’t drive my monitor. Need that DP1.4!,rtx_3080_3090_leak
"For 1440/1080 it will stay relevant for some time. For 4K, not so much and the 2080ti isnt enough to stay relevant at 4K either",rtx_3080_3090_leak
Yep made my friend think twice about buying an 800 2070 super,rtx_3080_3090_leak
"2070 super exists? that card is on par with a 1080ti, even before the super series a 2080 was still the same price as a new 1080ti ($700) and due uarch changes turing performs miles better on games that were once AMDs best like rainbow six siege and you get all the little gimmicks that you cant get with 10th gen like RTX & DLSS.

going used, however, made turing laughable at launch, £400 for evga 1080ti still in warranty or £750 for 2080. hard choice i tell you, it took me all 5 seconds to decide",rtx_3080_3090_leak
The 5700 XT is not faster than the 1080ti lol.,rtx_3080_3090_leak
"Although, to be fair the drivers for amd are a little better for Mac OS and Linux users. Unless you’re willing to use the web drivers for either platform.",rtx_3080_3090_leak
"Lol. I've learned to just ignore the underbids. If I allow bidding I only allow like 20 dollar less. Everything I've sold, (if I price it at or near the normal price) someone will pay for it. Sometimes it can take a few days. Allowing offers is only something I would do if I want it gone fast. As 75% of them just make me laugh.",rtx_3080_3090_leak
I paid $660 Canadian for it brand new from retailer before there seemed to be a shortage. Sold for $850 hahA,rtx_3080_3090_leak
"Yeah, I knew something wasn't right. 


With that said, I've seen the aftermarket boards going for well over $1k - $1.5K. There's no way I'm paying those prices, but plenty of people are willing to do that, and when people are willing to pay those prices, the prices stay that way. Frustrating.",rtx_3080_3090_leak
"CDPR is kind of in a pinch now after multiple delays; we have new hardware, new consoles, and a shitty economy across the board (thanks ~~Obama~~ Corona!). Cyberpunk sort of *has* a bit of an obligation to release now, especially to fulfill a potential bundle of promises, to us, to 3rd party MFRs, and to MS/Sony with all the promotional materials.

They can always patch a bunch of shit for weeks, even months, after the fact. That alone wouldn't be anything new in the age of digital distribution.",rtx_3080_3090_leak
Odds are better (Still not certain) since we passed the dreaded 91 day countdown.,rtx_3080_3090_leak
I work a salaried job and have to plan PTO. I already requested 3  days off near thanksgiving to have time to play cyberpunk. Please lord dont let the release dates change lol.,rtx_3080_3090_leak
Bold of you to assume it will release,rtx_3080_3090_leak
Bold of you to assume EPIC won't buy it as a non releasing exclusive just to take fucking the market over to a new level.,rtx_3080_3090_leak
I am planning on playing it on 4k so def will need a 3080 at least.  Not really not I want to get 10 GB tho,rtx_3080_3090_leak
Depends on resolution and whether you enable RTX really. If you're doing <4k and/or no RTX you'll be fine. If you are on 4k and want RTX you'll want a 30xx series.,rtx_3080_3090_leak
Probably.  It's supposed to be very demanding game.,rtx_3080_3090_leak
"With NY taxes, 3090 comes out to $1523.  That's pretty insane for a GPU.",rtx_3080_3090_leak
"Well, 3090 has about 21% more cuda cores and they use the same G6X VRAM (one is 19.5Gbps and the other is 19Gbps) so that performance gap should be around 20% plus minus 5%

That's probably the ""smallest"" performance gap between top of the line card vs their xx80 card.

For reference, 3 years ago, Nvidia shared these 

* 780 Ti vs 780 = +18%

* 980 Ti vs 980 = +25%

* 1080 Ti vs 1080 = +35%

So yeah this ~20% delta between 3090 and 3080 will be the second smallest gap since Kepler.

Funny enough, the last time they had xx80 card on their top GPU (3080 is slated to use GA102 just like 3090) it was Kepler too (780, 780 Ti, and Titan was using GK110)",rtx_3080_3090_leak
With dlss it's possible. I'm able to play death stranding at 60fps locked in 4k at max settings with dlss on.,rtx_3080_3090_leak
"Depends on your needs. I mostly just do sim racing and play a lot of indie games and just want things running at least 60 fps consistently. Most ""new-ish"" titles I have are stuff like MGS5 and Soul Calibur 6 and the like. They already run fine at 4k with some minor compromises on the 1070 ti.

Most intensive game I own graphically is Assassin's Creed Odyssey, which runs at 1440p or 4k but internally downscaled.

I'm not too picky about graphics; I still play SNES and PS1 games pretty regularly.",rtx_3080_3090_leak
"I know it's because of capitalism and I fully understand why they do it, but if you take a step back and think about it it's really silly.

If nvidia had real competition in a healthy market then they'd have to build only their best cards and sell as cheap as possible. But since the market is not healthy, and there's a duopoly, we get this ridiculous situation where the company intentionally cripples most of their silicon to meet lower market tiers.

If aliens who didn't have capitalism visited earth and saw this they'd laugh",rtx_3080_3090_leak
2880x1620. I tend to use a few arbitrary 16:9 resolutions my card can handle besides standard. Most commonly 2880x1620 (1620p) and 3200x1800 (1800p).,rtx_3080_3090_leak
I don't really understand what you're trying to say.,rtx_3080_3090_leak
"Yes, but why would you assume that that knowledge translates to them maximizing VRAM on this generation? If they calculated that not bumping VRAM is good enough and leads to better profits over 2+ generations, don't you think they would go that route?",rtx_3080_3090_leak
"Agreed, not to mention if no cards have that much ram then you arnt going to see games targeting it.",rtx_3080_3090_leak
"Yeah one of the top posts in this comment section is someone saying they won’t downgrade to “only” 10gb of vram. 

So if it tripled the FPS you get and at higher settings... but has 1gb less vram you won’t upgrade to that? Okay champ. 

even at 4K I don’t think many games use that much vram. It’s just really not an issue.",rtx_3080_3090_leak
"You’re forgetting that FS2020 is the *start* of the next gen video game titles. 6gb to start does *not* bode well for a 8gb max capacity.

Straight up lets not give nvidia credit here for this. They’re trying to get the whales to make the price jump from 800 to 1400. They’re also probably anticipating slashing their prices when AMD comes out with their next gen cards.",rtx_3080_3090_leak
Flying into JFK at 1440p on a GTX 1070 has my VRAM pegged at 7.2 GB so...,rtx_3080_3090_leak
"people said when PS4/xbox one were released back in 2013: ""2GB of VRAM is the sweet spot, you will be fine"", then it quickly became 4GB and to finish, 8GB. I heard about NVcache or vram compression and stuff but i'm kinda doubtful.",rtx_3080_3090_leak
"I am... :(

I bought my 144hz 1440p monitor without knowing what the fuck I was getting into and have been playing catch-up with the rest of my PC ever since.",rtx_3080_3090_leak
"majority on the steam survey are cheap laptops with integrated graphics < 1660ti. all 1080p or lower screens, also majority of gamers do not buy GPU’s above 300$€ where performance have not been increased to handle 1440p in AAA titles with ease.  

1660super here, while good and can handle 1440p fine in most games it struggles in the latest AAA above medium to stay at 60fps.",rtx_3080_3090_leak
"I'm on either a 4k TV somewhere between 1620p and 4k, or on a 3440x1440 100 Hz ultrawide. Yes, people do play above 1080p.",rtx_3080_3090_leak
"I've been playing on 4k for 3 years, do I exist?",rtx_3080_3090_leak
Do you not understand that's the issue they were stating?,rtx_3080_3090_leak
Not sure why you’re getting downvoted. They make different tiers of cards for a reason. Don’t buy a low-mid tier card and complain that it won’t run next-gen games at max settings. Buy the card that fits your needs.,rtx_3080_3090_leak
"Then your imagination is shit, next gen consoles are going to soon enough be the minimum specs and a 3070 with only 8GB ram is going to age fast.
Watch by this time next year 16GB cards will be available at a price comparable to the 3070 launch price.",rtx_3080_3090_leak
Warzone at 1440p high settings shows 10.5 GB of vram usage in EVGA precision X1....,rtx_3080_3090_leak
"Yea, u are beeing bottlenecked by your CPU. So what are you trying to say Here? Im getting 50+ fps",rtx_3080_3090_leak
Use. Vega 64 LC.,rtx_3080_3090_leak
"I also have that monitor, but it really has little effect on the VRAM requirements and further, it's usually the CPU that can't get the 144 Hz out, which is still mostly off of single core in most places but can ramp up to multicore depending on the game and area (i.e., TW3 Novigrad likes more cores, but in general will need them to be faster). 

If you want the GPU to handle the load more, you will usually go up in resolution.",rtx_3080_3090_leak
Get an LG CX OLED tv and run it at 4K 120hz. The picture is absolutely amazing.,rtx_3080_3090_leak
"Lol, the more casual they are, the less they will care about screen resolution, therefore most people stick to 1080p - plus it's cheaper.
People who actually buy higher resolution screens are usually hardcore gamers or enthusiasts.",rtx_3080_3090_leak
"Just because you prefer frames over resolution doesn't mean 1080p looks bad, or someone uses it for the sole reason to be competitive.",rtx_3080_3090_leak
"Acer Predator XB241H (TN panel, I know, but I got it on a pretty significant discount so it was a great deal).",rtx_3080_3090_leak
Steam hardware survey grossly over represents Internet cafes and other public machines.,rtx_3080_3090_leak
"I need to make use of my 4K 120hz LG OLED. I'm aiming for 90 fps or more at 4K. Honestly, there's a huge difference between 60 and 90. But over 90 fps, and I'd be lying if I could tell much if any tangible difference.",rtx_3080_3090_leak
"Not at all, in most triple-A games it won't get me stable 180 fps when maxed out - in Warzone I get around 130-140 fps, in Witcher 3 110-120, etc.
Don't get me wrong, I know that 1440p looks much better, but I wanted to have a solid rig that will last me for years for high framerate gameplay.",rtx_3080_3090_leak
If I run at 144hz I have to lower the resolution in my Vr headset to about 80% of the display resolution. In VR you usually want to supersample up to 150% of the headsets display resolution for decent visual fidelity.,rtx_3080_3090_leak
"Bingo. I'm not crazy about these kinds of leaks because people will just get caught up on the *amount* of something compared to another in its category. I bet only a select few would even notice a difference in how they use their computer when going from 10GB to 20GB of VRAM (especially when that use is mainly gaming). 

Video editors and ML/AI nerds are probably drooling for that 3090 though. I know I am as it's currently my tears that help me lube my After Effects timeline.",rtx_3080_3090_leak
"Awesome, I know I will get 4k at some point but 1440 is great for now.",rtx_3080_3090_leak
"Resident evil 2 at max graphics uses 10gb of vram at 1080p.  

That released last year.

Edit. I just opened it and checked.  I was wrong. It uses 12.34gb. Even more than I thought.",rtx_3080_3090_leak
"Sure, but only some does & not all. Might be the factor in churning out high FPS stutter free but either side of it requires actual usage analysis.",rtx_3080_3090_leak
"> 3700X + 2080 Super.

What? Are you saying that the new consoles will have similar performance as that?",rtx_3080_3090_leak
"> And then both have CPUs and GPUs which put them in the ballpark of an R7 3700X + 2080 Super.

Ima gonna have to ask for a some real hard sources on such incredibly laughable claims like this. With hardware like that, the consoles would have to cost 6-700$..",rtx_3080_3090_leak
Thanks! My brain kept going to “All in....B...” like AIO,rtx_3080_3090_leak
Do AIB partners get worse PCBs?,rtx_3080_3090_leak
I believe you are correct!,rtx_3080_3090_leak
"Well they actually typically don't use custom boards. They just copy the reference PCB design to a T. What they do change is firmware, cooling, GPU frequencies, etc.",rtx_3080_3090_leak
"AIBP would be more accurate or just ""partner cards"" because all of these cards are add-in boards. Founders Edition cards are still add-in boards. 

Everyone just started saying it for some reason.",rtx_3080_3090_leak
snob term for 3rd party tbh,rtx_3080_3090_leak
Associates in Bachelors,rtx_3080_3090_leak
With micron as only supplier will they have enough chips for releasing a 20GB 3080? I think that they will probably wait some time until samsung and hynix release GDDR6X memory to launch the 3080 20GB version.,rtx_3080_3090_leak
"Ahhh, ty ty, good to know. So we MIGHT see a ""budget"" 3090 maybe?",rtx_3080_3090_leak
"What is the bus relationship on the capacity of the Vram? Like wouldn’t a 32 bit bus on the memory chips allow for 384 bit bus to have 12 chips? And then you gotta know how much memory per chip, and if it even is 32 bits per memory chip. Idk these numbers for Ampere though, like the word size of the memory chips themsleves, how many GB’s they are, etc. lol

I would assume then with the 384 bit variant having 12 or 24gb, and 32 bit word length for the chip, each chip is 1-2gb for the 12 or 24gb model, and then the 320 bit model has 1-2 gb as well, but only 10 chips? Or 64 bit and 6-12 chips? Or 5-10?",rtx_3080_3090_leak
Another commenter pointed out the possibility if a 12 GB 3090 bc of that... I am... very interested in that notion lol.,rtx_3080_3090_leak
"Finished the article lol, looks like a 3080... ""mega"" lol or something with 20gb of VRAM willnrelease pretty soon, but probably not at thr same time.",rtx_3080_3090_leak
"It'd like to point out the idea of a 3080 Super, Ti, or any other such refresh on the card is 110% speculation at this point.  We have no way of knowing if that will even happen this generation, or if it does then much less what they'll end up calling it or when it might be released (although not until well into next year would be a good starting point).",rtx_3080_3090_leak
I swear we just replayed the Futurama scene,rtx_3080_3090_leak
So hard to wait for the official announcement! I'll only drop $1300 odd on the 3090 if it can carry me through 4 years of 1440P ultra gaming.,rtx_3080_3090_leak
"It wasnt the naming scheme, it was the perf/price. 

Don't be hung up on a suffix. Its about the hw and being a refresh/refined release.

My Geforce 2 TI was amazing and would have been the same called Ultra Super.",rtx_3080_3090_leak
"i just had to grab 32gb of ram, turns out MSFS 2020 is a bit of a ram hog lol regularly using 24gigs, i feel better about that investment then a new $2000 video card to replace the 1080Ti",rtx_3080_3090_leak
Im still using a 3770k to this day. 7-8 years chugging now. I’d say ive gotten my money’s worth,rtx_3080_3090_leak
Editing 4k video on 16gb was painful had to steal the other two 8gb sticks from my guest pc lol,rtx_3080_3090_leak
Holy crap Minecraft uses 19 gigs of RAM?!,rtx_3080_3090_leak
"\>I traded an 8700k system for a 3700x system

You understand thats an up to 40% downgrade in frames when gaming. Unless you are specifically rendering. (outside of video rendering) You swapped out to a slower CPU.

[https://www.gamersnexus.net/images/media/2020/10900k-review/intel-10900k-twtk-1080p.png](https://www.gamersnexus.net/images/media/2020/10900k-review/intel-10900k-twtk-1080p.png)

&#x200B;

[https://www.gamersnexus.net/images/media/2020/10900k-review/intel-10900k-hitman2.png](https://www.gamersnexus.net/images/media/2020/10900k-review/intel-10900k-hitman2.png)

&#x200B;

[https://www.gamersnexus.net/images/media/2020/10900k-review/intel-10900k-f1-1080p.png](https://www.gamersnexus.net/images/media/2020/10900k-review/intel-10900k-f1-1080p.png)",rtx_3080_3090_leak
\-\_-,rtx_3080_3090_leak
I am under the impression that DLSS 3.0 will involve better VRAM usage. So the same 8GB VRAM now might be ‘worth’ more once 3.0 gets adopted.,rtx_3080_3090_leak
I'm on a 1080 on a 3440x1440 100hz monitor. It really has been struggling lately. I'd settle for 40% honestly.,rtx_3080_3090_leak
"Mainly MW2019, R6. Believe it or not, a 2070 super actually can't maintain 144fps at 1440p in Siege, all those benchmarks online where people get close to 200fps are because they forget to change the TAA render resolution which defaults to 50%.",rtx_3080_3090_leak
Never heard of that one. What was the 8800GT like?,rtx_3080_3090_leak
Opted for the 8800 GTX and that thing also lasted for half a decade.,rtx_3080_3090_leak
"The next generation of cards after Ampere, which will use an MCM design.",rtx_3080_3090_leak
You could just not jerk off to your video card,rtx_3080_3090_leak
How did you come to the mathematical conclusion of 500 for a new 3080?,rtx_3080_3090_leak
I dont have a 1080ti...i have a 1080. And I know what you're saying but you're still talking about spending $1000+ for a graphics card and im not sure there will be that much of a difference between a 3080 and a 2080 for the games on my pc,rtx_3080_3090_leak
Nah just my memory being ass. But if amd is going to launch a new architecture we are probably going to get a super/ti,rtx_3080_3090_leak
">I mean the 1080Ti will even survive the next 1-2 years at 1080p.

Lmao the 1080ti will survive like 10 years at 1080p assuming the card doesn't literally die. A 1080ti is more powerful than the 2080 equivalents that are in the new 4k consoles.   (remember that it'll have more vram than the 3070 if this leak is to be believed).  Also remember that 1080p vs 4k is the same as 540p vs 1080p, and you better believe that something like a gtx 480 can run games at 540p.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"> 30FPS at 4k on ultra in MSFS 2020 is an indicator

Well to be fair to my system, I'm usually in Ultra at ~55 frames on *almost* everything.",rtx_3080_3090_leak
I can't run games with Raytracing the way I'd like :p,rtx_3080_3090_leak
"The 10 and 20 series got intermediate cards. 

The 1070ti exists.

The 2070 super exists.

It doesn't matter what they call it, rest assured they'll put somthing there to fill the price gaps.",rtx_3080_3090_leak
"I agree with you, in the sense that most tech subs seem to be underwhelmed and disappointed before  any tangible performance data comes out, which is frustrating to say the least. People here already pissed off about how much VRAM these cards have, when its legit a non issue in like 90% of cases. 

HOWEVER, there is no way that Nvidia will forget that a mid cycle refresh gave them a ton of excitement, media coverage, and definitely some extra revenue, and it would be semi naive to think they wont do it again to try to steal some thunder from Big Navi",rtx_3080_3090_leak
They're playing us like a damned fiddle.,rtx_3080_3090_leak
"Honestly I think I'm probably gonna hold onto my 1070 until the 4000 series, there really hasn't been a huge incentive to upgrade for the 2k and 3k series.",rtx_3080_3090_leak
I think you will be better served with big navi,rtx_3080_3090_leak
"What are you basing that on? You have no price/performance numbers.

Extrapolating current gen or comparing next gen HW... grand.",rtx_3080_3090_leak
bought a 3gb 1060 when I was on a budget. Was hoping the 3070 would be the solution but ig i'm gonna wait it out a little longer,rtx_3080_3090_leak
I got a 2060Super last year and almost went with the 2070S but didn’t see the value when gaming at 1080p 60hz. Then I got a 240hz 1080p monitor. It still can drive most games at those framerates but I have to crank down some settings (not a real issue for esports). I was thinking about going for the 3070 this release but man Nvidia is being so damn shitty with their options. Where the Super cards were an amazing value I really can’t see that here yet.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
I swear if the 3060 has 6gb at 399 I'm not going to buy Nvidia ever again. I wanted to get a 3070 but for 600 dollars I thought they will atleast give us 10gb.,rtx_3080_3090_leak
I think you're right. I mean the product gap between the 3070/ 3080 and the 3090 is so big you could land a jumbo jet in it. It would surprise me if Nvidia didn't release 'super' versions...and with 'super' price tags.,rtx_3080_3090_leak
Wouldn't be surprised to see a 3070ti with 10 and GDDR6X to fight against Navi 22.,rtx_3080_3090_leak
"Well, since 2080 ti has 250 w TDP that's a helluva efficiency.",rtx_3080_3090_leak
"I dont want efficiency,  i want to be forced to wire my house with 240v 30 amp outlets for my pc.",rtx_3080_3090_leak
I wonder where I could get a energy efficiency breakdown of their cards. I have a 1060 GB that I don't know how much watts it uses,rtx_3080_3090_leak
"I mean, the 2070s is still going to be left in the dust.. it's still a good card but it's simultaneously a bad buy due to timing.",rtx_3080_3090_leak
"Wait for benchmarks, then wait again for 7 months for the supers or ti at the same price and buy that. That's my plan and i'm sticking to it. Everyone who buys first will feel shafted in a year.",rtx_3080_3090_leak
">essentially **forcing** a vast majority people to the much more expensive 3080

How? it's not that 8GB of VRAM makes games unplayable, monitoring tools report the allocated memory not the actually used one so you have to look for performance degradation.",rtx_3080_3090_leak
"About 6 months to a year, depending on if AMD has anything to compete and push nvidia to release a refresh like they did with RDNA.",rtx_3080_3090_leak
"Please dont listen to any of the answers you're getting here.

There's absolutely no indication whatsoever.

It could come a month afterwards or a year later or any time in between.  Or straight up never at all.  Entirely depends on Nvidia's current strategy, which changes each product release.",rtx_3080_3090_leak
I would think a year after release of 3070.,rtx_3080_3090_leak
yeah you are right i thought it will atleast have 18gbps G6 and its 16gbps :P,rtx_3080_3090_leak
"The price won't be, sadly. The problem with the new 3000 cards being so goddamn expensive is that they'll likely prolong the viability of cards like the 2080ti, which will keep their prices high on the market for at least another year.",rtx_3080_3090_leak
"200 percent more isn't 2x. It's 3x.

Relative performance will vary game-to-game and with resolution, but in general you're looking at over double 1080p framerates for older games and around triple otherwise. Combined with more VRAM means that it's a huge upgrade ignoring newer features entirely.",rtx_3080_3090_leak
"> 970

equal to 200 percent more performance. So x2 what you are getting plus the up to date features like DLS2.0 DX12.2 and RTX",rtx_3080_3090_leak
I have the same card and looking to upgrade to 3070/80. Hmm,rtx_3080_3090_leak
"Different use case, I honestly reckon the 3090 is a titan replacement and that extra ram is for rendering.",rtx_3080_3090_leak
"Digital foundry has put out their early benchmarks, 70-90 percent faster than the 2080. My calculations put that at 35% faster than the 2080ti on average.",rtx_3080_3090_leak
"For the current cost, sure. I mean if there's a decent drop in price. There are games out there that don't reach 144fps on maxed out settings on even a 2080ti. Plus, future games should be more demanding even at 1080p with the new consoles, should they not?",rtx_3080_3090_leak
I feel like a 1080ti or super would be more cost effective in 6mos if your buying used for 1080,rtx_3080_3090_leak
">  You can easily play any game 1440p 144Hz with a 2070 super

Nope, lol.

Not if you want high settings.",rtx_3080_3090_leak
"1. There are games that don't even reach 144fps with a 2080ti with max settings.
2. Future games should be more demanding even at 1080p. Although with DLSS or whatever you might be correct.",rtx_3080_3090_leak
240hz and 360hz monitors... rare combo but it does exist,rtx_3080_3090_leak
Wont DLSS 2-3 help with these things?,rtx_3080_3090_leak
Preach man. The amount VRAM I see here is highway robbery.,rtx_3080_3090_leak
"A game using all the available vram does not mean that it is actually using it and limiting performance. Many games allocate information using all available vram just in case because why not, every megabyte of vram not used is a wasted ram.",rtx_3080_3090_leak
"I played BF V in 4k with RT on and DLSS and it ran at 60fps on a 2070.
Also, nothing is futureproof.
The 3080 will be obsolete in 4 years.",rtx_3080_3090_leak
"some people cant look beyond the past. some scoff at the mere mention of future proof....some people are idiots lol

you will easily get 6 years out of that card and thats top end gaming(the future may be 120hz 4k but if we focus onwhat we have rather that what we dont we can be content rather than elitist) could probably squeeze out some more years mid-low end gaming .",rtx_3080_3090_leak
if ur playing at 4k then you should be ready to pay a premium for a premium experience. get the 3090 and call it a day,rtx_3080_3090_leak
"So you max out 8 and the game juggles 8 gigs worth of texture around, smartly, and you will still have decent performance.",rtx_3080_3090_leak
No it doesn't...,rtx_3080_3090_leak
"Modifications of the base files do not count
You can make a game eat 64 gigs of vram with mods..",rtx_3080_3090_leak
"this is one the worst optimized games out there.
i saw it lag on a 1070 ti on low..",rtx_3080_3090_leak
"Not expert here, but bus is like the connector that connect RAM chips and the GPU. It's like an interface. The RAM chips/capacity can be only an integer multiplier of the bus.

That's why a bus like 128 or 256 gives nice round IT number like 8GBs of VRAM, while a ""non-round"" bus like 320 or 384 gives these weird 10/12/14 numbers.",rtx_3080_3090_leak
"Every chip have a 32bit bus, so the card must have 10 chips",rtx_3080_3090_leak
this was leaked months ago,rtx_3080_3090_leak
"Thats a bit much, even for modern hardware. If thats what u truly want, gotta pay a premium for a premium experience. This is one of the reasons im still using 1080p 144hz. Easy to run, dont need to upgrade often, and it doesnt look as bad as people like to say. I picked my 2060s up for 310$ too so cant complain.",rtx_3080_3090_leak
GP108 was samsung while the rest of pascal was tsmc,rtx_3080_3090_leak
It has happened before,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"The latest info we got about that process was that is completely broken (under 30% Yield Rate), but maybe they manager to fix it in time for Nvidia.",rtx_3080_3090_leak
"Samsung make bigger hotter chip but more of it, TSMC make smaller cooler chip but has lots of customers. Nvidia managed to get lots of TSMC anyway",rtx_3080_3090_leak
"I doubt it when Samsung's 7nm is actually a thing, they can't just rename 8nm to 7nm.",rtx_3080_3090_leak
"> Moore’s law is dead

lol",rtx_3080_3090_leak
"Not just that, just also the fact that Samsung's 7nm right now isn't optimum. It'd be Nvidia using TSMC's 40nm for Fermi again.",rtx_3080_3090_leak
"I'm saying they could've had masks made for both processes.

Also yes cutting edge GPU uses cutting edge memory. A cutting edge memory that didn't exist anywhere on anything yet. The first bit of confirmation that it even existed was Micron a week or two ago.",rtx_3080_3090_leak
"I'm leaking this exclusively on Reddit, but I have a source that tells me the sun is hot. Updoots to da leff",rtx_3080_3090_leak
"Yup. 

Highest Model -> Highest model has gone up over around 90-100% in two generations if pricing rumors are true.

People defending that too.",rtx_3080_3090_leak
"Right now i am using all of it in Horizon Zero Dawn. It starts with ~ 9GB, then fills up in the next few min. Until then gameplay is smooth, once full i get a lot of VRAM stutter. This is a glipse of the future for low VRAM cards like the 3080 or 3070, so i dont want this to happen in Cyberpunk or any of the upcoming next gen games if i shell out 800-900€ for an upgrade.
One never has to much ram, only to little

Edit: HZD screenshots https://imgur.com/a/cZQGh2b",rtx_3080_3090_leak
Lol “functional drivers” as if the cards were paper weights for a year.,rtx_3080_3090_leak
"Likely not due to the gamer market, though. They are doing more work with data centers and such.

That said, that only kind of underscores your point - they don’t have to cater to us with their pricing and products if they make the bulk of their money elsewhere.",rtx_3080_3090_leak
"Yeah, *now* they are, after a year and a half of trying to get their stock price back to where it was before they fucked up the 20xx launch.",rtx_3080_3090_leak
Maybe it'll be 17.5gb instead of 20 ;) was so prouf of my r9 390 8 gb at the time while 970 owners had 3.5 lol,rtx_3080_3090_leak
have a 3gb 1060 because I was on a budget when I was building in late 2017. Still unsure on whether to go 70 or 80 or wait for the refresh because I haven't followed closely lately besides VRAM numbers coming out,rtx_3080_3090_leak
Our time has come and the wait will be completely worth it my friend.,rtx_3080_3090_leak
"> it got clear in first months

It was very clear when it wasn't even possible to use on stable windows until many months after launch.",rtx_3080_3090_leak
"They are absolutely going to announce something that hasn't been leaked.  


Its so obvious, i'm not sure why anyone hasn't commented on it. Either this card is going to be a massive flop, or they have something major up their sleeves.  
   
They're going from 12nm->7nm , which is more dense and power efficient, yet the cuda core count is basically the same, the boost clock is the same, and the power usage went up. So where the hell did all that power and transistors go?  


They're likely going to leverage DLSS in such a way that its applied to every game and conventional rasterization is less useful. Afterall, why would you need 20GB of RAM if you intend to render everything at 1080p-1440p downsampled from 2160p? And why would you skimp on the last generation of cards before a new major competitor enters the arena (Intel)? They wouldn't. This is their opportunity to cut their competition off at their knees before they have a chance to get their footing.  


I'll bet you that the reason the core count has stayed relatively the same is because they dumped ALL of the extra transistors and power budget into some new super tensor core (or a super count of tensor cores) that are able to chew through DLSS like its nobodies business. In order for that to work well, they needed a balance between AI processing/ray tracing and conventional rasterization support. You can't have too much without the other, otherwise you end up with a horribly imbalanced card that can barely do either right, like the 20xx series.  


And look! They discontinued the 20xx series FAR in advance, meaning the tech on there probably isn't compatible with what they're doing and they don't want people to be super pissed off at them for selling obsolete cards right up to their next gen card.  


Additionally, they probably realized that the 3070 wasn't going to be enough this generation to hit that mark, so they probably shifted its production over to Samsung for 8nm and are targeting a different kind of performance with it (better than 20xx, but still likely in the same realm as current cards). The 3070 and below is probably going to try to compete with the consoles.  


Whatever they're trying to do, its pretty obvious they're trying to leverage their proprietary tech to take over the market. Looking at conventional performance specs isn't going to give you the complete picture. I think this was a go big or go home moment for nvidia. They didn't go big enough for the 20xx series to work with their vision of what it should've been, and I don't think they're making that mistake again.  


Then again, i'm just a random person on the internet.",rtx_3080_3090_leak
Yeah the gap between the 3080 and 3090 is HUGE.,rtx_3080_3090_leak
">3090 is way to exp.

Way too expensive? We don't even know the price...",rtx_3080_3090_leak
"Yes, but the GTX 1080 Ti falls behind at high resolutions and doesn't come with the newest goodies like RTX, DSC, and HDMI 2.1

That being said, a ~$350 GTX 1080 Ti is going to be a **bargain** for anyone still rocking 1080p/1440p monitors once the new generation drops.",rtx_3080_3090_leak
"Let's put it this way; if Big Navi actually performs at a level comparable to the 30xx series, it'll be the first time AMD has been competitive to Nvidia during the beginning of a generation in...what, a decade? 

I don't believe they'll have anything to rival the 3080/S or 3090 for at least a year.",rtx_3080_3090_leak
I think the ti is out and Super will replace the nomenclature but I agree with your restraint for most people.,rtx_3080_3090_leak
"Waiting till halfway just devalues your current card and oftentimes not the card you are waiting for.

2080 ti/1080 ti never dropped in price. But if you waiting even X months past release you just wind up losing a shit ton. I sold my 2080 ti for $1100 and even hypothetically they launch at a ridiculous price of $800 for 3080 and its only a tiny bit better then 2080 ti... That would put my 2080 ti at probably like $700 used. 

Imo.",rtx_3080_3090_leak
I don't care if someone else gets 'moar' fps than me. I just want to comfortably play Cyberpunk (and future games) at 4k ultra with Ray Tracing on that's why i'm going getting the 3090 at launch. It will be glorious. But everyone has to find what works for them and what works for their budget.,rtx_3080_3090_leak
So don't buy the 3080 on Thursday?,rtx_3080_3090_leak
The TI has historically launched a little after so not to surprising.,rtx_3080_3090_leak
It would have to be 20gb based on the BUS and that still leaves a significant gap between it and the 3080.,rtx_3080_3090_leak
">I'm aware of that, but the fact that they are then not launching a 3085 or 3080 Ti or 3080 Super or whatever inbetween the 3080 and 3090 is wat baffles me

The ""3085"" type models, or ""Ti"" cards, or ""SUPER"" cards have always come out later. The 2080 Ti was the first time we saw a ""Ti"" model launch day 1 since the Geforce 4...",rtx_3080_3090_leak
There saving a 12Gb 3080ti for when Big Navi launches.,rtx_3080_3090_leak
Or for artificial intelligence development. The RTX titan is currently the best card for that.,rtx_3080_3090_leak
"I never said it was smart, just that it's what is happening.",rtx_3080_3090_leak
">What you explained towards the end is literally what the Titan cards used to be. 

The original GTX titan was more so marketed as a crazy powerful gaming graphics card that also had some use for GPU compute stuff.",rtx_3080_3090_leak
"If this is on Samsung, the Titan/3080ti/Super refreshes could come on TSMCs node instead.",rtx_3080_3090_leak
"Sounds like the issues will end up being difficulty exporting to the EU rather than importing from it, so you might be ok. You can always just change the money back after the crash and buy in the UK anyway.",rtx_3080_3090_leak
I think he meant it to the lad who bought it.,rtx_3080_3090_leak
prices will likely be announced for some of the cards.,rtx_3080_3090_leak
"HDMI is also used by consoles, home theater equipment, and many other professional video stuff while displayport is almost exclusively used by graphics cards and computer monitors.

I don't think it's comparable.

Also, it took more than two years to get a HDMI 2.1 capable graphics card. What the fuck? I would absolutely hate to have to wait that long for a DP 2.0 capable GPU after displays supporting it come out.",rtx_3080_3090_leak
Don't you just get put on a waiting list though?,rtx_3080_3090_leak
Had forgotten about brexit with this bloody pandemic....ha. Good advice,rtx_3080_3090_leak
"Surely, the 20GB model wouldn't launch for at least 6 months after the initial 10GB model version? It would be a bit of a kick in the guts otherwise? I had my mind set on the 3080 for my first ever pc build (currently a console 'peasant'), but now this 20GB model is making me doubt a few things...",rtx_3080_3090_leak
That's the thing though. They can try to sell their compression but I would have to see it to believe it. Putting blind trust in a presentation slide with little to no independent review is dangerous. I think it's warranted to have some concern at least. Especially if they then come out with higher GB cards a year later. Then what will people say about these low numbers???,rtx_3080_3090_leak
"This totally could be the case. If it is, I still think it will affect so few people that demand would still be high and you could sell the 3080 10gb for a 20gb version for only a minimal loss at that point.",rtx_3080_3090_leak
The fuck is this comment even supposed to mean? You think a 3080 is going to perform worse than a 1080ti in future games? 🤣 You people are clueless ramblers,rtx_3080_3090_leak
"Potemtially very true. But lets wait for the benchmarks before getting worked up about the amount of RAM in the 3080/3070, pretty much all im saying",rtx_3080_3090_leak
"I agree, that's what i was trying to get at. If theyve released a card that cant compress the files then shame on them for being so daft to not increase the RAM. But theres no point in saying its not enough RAM until we know they havent got the tech and that 10GB isn't enough.",rtx_3080_3090_leak
"Haha i find it quite funny being told to let things lie. all i've said is ""lets wait for the benchmarks"". It's not combative. The point of my post was exactly what youve told me to do. Let's not get worked up about things without good reason. Use your own logic and apply it to people getting upset...?",rtx_3080_3090_leak
"Or perhaps there's legitimately only incrimental gains that you can get out of going higher in the VRAM when factoring in explicitly higher costs to the consumer? Do you honestly think Nvidia wouldn't continually increase the VRam in these cards each generation if it drastically improved performance? Would that not be the easiest way of slamming out these cards to make them more money? What you don't understand is that with more VRAM comes more implicit cost. IF you want to pay an extra 600 dollars for a card with double the Vram be my guest, but if the gains aren't even that noticeable, why are you really buying the card? To flop your dick on the table? Wait till the benchmarks....stop thinking Bigger=better.",rtx_3080_3090_leak
"So you play at enthusiast resolutions with enthusiast hardware like VR, but don't want to pay for enthusiast gpus to actually run it? Time for you to step down.",rtx_3080_3090_leak
"If you want to be specific, TDP stands for thermal design power which refers to the heat generated by the component. Usually you see it mentioned with cpus when you choose a cooler for them. Here it's TGP which stands for total graphics power, which is the power draw of the gpu (not sure why everyone calls it TDP here) assuming you run it at stock without overclocks.

TGP and TDP aren't usually the same because I know my cpu draws more power than its TDP suggests when it's under load.",rtx_3080_3090_leak
That’s what the article says.,rtx_3080_3090_leak
"After LG announced their 9 series OLED TVs supporting 4K120HDR VRR Nvidia launched a firmware patch that enabled on RTX cards (and Turing cards) VRR through HDMI 2.0. A 2.1 feature on a 2.0 port.

It's more than certain that HDMI on RTX 3K will be 2.1 fully.",rtx_3080_3090_leak
So we can get an LG CX now?,rtx_3080_3090_leak
I know I was just wondering what the difference between DSC via 1.4a and normal 4k 144hz through dp 2.0 is.,rtx_3080_3090_leak
"Visually loseless, so if few bits are missing is irrelevant. Claiming otherwise is like buying headphones or audio system with more than 20 000hz and claim you can hear diffarance.",rtx_3080_3090_leak
DP 2.0 test tools don't exist yet. it takes a while for this stuff to be adopted. I work for vendor that makes the tools.,rtx_3080_3090_leak
Don't expect that to happen. DP 2.0 tools don't exist yet.,rtx_3080_3090_leak
"I've now heard rumors that Nvidia will implement an efficient compression technique, hence reducing the amount of vram used. This might explain the relatively low amount of vram on the cards, I surely hope so. Wanted to go for the RTX3070 but with only 8GB vram I have my doubts. 
Will either wait for AMD or the 'super' cards if that happens.",rtx_3080_3090_leak
"That's the hope. And it makes sense that they would do that. I could just be a little more patient and wait for the rumored 20GB 3080, or maybe benchmarks come out and I find the 3070 is easily enough for what I wanna do. That's why I haven't made a decision yet. But based on the news I've seen it seems like Nvidia is really trying to strongarm consumers into getting a 3090. I'm trying to invest a good chunk of change into a card that I won't have to worry about for years to come, so as of this very moment I'm leaning towards the 3090, but my wallet yells at me every time I think about it",rtx_3080_3090_leak
What if AIB use dr6 and not ddr6x?,rtx_3080_3090_leak
"Is the extra performance worth the cost though? That's what I'm trying to figure out myself. Of course it will perform better than the 3070, nobody's surprised about that. That's why I said multiple times I'd wait for benchmarks.",rtx_3080_3090_leak
No but it's capable of more than HDMI 2.0b.,rtx_3080_3090_leak
"good one, I have hd 7770, r9 270x, r9 390, gtx 1070 ti and rx 5700 xt the only problem that I had was with the 1070 ti not having the dithering making the color banding so ugly that I had to sell it for a 5700 xt

Get yourself a card that support dithering and you will never go with nvidia again",rtx_3080_3090_leak
Yeah there's always that one AMD user who didn't have any problems and acts like he represents everyone.,rtx_3080_3090_leak
It's not ok.,rtx_3080_3090_leak
"[https://www.tweaktown.com/news/74396/exclusive-aib-custom-ampere-cards-launch-alongside-founders-edition/index.html](https://www.tweaktown.com/news/74396/exclusive-aib-custom-ampere-cards-launch-alongside-founders-edition/index.html)

I know this is just rumour like everything else but there have been a number of AIB's registering cards so could well be true...",rtx_3080_3090_leak
I hope it's true!,rtx_3080_3090_leak
"this is what confuses me about people going insane complaining about the 3090. like brahhhh if you are buying a TOP END gpu on launch, u are not the kind who is tripping about a few hundred dollars",rtx_3080_3090_leak
">VR is not limited by vram at all right now.

I have a 1070 (8GB) and whenever I start up half life alyx it gives me a pop up warning about low vram, so it's very possible for VR to be vram limited. That said I don't think many other VR games have the rediculously high quality textures that alyx does",rtx_3080_3090_leak
"Yeah Control at 4K uses up 8GB of VRAM already and I expect that to go up in the future no doubt, at 8K it uses 18GB.",rtx_3080_3090_leak
I hope!,rtx_3080_3090_leak
I assume stuff like MOH + Lone Echo 2 will be also close to that VRAM limit though.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Yikes! Just got the monitor 2 years ago. Acer Predator x34P. Upgrading this will put me under the comfy wallet line to take the hit from getting the 3090.,rtx_3080_3090_leak
"There was an article about that and they said it will add around $50 at whole sale price.

A $50 BOM would translate to $100 retail? At least I hope so. I can’t stomach a $1K 3080

Edit: Got call out by a prick for not providing a source.

[https://www.hardwaretimes.com/doubling-graphics-memory-will-cost-nvidia-and-amd-less-than-12-gb-its-very-likely/](https://www.hardwaretimes.com/doubling-graphics-memory-will-cost-nvidia-and-amd-less-than-12-gb-its-very-likely/)

>That means NVIDIA will be paying just around $60-80 to double the VRAM on the RTX 3080 Ti from 11GB to 24GB.",rtx_3080_3090_leak
Yep. Im seeing VRAM being used by Nvidia to fill out the $1000-$2000 3080 to 3090 range.,rtx_3080_3090_leak
"Yeah I agree but it would be worth it to me. I game at 2k 144hz, 4K 60hz, VR 4K 90hz. So VRAM is important to me.",rtx_3080_3090_leak
"> I'm using 2080 Ti right now and 11GB is plenty.

I plan to stick to 1080p 144hz for as long as i can. 10GB is more than enough for this spec?

upgrading from a 1050ti so no idea about these high end cards",rtx_3080_3090_leak
The new consoles will for sure make VRAM requirements go up. We go from having to accomodate consoles with 8GB total RAM + VRAM to ones with 16.,rtx_3080_3090_leak
"> LG C9 TV

Oh damn I didn't know TVs were coming out with GSYNC now. :o",rtx_3080_3090_leak
"I wonder how performance for the 3080 will actually compare to the 2080 TI. Looking at spec sheet for my TI, it has the same amount of CUDA cores, 352 bit memory, 11GB of RAM, and a 1755 Boost Clock. The memory clock speed and bandwidth are the only area I see where the 3080 is a slight improvement over the 2080 TI. It’ll be interesting to see benchmarks. I might be missing something, but for now the 3090 looks like the only way to get a decent performance improvement over the 2080 TI, and even then I’ll be interested to see what kind of improvement the 3090 has over the 2080 TI.",rtx_3080_3090_leak
"C9 is a sweet tv, I love it",rtx_3080_3090_leak
"> I'm using 2080 Ti right now and 11GB is plenty.

I'm using a 1080 TI right now and 11GB is so very far from enough.

Even considering how weak raster performance is it's basically effortless to run into VRAM bottlenecks if I try to push anything that's actually demanding. Raytracing can gobble VRAM, non-gaming stuff light lightbaking (which is pathtracing) can gobble VRAM, high resolution stuff, high quality VR stuff... the list goes on.",rtx_3080_3090_leak
That's what I am banking on. Thinking of selling my 2080ti now because I think we will see a huge price drop if the 3080 is faster and cheaper. Retailers still selling 2080ti for over 2k in Australia,rtx_3080_3090_leak
It is enough for 4 k?,rtx_3080_3090_leak
They might be available right off the bat because this launch is not like past launches with the AIBs being ready already. But I could also see the 20GB versions coming later unfortunately.,rtx_3080_3090_leak
I wouldn't be surprised if they released those summer next year if they dont mention them tuesday.,rtx_3080_3090_leak
I edited my original comment. It makes sense to wait only if you are playing or planning on playing games at high resolutions like 4K and VR.,rtx_3080_3090_leak
"I'm waiting for independent benchmarks, I will be getting an aib card either way so I'm not too bothered, I can wait a bit longer.

There's rumours that these fe cards will have decent cooling for once but I'm quite doubtful given past releases.

I'll hold out for a triple fan thicc boi, I don't intend to water cool so I'll be watching/reading benchmarks with great interest.",rtx_3080_3090_leak
"I'm fully expecting a decent aib 3090 to cost £1400-£1500.

Aint no way I'm paying that, I'll hold out for the 20GB 3080.",rtx_3080_3090_leak
"Does this also work if you watercool the card in the meantime or would you need to leave it stock?

I read something here a few days ago that evga honors warranty even when you did use a waterblock (and therefore had to remove the cooler)",rtx_3080_3090_leak
Except Nvidia has confirmed that tsmc will be doing the majority of 7nm orders.,rtx_3080_3090_leak
No. 3440x1440 is relevant to more than 0.01% of the market for these cards.,rtx_3080_3090_leak
Thank you,rtx_3080_3090_leak
Yeah there is plenty of headroom there. You'll be good.,rtx_3080_3090_leak
Quality and efficiency matters when buying a psu. Best way though is to buy a watt usage monitor from a hardware store.,rtx_3080_3090_leak
Plug a watt meter into the wall to get the most accurate numbers. But some digital psus like corsair have software that will work well for this purpose.,rtx_3080_3090_leak
with my eyes😈:puts on praetor suit,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
OFF COURSE THE 780TI HAD 3 GB OF VRAM WHILE THE 290X HAD 4 GB OFF COURSE IT'LL USE LESS LOL,rtx_3080_3090_leak
"Omg, call of duty uses more than 9 GB of vram on the 2080 ti and only 6.5 GB on my 5700 xt omg OMG",rtx_3080_3090_leak
"IT'S LIKE RAM LOL, OFF COURSE THE GAME WILL USE MORE THAN IF YOU HAVE 16GB THAN 8 GB LOL the dude is comparing 2 cards that don't have the same amount of vram lol... how sad do you need to be",rtx_3080_3090_leak
So you're saying there's a misconception and then correcting people by throwing out an anecdote between an AMD card and an NVidia card in which the AMD card has less VRAM (yet they throw a shit ton more in),rtx_3080_3090_leak
"My r9 390 had 8 gb of vram while the gtx 970 had 3.5 gb, LOL 3.5gb... vs 8 gb... and the 8 gb was real unlike the 4gb on the 970 scam and btw it's just that nvidia compress the textures more than amd do",rtx_3080_3090_leak
True 😂,rtx_3080_3090_leak
"No I agree with what your saying and respect you for it. I'm just impatient and have been waiting for an upgrade, I'm big into vr and also want to dabble with Ray tracing and dlss 2.0. Also have always had an nvidia card. I truly REALLY do hope that amd can put nvidia in their place this time around. Everyone would benefit. Good luck brother.",rtx_3080_3090_leak
"As in valve index? Already own one, and it's part of the reason why I want as much horsepower as possible. Love vr man, I've been an enthusiest since the early DK days of oculus.

*edit* lmao! So that shows how much of a nerd I am, you were rendering to a diff form of saving and investing lol. Sorry man haha but yes I have a retirement fund and pention I'm working towards.",rtx_3080_3090_leak
"And the second best card won't be adequate for 4k performance, regardless of whether it has 10gb of vram of 100gb.",rtx_3080_3090_leak
"You see, these whales would have to be responsible with money for that to be the case...",rtx_3080_3090_leak
Yes all 2019 and 2020 LG OLED models support Gsync Compatible I believe.,rtx_3080_3090_leak
Yes,rtx_3080_3090_leak
2.0b and no your gtx does not do Gsync over hdmi. That is enabled only in RTX and gtx 1600 series cards. And who down votes the truth? Ignorance rules! Redditor X,rtx_3080_3090_leak
what is the difference between Ryzen 9 3900 and Ryzen 7 3700?,rtx_3080_3090_leak
"If the 3080 is £800 or less im just gonna get it.

1GB vram isn't a big downgrade in anyway compared to a 2080TI and its raw performance and hopefully significant RT gains should help sweeten the deal.

For all we know nvidia might have a trick up its sleeve to help with the lower VRAM this generation.",rtx_3080_3090_leak
"Yeah it's insane. 

2080 Ti has 1GB less VRAM than Titan Xp and it destroyed the shit out of it.",rtx_3080_3090_leak
"The longevity of the card is impacted by the specs.  The 3070 will be priced above consoles that will have similar performance on day 1, and perhaps better performance years from now.  A person choosing between either one (me), needs to consider that.",rtx_3080_3090_leak
"I mean the 3070 is rumored to perform like 2080 Ti.

My 2080 Ti is an excellent 1440p high refresh rate card. At 4K, this level of performance needs to start lowering the max settings. 

I think the 8GB VRAM might be impacted in the future if you're planning to run 4K but that remains to be seen.",rtx_3080_3090_leak
"That makes absolutely no sense. People on 2070 Super with 8GB VRAM will fare better than people on Vega Frontier Edition with 16GB VRAM.

VRAM doesn't drive performance.",rtx_3080_3090_leak
Well the speed is greatly improved with G6X now on 3080 and 3090,rtx_3080_3090_leak
Then sell it local for cash.,rtx_3080_3090_leak
"Then ignore the Money aspect of my statement, the rest remains.",rtx_3080_3090_leak
"Well, as someone who has followed AMD over the years you’d know why this time could be different. We have a new arch, RDNA, it’s not GCN which everyone knew was on its last stretch, and AMD hasn’t even tried to launch an actually high end card in many years. With the improvements they’ve made, with it actually being on consoles and with the info we already had. I do understand the skepticism though, AMD for many years has left the high end to Nvidia.",rtx_3080_3090_leak
"Well normally I do, but admittedly when it comes to nvidia I've kinda stuck with them unconditionally after one of amd's driver debacle  5 or 6 years ago, but it appears nvidia needs the competition as to not squeeze the life out of their loyal customers unfortunately, that's how business goes I guess..  

Point is they're probably not idiots and must've noticed lots of people were not exactly happy about the rtx price to performance ratio, and it seems nvidia themselves have leaked that they seem worried about amd this year, now take the whole tsmc and samsung thing into account, it seems suspicious to me that instead of dropping the pricing somewhat to make up for last round, they've increased prices even further, knowing they'll launch sooner than amd that just sounds like they want to cash in as soon as possible, before dropping prices again in case amd comes out with something competitive (if they do)  

Something smells fishy about the pricing",rtx_3080_3090_leak
At 750w he will have more than enough headroom.,rtx_3080_3090_leak
Got a link?,rtx_3080_3090_leak
Downvoted just to pile on even through I agree with you,rtx_3080_3090_leak
"No im saying that the 16gb of ram on the XSX is taking the place of both VRam and the DDR4 ram in which game game data is loaded to when gaming on a PC. 12gb cannot be dedicated to graphics, as it needs to maintain room for all other game data. Most modern games use at a minimum 6gb system memory, which would leaves 6gb left for dedicated VRAM. Of course, Microsoft is likely doing clever stuff with memory compression and offloading assets to the SSD to make this limited memory pool go faster. There is also often duplicated data stored on both RAM and VRAM, which will be avoided due to the use of one dedicated memory pool.",rtx_3080_3090_leak
Why?,rtx_3080_3090_leak
"Rtx3080 was being asked and 320W was the rumor. That is already a lot of power. The Vega cards were known for huge power draw and were closer to 250-300W and 180-225W with an undervolt. 320W is MASSIVE for a gpu. 
And like I said, even 400W peak should be easily doable since 650W PSUs from a good brand/model can handle peak powers above the specified 650W before failing.",rtx_3080_3090_leak
"Well, you do have about 125-150W, and maybe you don't want to upgrade to something better before you change your PSU.",rtx_3080_3090_leak
It’s all good! Thanks for the tip!,rtx_3080_3090_leak
So you see soaring demand (and salaries) in the private sector for a field that you think is useless & your deduction is that F500s enjoy losing money? That is top notch indeed.,rtx_3080_3090_leak
Just realised I’m taking about my AMD build on /r/NVIDIA 👀,rtx_3080_3090_leak
I see. Thank you,rtx_3080_3090_leak
[removed],rtx_3080_3090_leak
"I rephrased it in another comment. It's not as future proof as it would be compared to the software level. I do now think we need more VRAM, but it's something that both devs and card companies need to work on together.",rtx_3080_3090_leak
"True. Was hoping AMD would come out with something competitive. I wouldn’t mind switching over as long as they fix their drivers. Would also need a monitor that supports free sync, unless there’s a way to enable g sync on AMD cards.",rtx_3080_3090_leak
you're very patient.. :D,rtx_3080_3090_leak
"Then by the same logic getting the 4000 I can bypass the  5000 to get the 6000

One doesn't have to wait for the next big thing, or change every generation.  But if that is what you want, no problem as it's your money.  And mine is mine",rtx_3080_3090_leak
"If it's 40% better, then I'm the queen mother",rtx_3080_3090_leak
"Well of course, this is based on how badly you need to upgrade for your purposes.",rtx_3080_3090_leak
"Yeah, but I don't think 3070's price would be around 500$, more likely to be around 600$. And the same memory bandwidth as 2070, like come on Nvidia. I better wait for RDNA 2 and 3070 super as possible upgrades.",rtx_3080_3090_leak
I have no idea how that card performs. There will be games coming out in the near future that will eat up vram like crazy. I hope 8GB is enough.,rtx_3080_3090_leak
"No, the AIBs can customize the RAM themselves now. We could see a lot of cool 30xx customs.",rtx_3080_3090_leak
"Yea, it is for sure but we where talking about buying an old card at the same price of a newer, faster and with notable more feature one",rtx_3080_3090_leak
"Yeah, buying an overprice-gouged 2k series card right now is just plain stupidity! Especially when the new generation of cards will be coming out in just a few weeks!",rtx_3080_3090_leak
The 2070 super is not on par with the 1080ti in non raytracing games....,rtx_3080_3090_leak
"its a tiny bit behind, a year or 2 back i would have still recommended the 1080ti as it was just turing vs pascal but now most are going out of warranty, the 5700xt is new, comes with free games half the time aswell. up to you to decide how much 3 years of warranty is worth. but i value that more than 6% performance",rtx_3080_3090_leak
"Haha jup, setting a bottom price for bidding is a good way to go about!",rtx_3080_3090_leak
Maybe shortage because Nvidia stopped producing them for the introduction of the 3000 series? :P,rtx_3080_3090_leak
"Honestly I think the biggest hurdle CDPR has with Cyberpunk is fan expectations. They’re stupidly high. I’ve seen people thinking this is basically going to be a real life simulation in a cyberpunk world. 

For me personally, I expect this game to be virtually bug free, since that’s what they basically said they were working on both delays. 

But I agree, overall they’re in a really weird spot with their release date. They honestly should have just made this second delay until next gen release and released for both gens, but I get why they’re not",rtx_3080_3090_leak
Ahh the o’l Starcitizen play,rtx_3080_3090_leak
They have their own game store. GoG.....,rtx_3080_3090_leak
"I'm literally in the same boat as you. I wanted to upgrade in time for Cyberpunk to 4k compatible gaming, potentially at 144hz (~120hz), and was looking for the 3080 to hit those needs, but it's looking like the memory will gimp the card long term when next gen games start come out...",rtx_3080_3090_leak
Ugh that's so frustrating I can never keep up with the market... I just ditched my GTX 980 for the RTX 2080 Super like a month ago,rtx_3080_3090_leak
Laughs in Australia tax,rtx_3080_3090_leak
Pay someone to order it and drop ship it?,rtx_3080_3090_leak
Oh for some reason I thought it was more like 35% more cores never mind that makes sense then. The memory bandwidth will help a little more too. Time will tell. Thanks for the info!,rtx_3080_3090_leak
DLSS 2.0 might help ya,rtx_3080_3090_leak
Do you have scaling issues with abnormal resolutions like that?,rtx_3080_3090_leak
"Very possibly, but also with big Navi, it would be quite surprising to me that Nvidia would want to Bork their release cards. Nvidia WANT to be seen as the premium brand and really go out of their way to do so (which is why they release so many ""extras"" like rtx, dlss, freestyle filtering etc) and so if the difference between an $800 high end card being amazing or being revered throughout the community as a shitty card that can't play at high textures (as the guy I replied to originally said) is an extra gigabyte or two of Vram, I  just don't think they'd take that shortcut.

I totally agree that them putting 10GB on a 3080 Vs 20 on the 3090 is very strange in my opinion, I guess GDDR6X is just incredibly expensive or their memory bus just doesn't easily allow for a few more gigabytes without running into issues. I OBVIOUSLY don't know the reasons, but feel like 12GB on the 3080 and 18gb on the 3090 would have made so much more sense for the consumer but oh well. I'm sure there is a reason, probably financial.",rtx_3080_3090_leak
"Exactly, while VRAM requirements are going up, the idea that game devs are going to target 11GB+ of VRAM for upcoming games is just not true. What cards do people think game devs make their games on

It just as much comes down to people *expecting* new cards to be able to max out everything. I would much prefer a world where devs create an ultra setting that by definition is a bit much for the current cards, so that in the coming years, the game actually holds up when you play it on newer hardware, and when you play it for nostalgia it looks *better* than it did when you first played it. But It's unfortunately part of essence of ""pcmasterrace"" that either if a new GPU can't play everything on ultra, the card is a failure or the game is unoptimized. Bragging rights getting in the way of actually useful features basically.   


While flight simulator has its issues, it has received to much bad press around ultra being impossible to run at 60, but so much less has been given to the fact that high settings universally work on high end cards, and at low it still looks really great on a budget card. It's ideal in my opinion, but the community has basically turned it into ""this game is too hard to run!""",rtx_3080_3090_leak
"Console exclusive ports?

HZD was designed with console specific hardware in mind and the port blows.",rtx_3080_3090_leak
"You're blowing this out of proportion. They made a mistake not naming the 2080 Ti a 2090 for this exact reason.

Yes, technically speaking, they jumped from $699 to $1299 from the 1080 Ti to 2080 Ti. But that's completely ignoring the actual specs or performance of the cards.

Besides, most of the people that are complaining about the price probably aren't the target audience in the first place. Consider the actual performance of the 2080 Ti and proposed performance of the 3080 and 3090. 

Are most people really going to actually utilize those cards? Are most people not going to be completely fine with something equivalent to a 3060?

We also shouldn't be blaming Nvidia for having slightly high prices for top end cards when AMD still hasn't released a card that's stronger than a 2070 Super.

Also, we have to think about where we came from in the past 5 years. Back then around when the 1000 series released, 1080p 144hz was king and 1440p gaming was still new.

Now we are suddenly seeing a surge in 1440p 144 hz, ultra wide, and 4K?

How is it fair to bash Nvidia for their pricing when they are actually releasing those top tier cards (2080 Ti, 3080, 3090) to people can enjoy those resolutions. How is it fair when they are releasing sub $500 cards that can play 1080p perfectly fine and 1440p very well?

How is it fair when DOOM is the only game with a development team that has figured out how to make their games run fast and no one else has implemented it yet?

I know I'm gonna get bashed for this, but these cards are actually very reasonable considering their raw performance, especially when they're releasing technologies like DLSS and RTX.

Nvidia is thinking about the future whether most of you believe it or not. I can bet you in 5 years that even your 2070 Super or 3060 can play new titles in the future at 1440p just fine.

We see this in tech all the time. Software will advance, but hardware hasn't caught up, or vice versa. This is the time when hardware is ahead, but people aren't ready for it.",rtx_3080_3090_leak
"Sure, 7.2 GB, but not 7.9 or 8.0 GB right?",rtx_3080_3090_leak
"Same, but we are minority. Not on here Cuz humble brag, but 80% still use 1080p.",rtx_3080_3090_leak
I get a steady 70-75 FPS 1440p on Modern Warfare medium/high settings maybe your vram is overused?,rtx_3080_3090_leak
"I'm playing 1440p but me and you are minority is my point, my guy.",rtx_3080_3090_leak
"No, you are a unicorn!",rtx_3080_3090_leak
What's the issue?,rtx_3080_3090_leak
"If the 3070 ends up costing $700 (which is speculation obviously), it would be ridiculous to call that a ""low-mid tier card"" don't you think? I think it's entirely reasonable in late 2020 to expect a $700 graphics card to run nearly anything at max textures at 1440p for the next couple of years.",rtx_3080_3090_leak
Imagine implying $600+ card is low-mid tier. Lol.,rtx_3080_3090_leak
People are not complaining about low-mid tier cards. People are complaining about 70 series cards having only 8gb of memory and 80 series having 10. We've had those numbers for years now and often at a much lower price. It's just not a lot and for no reason other than to incentivise people to spend more on higher tier cards instead.,rtx_3080_3090_leak
"You shouldn't have to pay double when the only limiter is VRAM. Don't need a faster card, just need more VRAM and at this point the standard should be higher than what was on 10 series cards.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Because most people here are children and want the best of the best by paying $400.,rtx_3080_3090_leak
"Here's the thing: Games will use resources you give them unless they're bottlenecked in some way.

MW 2019 (I don't play BR games, so can't compare directly, only with multiplayer) at 1440p ultrawide uses less than 6 GB of VRAM on high settings and still pushes over 60 FPS.  
How do I know? My 980 Ti has 6 GB of VRAM.",rtx_3080_3090_leak
The game doesn’t take up 9GB of GPU ram on ultra let alone the high preset.,rtx_3080_3090_leak
Vega 64 doesnt even have 9gb of vram...,rtx_3080_3090_leak
I don't see myself upgrading to 4K until the price of the monitors and of the GPUs aren't so prohibitively expensive. 1440p/144hz and a GPU to power it are like 1/4th the cost and definitely more than 1/4th the quality.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"I mean let's be honest, the most casual people I know wouldn't even know what you're saying. I know people that play non stop but wouldn't be able to tell you what hz their monitor is. For a lot of folks I just think it seems more complicated to them than it actually  is so they ignore it or call us.",rtx_3080_3090_leak
I believe he meant casual in terms of mostly singleplayer gamers and not competitive multiplayer people. For singleplayer games I'd take higher resolution and better graphics over a high refresh rate in 90% of the games as well.,rtx_3080_3090_leak
"I’m incredibly casual, but I’d love a higher end monitor and I really care about the graphics; that said, I can’t really get anything better than 1080p as my GTX 1660s Ry 5 3600 allow it.",rtx_3080_3090_leak
"by casual I am not talking about how much people play or how much money they spend,I'm talking about how they play or what they care about .  

The point is, most people care a hell of a lot more about how the game looks (resolution) than frame rate, or at least they do if they aren't tricked into thinking they need obsurd frame/refresh rate",rtx_3080_3090_leak
"you do realise casual gamers usually play on a casual TV... and most customers of TV’s are looking to avoid 1080p.

people who buy resolution screens are mostly normal people, mac pro users, whatever. I think a lot of people here have warped their sense of what casual is.

&#x200B;

casual gaming people dont care about Hertz, latency, stuff like that. but everyone knows of 4K resolution as a household name. literally the main thing people are going crazy about for the next gen consoles are the graphics, I dont know a single person who ever bothered mentioning framerates regarding consoles. . iPhones even have QHD< resolution. 

&#x200B;

A lot of people here have their heads in the sand",rtx_3080_3090_leak
"Higher resolution looks better. That's obvious. 
I'm saying higher refresh rates are really only useful for competitive gaming (esp as high as 180hz), and the higher your resolution, the lower your frame rate.  Also it's often a trade-off when chosing a monitor (either selection/features or price)",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
...because 120 fps in the Witcher 3 simply isn't enough...,rtx_3080_3090_leak
Just so you know the refresh rate doesnt impact VRAM usage... you have to lower the display resolution because you are playing games on what is essentially two monitors at a high resolution.,rtx_3080_3090_leak
"Yes, they'll be similar to a PC with those specs.

And also the digital-only PS5 will probably be the cheapest option (not counting the rumored Series S ), and likely be in the $349-449 range.",rtx_3080_3090_leak
"> With hardware like that, the consoles would have to cost 6-700$..

No, Nvidia has just been charging huge margins on their current cards.

Console hardware is sold at near-0 margin, or even loss. Because they're selling a platform, not hardware, and then make their money of software and subscriptions.

Bear in mind a 2080 Ti would've beeen something like $400-450 if sold at 0-margin. Probably less now.

> Ima gonna have to ask for a some real hard sources on such incredibly laughable claims like this.

Not sure what sources you have in mind? We've been told what the specs are.

The PS5 is:

* 8c/16t Zen2 CPU at 3.5 GHz

* 10.3 TFlop RDNA2 GPU (and AMD have officially stated RDNA2 is higher IPC than RDNA1)

So that puts the PS5's *raw performance* as ~15% slower than a R7 3700X, and ~10% slower than a 2080 Super.

But then obviously consoles get single-hardware optimisation, and the above performance gap is hilariously easy to make up through optimisation.

There's evidence the current console generation gets a 40-50% performance uplift on their raw specs via optimisation.

Examples are Doom Eternal running at 1080p60 (rarely drops to 900p60) on a PS4, and RDR2 running at 1080p30 on a PS4.

The PS4's raw specs are an HD 7850 + a very pathetic CPU. But an HD 7850 can only get [~43 FPS at all-low settings in Doom Eternal](https://youtu.be/pm9awf5ceJ0?t=318). And that ignores any CPU-bottleneck.

And bear in mind consoles usually run games at ""medium"" PC equivalent.",rtx_3080_3090_leak
All in 🅱️one,rtx_3080_3090_leak
The Aftermarket in #ALLIN,rtx_3080_3090_leak
Rush B?,rtx_3080_3090_leak
No sometimes they have better power delivery. The main thing you have to watch out for are ones with bad coolers or not enough cooling. Every time there is a new series there is an AIB that biffs the cooler on some or all their cards. SO far all the AIBs that have leaked look like they have large cooelrs on them so that's good but will have to look out for what you want the weeks after the announcement. Or just wait for reviews. In general though the AIBs have good cooling but Nvidia seems to have upped their game on that front so it's anyone's guess.,rtx_3080_3090_leak
"Yes, since it is only on 3080 and 3090 seemingly.  Not to mention, the source that originally leaked the 20GB variant had also said it would be coming out in October.",rtx_3080_3090_leak
AIB is not going to launch with FE anyway. At the earliest i can see AIB stuff launching around when 3070 is launching. So I can see the 20GB AIB model coming out between 3070 and 3060 launch for the 2nd or 3rd wave of demand.,rtx_3080_3090_leak
Maybe?,rtx_3080_3090_leak
Or just brand it the 3080 Ti. I don't know but we should assume something between the 3080 and 3090 will come out eventually.,rtx_3080_3090_leak
"True, but I am currently sitting on a gtx 970 with 4gbs of vram.  If I don't upgrade my PC for another 7 years (after this time) I am kind of hesitant to only upgrade to 8 or 10 gbs of vram ..",rtx_3080_3090_leak
"I'll be waiting for the 2021 card probably bc  I got a 2080 super amd thats what I got for. 1440p 120Hz, and other than Anno, I get about 100 fps; Doom Eternal, League (thats like 250 fps lol),  far cry, few others.",rtx_3080_3090_leak
Wow @ 24GB.  I've got 32GB but I haven't seen that high of usage yet but I've not flown anything big (I'm a FS noob).  I guess it shouldn't be surprising considering I hit 17GB in the Cessna 152 for a training flight.,rtx_3080_3090_leak
I guess it just tries to use as much ram as it can get away with.,rtx_3080_3090_leak
"Oh yeah. I was rocking a 3770k up until I got an 8700k last year. New chip was definitely faster, but I had no complaints about the 3770k. Towards the last few months I had it chilling at 4.5 GHz... still couldn't touch my friend's stock 4790k Cinebench score.",rtx_3080_3090_leak
"Modded Minecraft really loves its memory my dude. That 19 includes Windows, but to have just Windows and a modpack taking up 19 gigs is pretty crazy.",rtx_3080_3090_leak
"Literally every single one of those benchmarks you linked are more or less neck and neck, even some within 5 frames average with equal lows. To me, having 239 instead of 247 average FPS in F1 2019 on a 144Hz monitor is well worth a tradeoff for 2 extra cores. 

Having used both CPUs, I am telling you *they are literally and functionally equivalent,* and that is demonstrated in those charts you linked. Please, if you make an extraordinary claim like a 40% downgrade, please at least show a *singular* incident of that big of a gap existing. 

Regardless, I game at 1440p where the CPU is even less of a limiting factor.",rtx_3080_3090_leak
40% you are dreaming. I think he’s thinking of future games,rtx_3080_3090_leak
Exactly should have went 9900k don't bother wasting your word tho.,rtx_3080_3090_leak
"Where are you seeing a ""40% downgrade in frames when gaming""??? In the benchmark results you linked the 3700X is 10% slower than the 8700K in Total War, 4% slower in Hitman 2, and 4% slower in F1 2019.",rtx_3080_3090_leak
"The 8800GT was a midrange card that smoked ATI’s top end card and even gave Nvidia’s own top end card for that gen a run for its money, as well as the higher end cards of the following gen. As late as like 2015, it was still being listed as the minimum requirement for games (and it was released in 2007).",rtx_3080_3090_leak
Ah got it. Thanks!,rtx_3080_3090_leak
"you should be able to sell for 1080 for around $300 (just going by ebay recently sold)  and the new 3080 will probably cost around $800, so $800 - $300 (from sale) gets you to $500 for a 3080",rtx_3080_3090_leak
"I don't quite understand what your saying. you asked if 2080 would be a good upgrade second hand and I'm telling you that it might be if you could get it for cheap since the jump isin't large, similar to 1080 ->1080ti",rtx_3080_3090_leak
"Yeah, I've stuck with a 980 for this long, since I just target 1080/60. A 1080ti blows that out of the water. If I had a 1080ti I'd just be waiting it out for the 4000 series.",rtx_3080_3090_leak
Are you saying the actual switch in resolutions improves the frame rate at 2k compared to what it would have been?,rtx_3080_3090_leak
"I don't have a 4K screen sadly, but 4k ultra at more than 55FPS is impressive for a card that is almost 4 years old, imo",rtx_3080_3090_leak
*Big Navi has entered the chat*,rtx_3080_3090_leak
"Boss, get down!

*The enemy scalper*",rtx_3080_3090_leak
I dunno but my 980 has been running solid ever since that was new. At this point just get a 2070 or 2080 once the new gen is out and people are swapping them again. That is if you don’t feel like upgrading your pc with a small used car.,rtx_3080_3090_leak
How? Jusdont buy it lmao.,rtx_3080_3090_leak
"2k, I passed on. But I'm using 1440p monitors at 144Hz. At this level I need to start tweaking more than I'd like just to get at least 80-100fps.",rtx_3080_3090_leak
"No thanx, I actually want to play games.

In my few experiences with ati/amd gfx its always a horror. 

144hz monitor set to 144 via windows, all works good. If at any point I open catalyst or whatever its called now it flickers my monitor, throws 10+ alerts about incorrect configurations and forces down to 60. I finish what i have to do, close that garbage, and go back to setting to 144.  rolling back drivers to 6 months earlier other wise Final Fantasy 14 wont boot, etc.",rtx_3080_3090_leak
I'm waiting to see what AMD offers there. And hope the performance compares to the 3070 at a good price.,rtx_3080_3090_leak
From my uncle who works for Netscape.,rtx_3080_3090_leak
It won't be. Why would it ever be? 2070 isn't faster than a 1080 Ti. 2070 Super matches or loses to the 1080 Ti depending on game.,rtx_3080_3090_leak
"Considering how they tuned the GPU memory to force consumers to certain SKUs, I don't expect a 70 series to outperform the former TI that was priced as a Titan.

That said, it might be faster than the 80 super? But they will very very likely make it so there is One downgrade in the 3070 vs the 2080 (S).

So that way you'll really want the 3080 instead. If they could blget you to buy for €800 once, they want you to stick in that category and not buy a €600 offering instead.",rtx_3080_3090_leak
"The 1070 beating the 980 ti was a one time miracle. The 3070 won't beat the high end from this past generation, but probably will come close for half the price.",rtx_3080_3090_leak
I bet it's lower for anything other than RTX titles.,rtx_3080_3090_leak
"I won't say never, but I'm pretty pissed about the 8gb thing. I know it's probably enough for a while but it definitely won't be enough in a year or so once next gen games start to come out.",rtx_3080_3090_leak
"Pleading with amd to be a competitor so the 'super' prices don't happen, last hope aha",rtx_3080_3090_leak
"If you recall the super cost the same as the original.

JUST STOP.",rtx_3080_3090_leak
And the 2070S has the same TDP as the 3070 (220W).,rtx_3080_3090_leak
"ye I mean...
3090 1500-2000€

3070 GDDR6 muah no

----> buy 3080 now for only 900€",rtx_3080_3090_leak
"your 1060 has a 120W TDP, there are performance per watt charts like here...  

https://www.tomshardware.com/features/graphics-card-power-consumption-tested

1660 Ti was the king until now... your 1060 is 76,9% as efficient as a 1660 Ti",rtx_3080_3090_leak
"Not at all, depending on his resolution he can probably max everything on every game. The 2070S is not going to be left behind in terms of performance, studios wont build a game that can only be played maxed out with these new cards, hes probably safe until next year with that card.",rtx_3080_3090_leak
"Lol, right..",rtx_3080_3090_leak
"Objectively it might not have been the smartest buy but I really wanted a new card for some games I wanted to play over the summer (Metro Exodus and RDR2 which I am now finally able to play in 4k) and considering the leaked prices I don't feel like I would have gotten a crazy increase in performance for the increase in price with the 3070. Of course, that's still speculation.",rtx_3080_3090_leak
No one feels shafted though. You get a year of a new card and when you need to upgrade you need to upgrade no one should ever feel bad about it. Most that upgrade it will be a big upgrade regardless.,rtx_3080_3090_leak
"Not really. Because if they somehow release a new 3090,i can sell mine and the difference probably won't be more than $200. In the meantime I'll have been using my new gpu for a year while the coupon cutters have been foaming at the mouth, circlejerking about prices on reddit for a year 😂😂😂",rtx_3080_3090_leak
"I will be doing this, its the smart thing to do tbh. The way Nvidia had operated lately should tell you its the right thing to do.",rtx_3080_3090_leak
"I agree... if AMD lives up to the hype, and brings competitive cards. Nvidia will be forced to drop prices. Even the prices of this upcoming launch.",rtx_3080_3090_leak
Which is great for people like me with a 2080ti so I can not lose my hat during this upgrade time.,rtx_3080_3090_leak
"My 970 was a freebie to me anyways, so I've been working on borrowed time as it is to get this far haha.  I've just been holding out as long as I could given the $$$ commitment on the GPUs now.",rtx_3080_3090_leak
That sounds almost worth it,rtx_3080_3090_leak
200% increase would be 3x the performance btw,rtx_3080_3090_leak
Maybe we band together to get volume discounts XD haha,rtx_3080_3090_leak
"I think it's for us prosumers that need the VRAM for ML tasks. You can't use nvcache because you aren't loading the data rapidly, you're iterating over the already loaded parameters. For instance GPT-2 355 is 355M parameters and ~355MB. You can't really compress it because it's already pseudo-compressed in how the array works.",rtx_3080_3090_leak
"If the 3090 is a titan replacement then it certainly won't be $1400, it'll be more.",rtx_3080_3090_leak
I know but 20 GB version of 3080 on the horizon. is it also for rendering? there will also be ti and super models with higher vrams.,rtx_3080_3090_leak
"You don't need 144hz for the games that are pushing that limit. It doesn't matter if you are getting insane high FPS if you are playing Tomb Raider, or Flight Simulator 2020, or any of those other ""immersive"" games that are crushing GPU's, and any of the games you would benefit from the higher refresh rate don't need to be run on a 2080ti to hit them. If 1080p if your target resolution, buying a 2080ti/3080/3090 is just telling Nvidia that you will pay whatever price they set just to have the best, which is part of the reason why it costs so much now.",rtx_3080_3090_leak
"There will be no *decent* drop in price for the 20 series cards for the life of the 30 series cards right up until whatever replaces the 30series are announced. 

20 series card manufacturing has already ceased and new old stock will be discounted a very little bit so as not to cannibalize 30 series sales. 

NVidia will see to that. Once the “40 Series” or whatever it will be called is announced you’ll start to see 20 series go on significant sale but by then the damage would have been done to that market. 

Now that doesn’t take into account the resale market value of the 20 series which will be determined by the sale price of the 30 series for the immediate future.

Every once in a while you might see a significantly good deal on a 20 series card for things like Black Friday or cyber Monday sales but they will be few and far between.",rtx_3080_3090_leak
">There are games out there that don't reach 144fps on maxed out settings on even a 2080ti.

Oh noez, I can't play red dead redemption 2 at 144 fps, how intolerable. 143 fps and below is unacceptable. /s

&#x200B;

144 is an odd number to cap your frame rate at anyway. Do you have some secret special 147hz monitor or something?",rtx_3080_3090_leak
My 1080ti does 1440 144 for me lol,rtx_3080_3090_leak
Yep,rtx_3080_3090_leak
Obsolescence isn't going to apply in 4 years. Obsolete is when it can no longer perform its function adequately. The 1080ti is still rocking people's socks.,rtx_3080_3090_leak
The 3080 should be enough to power 4k games at around 60fps... the 10GB VRAM is a potential limitation in allowing that to happen.,rtx_3080_3090_leak
If the leaks are right the 3070 is 10% faster than the 2080 ti and the 3080 is 33% faster. A 3070 or 3080 card is premium. It makes no sense to have a card with that high performance (and probably price as well) and not give it enough Vram to even play all of today's games at 4k. It pretty much guarantees that plenty of people will be losing performance from having to keep settings low in the future.,rtx_3080_3090_leak
i mean its probably fine for MOST games NOW. Maybe not for later,rtx_3080_3090_leak
I am seeing 10gb+ at 1080p ultra on my 1080ti.,rtx_3080_3090_leak
I play HZD in 4K and I've seen VRAM usage of over 10 GB.,rtx_3080_3090_leak
"OK but they matter for me. Modders are customers too and PC Gaming's modding is one of the best things in the art form.

Plus, Wolfenstein 2 with its max settings does use more than 8GB at 1440p. Not ""allocate"". I mean actually use.",rtx_3080_3090_leak
"Modifications and overall freedom to work eith game files is THE reason to use pc over console.
One of many, but one of the more important ones.

And they ""dont count""? Whoa.",rtx_3080_3090_leak
"Yes, it's got problems.  But it is a game that hits >8GB VRAM.

The point is that because the 1080 ti and 2080 ti are currently the only cards with >8GB VRAM it basically doesn't matter.  But the 1080 ti is over 3 years old, we're about to have >8GB on a card below an x80 ti, and AMD will probably give us >8GB on cheaper cards because unlike nvidia they tend to push VRAM.

And you know what happens when you hit the max VRAM a card has?  It stutters.  It doesn't just lower fps, it *stutters.*  Even the 970 struggled with some stuttering when going into its slower final .5GB that similar 4GB cards had no problems with.",rtx_3080_3090_leak
That would mean the 24GB on the 3090 are 2GB chips. That makes sense though.,rtx_3080_3090_leak
"yup has to do with the number of ram chips on the board.   Each memory controller is 32-bit for each memory chip on GDDR6/GDDR6X.          

4 ram chips x 32-bit = 4x32 = 128-bit

6 ram chips x 32-bit = 6x32 = 192-bit

8 ram chips x 32-bit = 8x32 = 256-bit

10 ram chips x 32-bit = 10x32 = 320-bit

12 ram chips x 32-bit = 12x32 = 384-bit

14 ram chips x 32-bit = 14x32 = 448-bit    

16 ram chips x 32-bit = 16x32 = 512-bit  


I don't see 14 or 16 ram chips happening though..   Nvidia hasn't done that since the GTX 260/275/280 models which had ram on front & back of the card.      I think the ram now gets pretty hot and would be cooling an issue with Ram on the back of the cards too.

That's one reason why 16GB cards isn't likely to happen for high end models as they'd be limited to 256-bit memory bus.",rtx_3080_3090_leak
"May end up dropping down to 1080p going forward, I guess. With Doom Eternal, I can get 1440p165 pretty consistently without dropping below 120 fps in most areas with a combo of Med/Low, so was hopeful for next gen getting me where I want to be, but Eternal is also really well opimized. Already got the money saved up for a 3080, plus a 2060S would prob sell for a decent price even after 3000 series, Either way, still really interested to see how the performance metrics turn out.",rtx_3080_3090_leak
"I never said it was imposible, only more troublesome.",rtx_3080_3090_leak
"Broken? In 2018-2019, yes. 

But Samsung 7nm has been decent for the last year.",rtx_3080_3090_leak
There’s no way it’s TSMC 7nm.,rtx_3080_3090_leak
"> I'm saying they could've had masks made for both processes.

Not without redesigning their process around 8nm. It's not a drop in replacement like 8nm is to 10nm or 14nm is to 16nm.

>A cutting edge memory that didn't exist anywhere on anything yet.

If the memory speed was leaked beforehand, it would have been obvious it was GDDR6X/GDDR7.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"It’s just smart business for Nvidia. The market has made it very clear the top end enthusiasts will pay huge amounts of money to have the best of the best. The halo effect is 100% real, and increases the perceived value of the rest of the GeForce 3000 series products, particularly the midrange products that make up the bread and butter of consumer GPU profits.

With AMD still yet to deliver anything performance competitive at the top end there’s nothing to justify charging less just for the sake of it. Charging what the market is willing to bear is retail pricing 101.",rtx_3080_3090_leak
"Come back, AMD! I can't wait to buy you again!",rtx_3080_3090_leak
"Im not arguing your point at all, but HZD is already piss poorly optimized",rtx_3080_3090_leak
That game seems to be an outlier. I would person wait to see how cyberpunk performs before committing 800-1000+ to upgrade a single computer part that may not even be necessary to play it optimally.,rtx_3080_3090_leak
"You are completely right in that DLSS3.0 will be their MAJOR selling point. They have massively improved the tensor cores way beyond what rasterization can deliver.

I think they will be aggressively pushing all benchmark numbers with DLSS3.0 and that way no one will be able to come close.",rtx_3080_3090_leak
"The feature I'll probably be most envious of is DLSS - after watching some Digital Foundry videos it looks like a real game changer for titles that support it. I'll continue using my 1080ti since it does fine and I'm a 1440p gamer, but DLSS just looks so promising.",rtx_3080_3090_leak
"I'm also very sceptical too, but if is it within 10-15% and a reasonable amount cheaper, it may be enough to tempt me.",rtx_3080_3090_leak
Exactly this. The cards rarely come down in value over the course of the generation. I know a mate of mine that just sold his 2080 ti for $20 less than what he bought it for at launch.,rtx_3080_3090_leak
"who knows. If it's real, they'll cost more too so.",rtx_3080_3090_leak
"That's fine, at least 20 is enough for 4K gaming, which these cards are supposed to be for.  Tomb Raider max graphics at 4K uses over 10GB of VRAM, and VRAM is just like RAM, getting more won't speed up the game, but not having enough will either tank performance or cause it to crash.

Edit: Why wouldn't 16 work (I don't know BUS limitations)?",rtx_3080_3090_leak
"Interesting. Not that I’m developing AI, but I like random facts.",rtx_3080_3090_leak
Sorry was directing that at Nvidia! :D,rtx_3080_3090_leak
"True.  Though, I *think* it's been floating around that this initial stack is built on both the 7 and 8nm?  With some of the lower tier cards on the Sammy 8nm.

I don't even remember where I saw that - probably some rando on Reddit honestly.  Only concrete thing ever said about ""using both nodes"" was a while back at an Earnings Call I believe and that doesn't necessarily mean it applies to the first run of Ampere.

Or has the 3090/80 now been confirmed on the 8nm?

Also odd that they have a full fat chip behind the 3090 still if nothing's going to come of it, but I haven't even looked into what's disabled on the 300 vs. 400 chip - there may not be much in it between the two.",rtx_3080_3090_leak
"Not really, prices go from 850 to 1200 euros for 2nd hand 2080 ti.. (Netherlands)",rtx_3080_3090_leak
Thanks!,rtx_3080_3090_leak
I think it depends. If they announced it upfront then it'll be okay but yeah we'll see,rtx_3080_3090_leak
Of course. I'm more concerned with the seemingly huge gap between the 3080 and 3090. Pricing will be crucial. If there is no 3080ti/super and the price for the 3090 will be above $1400 I will be massively disappointed. I'm tempering expectations now.,rtx_3080_3090_leak
I don't really expect some random consumer to understand why holding back vram sizes is bad for the industry. Your cost argument falls apart anyways because AMD has been offering a ton more memory per dollar than NVIDIA since a while ago. And their cards are much cheaper.,rtx_3080_3090_leak
So me willing to spend $1200-1400 on a GPU is not enthusiast? Considering the 3080 is $800 but then the 3090 is $1500+ with no GPU in between...is that ok with you? I'm just concerned there is a massive gap in between the two. Not sure what you are getting at.,rtx_3080_3090_leak
Ok cool I must have missed it.,rtx_3080_3090_leak
Good to know! May be a while that I look at TVs for living room PC gaming but might down the road!,rtx_3080_3090_leak
">RTX 3K 

That sounds like a cool gpu name in itself",rtx_3080_3090_leak
That you can have a longer cable except that there will be no difference.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Yeah Same. Rumors for price is all over the place right now. Might wanna grab a 3090 , but rumores also place the 3080 only 15-20% behind the 3090 , so an inhuman increase in price would be pretty stupid only for the vram. 

Time will tell.",rtx_3080_3090_leak
Don't worry. OP's post history is full of r/iamverysmart comments. He likes to stroke his own ego.,rtx_3080_3090_leak
"In fact I had more problems with my 1070 ti than my 5700 xt lol, color banding looked awful with my 1070 ti since it doesn't support dithering",rtx_3080_3090_leak
ok,rtx_3080_3090_leak
Yeah it gives that warning to a lot of people because its cached a lot of vram. Doesn't mean you are hitting the limitation. Keep in mind to a 1070 has older and slower ram which impacts its usage.,rtx_3080_3090_leak
I mean I'm pretty sure even a single 3090 won't reach 60fps/8K lol,rtx_3080_3090_leak
"Tools display the allocated memory, not the actually used une",rtx_3080_3090_leak
"> People online are ridiculous with their penchant to discourage future proofing.

Because you just can't tbh. Especially with GPU and if you want to constantly keeping up with max settings. 

IMO the parts you can futureproof are PSU, Monitors, Case, Storage, and RAM. Don't skimp on those.

CPU can last you longer nowadays too if you get good ones. For GPU, ultimately it all depends on the settings, resolution, and framerate expectation as well as whether one is okay with lowering down settings. If you always demand max or close to max settings, GPU upgrade is probably the one thing you can do to keep up. 

For instance, if you're on 1080 Ti and 1080p, then you're good for a few more years. Bring 1440p high refresh rate or 4K, then you're definitely looking to upgrade.

At the end of the day, it's always a balancing act between your need and your budget. But VRAM size has generally been relatively low in the totem pole because usually you want more GPU performance first before that ever becomes an issue. 

Of course next gen consoles etc might change the calculus but that's the historical take of it at least.",rtx_3080_3090_leak
"Yes but parts like that come around once in a blue moon and frankly nobody who bought them at the time had any way of knowing they'd turn out to be such long-lasting investments.  It was totally possible (as far as we knew) four years ago that Turing was going to come out and be a huge step up in performance for a reasonable price, then the 10 series wouldn't have seemed like as great of a buy.  Obviously that didn't happen, but we didn't know it wouldn't.

My point is while future proofing certainly isn't impossible, it's always a gamble on whether you're actually getting a great product for a reasonable price that's going to last you a long time, or whether you're spending a lot for extra performance you won't get to use before you decide to upgrade to something significantly better just a few short years later.",rtx_3080_3090_leak
i'm actually looking to pick up the same monitor. i envy your setup,rtx_3080_3090_leak
"I guess i've heard differently although I wouldnt call the source im referencing fully accurate.

Part of my calculation is that 4gb and 8gb gpus are typically $30 - $50 apart, but gddr6x is probably more expensive, and higher end cards can demand higher markup.

I hope for 100 bucks too.",rtx_3080_3090_leak
"""An article"", ""they""?? Who the fuck is ""they""? 😂 Some elementary level sourcing right here. Proof that people just upvote what they want to hear, not reason.",rtx_3080_3090_leak
Does higher refresh rate need more vram?,rtx_3080_3090_leak
"Does VR benefit from more VRAM? I'm on Index and I'm planning to get a 3080 at launch to upgrade my 1080, I'd like to be able to run Squadrons smoothly, although aside from that all I play is Skyrim and Fallout in VR.

My non-VR gaming is all done at 1080p and I'm more than happy to keep that going for as long as I can, 4K doesn't appeal to me.",rtx_3080_3090_leak
"Thats fair, but it makes a 3080 $1000 dollars.   
What if AMD comes in with a 16gb competitor at $600 - $700? 

(This is provided that AMD can reach equivalent performance in VR, and that they have decent RT and crucially a DLSS competitor.",rtx_3080_3090_leak
With 1080p gaming you can buy less expensive cards and still get high fps for years to come surely?,rtx_3080_3090_leak
"I'll probably get a 3070 and I'm almost certain that even 8 GB will be enough for the next couple of GPU generations at 1080p.

(I hope it will anyway)",rtx_3080_3090_leak
"I play at 1440p  at max settings and i've never hit 8GB.

For the next few years at max settings 8GB at 1080p will be fine",rtx_3080_3090_leak
"yep it is  
I game on 1080p 240hz and have 8GB vram",rtx_3080_3090_leak
"At 1080p you'd probably be fine even with a old 2060. I mean my 2070S runs most things 100-144fps at 1440p, let alone 1080p. If you dont plan to upgrade resolution, i'd suggest waiting for a cheaper 3060 or even getting a used 20xx when people start selling them as they by the new gen.",rtx_3080_3090_leak
Yeah more than enough.,rtx_3080_3090_leak
You really should go up in resolution with these cards.,rtx_3080_3090_leak
"16 that is shared with the OS. 0% a game will ever get 16GB VRAM on the consoles.

12GB VRAM is a more conservative guess on what a game could probably expect at peak usage on a console. So 2GB can be accommodated in the port .",rtx_3080_3090_leak
"Not to mention the new Reverb headset, which will have TWO 2160x2160 screens...  my wallet is crying rn lol",rtx_3080_3090_leak
People always exaggerate the need for vram.,rtx_3080_3090_leak
"No they wont. People keep bringing up the console bs but its just that. Just like with every generation, it'll take a good 4-5 years before games start consistently getting made with *only* the new gen in mind, regardless of the specs. Until then it doesnt matter what the new consoles are at all because the old ones will be dictating game design anyway.",rtx_3080_3090_leak
"No, we have to accomodate consoles that *can swap stuff in and out of VRAM near-instantaneously*. That's the real issue. The PS5's SSD is basically as fast as DDR2 memory, and devs are going to use it to store crazy big assets to stream on the fly that simply wouldn't fit within the VRAM budgets of current PC graphics cards.",rtx_3080_3090_leak
"This is a misnomer. There is a large pool of GDDR6 for new consoles, but there is segmentation between the OS and usable memory. There are two sets of slower and faster modules, and a portion is reserved for the OS.  I believe developer discussion is putting 4-6gb for the graphics.",rtx_3080_3090_leak
Oh yeah the C9 and CX are good stuff! I heard the CX has some firmware bugs because it's newer but you can't find C9 anymore unfortunately because it's last year's model :(,rtx_3080_3090_leak
2070 Super has the same core count as 1080 and performs more. You cannot compare core count gen to gen.,rtx_3080_3090_leak
"That we'll have to see but i don't see why not.

Wait for benchmark! :)",rtx_3080_3090_leak
I'll be joining you on the 20gb 3080,rtx_3080_3090_leak
"I'm not sure about the exact terms for that, check their website. What may work is if you get an EVGA hybrid that is watercooled or another watercooled EVGA",rtx_3080_3090_leak
"That statement could also include orders for A100, which would contribute a massive amount of volume and revenue. Going with SS for some geforce cards doesn't make that statement untrue.",rtx_3080_3090_leak
"Sweet I figured, its gold as well so should be fine.",rtx_3080_3090_leak
as someone with a EVGA 750W G3. what a relief.,rtx_3080_3090_leak
"I’ve got a 8700k and 650w, considering upgrading, should I stay put?  I’m going to get whatever 3090 FTW variant EVGA comes out with.",rtx_3080_3090_leak
"Alright cheers, yeah to be fair the 650w was gold my new 850w is only bronze as prices got a bit crazy but it does the job fine, they’re both evga so figured that should be fine. I’ll check out the watt usage monitor",rtx_3080_3090_leak
"Ah right, I should mention that the RT cores and to a lesser extent, CUDA cores are essential for work (AI denoise) and the older generation of Titan RTX is still prohibitively expensive.

The issue is two fold - we need RT cores to render in a reasonable amount of time, but at the same time we cannot work in large scenes because there isn’t enough VRAM. 

We’ve got the RT cores covered, we just need enough Vram on a consumer level. This next gen is a godsend for us because of the upcoming 20GB cards.",rtx_3080_3090_leak
Yeah it's called ram pre-loading. It's circa 2GB less than the GPU's max.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"That amount of frustration must really hurt your mental capacity if you compare a firehazard of a 390 with a 970. It's like comparing a 2060 with a 5700XT. But the 2060 uses 400W and the  5700XT only 100W.

And yeah. And simultaneously no. Nvidia compresses much more than just textures.",rtx_3080_3090_leak
I am on rx 480 and itching for an upgrade too. I really want to play cyberpunk with ray tracing. These cards can’t come out soon enough,rtx_3080_3090_leak
"You edited the post right before I wanted to send it to you.

Yes, what I mean is that just because you technically afford something, doesn't mean it's **always** a good idea to buy it.",rtx_3080_3090_leak
"You have no basis for that statement. It's the same chip as 3090 with a few functional units disabled. I suspect it will be within 15-20% of the performance, otherwise it's a bit of a waste of silicon.",rtx_3080_3090_leak
2020 can do hdmi 2.0b 4k120 no g-sync but hdr. With 2.1 it’ll do 4K 120 g-sync 40-120hz with hdr and 4:4:4 chroma,rtx_3080_3090_leak
i have the RTX 2080,rtx_3080_3090_leak
"The 3900 has 12 cores, while the 3700 has 8, which means (in short)  that the 3700 is better in games and the 3900 is better for multi-core tasks, such as deep learning and editing

Edit: the ryzen 9 is almost identical in performance with the ryzen 7, except for a few titles, and even then the difference is not too big, but for league you could probably crack 200fps with either",rtx_3080_3090_leak
"I’m the same as you, and for me it’s a 4gb upgrade from my 980ti. 
Yeah I think it’s gonna have a really decent boost in performance and I have a feeling Nvidia might have something planned too.",rtx_3080_3090_leak
"I run a 2080 at 4k and know exactly what my performance needs are.  I don't *need* to upgrade, but would like to.

8gb standard GDDR6 is below my expectations for a next gen 4k card.  Ampere might have snazzy new tech, but starting out the gate with these kinds of limitations is a mistake imho.",rtx_3080_3090_leak
"VRAM limits are like a brick wall, when it stops being enough you don’t lose a couple FPS, the game just locks up.

No one is saying that 16GB was reasonable on a Vega for games. I don’t think 20GB is reasonable on 3080 if custom AIBs offer it, it will throw the price/performance out of whack.",rtx_3080_3090_leak
"Yeah, but I was hoping for 3070 price point.",rtx_3080_3090_leak
I understand that. I never said he wouldn’t be fine. It’s probably best to upgrade. We also don’t know how old his 750W is,rtx_3080_3090_leak
"Dunno which article he's referring to specifically but I took a look at [JonnyGuru's most recent review](https://www.jonnyguru.com/blog/2019/04/08/fsp-hydro-ptm-750w-power-supply/) (from April 2019) and he's basically right:

>With the Hydro PTM being rated for 80PLUS Platinum, we expect to see efficiency numbers to be at least 90% @ 20% load, 92% @ 50% load, and 89% @ 100% load. Of course, we won’t complain if they’re better than that, will we?

It's so close in efficiency that the difference is practically negligible.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"This is opportunity coverage. Yes they are losing money on this, same as with diversity hires",rtx_3080_3090_leak
"Well theyre both great brands, just different, i mean im still running an ancient amd Pc",rtx_3080_3090_leak
"Wrong, because 3000 comes next month, or in October at latest for 3070 to get in stock, 4000 probably comes about two years later, so you buy 3000.

I don't think it's so hard to comprehend, but whatever.",rtx_3080_3090_leak
"It's going to be very close to a 2080 Ti based on rumored specs and common sens, that's about 40-45% and that's on rasterization, expect RT performance to be even higher than that.",rtx_3080_3090_leak
Can I borrow your crystal ball?,rtx_3080_3090_leak
"In terms of raw performance, the 1080Ti is on par with the 2080 and sells for cheaper. It’s missing features like RTX and DSC though. I don’t think people are overpaying for performance but it’s ridiculous that 2 generations later it’s still competing with flagship cards at all. It should be cheaper because the 2k series should have made it obsolete.",rtx_3080_3090_leak
I said yes just wait 3 days technically for yesterday card prices will go down once the new one come out,rtx_3080_3090_leak
"depends on the game, games that were AMD optimised run significantly better on turing than pascal. 
https://www.techspot.com/review/2017-geforce-1080-ti-vs-rtx-2070-super-vs-radeon-5700-xt/

TPU rates the 2070 super as 101% of a 1080ti.",rtx_3080_3090_leak
"Actually, you made me think about this more and if I find a 5700xt at a good price I might take it and resell the 1080ti.

I am a little concerned about the drivers tho.",rtx_3080_3090_leak
"I recently made this decision and I chose the 1080ti because the pricing was very similar and the performance was significantly better. I play at 4K so I need all the performance I can get. I used to own a FE 1080ti, but I got a nice Strix version the other day. Also, PayPal sorta gives you a 6 month warranty if you know how you use it.

I’ve also heard really bad things about the drivers for the 5700xt on all three major OSes. Whereas, the 1080ti has very good drivers on Windows, Linux, and Mac OS High Sierra.

This is all my opinion tho.",rtx_3080_3090_leak
"It has AMD drivers doe, makes it worthless",rtx_3080_3090_leak
"You shouldn't. NEVER expect a game to be bug free. The larger the game the more likely bugs will exist. Personally I'm fine with them delaying the game for polish, I'm just against them setting a date that isn't guaranteed. Go away, make your game then tell us the actual release date 2 weeks before release  not months ahead of time when you're still ironing stuff out.",rtx_3080_3090_leak
"We'll see. I plan to watch on youtube for a bit, see if it's good, then wait for the next gen of video cards that will run it well at mid-range.

Which means, yeah, I'll be waiting somewhere around 2 years. And I'll likely pick up the GOTY edition that has all the DLCs included and is half or less when it goes on sale, and has most of the bugs patched out.",rtx_3080_3090_leak
CRAWLING IN MEYYYYN SKYN,rtx_3080_3090_leak
"You aussies have nothing on Indian tax. Gpus,cpus etc are considered a luxury item by the government.",rtx_3080_3090_leak
"lol yeah you guys got nothing on our Australia tax, now that is brutal!",rtx_3080_3090_leak
Not really worth it to be honest.  I just have to sell a few of my Nvidia stocks.  I figure it's fitting,rtx_3080_3090_leak
Does the 10xx series support DLSS 2.0?,rtx_3080_3090_leak
Yea if your monitor does not have the weird resolution in their native resolution then it will look like shit,rtx_3080_3090_leak
"No, but YMMV. It fully depends on whether your screen supports the arbitrary resolutions.",rtx_3080_3090_leak
Looking out at the sea of children too young to have lived through Crysis.,rtx_3080_3090_leak
"> I would much prefer a world where devs create an ultra setting that by definition is a bit much for the current cards, so that in the coming years, the game actually holds up when you play it on newer hardware

Except if we're honest, most games with ultra settings are indistinguishable from high or very high settings, other than with the GPU load and performance. I don't really see that as ""keeping up"" if you can't tell the difference on the two settings.",rtx_3080_3090_leak
"Yeh and I'd kind of put flight sim into its own category anyway, it's not really a game in the usual sense.",rtx_3080_3090_leak
Reminds me of the Crysis craze back in 2007. I like it. :D,rtx_3080_3090_leak
"Agreed that most games don't have the ""extreme"" setting for next generation cards. These days they just repackage an update that otherwise would have come with the game and loosely call it a remaster (in most cases). The exception these days being for the new Crysis Remastered. I'm sure it will take 5 years to release a card that will max it out if it's anything like vanilla Crysis. Especially if that target is 8k.",rtx_3080_3090_leak
"The entirety of your argument comes down to:

>	We also shouldn’t be blaming Nvidia for having slightly high prices for top end cards when AMD still hasn’t released a card that’s stronger than a 2070 Super.

You’re defending the natural consequences of a monopoly, bruh. Nvidia’s prices are not due to fairness or development costs. They’re due to a lack of competition.

The 3000 series is looking to be some of the largest price hikes in the history of graphics cards. We’re talking about the bottom-end card being *four hundred dollars*. In what world is that fair pricing?

Part of this is so that they can slash the prices later to fuck over AMD. Part of this is so they can slash the prices more to release “Super” variants. 

And yeah, the cards are big because 1440p at 144Hz is a thing and because 4K displays will eventually be able to push those kinda of frames. However, that’s not and never will be the reason for the price.

The reason for the price is a monopoly. They are overcharging us and providing us with shoddy cards with last-gen vram in low quantities and arbitrarily limiting what their cards can do. And for no other reason than to make you pay more.

Pick a side that isn’t the one defending shitty business practices, bro.",rtx_3080_3090_leak
I have quite a few settings on medium and everything else on high. I had to bump shadows down to 1024. With everything in high the game would climb to 7.8 GB and then suddenly crash to the desktop.,rtx_3080_3090_leak
"Not without reason. Prices haven't been great since mining drove up prices. Still on the 980 and sticking to 1080 gaming as a result, since didn't see a point to a 2k monitor when I don't have the card that can push that yet. Had prices been better I'd have moved onto 2k or 4k gaming for newer games.",rtx_3080_3090_leak
"Can confirm, still enjoy my 1080p 165hz display",rtx_3080_3090_leak
"I have not played MW for 3months :).  but that game feels like an exception, i also had around the same framerate on medium high after doing some tweaking.  have you also turned down any post processing, shadows, AA and more?  

i’d like to see 100+ in first person, so i may upgrade to 3070 or higher if priced reasonable",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"The price of something has little to do with what “tier” it is. The 3070 is the the second lowest card in the series, whether it costs $5 or $50,000 is irrelevant.",rtx_3080_3090_leak
"Again, for those who can’t/won’t read, price is irrelevant to tier. It’s the second-lowest tier card in the series. Nvidia can announce a 3050 and charge $5000 for it, doesn’t make it a top-tier card.",rtx_3080_3090_leak
"I never said anyone should just buy the most expensive card just because. I said there are different tiers of cards with different specs. If you have a need for 10gb of vram then you should buy the card that meets your needs.

Also no one ever said a 2080S is irrelevant.",rtx_3080_3090_leak
Hmm well maybe some of the other settings I cranked up use a ton of ram? Or it'll just use whatever is available so it doesn't need to load stuff into vram later.,rtx_3080_3090_leak
"It's a huge difference. 1660 super here, playing warzone at 1080p ultra except the render quality cause in warzone I'm maxing out. It's mainly cause of the vast size. Usually in a single player situation only a certain circle is rendered in max quality but I'm assuming it gets tricky when there's 200 players.",rtx_3080_3090_leak
"In your case, it doesn’t.",rtx_3080_3090_leak
"HBCC, google it...",rtx_3080_3090_leak
"I get that. Definitely a diminishing marginal return. But it does have that extra polish with that many pixels. I think the new consoles will push devs to take advantage of 4K tv resolutions, so expect the price to come down dramatically as TV/monitors enter the 4K 120hz + market. TV and monitor tech is definitely converging, which is good for the consumer.",rtx_3080_3090_leak
"Of course 1440p looks better, but its also harder to run.  ¯\\\_(ツ)\_/¯",rtx_3080_3090_leak
"The vast majority of casuals play mp games non competitively. And despite reddits constant idiotic cirlejerking, they dont care the slightest shit about stuff like framerate or refresh rate, they just play on whatever they happen to have, whether its a old monitor or a shitty laptop, and crank up the resolution and graphics as far as they can because they dont give two shits about any competitive advantage..",rtx_3080_3090_leak
"I have an almost identical spec rig to yours power wise, only intel not amd - and from a purely non competitive standpoint I get 1440p 60fps most (if not all) of the time",rtx_3080_3090_leak
"But we're talking about PC gaming, not consoles which are played mostly on TVs where 4K is indeed the standard now.
Only a small fraction of PC gamers play on 4K and the majority by far play on 1080p - just take a look at Steam hardware survey for example.",rtx_3080_3090_leak
"Don't underestimate how good the smoothness looks.  Even in a non-competitive game, higher framerate is amazing.  I have a 144Hz and a 240Hz monitor.  The jump from 60Hz to 120 or 144 is insane how much of a difference it makes.  144 to 240, not so much, so as long as you have a 120Hz or 144Hz monitor, then go for higher resolution, so I think the sweet spot for current tech is 1440p 144Hz.",rtx_3080_3090_leak
They should. Just not thousands of times for every person that logs in.,rtx_3080_3090_leak
120 FPS in Witcher is going to be like 70 in Cyberpunk,rtx_3080_3090_leak
"Hmm. Well my FPS VR shows me constantly all around maxing my gpu when I game in VR, so I still probably will benefit from mor vram whatever the cause may be.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
🅱️All in 🅱️One,rtx_3080_3090_leak
the next generation xbone,rtx_3080_3090_leak
All in 🅱️ono,rtx_3080_3090_leak
I donno it sounds like the AIBs have a much bigger jump on this 3000 series compared to the past launches I've been in. We'll see though.,rtx_3080_3090_leak
The article implies 3070 is coming at the same time,rtx_3080_3090_leak
Gotta wait for the benchmarks now,rtx_3080_3090_leak
"i mostly fly the 172 G1000, usually its hovering around 18ish gigs but yeah depending where i am it seems to like its ram sometimes thats for sure.  hopefully the patch coming up will address some of the performance issues",rtx_3080_3090_leak
"Let me ask you a question- how much faster do you find the new processor when it comes to more basic tasks like opening programs, loading files, working in a video editor, etc.?

I'm in a similar situation using an old laptop i7-3610qm but was planning a potential upgrade to something like the 10850k.  The benefits to gaming and dense applications are obvious but how much faster does the computer really FEEL in day-to-day use?",rtx_3080_3090_leak
Do you have a link for the mod pack? I'd like to check it out.,rtx_3080_3090_leak
"""neck and neck""

LOL then why bother with a 3700x Its literally ""neck and neck"" with a 6700k in gaming.

Whether its 40fps in Flight sim. or 5fps in tomb raider, its a *literal and functional* downgrade",rtx_3080_3090_leak
"What future games? we have next gen games like flight sim. The new consoles specs are already out. 

Spending money on a CPU and Mainboard to downgrade a CPU because of ""team red"" is one of the dumbest things i've seen on here.",rtx_3080_3090_leak
">  the 3700X is 10% slower than the 8700K

Oof",rtx_3080_3090_leak
I'll checj that out! I didn't see any for less than 1k but that was a while ago,rtx_3080_3090_leak
"Bruh I’m running a 1050ti and I have yet to find a game I can’t run.  Even flight sim, I can get 30+ FPS at medium settings.",rtx_3080_3090_leak
"Yes it is, and people keep telling me it isn't possible. 


The only thing is to stick to FXAA/TAA, and turn Volumetrics way down. Card doesn't handle smoke/vapor well.",rtx_3080_3090_leak
Please save us from this price gouging AMD,rtx_3080_3090_leak
*A single burst from its gun can cut a man's wallet clean in half*,rtx_3080_3090_leak
"By getting us hype for shit cards. Also honestly I just made a new build in the hope of using one of these cards, so it sucks for me to have that plan interrupted. Also even if I'm aware of these dodgy tactics, most people won't be",rtx_3080_3090_leak
"Ahh, I'm on 1080p/60, so I have a good bit more leeway than you do. Definitely feel like I can keep what my target is until the 4k series, since I imagine most crossplatforms will be on the PS4/Xbone until the 4k series comes out.",rtx_3080_3090_leak
Never had issues like that in over 5 years of using an AMD card. In the first month with my 2070S one of the drivers introduced a bug that broke HDR in my games. So your mileage definitely varies ¯\\\_(ツ)_/¯,rtx_3080_3090_leak
Weird how great their CPUs are and how bad their gfx cards are,rtx_3080_3090_leak
"The fact that you call it catalyst says how long you didn't try AMD.
Yes, issues exist, but for the majority of cards have no big issues, not ""always horror"".

Let's hope they are competitive with Big Navi.",rtx_3080_3090_leak
Tbh if you're still using ATI to describe AMD cards you haven't used a recent card with recent drivers,rtx_3080_3090_leak
"Radeon drivers are amazing under Linux, talking about the open drivers of course.",rtx_3080_3090_leak
"The last few Adrenalin 2020 updates have been great for me. I've always had trouble with the software crashing and occasional black screens, made worse by using custom settings, with my vega 56. Now I'm suddenly able to finally undervolt and overclock and see what the card can do without the software crashing and resetting everything every day. It's been great.

The one thing I haven't figured out is screen flickering with freesync in some games. I currently just have freesync disabled which sucks but I don't really notice any screen tearing at high fps.",rtx_3080_3090_leak
"Same here. AMD is just not reliable, and I will continue staying away from them until that changes.",rtx_3080_3090_leak
"Big Navi leaks so far have shown that it will rival the current 2080 ti. 

Just depends on price and if still have software/driver issues.",rtx_3080_3090_leak
"It should at least match it, and hopefully it OCs well. The 2070 super overclocks safely like a mofo, 15% on avg. We just need to wait for benches in all honesty. The architecture change is too drastic to speculate on these numbers.",rtx_3080_3090_leak
Guess... I was right. That's all I have to add.,rtx_3080_3090_leak
"Pretty much the whole 1XXX series had incredible price / perf.

2XXX was kinda dissapointing, hopefully not a repeat.",rtx_3080_3090_leak
"The only way I see 8GB being enough is if Tensor memory compression makes 8GB perform like 10GB from Turing, but i also heard some rumors that its only coming to the 3090, we will have to see. The fact that it's still GDDR6 is what gets me the most, the 3080 seems like a way better deal, 2GB more ram and higher clock as well and a GA 102 Die. If this true I don't see the 3070 costing 600, I bet it's 500 and they're leaving a 3070ti just incase Navi bites them in the ass.",rtx_3080_3090_leak
Extremely doubtful,rtx_3080_3090_leak
I have never owned an AMD card but Nvidia doesn't cool it with the aggressive ass cost structure I'll be making the switch.,rtx_3080_3090_leak
At the same time regular 2070 is 175 watt. Could we expect 3070 Super around 300 then?,rtx_3080_3090_leak
"So the 3080 will use roughly about 3x the watts for a little over 2x the performance? Kinda reconsidering upgrading.

&#x200B;

I wonder if there is a way to get accurate costs of the amount of electricity i use.",rtx_3080_3090_leak
"You're right, actually I am finally able to play RDR2 in 4k which was impossible with my old 1070. Plus I had quite a lot of time for gaming over the summer due to Covid. And with DLSS 2.0 hopefully being featured in more games in the future the 2070S might even be enough for raytracing in a lot of games which is amazing.",rtx_3080_3090_leak
Almost nobody NEEDS to upgrade to a 3000 series right away.,rtx_3080_3090_leak
"AMD has a history of under performing compared to the rumors. Not to say they're bad, but sometimes the rumors are just rumors.",rtx_3080_3090_leak
"I feel bad for people with 900 series cards who were holding out an extra couples of years to jump on the ""year one"" upgrades this time around. You either get your bank account destroyed or you end up paying full price for last year's model, which is still cheaper than this year's model.",rtx_3080_3090_leak
"NVIDIA: ""For you, my friend... full price.""",rtx_3080_3090_leak
"Looks like my estimate of the 3090 being a titan replacement was correct, but you were right on it being more expensive too 1500 bucks, 

More importantly the 3080 being 700 means prices are the same as last gen. Thats a bit of a sigh of relief.",rtx_3080_3090_leak
"I've never purchased an Nvidia card so i'm not part of any pricing. Either way, if I want to play minesweeper on a 2080ti that'd be up to me right? Who exactly are you to be judging how games should and shouldn't be played? Yikes.",rtx_3080_3090_leak
I'm talking about a drop in price for perfomance for the new cards vs the  2080ti. .. n,rtx_3080_3090_leak
"Honestly,  what's wrong with you?  You seem to be very upset that someone might want to play video games at 144fps. Its rather odd.",rtx_3080_3090_leak
"I think he meant 3080Ti/Super

And really? my 1080Ti doesn't even reach 144fps on warzone or BFV at 1080p lol, but is highly possible that is because my CPU (2600X)",rtx_3080_3090_leak
"Yes it will still be usable in 4 years, but eventually you will need to replace your gpu anyways",rtx_3080_3090_leak
"It cannot ray trace?
It cannot run DLSS?
Technologies that will become the norm in the future.
We cannot stick to the past.",rtx_3080_3090_leak
can u give me a list of games that are unplayable at 8 gigs?,rtx_3080_3090_leak
"Yeah but how much is now and how much is later lol 10 years? no, 5 years? probably",rtx_3080_3090_leak
"Modders are a really small group compared to the PC market, youre not the intended target of graphic card manufacturers.

You want sexy mode in 4k? Buy more cards or buy a Titan, or any workstation card",rtx_3080_3090_leak
Apparently there are no 2GB GDDR6X chips yet. I think I read that it's doing some weird stuff where it has memory chips on the backside because it has two chips on the same module or something like that.,rtx_3080_3090_leak
"> I think the ram now gets pretty hot and would be cooling an issue with Ram on the back of the cards too.

Which may be why the FE cooler on 3090 has fans from both sides.",rtx_3080_3090_leak
"Yeah i understand. But keep in mind some games simply wont run at 144fps , like AC and Far cry 5. hard cpu bottleneck at around 90-100 fps",rtx_3080_3090_leak
"DOOM is an extreme exception and should not be used as a basis for any performance expectations, especially for comparing hardware. Their game is basically the only game that can run that well, and it comes down to software and programming, not hardware.

FS2020 is a great example, as in many instances I can maintain just about 60 FPS or higher on Ultra settings with a 2070. However, in places like JFK, it drops to 20-25 FPS. It also only uses DX11 and doesn't utilize any other new features.",rtx_3080_3090_leak
They’ve never done anything anywhere near that kind of die size tho. It’s only basically just been their own tiny exynos socs,rtx_3080_3090_leak
Yeah. People who always buy the latest and greatest will buy them no matter how much they cost. Nvidia knows this.,rtx_3080_3090_leak
Look at people still buying i9 10s lol,rtx_3080_3090_leak
I’m hoping they don’t cost more than $1500. I could prob sell my 2080ti for a few hundred and not be broke lol,rtx_3080_3090_leak
imagine gatekeeping what other people do with their hobbies,rtx_3080_3090_leak
I personally can't use my 240Hz 32:9 monitor without DSC and I can't get 4K @120Hz on my LG C9 without HDMI 2.1,rtx_3080_3090_leak
"Yup. The ""highest end"" barely fluctuates. Well planned timing will save you more then go with a middle tier cards throughout lifetime of upgrading.

Its the same for all electronics that upgrade whether its phones/tablets/consoles. My old PS4 Pro sold two months ago for same price I paid for it \[$400\] mainly due to Coronavirus scarcity\[still... but if I were to wait till like release date of PS5 I would probably get $200. People who are waiting for price drops will need to wait 2-3 years for it get that low to cover the difference \[maybe more\].",rtx_3080_3090_leak
"Different sizes of memory bus access different numbers of memory chips, which only come in a limited number of capacities. 

A 256 bit bus accesses 8 memory chips, so the realistic options are 0.5GB, 1GB or 2GB chips for 4GB 8GB or 16GB

A 320 bit bus accesses 10 memory chips, so it's 5GB, 10GB or 20GB

A 384 bit bus accesses 12 memory chips, so it's 6GB, 12GB or 24GB

Copied and pasted from another thread because it's accurate. The 3080 has a 320 bit bus so the next step up is 20gb",rtx_3080_3090_leak
"Introducing new SKUs or product lines makes it easier to jack up prices. I know everyone thinks the 3090 is a Titan replacement, but I would be surprised honestly. I can't imagine them taking an $1100 haircut on the Titan. Just not Nvidia's MO.",rtx_3080_3090_leak
"The rumors I've heard is that it's on Samsungs 8nm, because they couldn't secure enough TSMC time because they tried to play hardball on pricing and AMD scooped up the time.

Take all of that with a *massive grain of salt* though, as that is just what I've heard on youtube. **If** that is true, TSMC refreshes make sense. We'll have a lot clearer of a picture soon though.",rtx_3080_3090_leak
"Mmm good prices, im about to put my 2080ti strix oc on marktpkaats.",rtx_3080_3090_leak
800 - 950 in Finland,rtx_3080_3090_leak
"That'd put a big smile on my face, even if the price was £100 more. Let's wait and see. Only a few more days!",rtx_3080_3090_leak
"I think you've said it well. It's a ""seemingly"" huge gap. We just dont know what those numbers mean in real-world terms and what effect that extra ram will actually have. It might be massive, but it also might not be as bad as people seem to think it will be which could lead the 3080 to being a decent buy.",rtx_3080_3090_leak
"Look you can try and take the high and mighty ""you couldnt possibly know what youre talking bout compared to me"" stance all you want. If you think that developers dont develop because GPUs can't handle it then i'm sorry but you've lost me. You're arguing a chicken and egg that can't be resolved",rtx_3080_3090_leak
"I unironically recommend them. They are basically having the perks of high refresh rate gaming monitors while offering pristine image quality that doesn't lack in any way and they can give you 4K120HDR with VRR which sounds insane.

A friend got an LG CX and has been doing his gaming exclusively on it. Loves it to bits.",rtx_3080_3090_leak
"Yeah sorry, should define it better",rtx_3080_3090_leak
Hopefully at least 30fps.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"I wouldn't be surprised if the premium was at 200. At the end of the day it's not how much more it cost them, it's how much more they can charge us to maximize profits. I remember Apple was charging a $100 more for 64 to 128GB of storage when it literally cost them a few dollars.

Honestly if the 20GB version ends up at 1K I don't know if I can convince myself to buy it. Can I afford it? Yes. Do I think it's worth spending on something that depreciate relatively quickly? No.",rtx_3080_3090_leak
"You do realize you could just ask for the link instead of being an asshole right?

>At the same time, keep in mind that these are the retail prices and the wholesale contractual prices that NVIDIA and AMD will enjoy. Usually, OEMs pay around 50% less for graphics memory compared to retail prices. That means NVIDIA will be paying just around $60-80 to double the VRAM on the RTX 3080 Ti from 11GB to 24GB

Am I expected to dig up my history to locate an article every time I comment on Reddit? What do I have to gain from making it up? Here's the article I am talking about.

[https://www.hardwaretimes.com/doubling-graphics-memory-will-cost-nvidia-and-amd-less-than-12-gb-its-very-likely/](https://www.hardwaretimes.com/doubling-graphics-memory-will-cost-nvidia-and-amd-less-than-12-gb-its-very-likely/)

How about you apologize for being a prick?",rtx_3080_3090_leak
Not necessarily but faster VRAM (DDR6X) would help that. The larger VRAM would be more needed for my higher resolution needs.,rtx_3080_3090_leak
I think Squadrons will be ok. But in HL Alyx I get a warning on my 1080ti (11GB) that there is not sufficient VRAM when I have it on just high settings. It's more about looking into the future of AAA VR games than anything else. My 1080ti with its VRAM is still a beast in 95% of VR I do. BUT I'm getting the Reverb G2 with its 4K resolution and now getting into sim racing/flying and I will be looking/waiting for the high VRAM cards within my budget. I'm not going to settle with 10GB of VRAM no matter what Nvidia says about compression or speed. I'm looking to use my next GPU for 3 years and I think VR will be booming during that time so I want the best I can afford with the most VRAM possible.,rtx_3080_3090_leak
"I think Nvidia will launch these 3070/3080/3090 cards, wait for AMD and then come out with the higher GB cards and the 3080ti/super. But AIBs might just come out with higher GB versions before AMD. Time will tell...",rtx_3080_3090_leak
"Looking for a 4-5 year solution. 

Plus next gen is coming. I think this is a safe choice",rtx_3080_3090_leak
"I mean probably even a 1080Ti/2070S/5700XT will suffice for some time at 1080p, probably you will have to turn down some settings or such to reach 60FPS, but it will be possible lol

For 5 years though? at 2025 I expect AAA games run at like 30fps low at 1080p on these cards lol",rtx_3080_3090_leak
"Shadow of War *supposedly* over-subscribes my GPU by ~2GB but it holds 80fps on Ultra.

Lot of folks in here getting sweaty about a poorly programmed bar in the options screen.",rtx_3080_3090_leak
"Yup same here 1440p on Max settings with a 2080Ti.    The most i've seen so far is 9.2GB usage doing Flight Simulator 2020.

Most games are much less than that between 5-8GB for most games I've been playing over the past year.",rtx_3080_3090_leak
thanks,rtx_3080_3090_leak
Won't last the new gen for 5 years.,rtx_3080_3090_leak
tnx,rtx_3080_3090_leak
Dont have the space for a 27 inch monitor.,rtx_3080_3090_leak
">16 that is shared with the OS. 0% a game will ever get 16GB VRAM on the consoles.

It does not have to use 16GB for VRAM lol

It only has to use more than 8 for real. 12 GB on GPUs is fine for now though... if we had it...",rtx_3080_3090_leak
"Way less than 12GB probably, how many GB are reserved for OS on current gen? then you have subtract memory needed by the CPU too...",rtx_3080_3090_leak
10gb is plenty for that. I use an index at very high super sampling at times. Your gpu horsepower is an issue way before vram limitations,rtx_3080_3090_leak
"I run into VRAM issues with 8GB on my 5700 XT and RTX 2080. Even without mods in Wolfenstein 2... but I am PCMR. I mod games too. 

8GB is borderline ATM. 2021 will not see it get less borderline.",rtx_3080_3090_leak
"The games dont have to use 12 GB. They have to just use 8GB for console settings for PCs with higher level texture and model settings to demand more.

:P I like my textures at Ultra or High, not Medium.",rtx_3080_3090_leak
"No misnomer here. I clearly know that the RAM of consoles is shared between video, CPU, and OS. It will NEVER use 16 GB for VRAM. Hell, there will never be a game that uses over 12 GB of VRAM either since that would mane 1-2 GB are left for the rest of the game. Doesnt happen.

But ... all it has to do is use 9GB for its video memory segmnet. And then remember, consoles dont use Ultra texture settings most of the time. PCs are above them there in the majority of games. Even without HD texture packs. 

4GB cards do not work today well. 6GB can be broken too. Let alone in the future lol.",rtx_3080_3090_leak
Interesting I will have to keep that in mind down the road...,rtx_3080_3090_leak
"I think it's going to be the way to go.

If the 3080 is indeed around 35% faster than a 2080ti for a lower price then great but 10GB concerns me.",rtx_3080_3090_leak
A100's volume is nothing compared to GeForce's volume.,rtx_3080_3090_leak
Gold is fine. And evga is super good. I’m guessing you just had insane OC lol,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
thank you :) that is what I was explaining to you :) So why do you compare a 3gb card to a 4 gb one?,rtx_3080_3090_leak
That maxwell feature became more powerful with maxwell and even more powerful with pascall.,rtx_3080_3090_leak
"Lol, the r9 390 now beats the gtx 980 in almost every game... Funny no? And it'll get worst year by year LOL... If you are complaining about a 275W TDP I can't imagine how bad you will cry because the 3090 is 350W and even the 3080 is like 320W",rtx_3080_3090_leak
Imagine if 275W is a firehazard what the new 3090 350W and 3080 are gonna be jesus christ I can't imagine,rtx_3080_3090_leak
"329$ beating an 549$ GPU thats a big yikes, also with double the memory, 4 gb for the 980 vs 8 for the r9 390",rtx_3080_3090_leak
So you wrote gtx not RTX. Gtx 1080 doesn’t go Gsync over hdmi.  Your RTX 2080 can do that with the lg OLED line of TVs 9 and 10series. It for whatever reason won’t work on other hdmi 2.0 monitors.,rtx_3080_3090_leak
"If you're running 2080 at 4K currently then you want at least 3080 or 3090.

3070 is not going to cut it unless you're willing to settle for lower settings.",rtx_3080_3090_leak
That’s one weak brick wall if dropping the texture settings by one notch will resolve it.,rtx_3080_3090_leak
"I mean are the numbers the same with 80 PLUS Bronze, Silver? That’s what the mainstream buys",rtx_3080_3090_leak
Its not the same connector.,rtx_3080_3090_leak
Competition is great for the industry,rtx_3080_3090_leak
Your last word really says it all,rtx_3080_3090_leak
"It was on par at release, now the RTX 2080 is faster and in games using ray tracing there's no battle at all, DLSS and other AI application are also a plus as the new NVENC encoder is.

This generation NVIDIA didn't have a transistors density improvement that offered a cost reduction to be passed to costumers and on top of that they added a lot of new and advanced functionality that more than two years later the competition seems will struggle to match, Turing will support all the new API functionality that next console and AMD GPU have, it offered them even almost two years before they become officially part of the API",rtx_3080_3090_leak
">level 7somerandomii1 point · 13 hours agoIn terms of raw performance, the 1080Ti is on par with the 2080 and sells for cheaper. It’s missing features like RTX and DSC though. I don’t think people are overpaying for performance but it’s ridiculous that 2 generations later it’s still competing with flagship cards at all. It should be cheaper because the 2k series should have made it obsolete.

It was slightly slower at launch and was never on par. Modern AAA games and current drivers now show 2080 is simply faster, though not as much as people hoped for. Again, they are not ""on par"".",rtx_3080_3090_leak
"Lets hope they'll get a good deal then, personally, I'm going the 3k gen route, but a cheap 2070's not a bad idea as well, as you can still enjoy some good performance while waiting to upgrade to a 3070 if you so choose...

I'm afraid that if you wait too long then the prices for the 3k gens will skyrocket just like with the 2k gen as the 2080ti debuted at $900, and ended up at $1.2k before the price gouge!",rtx_3080_3090_leak
"personally, id currently wait for ampere and maybe navi just to see what this generation looks like. if you are a bit worried about the drivers and do have the cash to buy the new GPU first id do that just so you know you ain't going to have to spend hours trying to troubleshooting with no alternative.

ive also got a 1080ti, waiting to see if this is the generation to finally upgrade on.",rtx_3080_3090_leak
"just a reminder its not 6-month warranty, its 6 months buyer protection and very different or at least in the UK where i reside you cannot use it like warranty, you aren't covered if the item later develops a fault in your care. however, businesses are held to different standards. The closest the PayPal protection will cover is if it gets damaged in shipping or was sent faulty.

id advise you to give it a quick read and just make sure you know what their policy is where you live as it may be different for you, and you don't want any nasty surprises.

also yeah AMD drivers defo went downhill after Polaris, however from what ive heard they have be more or less sorted on navi now. nvidia drivers are s$!t on linux and havent been that great on mac for a while. AMD have better linux drivers than windows in some cases as well, especially OGL",rtx_3080_3090_leak
"Amd drivers work fine for me, i haven't noticed anything bad with it. I think I may even like it more than nvidea drivers.",rtx_3080_3090_leak
"If that works for you then cool, but I've never seen a game on YouTube that plays the same as it looked from a video. You need to actually play it imo to know how it actually feels, especially an rpg. Watching someone else make decisions is not the same as making your own.",rtx_3080_3090_leak
"I am Australian and Australians really exaggerate the ""Australia tax"" on consumer electronics. It was true about 5-10 years ago but it hasn't been like that for a long time. Our advertised prices include sales tax, which isn't included in US advertised pricing. When you calculate the difference taking into account our dollar value we're usually within 10% of the US price give or take. Sometimes (actually quite frequently) falling below the US asking price.

But people will still complain because apparently currency conversion and sales tax (which exists in the US but isn't advertised like it is legally required here) is too complicated for some people to understand.",rtx_3080_3090_leak
Don't think so,rtx_3080_3090_leak
"Probably. The PC with the 1070 ti is in my entertainment stand; it's hooked up to a Vizio M Series Quantum 55"" TV that supports arbitrary resolutions below 4k. 1620p and up are nigh indistinguishable from 4k on it, except in games where higher resolutions will have higher object density (it's rare, MGS 5: The Phantom Pain is the only one that comes to mind).

My desktop's monitor (3440x1440) doesn't handle arbitrary resolutions, and some sub-native resolutions, like 2560x1080 look like shit on it, like it's been smeared with vaseline. So it really does depend on the display and if it can handle the scaling.",rtx_3080_3090_leak
"*Looking out at the*

*Sea of children too young to*

*Have lived through Crysis.*

\- Kazen_Orilg

---

^(I detect haikus. And sometimes, successfully.) ^[Learn&#32;more&#32;about&#32;me.](https://www.reddit.com/r/haikusbot/)

^(Opt out of replies: ""haikusbot opt out"" | Delete my comment: ""haikusbot delete"")",rtx_3080_3090_leak
"I'm cool with that too. Devs from games like elite dangerous and others very explicitly say that ultra settings are just high settings with the dials turned up to double, in the same way 8x MSAA is doubly as hard as 4x MSAA but doesn't look much different. Again I like it because it means if/when you come back to the game, obviously it's only subtle but it means you get a little extra out of the game you wouldn't have otherwise, and doesn't stop the game actually looking good on current hardware at launch on high

If all games games were made so that ultra and high looked basically similar but had incremental differences at the cost of a lot of performance, I'd still be glad that option was in the game. It doesn't hurt anyone (outside of people getting butthurt they can't run the game on ultra at launch)

I mainly wish Devs would be more explicit with the performance costs Vs visual costs of settings. We always see breakdowns of how much if at all settings make a difference to the quality and performance by third parties, but all we ever get in game is ""this can greatly affect frame rate"" or ""this puts load on the GPU"" at the very best. I get it's not the companies biggest priority but the ambiguity of what ultra settings actually mean (for example in doom eternal ""nightmare"" settings run really well on most GPUs while flight sim's ultra settings are impossible to run) really means the community is quick to scream unoptimisation just because they can't get ultra. 

This is also made worse by GPU benchmarks almost exclusively being done at ultra settings. It totally makes sense to do it this way, but it means people will very quickly be like ""ugh it only gets 40fps in mankind divided"" even though that's not representative of a visually equal high settings experience",rtx_3080_3090_leak
"There's not going to be any business ever that will have ""fair pricing"" unless there is competition. Also, businesses that are in a new market won't really get flamed for their prices because there's nothing to reference and usually no competition. Expecting that is not realistic and, honestly, not really possible.

AMD would absolutely do the same thing if Intel failed to release CPUs that could compete with theirs. Or same to Nvidia.

If anything, Nvidia lowering their prices would probably destroy AMD. AMD's niche is lower cost at the price of slightly worse performance. If Nvidia lowered the price of their cards while AMD is in a lull with no ""top-end"" cards, the market share would sway drastically and AMD would drastically struggle.

At that point, it would actually be a monopoly, so realistically Nvidia is doing AMD a favor by keeping their prices high. It would also cripple Nvidia because their shares would basically be all over the place. This is business 101.

I agree that the low end card being around $399 seems a bit unreasonable, but is it really that bad considering inflation, the pandemic, and [the performance scaling we have seen over the past 4 generations](https://www.youtube.com/watch?v=wF22pzWH7qg)?

Honestly, assuming benchmarks hold up and we at least see half of the performance boost we saw from Pascal to Turing, I would not feel bad about those prices, especially if the prices will eventually drop after the pandemic and when AMD comes in with competition.

As usual, my opinion will be trashed because of how reddit works, but people are really letting numbers get to their heads, especially considering we are still in the middle of a pandemic and there's no way that the costs for Nvidia *haven't* gone up since it started.",rtx_3080_3090_leak
"I mean, we all do what is in our means!",rtx_3080_3090_leak
Because I have money.,rtx_3080_3090_leak
Cause I like big numbers.,rtx_3080_3090_leak
"Sure, but it's not like these are the only three graphics cards that exist. Usually, when people talk about ""low-tier"" cards, they're talking about things like the 1660 SUPER or the RX 580. Sure, relative to the RTX 3090, the RTX 3070 is a lower tier, but that's not how most people understand the terminology. 

The context of all other price points in the market is relevant when using the term ""low-tier"" and discussing what one should expect from a ""low-tier"" card. Nobody spending $700 on a graphics card has any delusion that they're buying a ""low-tier"" card.

Regardless of all the semantics, the point stands: If I'm spending a whopping $700 on a brand new graphics card released in late 2020, and I'm playing at 2650x1440 resolution, it's not unreasonable to have expected to run any game at max texture settings. 

In mid-2015, $650 bought you a GTX 980 Ti with 6GB of VRAM, which was enough for the games of its time at 1440p. Many of us were expecting that a similarly priced card released in late 2020 would be more of an improvement in VRAM. If the leaks are true, it's not even an improvement over the previous generation's VRAM (RTX 2070/2080).",rtx_3080_3090_leak
"Uh by memory CoD might have a pre-load option. I remember this was an issue in Advanced Warfare because at that time GTX 970 came out and the card ran the game brilliantly... unless you enabled the pre-load option which on purpose filled the VRAM with stuff so that it was ready. And of course that meant it loaded shit into the infamous 0.5 GB partition that was much slower.

Alternatively the VRAM is filled but with old data that is not used at that moment, but cleaning it out takes processing power so until that needs to happen it will just sit there.  
Java works exactly this way with memory - it will keep putting stuff into memory until it reaches the maximum memory amount it's allowed to allocate and then it runs garbage collector that attempts to free as much memory in one go as it can. And then the app keeps filling the memory again.",rtx_3080_3090_leak
"I don’t know anyone’s case where it does. A ton of us are playing and posting screenshots of the Dev mode performance monitor.

Post screenshots or you’re talking out your ass.",rtx_3080_3090_leak
My bad not familiar with that tech or those cards I guess. Thats why I am on the nvidia sub.,rtx_3080_3090_leak
I hope so! We'll always be moving in that direction. It's just hard to buy at the bleeding edge all the time.,rtx_3080_3090_leak
"Yeah, but that is the point, they care more about resolution and quality than about high refresh rates",rtx_3080_3090_leak
"They do care about frametimes and smoothness, as well as screen tearing. All of these things simply function better at higher and more consistent framerates. 

This idea that the human eye can only see 30fps got debunked a long time ago, and most people can admit 90 fps looks much smoother than 60fps, and the science says we have no idea what that upper limit on framerates are, but at the last, 90-120 is noticeable to most people.",rtx_3080_3090_leak
What games do you play? I didn’t realise my rig was that strong.,rtx_3080_3090_leak
"Agreed. Even single player games feel so much better to play, not to mention more responsive, with really high frames.",rtx_3080_3090_leak
"please God, launch with dlss2",rtx_3080_3090_leak
Perhaps [this other comment will help explain why](https://www.reddit.com/r/nvidia/comments/ii6179/nvidia_geforce_rtx_3090_and_geforce_rtx_3080/g3550h5/).,rtx_3080_3090_leak
"All in One 🅱️in  

Sounds like a scouser holiday",rtx_3080_3090_leak
3070 will be announced the same time but coming after 3090 and 3080,rtx_3080_3090_leak
"The day to day use is the biggest jump imho. It's noticeably much more responsive loading files it's also much faster. I am not able to comment on video editing.

One practical reference is loading a very large Minecraft modpack. My friend's 4790k (much faster than a 3770k) could load up the pack in about 8:30 and some odd seconds. My 3700x could finish in 6:00 flat. Both installations were on solid state storage. Over 2 minutes faster is a huge jump for the newer processor architecture.",rtx_3080_3090_leak
"[Here you are.](https://www.curseforge.com/minecraft/modpacks/integration-by-parts) It's a new pack called Integration By Parts. A lot of rebalances, guided progression, and custom multiblock machines.",rtx_3080_3090_leak
"You bother with it because it crushes in all non gaming tasks and if your gaming computer is multi purpose (mine is my Plex server), you are talking on discord, and you like to keep Netflix or YouTube open on the other screen then the extra cores matter. Unless you LITERALLY only have the game open when you game then Intel makes sense, but I'm the real world everyone has a lot of shit going on in the background",rtx_3080_3090_leak
Look not going to argue with a fanboi think what you want,rtx_3080_3090_leak
I can’t even decipher that..,rtx_3080_3090_leak
"Yeah, not significant for most users and more importantly nowhere near the 40% you declared.


EDIT: To add, the 8700k being 10% faster in total war is an outlier, as the two are usually within single digit percentages. https://www.anandtech.com/bench/product/2520?vs=2127",rtx_3080_3090_leak
"Stay with that. I upgraded to 1440p 144hz and honestly for the amount of money it was, meh. The graphical change wasn’t that great and now it’s a guaranteed hit to frame rate with the higher resolution. 

Stick it out until there’s a card that for 4K and whatever FPS you want at your price point. I’m not sure why everyone gets hung up on the last two numbers of whatever card they are getting.",rtx_3080_3090_leak
"Yeah lots of weird misinformation and I guess old anecdotal stories. ""It didn't work once for me so I'll swear fealty to Nvidia.""",rtx_3080_3090_leak
Almost like it's two different divisions and fields of expertise.,rtx_3080_3090_leak
"Didn't have Navi, but had Polaris and Tahiti and had absolutely no issues with neither of them.",rtx_3080_3090_leak
"They moved the Slider all the way to One side.

GPU --------------|- CPU",rtx_3080_3090_leak
Just about to say this. My Ryzen 9 3900x is a monster and i love it but i cant even think about getting an AMD GPU. I know they are two different divisions.,rtx_3080_3090_leak
"It’s because AMD and ATI are two different companies, AMD just bought them and renamed them.",rtx_3080_3090_leak
"their CPU software really isnt great either, but the hardware is less dependent in the case of CPUs.",rtx_3080_3090_leak
"They’re drivers are pretty bad compared to the competition, but it’s been like that since the ATI days, every time a new GPU releases it’s the same “ooo this is the time they’ll finally iron out the driver issues” but it never comes lol. I’ve always bought their cards and personally have never had an issue, but the amount of people having issues is too large to ignore, and the first time I do have an issue I’ll look into jumping ship to nvidia lol. In hope eventually they can get things working right because we need some pressure on nvidia to get the prices down a little. The mantra lately is “if you’re trying to just get one that works buy nvidia. But if you want to save a little money at the risk of crashing and burning you can try amd",rtx_3080_3090_leak
their cpus weren't exactly great either till a few years ago,rtx_3080_3090_leak
"Because catalyst is burned into my skull, and needing to find something like 3rd party omega drivers. Also I mentioned issues with 144Hz and I dont think we had those back in the catalyst days. Or FF14.

last card was an r9 380, in my kids PC still. I apologized and said they can have my 1070 when i upgrade.",rtx_3080_3090_leak
"Yes, I was using ati with catalyst drivers for a 144Hz monitor to play Final Fantasy 14 back in 2006.",rtx_3080_3090_leak
So basically the same performance compared to the 3070 according to some rumors.,rtx_3080_3090_leak
Agreed. My 2070S does overclock very well. Hopefully Ampere is a significant jump,rtx_3080_3090_leak
"Really? I'd be more surprised if they didn't have a card that's at least somewhat better than the xx70 tier of nvidia cards to stop a 3070 super being too expensive, they've always at least had a card at that level of performance",rtx_3080_3090_leak
"I've mainly had amd myself, 7950, r9 290 crossfire (mental heat ik) then 980ti, need an upgrade now badly",rtx_3080_3090_leak
"No one knows if ""Super"" cards are coming at all.",rtx_3080_3090_leak
"nope, more like 3,xx the performance.... if you like good performance at reasonable power consumption, the 3070 or 3060 might be your choice",rtx_3080_3090_leak
"I agree. However, I think a number of factors suggested amd might pull it off this time. Next gen consoles using AMD architecture, lots more money from a very successful recent CPU lineup.",rtx_3080_3090_leak
May I pay a premium instead?,rtx_3080_3090_leak
"I still think they'll have a traditional titan. Titan RTX was $2500? I just have a hard time believing nvidia will now charge 1k less for a ""titan"".",rtx_3080_3090_leak
"Dude, I never accused you of anything. 

You asked a question about performance, someone else said that the performance of a 2080ti is ridiculous for 1080p, which it is. Then you changed from performance to price, and brought up future proofing,   
 but the performance of a 2080ti or 3000 series equivalent is still overkill for 1080p, regardless of price, which I pointed out, and also said the ""need to have the newest/best "" mindset is why the cards have almost doubled in price over a 4 year period, which is also true.  

If you think the average pc builder wouldn't question someone for getting a 2080ti for 1080p gaming, I really don't know what to tell you. I would also question someone if they bought a school bus but was not a bus driver, because it doesn't make sense unless they have a very specific use case. Like how sensitive is your ego?",rtx_3080_3090_leak
"Honestly, buy the 2080ti if you want, but if you're going to game at 1080p, you won't be getting groundbreaking vfx either way",rtx_3080_3090_leak
"Just pointing out how silly it is to obsess over an arbitrary number. Higher frame rates are obviously better, but there's nothing special at all about the number 144.",rtx_3080_3090_leak
">but is highly possible that is because my CPU (2600X)

It is",rtx_3080_3090_leak
My first video card was a Cirrus Logic with 1mb of onboard memory on a 386/sx33. I think I understand the topic.,rtx_3080_3090_leak
Still doesn't mean the 1080ti is 'obsolete'.,rtx_3080_3090_leak
"I have run Quake II RTX on a GTX 1080 Ti with RTX on. It runs, although the low FPS makes it a fairly terrifying experience.

I really do not see the appeal of DLSS though. It being used to cheat at resolution just seems wrong.",rtx_3080_3090_leak
3 I think. That was the case with current gen,rtx_3080_3090_leak
"Dude, there are mods on Moddb (only) that have 1 million unique downloads in 24 hours. Just because it isnt as popular in Western Europe/USA doesnt mean it isnt popular overall. 

I pay for multiple high-end GPUs. I am technically more important as a customer than 99% of people that buy a GPU and play a bad game after that :P not that it matters for the argument at hand that is. 

Also you did not address Wolfenstein 2. A game without mods. Another reminder about it. You need to address this too.",rtx_3080_3090_leak
"If their statement of ""every chip has a 32bit bus"" is true, they'd have to be 2GB chips. Unless they're 16bit bus chips. I don't know. I guess we'll find out soon enough.",rtx_3080_3090_leak
"Man, if I saw 100+ fps in those games I'd get a hard bottleneck too.",rtx_3080_3090_leak
"i am ready to do exactly that, 3090 here i come",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"I've heard people mention certain cards mixing chip sizes, so what about 5 2GB chips, and 5 1GB chips?",rtx_3080_3090_leak
Right. I think there will still be a Titan but the 3090 will be a way for Nvidia to charge more than the 2080ti. The more I think about it the more I feel I need to practice restrain upon launch. It all depends on how much the 3090 will cost really.,rtx_3080_3090_leak
"Good deal.

Yeah, I'm hyped for the launch/keynote - but, it looks like I'll be waiting a little while to get a card.  

If any news about a 20GB AiB 3080 comes anytime soon, I'll probably be waiting for that over a 10GB launch 3080 unless it turns out to be a year long wait/refresh.  



Or hey, maybe they release the 3090 for 1,000 or less?  Heh, ^heh, ^^heh, ^^^heh...",rtx_3080_3090_leak
I checked prices on tweakers.net (Vraag & Aanbod part),rtx_3080_3090_leak
"But again, looking at the core count between the two the 3090 will be considerably faster. Time will tell.",rtx_3080_3090_leak
"I have a 48"" CX since last month, been running it with a custom resolution of 3840x1600 and it easily destroys my older monitors (PG35VQ and PG27UQ) in every possible way.",rtx_3080_3090_leak
Wanna toss my monitor for the TV. I love couch gaming!!,rtx_3080_3090_leak
"You got some high hopes there friend. 8k isn't twice as many pixels as 4k, it's 4 times as many pixels.",rtx_3080_3090_leak
"It helps that Turing was only a marginal upgrade, and not the usual generational leap in performance. I have a GTX 1080 and you can absolutely feel that it has aged. It's still a fine card, but it'll be slower than Nvidia's entry level card next year (2660 or whatever they call it).

I usually go 4 years between upgrades (2 if I go with a lower end card), but you really can't futureproof for longer than that with a GPU. With a flagship, maybe, but if you own a flagship, you probably game on the cutting edge, so having to lower settings or resolution won't cut it. GPU performance deteriorates quickly when a new series comes out due to how games are optimized.",rtx_3080_3090_leak
"Still talking out of your ass, I see.",rtx_3080_3090_leak
Ah interesting. I was hoping that 4k 60 won't need much more than 8gb vram with the 3070 being that low haha.,rtx_3080_3090_leak
"I'm kind of banking on VR games starting to support DLSS 2.0

I guess I can just get a 3080 and if I find it's not good enough for future VR I can always sell it and get a 3080 Super or whatever.",rtx_3080_3090_leak
"If thats the case, I imagine theyll do a wave to get rid of their samsung process stock, and then move to TSMC and do a faster more power efficient set (supers)

But I dont see that being something they can do fast, and if they dont announce more vram options at launch, I imagine it will be at least 8 months before we see more.",rtx_3080_3090_leak
I recently upgraded to a 27 inch monitor and still got a 1080p one. High refresh rate is too addictive :(,rtx_3080_3090_leak
"Yeah, understandable. It's just that the 3080/3090 are primarily aimed at high resolution and high refresh rate, so you won't get your money's worth immediately. On the other hand, it would comfortably last you many years.",rtx_3080_3090_leak
Yeah I was just being insanely generous to show that even in insanely generous scenarios it is only 2GB.,rtx_3080_3090_leak
"Maybe borderline for extreme scenarios, and even then. I got a 2070S with 8gb and dont come close to running into any vram issues. On 1440p/144hz too which while not 4k is still way higher than what 80% of people use. Calling 8GB ""borderline"" is beyond bs. Most people play just fine even with 4 these days, and 8gb will be fine for years more still.",rtx_3080_3090_leak
"I couldn't find the quote for estimated VRAM, but

https://news.xbox.com/en-us/2020/03/16/xbox-series-x-tech/


And another source was quoting at least 3gb isnt usable for games. The CPU portion is probably going to use 4-8GB so that limits vram 5-9GB. Based on current gen proportions it looks like it will be 6 or 8gb focused on VRAM.

The entire purpose of using the GDDR6 pool is for fast data loading from NVME storage into VRAM. Both Sony and MSFT have been pushing hard for that tech in their marleting. PCs do not have this as an option, so larger pools of VRAM to accomodate higher bandwith is going to be a thing.",rtx_3080_3090_leak
"If the 20GB card turns out to be true and doesn’t cost an arm and a leg, yea. But not the current ones, it’s unfortunate they chose to stick with 8GB for some of these",rtx_3080_3090_leak
"The 2080ti and presumably 3070 are more than enough for 4k at *moderate* settings. Except one has more vram.

The simple fact is that a theoretical $600 product should not be segmented so drastically below a $800 halo gpu.  I would expect this on a $300 midrange option, but at $600?",rtx_3080_3090_leak
"Dunno, but if you think efficiency is that important then you should note that in your recommendations

edit: Here's a table I found on wikipedia, the spreads are pretty close across the board: https://en.wikipedia.org/wiki/80_Plus#Efficiency_level_certifications

The higher the certification level, the better the efficiency overall, but there's still not much variation between various load levels. I'm not sure how much sense it makes to spend the extra money on a 1000W PSU over a 750W PSU just to get maximum efficiency.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
Why not wait 1 month and pay 50-100 more for a huge performance increase? or if u dont want to buy a 3x series why not wait for prices to drop first for a 2070 after ampere release?,rtx_3080_3090_leak
"A lot of that is specific to gaming though and even then, to recent AAA titles. If you’re just playing Overwatch or CS:GO it won’t make a huge  difference. If you’re using productivity tools or CUDA there’s not a lot of difference either. 

I fully agree though, those features do matter to most. They matter to me and that’s why I’m upgrading.",rtx_3080_3090_leak
"What I could do is keep my vega 56 but the performance it gives kinda leaves a lot to be desired for me.

I got a good deal on the 1080ti tho so assuming it works fine (haven’t gotten it yet) I could resell it and at least get my money back.",rtx_3080_3090_leak
"lol my secret is out. I've been using a mix of high and medium settings for ages. And frankly, I generally also put the shadows and other lighting effects lower, because it always looks terrible to me. So I get by with the mainstream midrange hardware. 

Honestly, the 670 could play Witcher 3 just fine, with its 2GB VRAM I think it was, at 1080p. People couldn't get Hairworks going on the 980Tis that well, if at all, until eventually people just kind of gave up on it and refused to use it.

I have a 1060 now, at 1080p, and I suspect I can run Cyberpunk on it just fine.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Ah, compensating for your tiny genticles.",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Yeah I don’t think anyone is happy about the price increases. I’m certainly not either. I’m just saying that if a product, a GPU in this case, has X amount of memory and it turns out you need a little more than that, then you go up a tier. That’s how it works whether we like it or not. I don’t go online to whine that years ago you could get this or that for the same price, I either buy what I need to do the job or I don’t, it’s that simple really.",rtx_3080_3090_leak
I see. Yeah I am an engineer in HDD industry so we do a bit of garbage collection as well. I never really thought of having to do it in VRAM for some reason. That does make sense.,rtx_3080_3090_leak
"Ah, so now you start being rude. 
Look bro, just because your Potato CPU + GPU can’t handle more than 30 FPS in FS2020 doesnt mean anybody else can’t. You already showed us your lack of knowledge. 

But if you want a screenshot, here you go. 

[Pic](https://ibb.co/n6cTB4n)",rtx_3080_3090_leak
"No prob. But the fact that games demand more than 8GB on 1440p remains. And that’s without Raytracing and other fancy stuff...

Edit: I just simply can’t imagine Cyberpunk on 1440p with ultra/high preset and RT enabled just using 7gb.",rtx_3080_3090_leak
"Mine craft, solitaire and pinball lol just kidding. So yesterday I just clocked Horizon zero dawn. Doom eternal I’m still loving trying to beat it on nightmare. Project Cars 3 I’ll get to at some stage... Before Horizon the last two games I clocked were Witcher 3 and Jedi: Fallen Order. All of the above mentioned were at 1440p with anywhere from medium through to ultra graphics settings. Worth mentioning I am over clocking my gpu as well but still",rtx_3080_3090_leak
"Oh wow, that should mean I'd see a huge improvement going from the old laptop CPU to a top of the line desktop one.",rtx_3080_3090_leak
"Cool once the 3080 comes out and I build this system I'll have to check Minecraft out. I played Terraria some and I know it's a side scroller, but there are similar themes. I enjoyed Terraria. So I'm sure I'll like Minecraft.",rtx_3080_3090_leak
"You wont experience game slowdown with discord, web browsing or youtube on any modern intel proccesor.   


The extra cores count in rendering, workstation tasks. But offer no real world advantage.   


I own both a 9900k and a 3950 in my office. These arnt teams, theyre products.",rtx_3080_3090_leak
"Its  a product, not a sports team. Buy for your use case.",rtx_3080_3090_leak
"A 2 generation old cpu. 

thanks for proving my point.",rtx_3080_3090_leak
"Yessir. I had an old ATI card that was a horror to get even simplistic world of warcraft running off of consistently. Then the R9 380 I had problems with. I had a few other friends comment problems with AMD. Again, just stories. But ive had 5 of 5 western digital HDDs die on me and a friend swears by them.",rtx_3080_3090_leak
"Yeah, not sure I'd expect any different from the nvidia sub though. AMD cards aren't quite as reliable as Nvidia's but the value is often good enough to make it worth it. It's hard to tell whether it's going to be the case this generation until we see benchmarks and prices from both.",rtx_3080_3090_leak
This is true lol.,rtx_3080_3090_leak
[removed],rtx_3080_3090_leak
"I had a 7970 and never got any problems. Sold it to a friend, neither did he and now still hasn't got any with a RX 580. However other friends did have problems with AMD so I guess it depends on your luck, I guess.",rtx_3080_3090_leak
No issues with my 7850. Constant problems with my 5700xt.,rtx_3080_3090_leak
Or just wait till the cards are released before making up your mind.,rtx_3080_3090_leak
What card do you have? Afaik all outstanding driver issues have been resolved,rtx_3080_3090_leak
Do you have a link? I have only found a timespy leak which shows the 3080 being a 30% boost. Which would imply the 3070 being about the same as 2080 ti but curious to know how close since on specs the 3070 seems lacking.,rtx_3080_3090_leak
Anythings possible! Lets hope they get the drivers polished this time around. The CPU's seem to be from a different universe from Radeon cards.,rtx_3080_3090_leak
"Adam Jensen almost word-for-word stated that the 3090 is a titan replacement.  
He called the 3080 the current flagship for gaming (I assume gaming only/gaming focused purposes)

Lets remember that titans used to cost a lot less. Back in 2016 the titan X was 1200usd.

Its possible NVIDIA sees it fragements the market too much, and that they need a more transitional card.",rtx_3080_3090_leak
Why would I buy a 2080ti? We've been talking about the equivalent performance 3000 series card and if the price is better versus the 2080ti prices.,rtx_3080_3090_leak
Ehh... really?  Obviously I meant high fps .. not exactly 144fps. You pointed out nothing and just derailed a normal conversation to be rude.,rtx_3080_3090_leak
"Sad life, the 1080Ti for me is enough luckily for 1080p, but I will see AMD and their Ryzen 4600 when they release it

I really hope they do 8 cores / 16 threads for the 4600 :(",rtx_3080_3090_leak
"5 fps is not playable.
I played ot on my 1080 Ti, it cannot do the job.",rtx_3080_3090_leak
"1 million out of 1 billion+ is almost nothing :)

You're more important? Nah, manufacturers do not give a single fuck about you, or the modding scene. Even so, Nvidia don't even make half of their money from the ""video-game oriented GPU's"" They make GPUs for gamers out of hobby, they make billions in other markets.

&#x200B;

Okay Wolfenstein 2, runs great at 4k, even if it actually uses 8GB of VRAM, that's alot of VRAM and it can shuffle it around. You are not seeing 8 gigs of texture information at any given point, its just loaded in incase you need it.",rtx_3080_3090_leak
"Or the chips have more than 32bit controller or they are 2GB chips, 24 chips on a single card it's impossible unless they are on each side that isn't common. We can only wait the presentation to be sure",rtx_3080_3090_leak
"Definitely fair play. 

I personally just always buy the last generations highest model. Which keeps my overall costs quite low when you factor in how much I actually spent between purchasing and then selling used. 

So my tower is always fairly beastly and my GPU costs me a few hundred every 2-3 years. Bought my 1080 ti when rtx cards came out, for $550 (CAD) and will probably sell it for $400+ when 30xx is out.",rtx_3080_3090_leak
I'm unsure. I may be completely wrong on this but if it's the same as mixing different sized RAM sticks on your motherboard that could be extremely detrimental to performance.,rtx_3080_3090_leak
"afaik the 2GB chips do not actually exist yet, they are in the catalog but not in production",rtx_3080_3090_leak
"I'm in the same boat. I really want a new GPU because I just got a 3840x1600 monitor. But I'm not buying the 3080 with relatively limited VRAM, and I'm not spending 1400 on a 3090 (provided price leaks are true)",rtx_3080_3090_leak
"According to leaks, it's 15% between the two cards. https://twitter.com/kopite7kimi/status/1298505452888551424?s=20",rtx_3080_3090_leak
Awesome. I want to do the jump too. Gaming monitors are overrated,rtx_3080_3090_leak
"Ah crap yeah..

Edit: It looks the the 2080ti can do 8K at 30fps already!
https://www.youtube.com/watch?v=zDFCSzQ4TrA",rtx_3080_3090_leak
"I mean, it will be ok to game 4K @ 60fps and the VRAM will be faster which will help a bit. I only see the VRAM go above 8GB in a few things. I'm just a hardware nut with higher resolution peripherals all over the place lol. I'm also heavy into VR and will continue to keep getting the higher resolution headsets.",rtx_3080_3090_leak
"That would be amazing and I hope that is the case too! That would really help out the high end resolution headsets. 

I like the stance. I also sell GPUs for new ones. The 3080 will hold it's value for a while.",rtx_3080_3090_leak
I agree if there are no announcements or hints on higher VRAM cards from the AIBs around the launch it might be a while or at least until after AMD does their launch.,rtx_3080_3090_leak
"> 27 inch monitor and still got a 1080p one

the PPI....",rtx_3080_3090_leak
"> On the other hand, it would comfortably last you many years.

exactly the plan.",rtx_3080_3090_leak
"Wolfenstein 2 with its actual Ultra settings (manually set the settings, not with presets) will make you stutter due to a lack of VRAM at 1440p with 8 GBs. It does for me, it will for you too.

Also, I am a modder... and at 4K now. Do you know what modding or VR does to VRAM at high resolutions?",rtx_3080_3090_leak
"Yes I know all of this.

There are not hard limits, you can actually use the RAM as you wish. You can have a game with a lot of VRAM and less RAM allocated than what MS states. 

I don't see how you guys are saying anything counter to what I am saying. I just believe and hope that 8GB on mid-range and above GPUs becomes obsolete ASAP.",rtx_3080_3090_leak
"Ahhh, so i can plug in a PCI Express 4.0 into my motherboard?.",rtx_3080_3090_leak
"The same reason I didn't get a 2070 Super - the (approx) £75 (let's take an average) was a fair bit more than I wanted to pay.

On the other hand, the 2070 I got was at its (Asus Dual Evo) lowest point of just £7 more than the equivalent 2060 Super.


One other factor I haven't mentioned but will now -


My GTX 970 at 28cm was literally scraping against my hdd cage.  The rtx 2070 version 1 (no longer produced) was 27cms.  I actually wanted the Asus rog strix 2070, but that is 30cms. However the version 2 dual evo I ended up getting is just 24.2 CMS and it is not a ""mini"" version, so it was perfect.

However there is another twist -

The rog strix doesn't have a DVI port.  I have an Asus 236 nvidia 3d vision monitor from 2011 which has hdmi 1.0 and dvi.  The hdmi only runs at 60 Hz, but the dvi runs at 120 Hz which is essential for 3d gaming (60 fps per eye).

The dual evo was the only asus 2070 card with a DVI port.  Short of changing my 3d monitor to a newer one with display port (a much more expensive cost...) this was the best option all round.

I've also heard the 3000s are bigger (generally) in length.  But even if that isn't the case...dvi ports are being phased out of higher end / newer cards.

So for 3d vision gaming (which if you haven't experienced it is amazing...can't go back to 2d after playing it) I worked out the best scenario all round.

Hence it wasn't just a case of waiting another month, but of weighing up ALL the variables.

Lastly you can't use a standard dvi to display port adapter for 3d.  It has to be a special dual link one that are over £100 - again pointless, as better and cheaper to buy a 2070 with dvi port.",rtx_3080_3090_leak
"Well, if you are playing Overwatch or CS:GO you don't need an RTX card, everyone has their own needs but for CAD, architectural visualization, professional rendering, AI, and CUDA in general Turing offered a lot of improvement, sometimes even staggering improvements like with ray tracing and AI applications",rtx_3080_3090_leak
Big wallet...little dick.,rtx_3080_3090_leak
"How am I an asshole? Nothing I said was making fun of people, and was just saying what my plan was. Seems like your insecure. Sorry.",rtx_3080_3090_leak
I actually am. I have so much money it's all I can do.                  :( I can buy you a 3000 series card if you'd like?,rtx_3080_3090_leak
Those aren't low tier cards those are what I scoop up my dog's poo with.,rtx_3080_3090_leak
"Sure, that's what we all *have* to do, but that doesn't mean it's bad for us to discuss how the next generation of products lines up with our expectations. What you call ""whining"" is just feedback.",rtx_3080_3090_leak
"> I’m just saying that if a product, a GPU in this case, has X amount of memory and it turns out you need a little more than that, then you go up a tier. 

Precisely, I need a little more, not over twice more that the 3090 has. And Nvidia isn't offering that right now.",rtx_3080_3090_leak
"I'm not 100% sure it's the case but when I was watching VRAM behaviour while testing something it seemed like that.

And I guess smart approach is to pre-load stuff you have high chance of encountering anyway if there's enough free space.",rtx_3080_3090_leak
"Isn’t cyberpunk 2077 going to be optimized for current gen though?  Also game engines are getting more efficient at processing high poly assets, fluid simulations, hair simulations, cloth simulations, and dynamic event calls.  While we will have far better hardware to push all of that, the binary crunching is getting more optimized for game functions.  Ray tracing is still not super well done in hardware or software optimizations, but GI and dynamic shadows should be within next gen and modern GPU performance capabilities on a fairly common level.  Also with many of the choke points now removed from a lot of the game development steps, studios should have more time to spend on optimizations in their game.  AAA development may not have those resources put into the optimization process though.",rtx_3080_3090_leak
I notice you didn't address my media server,rtx_3080_3090_leak
"Yeah bummer. I own a 2070S for main PC and a 5700XT in another, I've had hiccups in both but they both work well (with the exclusion of RT on the AMD card)",rtx_3080_3090_leak
Good Bot,rtx_3080_3090_leak
Good bot.,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"Well from what I read in the past many cards had issues for months, like navi",rtx_3080_3090_leak
"5700xt, yeah I’ve never had any issues. I think most of the driver issues are resolved, but the known issues list has a few that have been there for way too long. Also the drivers seem really sensitive to ram clocks/timing. Although my ram is overclocked and I haven’t had any issues.",rtx_3080_3090_leak
"I don't remember if this was the one I saw the rumour on but here.  
[https://www.tomsguide.com/news/amd-big-navi](https://www.tomsguide.com/news/amd-big-navi)",rtx_3080_3090_leak
So 120 is not high fps?,rtx_3080_3090_leak
I got 12 FPS on it. It completely transformed the experience. :P,rtx_3080_3090_leak
"1 million in 24 hours makes it enter AAA category. Its good for a mod. No AA or AAA game ever has 1 billion sales or unique downloads so I dont know how you use that unironically.  Only megahits or F2P monsters like Fortnite or World of Tanks can eclipse that. Your average Far Cry or Assassins Creed cannot do that in 24H.

"" You're more important? Nah, manufacturers do not give a single fuck about you, or the modding scene. Even so, Nvidia don't even make half of their money from the ""video-game oriented GPU's"" They make GPUs for gamers out of hobby, they make billions in other markets.""

Here we fully agree. Nvidia and AMD and Intel are instrumental to human progress and that matters more than gamers. I am an engineer and I am pleased with the RnD they are putting into things that matter for the output of mankind.

Wolfenstein 2 runs great until it stutters from lack of VRAM. Shuffling from RAM to VRAM even over PCIE4 is a massive hit to performance... like IDK how you can say that with a straight face. 

Face it dude, 8GB isnt optimal in 2020 or 2021 (especially). Games will get heavier again with the new consoles out.",rtx_3080_3090_leak
You are clearly uninformed on this topic.,rtx_3080_3090_leak
"Mixing memory types has been done before; to post good marketing numbers, good narrow benchmark scores, but worse real world performance.",rtx_3080_3090_leak
"Well, either way, the 2GB chips will be needed for the 20GB cards, so if it's possible to mix chips, they could still make a 15GB card.",rtx_3080_3090_leak
Exactly. Seems like this launch is not looking as hot as I once thought. Mainly because of the price leaks/speculation. Time will tell we only have a few more days left!,rtx_3080_3090_leak
That doesn't seem right. Time will tell.,rtx_3080_3090_leak
Am sure I could run war thunder in 8k60fps on my 1070ti too. Doesn't mean it can do it in an actually demanding title...,rtx_3080_3090_leak
"Also, let's keep in mind that while we are enthusiasts, most people are going to be getting 3070s for the most part, and developers are still going to target that audience the most.

Even HL:Alyx was targeting 1080s (non-ti)",rtx_3080_3090_leak
"I actually use a MacBook Pro at work and am totally fine with the 27"" 1080p when I game, thankfully I'm not too particular about the PPI. The amount of money I'll waste (on the PC specs) to have both high resolution AND high refresh rate..",rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
in your specific case this actually sounds reasonable considering the dvi vs display port. fair enough!,rtx_3080_3090_leak
You like talking about my dick. Really weird. I can pay you if you'd like to keep talking about it?,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
A media server would be an excellend use of an AMD processor.,rtx_3080_3090_leak
"Thank you, Eradik, for voting on haikusbot.

This bot wants to find the best and worst bots on Reddit. [You can view results here](https://botrank.pastimes.eu/).

***

^(Even if I don't reply to your comment, I'm still listening for votes. Check the webpage to see if your vote registered!)",rtx_3080_3090_leak
Just FYI Navi was essentially one card for the longest time. 5700XT and 5700 are the same but the 5700 is cutdown,rtx_3080_3090_leak
Yup. I really don't see your fixation on this.  There majority of high refresh rate monitors are 144hz. Naturally someone talking about wanting to play at high refresh rates is going to mention the number 144...  anyways this conversation got seriously stupid.  Bye.,rtx_3080_3090_leak
So I was kind of right?,rtx_3080_3090_leak
"I mean the titles in the video are Metro, The Division, Hitman and Witcher 3",rtx_3080_3090_leak
That's right but I will be playing sims in 4K VR here soon. Most VR games are more spec'd for the mid/lower resolution headsets though so it will be a long while where VR in general will need that kind of power. What I plan on doing will take a TON of power to do at native resolution until more things have DLSS 2.0. I do think that will come though.,rtx_3080_3090_leak
Even if my motherboard says its PCIE 3.0 compatible?,rtx_3080_3090_leak
"Thanks for the understanding

\- I don't know of course if NONE of the 3000s will have a DVI port - but even if they do...if the 2000 series is anything to go by it will only be the lower-end 3000s, and / or the cheaper branded / smaller ones

\- so as an Asus fan, I might not get an Asus 3070 (as an example - or even a 3060) with a DVI port

\- hence that £75 more I was anticipating might not be £75 only   - but another £200 to £300 for the later 3D monitors

\- or another say £125 for the special adapter I mentioned...WHICH I have read are not entirely dependable at ""switching"" the 3D on from the DVI (monitor side) to the Display Port (GPU side).

\++++++++

Fast forward to the 4000 era   - by that time I might be more inclined to upgrade my 3D monitor to a bigger (27"" versus my current 23"") one

\-  and it will of course have Display Port on it

\- and then I have the option to get a 3070 / 3070 Ti / 3080 (or whatever) - or dive into the 4000s

\- and the lack of DVI will no longer be an issue.

\++++++++

TLDR - a 3070 as now might end up costing me a couple of hundred pounds more than the 2070 I got, due to hardware incompatibility / 3D-vision necessity",rtx_3080_3090_leak
That's why I will buy a $1400 gpu,rtx_3080_3090_leak
[deleted],rtx_3080_3090_leak
"LOL, did not know that. Then Ill wait for the 3070 or 3060.",rtx_3080_3090_leak
"It's not just generational compatibility, either. They're also compatible between sizes, A PCIe x1 card fits into a PCIe x16 slot. There are slots slots without the plastic at the 'back' of the connector allowing you to even use an x16 card in an x1 slot.

""If it fits, it works."" is effectively the rule for PCIe.",rtx_3080_3090_leak
