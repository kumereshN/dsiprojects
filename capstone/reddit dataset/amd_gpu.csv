Reddit comments,tag
Sounds like Samsung 8nm is cheap,amd_gpu
"I would have been more scared if the 3070/3080 prices were higher. This tells me Nvidia knows AMD has competition coming this generation and they need to stay price-competitive.



This is likely good for consumers.",amd_gpu
They might have the ethics of a Mongol invasion but their tech really is something else.,amd_gpu
"AMD, it is GAME ON. If Lisa Su is preparing for a ""show of force"" with this Navi 2X lineup, it better fucking be GOOD. I actually liked the Nvidia broadcast app.",amd_gpu
NVIDIA's software and Ai learning is a big selling point here too.,amd_gpu
"The Ultimate Countdown marketing campaign Nvidia did was brilliant, AMD RTG needs to do something similar...",amd_gpu
"Shouldn't we all be excited? 

I'm an AMD guy but if they can't compete then I'm going to go to Nvidia. 

Brand loyalty is for suckers",amd_gpu
I think Nvidia is actualy competing with the new consoles prices. 499$ for 2080Ti performance as they say is a dumping price.,amd_gpu
"The reputable leaks on RDNA2 Says that it will be 40-50% faster than 2080ti. You couple that with the rumored focus on power efficiency by AMD to take full advantage of the TSMC process 7nm+ or whatever we are on now. Don’t forget that the Samsung silicon that has pushed nvidia to 350 TDP. 

This isn’t impossible. To me, nVidia didn’t raise prices because they think that AMD is coming with some competitive and want to get as much buy in as they can before they potentially have to lower price.

I’m waiting.",amd_gpu
$700 for a 3080 is a lot better of a price than people were expecting.  Maybe we'll see a $600 AMD GPU that approaches that performance.  All I want is 1440p and 100 FPS or so with high settings.,amd_gpu
"Im sure AMD has something good to show us, for their first RDNA generation with RT im not expecting BOOM WOW AMAZING but I am expecting it to be competitive if not on performance then on pricing.

Nvidia does seem to have learned from Turing however and double the performance of Turing for the same price is a step in the right direction, if AMD comes out punching then it might force Nvidia to lower its prices even further.

And believe me, we really do need AMD to come out throwing punches because lack of competition is how we get another generation of Turing.",amd_gpu
"If they're smart they'll leak something, but it would have to be INSANELY good.

Right now it looks like we're in the early 2000s again when nVidia was the only answer.",amd_gpu
"Anybody else catch the nickname for the 3090 as a ""BFGPU""

Aka. Big F\*ckin' GPU. 

I thought that was cool.",amd_gpu
*Poor Volta...*,amd_gpu
"In b4 refresh of Ampere at 7nm throws more dirt in the wound.

&#x200B;

Edit: Nvidia is absolutely wrecking shop on the software side too.",amd_gpu
"Since the other thread got deleted might aswell post this here.

I wouldn't say R.I.P before we see what AMD has to offer.

But i would be lying if i said a 3080 for 700$ offering better performance then a 2080ti isnt spectacular.

And so is the 3070 offering 2080ti performance for 499$.

Thinking more about it. 2080ti performance for 499$ is fucking insane though.",amd_gpu
"Amd is going to need to pull out double the performance of the 5700xt

Wish I was exaggerating",amd_gpu
Get ready to score great second-hand AMD gpu's half priced from people jumping on the hype train.,amd_gpu
My rx580 is excited for rx5700 price drops or used prices :),amd_gpu
"Why scared? AMD have the almighty, freshly announced, RX 5300!",amd_gpu
"PRICE PRICE PRICE      
is key!",amd_gpu
Just relax and let's see how RDNA 2 turns out.,amd_gpu
"I'm of the thought that if AMD had nothing competitive to nVidia in the pipeline, the prices would've plateaued not been dropped by $100. nVidia's track-record is that they do not drop prices unless they actually have something to compete with.",amd_gpu
"This is all weird to me. As someone who only casually follows the hardware news (not looking to upgrade for a bit) there seems to be a bit of Stockholm Syndrome going on. People are EXCITED about the prospect of a $400 3060? That's a GOOD deal?

""But it's X% faster than the 2060!""

Well yeah, that's what's *supposed* to happen when you launch a new product line. GPU prices have gotten way out of control.",amd_gpu
"3070 for $499 is what got my attention, 3080 looks good also!",amd_gpu
"A $1200 GPU for $500 sounds massive but remember the RTX 2080TI is way overpriced for its performance. The 2080TI is about 25% faster than a RTX 2070 super(opinion based on benchmarks compilation from different sites), very good  but not mind blowing. I think AMD will do as usual, get a competitive card to battle the 3070 and 3080 and leave the ""enthusiast"" spot alone for Nvidia.",amd_gpu
"Nvidia are going with a much more aggressive pricing schedule this time.  *They* think AMD can bring some real competition.

Calm down and as always, wait for independent benchmarks.  Obviously Nvidia are going to make their hardware look as impressive as possible at the product launch.  Lets see what the gotchas are - for a start, will the actually be available at that price.",amd_gpu
"If AMD has something good cooking, we'll probably hear about it soon. If they feel like RDNA2 is DOA, then they'll probably let this pass for a while and change their marketing strategy for Big Navi. Maybe changing it to Medium Navi...",amd_gpu
Why? This is good for amd. Nvidia is blowing them out of the park. They are being forced to innovate. I just hope they can respond.,amd_gpu
They will just have to drop the price like they always have done if true. Remember to take their benchmarks with a grain of salt.,amd_gpu
"Don't be, enough with Polaris replacements sold for 399$, which should have been 299$ at most one year ago.",amd_gpu
Please press F for my 2080Ti that I bought 6 months ago.,amd_gpu
Mods removing the threads lmao,amd_gpu
"\*If Big Navi is doubling it's spec's it's not only going to compete against the RTX 3080, it's going to just beat it. 

The RTX 3080 is 30% faster than a 2080Ti, if AMD can double the performance of RDNA1, they will beat that, just barely.",amd_gpu
scared of what? are you losing money?,amd_gpu
Yeah I’m selling my 5700xt ASAP if the 3070/80 performance is true.     Unless AMD really knocks it out of the park,amd_gpu
"I'm not worried at all. I'm inclined to believe NVIDIA's pricing is in concern to what AMD is cooking up, AMD is able to fit 2080+ tier GPU in the xbox series x. This speaks volumes if you're familiar with consoles and how they're built. This means AMD can likely sell a 2080 tier GPU for around $300. The 3060 will likely cost $350 and have 2080 performance.",amd_gpu
"If AMD doesn't at least release some details about RDNA2 before supply catches up to demand for RTX 3000, people are going to drop their money on RTX 3000 and not wait for RDNA2. AMD knows this, so if they aren't forthcoming with more info, we have to assume that RDNA2 is not up to par with RTX 3000 and it is dead before it arrives.",amd_gpu
"Yeap, I doubt that AMD will have an answer on this...",amd_gpu
"Yep. I feel I had the amd-fanboy slapped out of me today. 😂

The 3070 is spot on in price-performance ratio. I'm thinking AMD will have to sell their top tier gpu at the same price as the 3070 and will have a worse RTX performance.

I bought my 5600 XT on February and in retrospective after tons of drivers errors, having to exchange it for a different model, the Xbox Series X announcement, and now Ampere; I'm starting to feel that it was a pretty bad decision.",amd_gpu
I mean there cards are in the new console and seem very good there and affordable. I doubt they’ll get to 3080 performance but they’ll be budget beast just like they were last year.,amd_gpu
"Not sure why everyone is scared. If the Xbox is anything to go by, AMD will at the very least be competing with the 3080.",amd_gpu
Why being scared? Just buy what's better and that's it. Doesn't matter if it's Nvidia or AMD.,amd_gpu
"Bear in mind AMD have basically already told us the performance of top-end RDNA2, when they officially said RDNA2 is 1.5x the perf/W.

If you run the numbers, this means a ~300W RDNA2 card would be ~30% faster than a 2080 Ti.

So this means realistically the best they can do, if they make a screaming 300+W card is ~20-25% faster than a 3070.

But then that's without DLSS, and it'd be very surprising if AMD's 1st attempt at RT is better than Nvidia's 2nd.

So we're looking at top-end RDNA2 being:

* Faster than a 3070 without DLSS

* Slower than a 3070 with DLSS

* Slower than a 3070 in RT

That'll be a tough choice is priced the same, and DOA if more expensive.",amd_gpu
Nvidia knocked it out of the park. I don't know if AMD can have a Ryzen moment with Radeon sadly.,amd_gpu
"Less than 3% of Steam users have RTX 2080/S/Ti models. AMD won't show anything insane, AMD will show something that makes sense for most gamers.",amd_gpu
"I’m stuck on amd because of hackintoshing, but man do these new cards tempt me",amd_gpu
Nvidia 30 helps amd cpu sales. Think positive if you are a fanboy.,amd_gpu
Can't wait to pick up a second 1080Ti for under $200 for my rendering rig,amd_gpu
"Just because they don't have top place doesn't mean they don't have value. 

They are still a very competitive product.",amd_gpu
"I will continue using AMD gpus until Nvidia actually starts to support Linux. then I might make the switch, but for now, go team AMD",amd_gpu
"Why be scared? NVIDIA always dominated the GPU scene lol

This will make AMD be more competent with their new line of GPUs in the future",amd_gpu
"Please, that's nonsense. We don't know much about the new Nvidia cards aside from they appear to have a lot better ray tracing performance. That chart with the relative performance improvement says nothing about what games they used or what settings. 

Also AMD has long ago claimed 2xperformance per watt advantages in RDNA 2 over RDNA. Their codename for their upcoming release was ""nvidia killer."" 

Now who knows what the final performance will be of *either* companies next products but I feel quite confident that performance will likely be comparable between the both product stacks.",amd_gpu
"Forget about the Vega, RDNA2 is a different animal and the real deal. The moment AMD separated gaming & Enterprise, shows me they are serious about Gamers.",amd_gpu
Nothing is being sold at msrp. Good luck finding those deals.,amd_gpu
"I decided to spin up a RTX 3080 series matrix based on baseline benchmarks from Hardware Unboxed and what we saw today. I went ahead and placed RDNA2 at 100% to show if it stuck to AMD's claims. The FPS is calculated based on those percentages of performance increase. In two columns, one for a 5700XT baseline and 2080Ti baseline.

[https://imgur.com/vNyknsZ](https://imgur.com/vNyknsZ)",amd_gpu
"The 3080 performance is right where the leaks have said it would be for the last 3 months.

The leaks/calculations show a big RDNA2 will be in the ballpark of 30%-40% faster than a 2080ti, which is right around a 3080.

There's no reason to think AMD won't be able to compete with a 3080. That's been expected for MONTHS.",amd_gpu
"Never went Nvidia because their cards are always overpriced compared to AMD. Even with similiar benchmarks.

I have faith. Always get my money's worth out of a Radeon card.",amd_gpu
"I don't really get why you'd be worried about AMD right now.

Even a console APU is getting 2080 levels of performance with just 36CUs and limited cooling and power budget. They only need to scale that up to 72CUs to compete with Nvidia's 3080.",amd_gpu
are you satisfied?,amd_gpu
Poor Big Navi.,amd_gpu
"This is good news for AMD. NVidia confirmed that these GPUs are fabbed on Samsung 8nm, meaning that Big Navi will, at minimum, have a slight transistor density advantage. If Big Navi is fabbed on TSMC N7+, a 500 mm^2 die could easily exceed the transistor count of the full GA102.",amd_gpu
More excited for the Zen 3 release to be honest. Pretty sold on the 3090. Can always bet Ryzen will be phenomenal.,amd_gpu
"I hope AMD at least leaks some info in the next few days.   I don't even know when they intend to actually announce their new cards.  If I don't hear anything in the next few weeks, I will be getting a 3070.",amd_gpu
"How many times must this be said..

&#x200B;

The presentation was made with DLSS and RTX on vs Turing. It is in the damn slides. The rasterization performance is yet to bee seen. Since when do we freaking believe PR hype and fluff? Wait for reviews as always..",amd_gpu
"Depends if nvidia set these prices because they knew rdna2 performance or some other reasons. I'm still holding out until the rdna2 launch and maybe i'll upgrade my 5700xt, giving it to the wife.",amd_gpu
"The RTX 3070 for $499 offering 2080Ti performance, much better Raytracing, has DLSS, and more.... man, AMD really needs to pull a big Ryzen with Big Navi, otherwise, they'll instantly lose the high-end market again.",amd_gpu
just goes to show how powerful marketing is,amd_gpu
I'm excited if nvidia felt the need to push that hard navi2 must be great to,amd_gpu
"Nvidia has played their cards. Now it’s AMD’s turn. If RDNA 2 is impressive, then competition will thrive. If not, then I guess I’ll be a proud owner of a 30 series card.",amd_gpu
"3070 looks around 40% faster than 2070 super (around 2080 ti). Same TDP.

3080 looks around 50-60% faster than 2080 super. 23% more TDP.

They also have low amounts of VRAM. Not sure why people are scared. The only surprising thing were the prices.",amd_gpu
"I expect the top end RDNA 2.0 to be on par with the RTX 3080, with more vram (16GB), with VRS + RIS instead of DLSS and less raytracing performance. Priced at 599-649$.",amd_gpu
"From my calculations, Navi 2x (aka 57000XT \* 2) is almost on par with 3080. Maybe AMD won't compete with 3090, but most of us won't buy it anyway, so I'd say it could be good enough to compete in general",amd_gpu
"Honestly Big Navi being unable to compete with 3090 wouldn't do anything other than marketing for NVidia.

RX 570 and RX 580 still dominate the entry-level market despite being a 14mn refresh.With RDNA2, AMD can terminate Polaris's production and cut RX 5500's prices to remain dominant on this budget line, which comprises most of the total GPU sales.

So if RDNA2 gets AMD to extends this lead up to the RTX 3080, NVidia would lose a significant portion of their lead on total card sales and all they could do is claim ""oh, we still have the strongest GPU"".",amd_gpu
My Vega 56 is still going strong.,amd_gpu
"Remember folks, the bottom line is the RTX 2080Ti was the flagship for Nvidia, now replaced by the RTX 3080. In all the slides today, including the Digital Foundry benches have it against the RTX2080 Founders Edition. There is a reason why Nvidia marketing did that.

From flagship to flagship, the RTX3080 is 25%-30% faster than the 2080Ti, which is great. Especially at the $700 price tag. But that's it, that's what Nvidia has brought to the table.

All RDNA2 has to do is make up the 35% ground to the 2080Ti and then the additional 30% to be competitive with the RTX3080.

It will have the clock speed advantage, more VRAM, more bandwidth, better TDP and on a second-generation go at 7na. Not to mention the volume that TSMC can handle. On rumor laden paper, and AMD promises of a double spec RDNA, it's something absolutely achievable.",amd_gpu
Why? Navi sounds awesome.,amd_gpu
"AMD doesn't have to beat Nvidia's performance.  AMD just needs to deliver similar performance at reasonable prices.

With these CUDA cores having 2 FP32 units each, I am wondering about their specs.  They could be pulling off what AMD did with the FX CPU series.  According to linear calculation (safe bet on Nvidia GPUs to compare performance), the RTX 3070 should be 50% more powerful than the RTX 2080ti.

Edit:

I considered something about FPUs and such and...

For the 3080 to have twice the CUDA cores where each one has an extra FPU32 added, the transistor count should be demonstrating this in addition to raw performance, and I don't find the specs listed on Anandtech's article as supporting that there is at least 4 times the FP32 performance from the RTX 2080ti to the RTX 3080.

I am suspicious on the released specs.",amd_gpu
A majority of the market isn't top of the line GPUs. 🤷🏻‍♂️,amd_gpu
Friendly reminder that brand loyalism is a ridiculous and childish concept.,amd_gpu
Scared of what? Having to buy nvidia? So cringe,amd_gpu
"Hey buddy, let me tell you about an entire market of computer-buyers that don't have $1400 to drop on one component. You've spent too long on reddit pcmr and buildapc.",amd_gpu
"If AMD actually makes Navi 2x , twice the performance of the 5700xt  then we get:  
\> 2080ti is 40% faster than 5700xt, then 100% faster than 5700xt means  42% faster than 2080ti  
\> 3080 is 70% faster than 2080 and 2080ti is 35% faster than 2080, which makes 3080 35% faster than 2080ti  
\> Top end navi will likely beat the 3080 if AMD achieve what they set out to do: get 50% increase per watt and create high end cards (Atleast 33% higher watts)",amd_gpu
How can things be looking grim when we haven't seen what AMD has yet,amd_gpu
"I'm sorry, but I think nVidia > AMD, the drivers for AMD GPU's kill it for me, and nVidia is just generally more powerful. THOUGH I might end up going with an AMD GPU in my next build, because I need an upgrade from the gtx 1060 I paid $300 for back in 2016-17.",amd_gpu
"Actually Ampere is a pretty bad advancement. The flagship 3080 is barely 20-30% faster than RTX2080Ti (3090 is a Titan eqv, so not comparing). It also pulls more power and generates more heat.

The only reason it looks good at all is that pricing went from stupid back to what people were used to. But in an absolute performance improvement metric, this is as bad as Turing was.

Turing gave AMD plenty of time to get their act together, and given how poor a step forward Ampere is, it might be the last chance AMD gets.",amd_gpu
"i swear i dont go amd this time again after all problem i had with rx 480 and 5700xt 

not again 

hello 3070",amd_gpu
"Was gonna say this.. I'm quite pro amd but they better have something special before the end of the month or 3080 it is..

I mean.. 2x the 2080? Outside of raytracing? Did I see it right?",amd_gpu
Jensen would not be releasing this pricing stack if he wasn't concerned about what AMD is bringing to the table.,amd_gpu
[deleted],amd_gpu
3070 faster than a 2080ti for $499. 3090 does 8k @ 60fps. Unreal. Consoles went obsolete before launch.,amd_gpu
"There is a reason Nvidia didn't raise prices this time around. The reason could very well be because they know AMD GPUs are good. If they knew there was no competition, they'd have put the prices up.",amd_gpu
The good ole concern trolling has begun already it seems.,amd_gpu
I think AMD is probably a bit nervous. I think RDNA 2 will be good and likely hit the RTX 3070/2080 Ti performance level. But they wont have anything to take the RTX 3080/3090 imo.,amd_gpu
"We will have to see what comes of it. If Nvidia can hit these price and performance metrics there is no reason why AMD can't. 

&#x200B;

The other interesting thought is that Nvidia is not known for pricing parts low. Which means AMD is most likely very close on performance. If Nvidia was truly blowing them out of the water performance wise then they would have priced higher",amd_gpu
"I’ll wait for reviews, something doesn’t smell right, the 3070 has 1500 more cuda cores than the 2080ti for $500 less. Nvidia are either pulling something sneaky or they’re super scared of AMD",amd_gpu
Is Big Navi speculated to being 7nm good enough to upset Nvidia? Generally curious on what you guys think. I don’t know much about GPU architecture to form an opinion myself,amd_gpu
Anywhere to pre-order the 3080?,amd_gpu
Anyone know date of AMD's next GPU announcement is?,amd_gpu
"In all honesty that event totally bought me over (again).

NVIDIA simply has the expertise, besides raw GPU power they are just so much stronger on the software side.

Prices are also fair kind of, just the 3090 is a bit more than I had hoped. Competition is needed.",amd_gpu
How much should i sell my XFX RX 5700 for?,amd_gpu
they´re cheaper,amd_gpu
"https://twitter.com/kopite7kimi/status/1300845839003205633
Who knows what it means",amd_gpu
"Why, have you seen some benchmarks ?",amd_gpu
"They really got the prices right. A 3070 that has the performance of 2080Ti for 499 is mighty impressive indeed. My current 2060S cost about that much when I bought it.

I also love the tech that reads compressed data from an nvme ssd with the gpu. I suspected that they’d announce something like that, now I’m looking forward to checking out some future real benchmarks.

Overall, really cool stuff. It’s obvious that nvidia has some really smart people.",amd_gpu
"Lets just keep our fingers on the F key for now and wait for AMD to show us something.
Amd GPU division might just into a SOC supplier now.",amd_gpu
I am actually pleasantly surprised with Nvidia's price points. They are fair for what they are providing at every pricepoint.  I'm not sure AMD will be able to compete but the onus is on them to prove to me they have a reason before 9.17 to not give nvidia my money otherwise they loose me for another gpu generation or two.,amd_gpu
You should never want for some company to “win”,amd_gpu
"I agree. It's not only about the great RTX DLSS performance, the amount of new NVIDIA-exclusive technologies they showed has me worried. I think I might get an RTX 3060 or even 3070 if AMD's offerings aren't superb. I mean, I don't care if they aren't able to compete with the 3090, I can't afford $700+ GPUs, but at least gimme 3070 performance for $400-450 or smth.",amd_gpu
"The killer move is 500$ for 3070 while better then 2080 ti, considering how many future games will have rayttracing and amds implementation is likely to be worse then this 2nd gen rtx there is just no possible win for them.",amd_gpu
One word - consoles.,amd_gpu
"The 3080 is 70% faster than the 2080/5700xt in a few games already according the Digital Foundry,  and that's not including a 100% performance uplift of rtx. At $700

So nvidia at least has done what was necessary to take the conversation off consoles.   AMD can presumably double 5700k performance,  so they have the same opportunity.",amd_gpu
"Guys. I just watched the launch. Man these Nvidia cards are beautiful as they are powerful. Whoosh I haven't seen a founders edition look that freaking awesome in a while.

I've bought Nvidia all my life, but I decided I'm going to go amd / big Navi this time just so I can not have my triple boot with Linux and Mac and not have my driver issues.


But in all honesty, don't write off AMD... Remember AMD JUST took Intel to the cleaners these past two years. I have faith. And even if they don't quite come close to the 3080.... So what. May the best team win",amd_gpu
"Look, I'm an AMD fanboy. I bought a Radeon VII at launch and boy I'm not happy about it. Driver support sucks and obviously they got more important things to do than fixing bugs with a card that was discontinued months after launch.  
I really hope AMD wins by a decent margin here because if they're about the same price/performance, I'm switching to team green.",amd_gpu
4700-3080 looks like the next hot setup.,amd_gpu
"Nvidia 1st, AMD 2nd, like always. What are you scared about seriously?",amd_gpu
"Idgaf about AMD I just want better graphics performance/$, whether its AMD or NVIDIA that provides it",amd_gpu
what nVidia pulled was astonishing. I am an AMD user (CPU) so not famboy but this is crazy,amd_gpu
This won’t age well.,amd_gpu
Stop simping for private companies,amd_gpu
"still not cheap but more reasonable than the turing, upcoming console launch certainly played the role as well,if they carried this on, the ps5 / new xbox would make their prices openly stupid.",amd_gpu
Amd stock is up 300% in the past year. I'm not concerned for them.,amd_gpu
"Wait for benchmarks and tests. Nvidia is very good at marketing. Not to say that these won t be good products, but let s have the numbers in our face first.

Also, I don't think AMD is interested in the high end. The ps5 and new xbox will likely sell well.",amd_gpu
"AMD GPUs sell like hotcakes, normally as quick as they can manufacture them.

If you don't buy them because the card/drivers/stability/support/added technology is trash, don't worry. Someone else will.

Just vote with your wallet. AMD can implement the things Nvidia does perfectly, they don't need a 1500€ GPU.",amd_gpu
"I love AMD & what they've done with Ryzen (unlike Walt), but if they're not gonna win at GPUs, it's not the end of the world. Having actual competition for NVIDIA would be nice, but they definitely haven't been able to do that for a very long time. Ironically, maybe Intel can step up there.",amd_gpu
"So what if AMD doesn't win the performance war?

Being a budget-minded builder price/performance will always be king and AMD has never let me down.",amd_gpu
Personally waiting to see what AMD has to offer before I buy. If AMD flops then I'm just going for the 3070 seems like an incredible value.,amd_gpu
AMD has the resources to fight Nvidia; AMD:s stock is ten times higher than 3 years ago. This is going to be awesome for consumers. Nvidia is going all out with these prices; they are terrified of AMD.,amd_gpu
"Depends what you are looking for. If you want the absolute fastest card on the market, then yeah, but if you want a card that will still play most games at 1440p with solid fps but don't want to drop $500.... then And is a solid option.

Is AMD coming out with something soon?",amd_gpu
"Listen, AMD is in both the Xbox Series X and the PS5. They will be just fine.",amd_gpu
"Remember, always wait for the benchmarks.

The specs presented on each type of card can be ""misleading"" in terms of non-RTX performance. Unless there are benchmarks from reputable tech channels, I will hesitate to tell that AMD has outright lost to them.

That being said, I am also worried that AMD would need to run their cards so close to the redline that reliability becomes an issue. Or that longstanding history of drivers holding down the true performance of the card just like with Navi (RX 5700 XT matching RTX 2070 Super doesn't happen at launch).",amd_gpu
If AMD treats its GPU technology the same way they've been grinding intel's corpse recently they might drop a bomb on the industry and release something great and way more competetive.,amd_gpu
"As a Linux user, I'm getting an AMD GPU even if it's worse performance.",amd_gpu
"Dang, this thread isn't just a ton of fanboys. Awesome!",amd_gpu
"3080 is 60-80% faster than a 2080 yet somehow it's teraflops increased from 10-29. The raytracing performance hit still looks painful. I don't really see $699 GPU all that accessible to most gamers, looking forward to what AMD offers.",amd_gpu
It's been grim since 2015-2016.,amd_gpu
"As others have pointed out, there are signs that Nvidia expects competitive cards coming out of AMD's RTG division. Kopite7kimi's tweets also suggests this, so even if they can't quite compete with the RTX 3090, they are going to be up there with the RTX 3080.

I am, however, scared for AMD's marketing department. Nvidia's marketing was on point. People are genuinely hyped for Ampere. They need to derail that hype train and get people on board with theirs.

I'm also scared for their driver team. They have taken a lot of flak for the lack of quality in the drivers. They have a lot riding on their shoulders. If they deliver, Radeon will be able get back some mind share, as well as market share.

Edit: missing words",amd_gpu
"I haven’t paid for anything AMD related since the original phenom, whenever the hell that was. AMD hasn’t impressed me in years. It’s sad too because it would be nice to have some actual competition.",amd_gpu
So it begins ... https://twitter.com/sherkelman/status/1300842481886662658,amd_gpu
"they don't have to be insane, just affordable. most people aren't spending $700 on a GPU or $1500... -- if they can match the performance of the 3070, for $200...",amd_gpu
I'm not.,amd_gpu
This is a weird post. You would rather Nvidia to hold back and release weaker GPUs?,amd_gpu
I'm never buying an AMD card after the issues I had with my 5700 XT,amd_gpu
"I am not. I am very optimistic. I think AMD can win here just with the CPU, when there is more availability on ryzen then intel. i think RTX 30 will be a paper launch.",amd_gpu
Don't worry bois we got Radeon VII.,amd_gpu
Why’re so many people seemingly scared that nvidia showed up with a decent card? You should be mad hyped up. This is competition. This is how we end up with INSANE cards in a decade. I’d nvidia put out some fresh dog shit then progression would be slow. As the consumer you should be overjoyed any time a company releases a great product,amd_gpu
"We didn't see all that much from the presentation, the real world performance is still unknown, as is the availability of the cards, all we have seen was marketing, it does seem to be impressive, but I can't draw any conclusions until I see the reviews.

Ampere might turn out better or worse than advertised, but we won't know that until we get the exact numbers.",amd_gpu
I watched the livestream and everyone was just typing RIP AMD,amd_gpu
I'm just glad Nvidia is hitting it out of the park. Karma for fucking my x370 board over.,amd_gpu
"There is actually no RDNA2, AMD used the R&D money to buy some missiles targeting all Nvidia facilities. INSANE!!!!1111!!",amd_gpu
Those gpus are all crazy expensive. Amd's position of a budget king will be untouched,amd_gpu
"Or they can sell a 2080ti level card for under $400.
Most Steam users are on a 1060 level. That’s the market sweetspot",amd_gpu
Don't they generally have better value gpus like the rx 580?,amd_gpu
"Yes, I am curious what AMD has to offer. Let's pray for the best 🙏",amd_gpu
Paid content,amd_gpu
"Nvidia has amazing high end cards, again.  But, back in reality where most of us live, I'm sure the mid tier AMD stuff will still be competitive.  They still sell 10x more 580s than 2080 tis.",amd_gpu
If this means that AMD will be forced to offer a GPU with 2080ti performance for 399 then it is a big victory for consumers.,amd_gpu
Why? Competition is good for everyone. I love capitalism.,amd_gpu
"Why, clearly all what nVidia presented in 30 series screams how desperate they are.",amd_gpu
"I absolutely love users with GeForce 1060 / Radeon 470 explaining about how AMD ""must"" do this or that in the  $ 1000 price segment in order to whatever

Gimme something that can run games for 3-4 years at around $300 and sod off!",amd_gpu
most of us are buddy it's looking grim the rdna leaks were looking good but after nvidia showcase the leaks are bad man still buying amd if the price and performance are good,amd_gpu
"Let's face it.  It's gonna take a while for AMD to catch up with Nvidia.

But AMD will go ahead and release a high end GPU and it's probably

hard to counter 3070 with rdna 2.",amd_gpu
"My guess is Big Navi will perform similar to the RTX 3080. But I don't think they expected Nvidia to price it so low. It'll be interesting to see what happens.

Also, AMD has been very quiet about this. They need to announce the cards and Zen 3 soon.",amd_gpu
"Rumors puts rdna2 as more powerful than the 2080ti. This would line up with the 3070, meaning if AMD wants to try to compete with Nvidea, there's a hard line at $499",amd_gpu
"Once you cut through all their marketing jargon and hype its entirely possible that theyre not nearly as special as some people think. Doing some quick math the 3080 is supposed to be 2X as powerful as the 2080, with the 2080Ti already being 30% faster on average. It comes out to the 3080 being roughly around 27% faster than a 2080Ti.   
Theyve muddled their numbers to the point where I cant make heads or tails on most of their claims. Them being stuck with samsung instead of TSMC will probably give them the short term advantage but a longer term loss.",amd_gpu
"NVidia has consistently milked their customers by releasing their mid-range smaller silicon chips as their ""high end"" charging +100-200$ generation over generation for the last several years.

The 2080 was 15% better than the 1080 for +16% price, literally a DROP in price/performance gen over gen.

The reason they could do this is AMD didn't even enter the high-end space, their highest end card their latest gen was 251mm\^2 while usually ""big"" cards can be 500+

THIS \^ is what it looks like when NVidia is FLEXING, when NVidia is DOMINANT.

When NVidia announces that they made a 27 pound 3-slot thick 400 watt card with an unprecedented new power connector that is 700+mm\^2 and costs as much as the Radeon Fiji Pro Duo 1400$ or so, that is what the world looks like when NVidia is being pushed.

AMD may not have the highest end halo card but NVidias behavior is not as though there is an increasing gap between the two companies, it looks like there is a decreasing cap.",amd_gpu
"I am not scared at all...;)  How silly...;)   Sheer stupidity.  I want to see AMD's ""disruptive"" 4k Big NAVI myself.",amd_gpu
"Nvidia prices are lower this time around for a reason, they likely expect RDNA2 performance to be strong. 56 CU RDNA2 at 1.8GHz is already hitting RTX 2080-2080S level of performance.

We are yet to see what a fully unleashed 70-80 CU RDNA2 GPU can do at 2GHz+, and with dedicated fast GDDR6/6X VRAM.",amd_gpu
I think Big Navi will be more efficient but almost nobody seems to care about that.,amd_gpu
"AMD severely lacks in software features (and has for a decade). Awful drivers, barely any features to compete with Nvidia, and no high-end cards for gaming compared to Nvidia? Yea, check mate unfortunately if they don't have anything crazy up their sleeves...

Nvidia's price premium pays for itself in the long run with all of these new features Nvidia has been packing for RTX cards. Constant innovation!",amd_gpu
Remind me again when was the last time NVIDIA gave things away for free? If you think these prices are what they are because NVIDIA is your friend you're in for a rude awakening. I expect a gen refresh as soon as Navi2 rears its ugly head.,amd_gpu
In Big Navi we trust,amd_gpu
"Ehm, 3080 has TDP of 320W! That's a lot. So if AMD just doubled RX 5700XT, and with claimed 50% improvement in performance per watt for RDNA2 compared to RDNA, that's \~335W TDP for also roughly 2x performance of 2080. And on top of that we need to add architectural improvements and I would say AMD is in good position this time.",amd_gpu
"This basically an answer to consoles. For around $500 you can get either a ps5, or a much better performing gpu. They say consoles perform aroung 2070Super, this is too big of a performance difference to pass. 

We will have to see how nvidia reflex compares to the custom SSD tech by sony. But now having PCIe 4.0 and a specialized method for moving assets to the gpu, I believe performance will be similar. 

We will also need independent benchmarking to confirm. But everything points out that buying an nvidia gpu will be a better investment for you than going console. 

FPS, RTX, DLSS, and all the software AI magic baked in. I believe sony and microsoft had nvidia hold up on launching the 3060 for this same reason. 

Imagine a sub $400 3060 with better rasterization performance than console, RTX, DLSS, and everything else, this would be too much.

Maybe AMD also have something to do with Nvidia lowering their price. But TSMC node is more expensive than dirt cheap samsung 8nm. 

Thinking about what AMD need to compete with the 3070. They basically need to double the performance of 5700XT ,add RT. We know AMD RT will not be the same performance as second gen nvidia RTX. So while this card could offer similar/better rasterization to the nvidia 3070, it would still lose on featureset. So they will have to deliver on price. So basically aither better than 2x the 5700XT for a

Not even talking about defeating the 3080, they would need to go beyond double 5700xt performance for that. 

They need to secure the low end this time. They could take advantage of the lack of 3060, it leaves a hole in the market. But if they release a better than 5700XT with RT for around 300 it would make sony/microsoft unhappy, So I guess they, just like they did nvidia, will ask them to stay out of low end at least until after the holiday season. 

They also could take true advantage of node and energy efficient and make good, cheap laptop GPUS. 

In general AMD could also take advantage of the relatively low 10 and 8 GB memory of the 3080 and the 3070 respectively. Maybe give 16 and 12GB for the competing products respectively? Are they waiting for next gen HBM ?, maybe that could land them a marketing win over G6X",amd_gpu
"People are acting like some kind of doomers, ""wah it's over nvidia won, rip amd.""

Like stfu. Yeah the reveal was kinda cool. Did they show us any real world performance and or benchmarks that we can use and compare with other cards? (as some of us have also pointed out)

No. 

It doesn't even look that good. Half of the video looks like an alpha build of minecraft.

I'm hyped to see what AMD has to offer and compare both teams' new lines of gpus in the real world.",amd_gpu
"As I stated on the meme picture post that was removed because mods are lame ducks....

Nvidia is scared. A 2080ti performing 3070 (shown as equal on the graph, but his ""voice"" said ""slightly faster"") is going from $1200 down to $500.... that is a HUGE drop in price that doesn't fit Nvidia's typical way of doing things..... which proves they have information on Big Navi that we do not....

Lets be honest here, I was assuming AMD to bring us a 2080ti combatant, for $600. This was my own breaking down of rumors and leaks along side Lisa Su saying ""we will disrupt 4k gaming the way Ryzen disrupted desktop"" which back then, the 1800x was $500 and Intel's was $1000+..... so to preemptively go and shoot for $100 dollars cheap than my GUESS, just blows my mind. Nvidia must be VERY scared that Big Navi will compete.....",amd_gpu
AMD is done for. No way they can beat Nvidia,amd_gpu
Are you doubting Lisa sue bae? Get out now.,amd_gpu
"I am going to go with Nvidia almost surely. I don't trust Radeon drivers, and they just can't offer the same software innovations that Nvidia is showing. I really hope the remain competitive.",amd_gpu
[deleted],amd_gpu
RIP AMD LOL.,amd_gpu
"Did you watch the same presentation as the rest of us? 

With all those supposed super performing cards, they are not jacking up prices except for the top end model? This reeks of them expecting AMD to come out with some strong GPUs at a lower price point. That is why they frontloaded the video with lots of embellishments that have little to do with gaming. It seems they want to stick to their price point through all that extra jazz even if AMD matches their performance.",amd_gpu
"There  is a reason NVIDIA price is not that high. That reason is AMD. We do not know what they have, but it is good enough to put stop to NVIDIA continous price hiking.",amd_gpu
"Dunno why everyone is jumping to conclusions, we don't really know anything other than price. Tflops mean nothing, and up to 2x performance in RT is honestly lower than I was expecting.",amd_gpu
RDNA2 is going to surprise you. Small efficient dies undercutting Ampere in price with more or less similar level of performance atleast till 3080. Remember HD4850/70 vs GTX260/280,amd_gpu
"Ive always been planning to switch back to Nvidia, this was the nail in the coffin. My vega has been good but AMD are an absolute trashfire with their drivers, so many issues I give up, getting one of the new 3080s",amd_gpu
WDYM? AMD 5700XT shat on the nvidia counterpart for the same price bracket,amd_gpu
Nvidia is betting more on AMD's prowess than you are. Think about that.,amd_gpu
"I bought a 5700 XT December and through much software headaches that even last to the present (20.4.2), I often wondered if I should've bit the bullet and pay 60USD-ish more for a 2070, now seeing 3070's price and performance claims, there's very little reason for me to keep buying Radeon.",amd_gpu
"Fanboying is so weird. Just get nvidia if its better, you owe nothing to AMD.",amd_gpu
"It's weird to me that even with that technology their chip was not integrated into the PS5 and Xbox X, so AMD should have some arguments too",amd_gpu
"All these AMD doom sayers. People are forgetting the xboxsx has around 2080ti performance(based on tflops) and microsoft claimed power draw is the same as previous generation. Which puts the xboxsx at max 170 watt power draw (including cpu, ram, ssd, drive etc.) 

So if they make a card around the same 220 wattage as the 3070 they would have similar performance(tflops). 

Unfortunately amd has no dlss and the ray tracing metrics are incomparable but it wouldn't surprise me if amd is worse at ray tracing. 

Rumors are 500$ for the consoles (consoles either break even or loose abit of money) and this time the storage takes a more significant portion of the budget. 

I could still see amd competing though, offering better perf/$ up to atleast the 3070.

I think nvidia had some insider info about big navi, this would explain why nvidia increased the power envelope by this much.",amd_gpu
"I was looking for /s bit couldn't find it...

OMG this post was serious? Have a downvote.",amd_gpu
"Wow, so many people drinking the green kool aid...",amd_gpu
[deleted],amd_gpu
"According to Digital Foundry, the GPU in the Xbox Series X beats out the 2080Ti.

Unless both Microsoft and Sony went all-in on the specs, that is the midrange chip of the Big Navi line up. So they should have a competitor to the 3080 at least. Would be nice if they could battle the 3090, but I'll take 3080 for now.",amd_gpu
If they don't leak something in the next week or so I'm pre-ordering a 3080. No response to nvidia's announcements to me means they most likely don't have an answer.,amd_gpu
They gonna have to compete with the price for sure AND the performance. I’m excited,amd_gpu
"I have to admit nvidia surprised me with this event,never owned a nvidia card with that said the 3080 is looking mighty delicious at this very moment!! PS: I'm still waiting to see if AMD can change my mind to owning a Nvidia card my first time ever.",amd_gpu
"Was surprised they didn't cost more but at the same time they also didn't really show performance on it outside of raytracing and just said ""twice the performance (""relatively"") on one chart and we all know how charts can be. 

Also they compared to XSX on raytracing which is good, they didn't really say WHICH card they were comparing to but I'll assume the 3080 (58TF) which means the XSX at 25 has almost half. No idea how much their tensor cores boost that number by. 

I'd say AMD's raytracing will be decent at the very least because it will clearly be higher than the XSX which has to be within certain power, cooling, price restrictions (it's a whole product, not just a gpu). It's probably unlikely that they will have their own equivalent to tensor cores though cause you would assume they would've been in the XSX or PS5 if they had them. 

I'll be super curious to see how AMD prices their cards and more importantly, when and how they start talking about them.",amd_gpu
"Even if AMD manages to match non-RT/DLSS performance, do they have anything in the wings to compete with RTX IO?",amd_gpu
"Yeah...  
AMD needs to have something that's seriously cheaper and/or faster..   

I mean, on top of just the speed, Nvidia also has the cuda which is used in everything that's related to machine learning. I'm struggling to get anything running on an AMD gpu. And running them on CPU either isn't supported at all or is horribly slow and inefficient. Even with ryzen 3900x.  

The reasons for me to get a new AMD GPU are getting slimmer and slimmer :/ And I really dislike Nvidia as a company.",amd_gpu
rip,amd_gpu
[Don't be :)](https://twitter.com/kopite7kimi/status/1300845839003205633),amd_gpu
"So when is AMD planning to show big Navi, anyways? Anyone know?",amd_gpu
"yeah with Nvidia IO and FP32 2x, lol no.

&#x200B;

GG AMD your not beating the 3090 period.

They will probably beat the 3070 and maybe the 3080, but we will see.",amd_gpu
[sad reacts only](https://imgur.com/WugdBke),amd_gpu
[deleted],amd_gpu
[https://twitter.com/sherkelman/status/1300842481886662658](https://twitter.com/sherkelman/status/1300842481886662658),amd_gpu
Get jebaited.,amd_gpu
"Last time Nvidia had this level of jump in performance was going from Maxwell-to-Pascal, and AMD had *nothing* in the enthusiast-segment to compete against Nvidia for a whole year, and even then, Vega was a flop in every computational task but *mining.*

With the different technologies Nvidia is showing to go along with their new Ampere cards, AMD is going to continue fighting a steep uphill battle against Nvidia.",amd_gpu
Ok I'm just waiting for 5700XT / 2070 for the price of 580,amd_gpu
Going to have to play the cheap game. They’ve had enough time to figure it out and I feel like they can’t compete with these cards. Source: My ass.,amd_gpu
I've just looked at Nvidia's site and the 3080 has 8704 CUDA cores and the 3090 has 10496!  Those leaked specs supposedly from AIBs with boxes and everything were totally fake.  Maybe the FP32 numbers are real and there is no DLSS trickery. https://www.nvidia.com/en-gb/geforce/graphics-cards/30-series/?nvid=nv-int-cwmfg-64629#cid=gf73_nv-int-cwmfg_en-gb,amd_gpu
I think we should all panic and speculate on Reddit because reasons!,amd_gpu
"I think its possible still that AMD releases a 3080 contender, maybe even possible to take on the 3090, but to match features with nvidia, especially the memory stuff, idk if amd can do it. My faith wavers.

I also think it's important to remember that with AMD's step toward pcie 4.0 every 30 series card will pair with an AMD processor, and Intel is still out of the game for the next few years. 

Tldr: AMD IS WINNING EITHER WAY!",amd_gpu
I wonder what it will be priced like in Canada,amd_gpu
I will be more worried if they don’t tease something before the 17th because that would mean they don’t really have nothing to compete with.,amd_gpu
"I am more scared of the new mining performance these cards will have. The new memory speed and computational power means that they will probably be coveted by miners.

Source: used to run a mid size mining operation. Around 25 cards.",amd_gpu
"Their last product had solid bang/$ and was on a tiny die. 

Their upcoming product is looking to be 2x that. 

I'm giving an edge to Nvidia in terms of odds of being there go to choice but rdna 2 should be competitive.",amd_gpu
"NVidia needs to come out with something in the $200 to $300 dollar range, otherise, yeah, it's awesome and they will kill AMD at the high end, but the mass market doesn't come close to touching $500 graphics cards.",amd_gpu
I hope some money from the CPU department has gone to good use in the GPU side. The RTX 3000 series is just.... insane.,amd_gpu
If they manage to reach 2080ti performance or better at a competitive price I reckon they’ll be fine,amd_gpu
"They may have to relegate themselves to the CPU department mainly, which, at the rate Intel is going downhill, may not be too bad.",amd_gpu
"Why? The 3070 is very well priced and something that everybody that didn’t have a 2080 or above would want to upgrade to right now so that will definitely cost sales to AMD but it isn’t something that can’t be matched. The 3090 is a nicely positioned niche flagship that will probably retain the halo to nvidia as intended but if AMD is willing to accept that, it shouldn’t be the end of the world. As for the 3080, with just 10GB it is obviously a card that will be overtaken very soon by AMD, another nvidia 3080Ti type of model, or both. It’s game on.",amd_gpu
i think the reason for nvidia being so low is because they know amd has something for lower prices.,amd_gpu
"3070 is really tempting for me. It will be interesting to see what AMD can offer. Either way, I smell an interesting battle in the upcoming weeks. And I'm not even talking about Costa vs Adesanya or Khabib vs Gaethje.",amd_gpu
Even if big Navi performs well those AI features were enough to basically have me set sail already.,amd_gpu
"To be honest, Nvidia showed super performance boost... only in games with DLSS.  
Not a lot of charts was shown, specially with games without DLSS, I can assume that leap in raw performance is not that great.",amd_gpu
 [https://twitter.com/sherkelman/status/1300842481886662658](https://twitter.com/sherkelman/status/1300842481886662658),amd_gpu
"Hopefully they can target slightly lower performance for a price undercut. 15% less performance than a 3070 for 300 bucks? could be a winner.

But i don't see them competing directly.",amd_gpu
The Nvidia pricing is insane. So it honestly doesn't even matter. Goal is to drive pricing down. Nvidia did that themselves.,amd_gpu
Nvidia cheery picked (of course) the performance figures for the presentation.   They have  put huge effort into improving  the hardware begin ray tracing and DLSS.  What I want to see is gen on gen performance comparison without those.,amd_gpu
"Not yet. That was an excellent one man show, though.",amd_gpu
They are packing tons of value into these prices. Software AND performance. Dibs on a 3080.,amd_gpu
"Even if they pull off a miracle and do compete with the 3080 they're nowhere near Nvidia on the software. I have zero brand loyalty and will buy whatever I feel gives the best performance and user experience for a given use case, this has led to a Ryzen CPU in every build in recent memory I've helped people with. I can't see AMD dropping something that I could justifiably buy or recommend over its Ampere equivalent.  This shaping up the same way Pascal vs RDNA did.",amd_gpu
big navi myth died before even be born,amd_gpu
"What's to be scared about?

I love my 5700XT, but these are products we're free to choose. We're not bound by some force to only purchase one brand over another. So if Nvidia brings it (like they did), and AMD doesn't (we'll see), then I'll buy Nvidia's card.

I'm going to wait and see what AMD offers, because DLSS is no joke.",amd_gpu
Wait until a 3rd party gets ahold of the card before you pronounce AMD dead.,amd_gpu
Read my previous comments. I’m not scared for AMD at all. I think this is going to be a very competitive fall.,amd_gpu
If AMD can not undercut NVIDIA by quite a margin their absolutly terrible drivers will be the deciding factor for me. I don't care about saving 50 or 100 bucks and then having to deal with shitty drivers all the time.,amd_gpu
A really solid line-up from nVIDIA,amd_gpu
"I'm not holding my breath. They crushed Intel with Ryzen, but Nvidia won't be caught dick-in-hand. AMD is trying really hard to not earn my GPU money.",amd_gpu
I really hope AMD has better RT than Turing. Even a RTX 3070 competitor at $399 would be a hard sale with DLSS 2.0 and much better RT performance,amd_gpu
"The Big Nav seems promising, maybe there's hope",amd_gpu
AMD are probably scared as well. Honestly impressive for the price,amd_gpu
"Yeahhh doubling FP32, 8.5k cuda cores, g6x...

NVIDIA is reacting to consoles, poor 20 series $-per-fps reputation, and AMD's rapid gpu advancements. The only thing the could have done to get at AMD further would have been HBM2E.  
(But I think that co-deving G6X gives them lower prices for it, and not using HMB2E in consumer tech keeps prices higher due to overall lower demand/higher margins in servers to eat costs, which could have allowed AMD to more affordably use it anyway?)",amd_gpu
"For some reason i am not too worried for amd or hyped up about the 3000 series reveal thus far. To be honest the main point that i noticed is being pushed this generation is price to performance (for the 3070 and 3080) with the titan card renamed as 3090. Generation to generation jump in performance is around 30% from the looks of the 3070 (2070 to 3070) if it has the performance of a 2080ti. 3080 series ""double everything"" sounds marketing BS and there seems to be a catch that is missing that would be caught out during the reviews
That said, AMD has a lot of catching up to do. Even if they do Match 3080 in performance, their implementation of RT has to be on par or better than nvidia's, have a good competitive alternative to dlss, and fix their software/driver stability issues moving forward. 
Personally, i am guessing amd has something interesting up their sleeve. Lets wait and see if that turns out to be true.",amd_gpu
"Amd has never competed with high-end performance, just pricing. I’m sure the low to mid range hardware will still sell pretty well whatever they have in store.",amd_gpu
"In the presentation, he said the new Marbles was 100% path-traced, zero rasterization. Does this mean the raster cores were sitting idle while the RT and tensor cores did all the work? This is what makes me optimistic for AMD's hybrid core design: every core can do rasterized or RT work, leaving nothing idle regardless of workload.",amd_gpu
I don't want insane.  I want an upgrade to my 480 that won't burn my house or my power bills.,amd_gpu
AMD needs to make an announcement ASAP. The price on the RTX 3080 was devastating to AMD.,amd_gpu
"Looks like the 6700XT (or whatever they call it) will be $400 and the 6800XT (3080 equivalent) will be $600. If they can come out the gate with stable drivers, they'll be in good shape.",amd_gpu
"We still good in cpus, and gpus we can improve",amd_gpu
"Just buy an Nvidia GPU dude, it'll be the better product. Don't be a fanboy, just buy whatever's best for you",amd_gpu
Marketing!,amd_gpu
"It is not necessarily about performance.

If AMD has a card that gives near 2080ti performance for around $300 then they will sell tons of them.

Not everyone can afford a $1k+ graphics card.",amd_gpu
"Isn't AMD a more well rounded company? Isn't Nvidia   just a graphics card maker? Doesn't AMD have a wider market because they have the integrated graphics market also?
I really don't know so be nice.
Thanks",amd_gpu
"I am ready to upgrade from my vega 64, I really don't have any faith that AMD will pull off a miracle here. If they do, I. Will buy their card 1st day of release but if they don't, it's team green for me.",amd_gpu
"I dont think AMD can beat nvidia in features but honestly if they beat them in raw performance, undercut a bit and be more efficient at that. I think competition would be pretty fierce then.",amd_gpu
"If they can compete with 3080, they're fine. The 3090 is just an insane halo product that won't sell a lot of volume. RDNA2 will complete the transition to RDNA, so they should be competitive in terms of pricing, performance, and energy usage.

The only thing that's unknown at the moment is how they'll implement raytracing (we're guess a hybrid approach) and if they'll have any tensor cores.",amd_gpu
"i wouldn't be too worried. Nvidia had amped the power up a lot to gain the performance advantage, so they know whats coming",amd_gpu
So... When is AMD going to be showing off their cards?,amd_gpu
AMD will be more power efficient for sure and I suspect on par with nVidia.,amd_gpu
I'm just sitting here getting excited for that 5700xt price cut.,amd_gpu
"Keep in mind, that the 2x power (they say power, I can’t tell if they mean performance, or what) is not only their numbers, which are usually skewed, but also the 2080 vs 3080, not 2080Ti vs 3080.  (Which is a valid comparison since neither the 2080 nor the 3080 were the top cards.).  Rumors I’ve seen say Big Navi is 50% faster than 2080Ti, and that was on early samples, so who knows.  hopefully they have -something- competitive at the high end.  They better hurry up and release something, I’m jonesing for a fix.",amd_gpu
Honestly i do not like how THICC these GPU are. Like damn they huge.,amd_gpu
I'm just wondering if i could get anyone to buy my vega 56,amd_gpu
"Me too. Holy shit those prices are insanely good. 

Please AMD, beat those cards.",amd_gpu
"Why would it look grim or scary for AMD?
Jensen priced it so in order to be anle to compete with RDNA 2 as we all know it has shit ton of efficiency and even rdna1 chip 5700xt is only 251mm in size yet delivers  power higher then RTX 2070 and is tiny bit behind 2070s while rtx 2070 die size is 445 while 2070 super is 551mm according to google.
That in ITSELF is insane. Now imagine RDNA 2, which already has 50% performance per watt increase compared do rdna1, with 500mm die size.
If RDNA 2 flagship doesn't show its monstrocity and what it's capable of then i dunno what will.",amd_gpu
"You got a short memory. I remember the same sentiment when the gtx280 came out and all amd had was the 3870.

Not saying either way what will happen but this is by no means new ground.",amd_gpu
"Doesn't look like anything to me at all, without knowing what AMD has on deck...",amd_gpu
"I'm not worried. They're more cost effective. But that'll only get them so far. And whatever. If I can get a decent card that can play VR perfectly well, that's all I need.",amd_gpu
I am genuinely scared that Nvidia will beat AMD.,amd_gpu
https://twitter.com/sherkelman/status/1300842481886662658 :D,amd_gpu
"Think about it this way, if it's 50% more powerful than the Nvidia 2080ti (which based on rumors may be the case) then it will be about on par with the 3080.",amd_gpu
"Sorry AMD, looks like I""m gonna have to go team yellow. Gonna upgrade my ryzen for a 3000 in a year or 2, but for now I'm gonna switch to a RTX 3050/3060 since these finally have consumer grade prices.

And I""m not even talking performance. The nvidia enconder and rtx voice are way too good to pass on now that I am gonna begin streaming.",amd_gpu
"I’m hoping now that AMD has firmly stomped a mud hole in Intel and walked it dry (thanks in part to Intel shooting them selves in the face for the meantime), I’m hoping they can put the same effort into their graphics.  

5700xT was decent, but personally I’m waiting for a true replacement for the R7.  

If it needs 400 watts, so be it, so long as it is a compute monster and can render 8k at idle.  Yeah, wishful thinking.",amd_gpu
I'm interested. IIRC both next Gen consoles use amd Gpu. So I'm sure Devs will get benefits from their pc counterparts. Or was it just amd CPUs? It's been a blur these last few months for me.,amd_gpu
"Yeah, Nvidia has a very strong offering with Ampere. I may consider a 3080, and I haven't had a Nvidia GPU since RIVA TNT.

If AMD wants to compete, they'll need to deploy a 4 shader engine, 8 shader array (2x Navi 10) GPU. That's double the rasterizers, primitive engines, TMUs, and ROPs over Navi 10.

I don't think it can touch 3090 performance, but if the +50% perf/W for RDNA2 is true, they can deploy even larger GPUs to combat 3090 within the 350-400W power range. Or they'll simply push Navi 20 harder (2.1GHz+ game clock) and watercool it.

They could land somewhere between 3090 and 3080.",amd_gpu
"Considering the debacle that was the launch of the 5700XT with the blackscreen errors, yeah, they should be afraid.  I know, I lived through a month-long nightmare with the 5700XT before I returned it.",amd_gpu
"AMD should have a frequency edge. >2.1 ghz could be feasable, so a 20% lead over Nvidia there.
If only they push the number of cores, together with a good ”IPC” uplift... but it’s going to be hard to win...",amd_gpu
i think nvidia knows amd have something big but well see this is good for us,amd_gpu
Do we have any idea of a time frame of AMD giving us info on the next GPU line up ?,amd_gpu
"Why? You’re a customer, not an investor.",amd_gpu
"Amd makes superior cpus.

Nvidia makes superior gpus.

Ryzen+Rtx is a beautiful combo. My R7-3700x, 2080ti build is serving me well.",amd_gpu
"Why would u? Price wise Nvidia is not exploiting the consumer so competition is not being a huge problrm

So unless u really want an amd gpu fearing for what amd will deliver is pointless",amd_gpu
I am too.,amd_gpu
I thought the agreed configuration was amd cpu with Nvidia cards?,amd_gpu
cringe,amd_gpu
"Sad RTX 2080ti owner here. Decided to buy in Feb. I got it for a good deal but not good enough, should’ve got a preowned 1080ti.",amd_gpu
AMD is busy selling their chips to Sony and Microsoft.,amd_gpu
"Looking good for me. I sunk cash into an rx480 that's served me well, but now with a whole new build on the way, I'm looking for something a bit different.",amd_gpu
"Mining is coming back, AMD will sell tons of GPU anyway. Said that, Big Navi seems huge from rumors and insiders. So, let's see.",amd_gpu
Does anybody know when will the next conference show be aired ?,amd_gpu
And g9us arent as good as the best Nvidia gpubut they are better for price Performance,amd_gpu
I think amd is gonna target mid to high range. Their most powerful gpu would compete with rtx 3070. I hope I'm wrong.,amd_gpu
NVidia hasn’t open sourced drives yet I’m not scared,amd_gpu
From someone inside Intel atm. You just wait.,amd_gpu
"How much does Nvidia and AMD know about each others progress, work, devolopmwnt?",amd_gpu
I hope they also showcase working drivers so people have a true reason to switch. Who cares if card is more powerful than a competitor if drivers absolutely kill both the card and performance...,amd_gpu
I kinda feel bad if amd dose not make something crazy ima go with nivida,amd_gpu
When will AMD actually come with their next gen of cards?,amd_gpu
RIP AMD GPU :(,amd_gpu
"Did they allocate too much engineering and marketing time and money on their CPUs to get all their new Ryzen chips, and pushed their GPUs  as not being as high priority?",amd_gpu
"Meh, we'll have to wait and see, nvidia going back to pricing from a few years ago kinda suggests amd might have something worthwhile in the pipeline.",amd_gpu
"At the price point I epect AMD will be very delicous, if RTX price is like this. Amd maybe will be much lower?!",amd_gpu
"I don't think AMD care to compete in the high end market, they know the real market is mid range gamers. Most people can't afford to drop 1k on a GPU.",amd_gpu
"If next gen consoles are relying on them, I have some faith they can compete.",amd_gpu
"I hope RDNA2 is good, especially at the sub-$400 range.  For example, the 5600XT is a great alternative to the 2060 (comparable performance, great power consumption, good availability and sale prices, and ""good enough"" drivers).  So if AMD can repeat that and prove they're the best card for mid-range gaming and power efficiency, I'll be happy.",amd_gpu
AMD how about to wake up and start to give us some details? again you lose to Nvidia thx to your own stupidity,amd_gpu
"I disagree.  Seeing the price point for the bottom two of 3 Ampere cards proves that AMD will be competitive there.  They are trying to get out ahead of AMD in being the value player.  Amazing what real competition can do.  

Regarding the high end card though, I think the 3090 will be king.",amd_gpu
"I don't know what to think at this point. 

I felt AMD has been taking too long to come up with a high-end GPU.   
Big NAVI should have launched in 2019 and not left the High End Turing cards unchallenged. 

Now NVIDIA has only got bigger and better .  

AMD should have put more focus on Radeon future.  A part of me think the console business is holding AMD back big time.",amd_gpu
"That Nvidia did things this way and this aggressively, seems to point to them seeing AMD's upcoming devices as serious competition.",amd_gpu
"I agree but let's see real benchmarks...the metrics used were not clear.


Good for gamers regardless

Nvidias approach versus Intel's approach a bit different",amd_gpu
Very good for the consumer!,amd_gpu
"I wouldn’t be scared so soon. NVIDA left an obvious gaps between their stack for a Ti model. I expect wholeheartedly that AMD will beat the 3080 and 3070 in performance. NVIDIA strategically renamed the Titan to appear as if it was in the same segment as the gaming cards for marketing reasons (to cause that scare, and to lead regular games to believe that NVIDIA offers the superior product, and based on this thread, it’s working). 

With that said, I expect NVIDIA to release a 3080 Ti/Super and a 3070 Ti/Super to counter AMD’s offerings. 

I wouldn’t count AMD out just yet, they’ve proven that they can offer a comparable product that is more affordable. I fully expect them to force NVIDIA’s hand in releasing Ti/Super models at a higher cost then AMD competing products. 

Only time will tell, but I’m pretty certain this is going to happen.",amd_gpu
Do you own AMD stock or work there? Why do you care?,amd_gpu
And here I am still happily playing away on my R9 290...,amd_gpu
"What's the ipc difference?

Because NVIDIA will need 1.3 to beat amd with the rumored big navi specs.",amd_gpu
I have a 3700x with a 5700xt and right now im running any game I want 100 FPS + 1440p. I purchased the gpu for 300$! However my next upgrade is currently looking like the 3070 unless if AMD beats the 3070 for price to performance like they did with the 5700xt vs the 2070/2070 super,amd_gpu
"AMD pretty much HAS to come with cheaper prices and good driver support this time, I don't see them standing a chance otherwise.",amd_gpu
"I recently got a 5700xt, I’m still within the frame to return it. Should I do that and go for Nvidia? Or just stick to my AMD",amd_gpu
Interesting.,amd_gpu
"As much as Amd said that RDNA is like ryzen when it first launched, I certainly dont agree with that statement anymore. Amd is farrrr behind nvidia in perf/watt now and they were already on 7nm. Considering the performance of rtx3080. It seems like Amd isnt gonna be able to compete this generation either in higher end. And if they do get to compete with nvidia in mid range, i dont see them get much profit this time around too. Sighhh",amd_gpu
"RX 5800XT and 5900XT maybe? Idk honestly, the RX 5700 and 5600 Series are good but for the most part riddled with problems.. I hope they have something great too cause there's no say in hell I'd pay 1400U$D for a ""RTX 3090""",amd_gpu
Price for profomance. If there cards don't perform as well but are well priced it doesn't really matter.,amd_gpu
It's a price off boyssss,amd_gpu
"Put it this way, nVidia had it's weakest lineup in Turing last year with terrible pricing and no RTX hype, they were wide open to be KO'd by amd. nVidia ended with a huge majority of the market share.

What we see right now is like Pascal all over again, it took amd 2 years to match the 1080Ti with the VII. Expect the same again, nvidia decided to deal an absolute haymaker with the 3070 & 3080, amd can't compete sadly. Hopefully they'll adjust their strategy accordingly and aim for a specific segment of the market, perhaps low end low-mid, they need to stop attempting to compete across the board.",amd_gpu
"Don’t be scared, real world performance isn’t any better on ampere


https://youtu.be/UjVvXGzvPZU",amd_gpu
"I want to see how the RTX 3090 fares against the RTX Titan. It seems to me that the 3090 was going to be the Titan of this generation, but they had to pull it out of the clouds ($2500) and price it like a 2080ti replacement ($1500) to maintain their earthly crown.

On the OEM-front, RTX3000 cards are going to require higher-end PSUs and more thermal consideration from manufacturers. As long as AMD has managed to keep power consumption under control, I think they have the edge there.

For those of us who build our own machines, AMD will undoubtedly be able to compete in each segment except for maybe in Titan territory. The pricing of the ~~Titan~~ 3090 indicates nVidia knows they need to bring the Titan down to compete with AMD's upcoming flagship.

I'm excited! I'm definitely snagging an RTX 3090 for my workstation. And so long as AMD doesn't drop the ball on drivers, I'll have an RX6900 in my gaming rig -- if not for performance, then for the sake of having *69* in the name =P",amd_gpu
"Personally - I'm aiming at RTX 3060 once the release it in few months. I doubt AMD will have something competitive by then in this segment. Not to mention they don't have anything like DLSS, which may be a factor in more and more games as I'm sure nvidia will be pushing it hard. Then you have question of ray tracing support - nvidia has beta stage (Turing) behind and they have DLSS to compensate performance loss. Also the question is - how well ray tracing will be supported by game devs for AMD cards.

There is also one more problem - limited supply by TSMC, which is overloaded with gazillion of orders.

When is even AMD to announce these RDNA2 GPUs?",amd_gpu
"Just a little out of context but how does Samsung 8nm manufacturing, NVIDIA (or AMD) and the partners like ASUs, MSI work? Does NVIDIA place order for PCBs with Samsung who manufactures it and then NV sends it over to partners who can modify it per their design?",amd_gpu
"I really feel terrible, Whenever I look at that smug CEO‘s face, I really feel terrible.",amd_gpu
Doesn’t nvidia’s development of cuda make this moot for use in the data center?,amd_gpu
"AMD did say they want Big Navi to disrupt the graphics market like Ryzen did the CPU market.  If they price it like that, then people will buy it.",amd_gpu
AMD is in all the new consoles too. Poor console suckers hahahahaha!,amd_gpu
"AMD went after cpu/server market share, which was a smart move for the company as a whole. There is no way to catch up to Nvidia in graphics, no memory architecture (RDNA2) is going to compete with AI (DDLS and RTX). 

AMD should feel good about knocking intel a few pegs back, and good about not trying to fight both companies at the same time. It will take another generation or two of good earnings to fund the R&D of a better GFX card, so they took a backseat.",amd_gpu
I don't think amd will compete this generation at least there CPUs are doing well,amd_gpu
My opinion on the prices is they know how broke people are in general from covid and by lowering the price cheaper than the last iteration when it came out gives the illusion of bargain on top of putting it more in reach.,amd_gpu
"The leaker that have like 90% been right on RTX 30 series have said that AMD's Navi 2X card is really strong. 

I don't think AMD will have anything to counter the 3090 (but who cares it's a Titan in disguise) but competition is back. Rasterization is still what matter NOW, but they had to get their Ray Tracing solution sorted out quick.
Especially since Nvidia have a noticeable head start and great tech (DLSS 2.0) to lower the impact of such features.

The real deal will be Navi 3X (vs Nvidia's Hopper). Lisa Su started with Zen, step by step to make us forget about Bulldozer. It's a matter of time for AMD to be a real option in every price segment (Not just low to mid-range).",amd_gpu
maybe better drivers?,amd_gpu
"I will always prefer AMD. Why?

Because they actually give a fuck about Linux. I use Arch btw",amd_gpu
At least they make good CPUs,amd_gpu
When dem new amd cards coming?,amd_gpu
Even price cuts won’t help amd if it not competitive now. Check out the digital foundary video the preliminary numbers are kinda staggering.,amd_gpu
"if Nvidia has to strech this far it means AMD new lineup is gonna blow a lot, I only hope AMD does CDNA for the consumer and executives realize computing is not an exclusive datacenter thing, xddd (or at least add ROCm support for RDNA2)",amd_gpu
We need a statement of AMD_Robert on Team greens offerings! Or of somebody lese in RTG!,amd_gpu
"I previously thought I can keep my RVII... now? Not so sure HBM2 provides any advantage whatsoever, especially of RDNA2 will top at 80 CU's. It'll shred RVII to bits heh...",amd_gpu
"Just bought an AMD GPU, whats going on?",amd_gpu
"Take the Radeon Pro VII, add another GPU onboard, and double the RAM.

BAM! 4-way SLI with two cards.",amd_gpu
"Why? Nvidia went back to reasonable pricing and performance jumps, AMD is promising to double all aspects of Navi 1, it's pretty clear that at least the 3070 and 3080 will be matched or beat before the year is finished.",amd_gpu
Who knows someone that works at AMD?   Are they quietly confident tonight or are they drinking heavily?,amd_gpu
AMD is making the GPU for the PS5 and Series X. We have been seeing demos for those games for a while now. The main thing we haven't seen is Raytracing but it is apparently capable.,amd_gpu
I’m nervous cause I’m running Linux and from what I can tell it seems Amd cards generally run better on Linux so I’m really hoping they pull through with the gen 2 cards,amd_gpu
"As an AMD guy, I know they will respond to this in the same way they've responded to everything in their existence as a company. 

'You know... I've been looking over our current offerings guys. And I think I know what we should do next time.... More Power!'

I mean.... Those Threadrippers though. Its getting silly now lmao.",amd_gpu
"Yeah I'm gonna be selling my 5700XT and spending the difference on a 3070. I'm sure reviews will do well, considering Digital Foundry has the 3080 and it does 80% better than the 2080",amd_gpu
So am I. Honestly didn't think I would be jumping ship. AMD might not give us best of the best but we get best for our money. But man that 3070 is looking very tasty,amd_gpu
Amd will definitely have a 3070 level card. I'm so excited for AMD gpus. Because they have to undercut NVIDIA. 3070 level gpu for 399 would be insane,amd_gpu
" The RTX3080 is looking to be 30% better than the 2080Ti. So RDNA2 needs to be 60%+ to be competitive with it. If you double the specs of RDNA1, you'll get that and more.  


The kicker is, AMD is going to win with clocks and more VRAM. That alone, I feel will put them over the edge. Especially considering they have a few weeks for last-minute tweaking.  


Moreover, AMD might also have a HUGE advantage when it comes to the availability of the cards. They have the lion share of TSMC with a node on its second generation. Where Samsung has to keep up with all those orders.TBH, I think the story in the next few weeks is going to be the lack of availability of Nvidia cards and AMD's sliding in with either a winner or a photo finish competition between the two.  


This fall is going to be freaking amazing.",amd_gpu
"Well to be honest, GA102 is 627mm2 die size with 28bil transistors.

Rumoured ""big navi"" is expected to be \~500mm2 die size with \~21bil transistors according to  [this source (compiled from rumors)](https://www.techpowerup.com/gpu-specs/amd-navi-21.g923) , that's like a 33% increase in transistor count and thus unreasonable to expect the AMD card to come anywhere near it when both are fully unlocked.

GA102 actually has greater transistor density than NAVI10 which is surprising.

The 3080 however expected to only double the 2080 when RTX is on. In Borderlands 3 it looks to be around 33fps vs 61fps which is 84% ahead (still sizable increase)

""Big Navi"" should double 5700XT at the very least which is somewhat close to 84% ahead of 2080. (Ignoring raytracing performance where we know next to nothing besides some non-comparable specs from microsoft + a few tech demos)

And that $699 very aggressive and reasonable pricing for 3080 is exactly where AMD might price their flagship card. They will probably be less efficient (Nvidia claims 100% efficiency gain vs turing, while AMD claims 50% vs NAVA1X, however nvidia's numbers might be with RTX workloads which would be best case) 

No matter what, this is the largest generational improvement in performance that we have seen in a while. Makes my GTX1060 look like integrated graphics.",amd_gpu
"Well considering their GPUS will be using the same technology that is in the new consoles, it will probably be power efficient. This has always been AMDs biggest problem on the GPU front imo. Nvidia always beats them hard in efficiency. However i do not think they will have a more powerful card than 3090. But i am pretty sure their flagship will be comparable to a 3080, maybe even. That said i am probably getting a 3080 unless AMD announced their card before and its better.",amd_gpu
"I mean, judging by the released specs for the series X and PS5, it looks like the amd GPUs don't have that much to be worried about",amd_gpu
Big price cuts soon on Navi or lol,amd_gpu
"Lisa Su will bring the heat again, don't worry",amd_gpu
"Don't worry, if Nvidia weren't worried about AMD they'd have either given less or charged more for them.

I'd argue the fact the titan now runs for $1,500 and is called a 3090 is also telling. Nvidia expect competition for the 3080 and want to hold the ti name back, they wouldn't have dropped a grand off the titan and shoved off the name otherwise.

*Don't underestimate a generational leap. It mightn't look good with how AMD has performed in the past, but look at the Vega to Navi jump. 20 less CUs, lower clocks, far slower memory and the 5700xt just about matched the radeon 7 at far lower power draws.",amd_gpu
They are gonna have to bring something incredible to touch nvidias announcement.,amd_gpu
"The 30 series has 2X SM, so basically double the core count. It's going to be a tough one to beat, especially at that price.

The 3090 RTX is 36 TFlops!",amd_gpu
"There there, radeon can't hurt you, it's just a bad dream",amd_gpu
"let’s see, honestly i’ve had bad experiences because I got unlucky with my cards and so I might just default to Nvidia next",amd_gpu
Good luck red team.,amd_gpu
2080Ti performance for $200,amd_gpu
"It sounds like both Ampere and RDNA2 are going to be ROUGHLY 50% faster, give or take 10\~15% or so, which leads me to believe that amd is going to be stuck in the same position they are already in with their 5000 series vs nvidia's 2000 series. Not a bad thing, but not great either imo.",amd_gpu
This is actually a good thing. Consumers like us will be the winner either way and that's more important than AMD or Nvidia winning.,amd_gpu
I like the Ryzen but  I am going to stick with Nvidia.,amd_gpu
 this is crazy because it's probably going to force AMD to reprice the gpus at much lower then what they probably wanted too. and yes I'm totally aware that AMD usually gives you a pretty great price to performance ratio but nvidia is doing the same it seems.,amd_gpu
Sometimes it really do be like that.,amd_gpu
"I'm not sure the AMD really sees desktop GPUs as being critical to their success.

So far as I know AMD has had and still has a massive edge on Intel and nVidia with providing hardware for consoles. Even with existing GPU they still compete with up to a RTX 2070 give or take. That leaves the 2080 and up as nVidia territory, which I would assume is also the lowest market volume for nVidia.

AMD could take the top spot for bragging rights if they really wanted to, but it would only really be for bragging rights since they would be splitting a fairly small market.",amd_gpu
I am praying to Lisa Su that they can be competitive! I feel like they have to have something up their sleeve or why else would nvidia just pump out the hottest generation leap I can remember,amd_gpu
"heh, it's probably going to be the same thing we've had for the last idk how many years... AMD's high end will probably be between a \*70 and \*80s card.",amd_gpu
"On the bright side, AMD having a genuine GPU presence is the reason normal people are genuinely able to afford new gen cards at launch. Can only imagine the price of the 30 series if there was no real competition",amd_gpu
Their stick price is up $30/share. I think they’re going to crush it.,amd_gpu
Well they didn’t really put up a fight ever since 1660 ti and the super cards came out...,amd_gpu
"I widh AMD Radeon the best of luck, the fight's gonna be good.",amd_gpu
How about we wait for actual benchmarks before making these kinds of claims?,amd_gpu
"I have seen this play out many times before, I am waiting for actual benchmarks in real world usage. I will also not be jumping in so early as I know damn good and well, a Super or a Ti variant will come out by December or Q1 2021. And I remember when Lisa took over, she specifically said getting into the server market & CPUs...I’d say she ticked those two boxes. I am VERY curious to see the GPU aspect this time. I do know they have no interest in the 3090 or Titan portion.",amd_gpu
Should I buy stock in NVIDIA? Which is coming out with a new line of products?,amd_gpu
https://twitter.com/sherkelman/status/1300842481886662658?s=20,amd_gpu
This is all very exciting!! Gamers for the win!,amd_gpu
"If it's not a 3080 competitor for 500 bucks nobody is going to care. Nobody cared when AMD sold a slightly nerfed 2070 super for 100 bucks less, clearly they need to match or beat the 3080 for at LEAST 100 dollars less but probably more. I don't see how else they're gonna win here.",amd_gpu
"Linus said it best, Nvidia isn't considering AMD their main competition, they're considering Sony and Microsoft as their main competition. (PS/XBOX)",amd_gpu
they make the Gpu and the cpu. they've always been the choice for dollar per performance.,amd_gpu
"I'm not in the market at any of the price points Nvidia just announced, and frankly I'm waiting for either company to come out with something compelling. It's nice to window shop the Ferraris, but I'm not buying one.",amd_gpu
Big navi better big really big.,amd_gpu
"DF has a hands on preview up. Scary numbers.

[https://www.youtube.com/watch?v=cWD01yUQdVA](https://www.youtube.com/watch?v=cWD01yUQdVA)",amd_gpu
"Well, AMD have the consoles to worry about, maybe they will delay competitiveness with NVIDIA for next year?

I too do not see how they can match series 3000 rn. I want to be proven wrong, but I'm just not confident.",amd_gpu
"At least they have some kind of a chance, given the profits from their hardware in game consoles & Zen chips,  they're going to have more R&D money than ever.",amd_gpu
"DLSS too, devs would probably include support in most of AAA titles, ez frames",amd_gpu
"Agree, nVidia surprised gamers by the 'low' prices on the 3070 and 3080. Forget about the 3090, its basically a Titan.

AMD needs to get out some info on specs or prices, or the race is lost before it has even started.",amd_gpu
"I really think Nvidia and AMD should have started working together on a more serious level a long time ago. We could *maybe* have a theoretical best of both worlds. Cheaper for the consumer, still has these amazing feature(s) like RTX and whatever else idk lol. But that seems like wishful thinking.",amd_gpu
"Plus a year of shit drivers on AMD, go green folks",amd_gpu
"Did you listen Huang last day? 'its now safe to upgrade Pascal friends'. I am very optimistic that AMD has something big going, since NVIDIA killed its RTX 2080 ti.",amd_gpu
AMD is fine either way. Their CPUs are still on top so it's not a massive deal,amd_gpu
"They definitely came out swinging! The 3070 is just a crazy-good deal. Amazing deal.

That said, unless I was invested in AMD I wouldn't be ""scared"". No company should have your blind allegiance just because they do. Make them earn it.

What AMD has done across both sectors is really incredible but Nvidia did their due diligence. It's not fair to compare the CPU market with the GPU market but Nvidia isn't pulling an Intel. They probably realized that they couldn't afford to NOT pull a few aces from their sleeves.

That said, I'm sure big navi and such will be a good deal. Especially now that AMD can't toss out a worse card for the same price. 

Consumers are winning here.


Edited for grammar",amd_gpu
AMD has always been competitive in some way. They'll be alright.,amd_gpu
me too. it seems wining Nvidia on efficiency will be very difficult for AMD.,amd_gpu
Maybe they won’t catch nVIDIA’s performance but they can compete with adequate prices.,amd_gpu
"As an Nvidia/Intel fanboy id still say it’s way to early to tell if Navi should be on suicide watch just yet. My assumption is that it will be like the last generation where Nvidia was alone at the top end and it was a slugging match between amd and nvidia for the mainstream levels. My prediction is Amd will probably offer cards to match the 3070 and 3060 at a similar price with maybe a few bucks less to try and make up for nvidia’s greater brand recognition, Leaving the 3080 and 3090 alone at the top. Will be interesting to see how it plays out. You can really tell nvidia is throwing all the punches to keep distance between amd to prevent themselves from being in the same situation as Intel is.",amd_gpu
Lets see what AMD will deliver; Since they revolutionized the laptop market my guess is nVidia will own this generation but AMD will survive that and do better in the next one,amd_gpu
"I hope AMD can pull a ryzen for GPUs but I really doubt it, they could just focus on best price to performance at low end with how good tech is now low end is pretty much 1080p 60fps high in most games, which is more than enough for most people.

Obviously we are enthusiasts we want the best we can get and we can tell the difference between a 60fps game and a 30fps game but most ""casuals"" can't, my friend didn't even know what frame rate was until I explained it to him. 

He just called frame drops lag even in single player games, we have to remember as much as some of us may not like it the majority of gamers are ""casuals"" who don't even know what the difference between 720p and 1080p is without being shown side by side.",amd_gpu
"It’s looking very grim from my perspective. I remember seeing a comment on /r/AyyMD just the other day to the effect of “until ray tracing replaces rasterization, I don’t care about it”, which was a completely valid standpoint 3 days ago. Nvidia is pulled out all the stops. Yes, we absolutely need to see third-party benchmarks before we set anything in stone, but with double the number of CUDA cores, and more than double the transistor count at a significant node shrink, methinks that nvidia didn’t cherry pick their numbers so much as they reached into their bag of “AMD will literally have to triple their performance to touch us” and chose some benchmarks at random.",amd_gpu
Perhaps with AMD making money on PS5 & XSX GPUs the PC releases could be cheaper than expected with a loss leading mid range offering...,amd_gpu
"Even if AMD has competitive cards, I feel like dlss had basically ensured that Nvidia is gonna come out on top regardless.",amd_gpu
"Could be possible to see some RTX 2080ti’s on second hand market for about 250-350 ???? That could be enough for me since I have a Vega 64 with 2560x1080 dual display.
With a top tier Turing card I will stay pretty good for the years to come.",amd_gpu
"

AMD soon will be making phone SoCs with Samsung......waitaminute Samsung again? 

Samsung got their hands with AMD for mobile stuff and with Nvidia for computer graphic cards!

Oh, AMD is making money with each video game TV console sold.",amd_gpu
"I had amd gpus and i always had problems with them, also drivers. Everytime a blue screen when updating",amd_gpu
Idk sounds really expensive,amd_gpu
"Am I the only one seeing the new cards from nvidia over the top expensive ?

500 $ the least. what about cards that once cost 200-300 € ?????

they totally did not adress the mainstream market and nvidia introduced a new height of price and everyone is raving about it. why ???",amd_gpu
The perceived driver issues is keeping me on team green (but zen 3 for cpu!),amd_gpu
"I felt AMD getting blown out of the water in the background as i watched Live.

Wonder how AMD will compete.",amd_gpu
"Brand Loyalty was our Grandpa’s game.

They’re just out to drain us dry at this point.",amd_gpu
I mean they can't win everything and you can just use their CPU and Nvidias GPU...,amd_gpu
"I'm not

Big navi should at least be on 3080 levels or beat it in shader performance (we don't know RT)

As it seems not it will be about 2x 5700x + 20-25% clock speed + the architecture improvements",amd_gpu
"I'm still super hyped but I hope they won't bring up the price, I hope AMD is coming out with something great too.",amd_gpu
Rmemeber they are on a slightly modified 10nm process while AMD is going to be at 7nm+,amd_gpu
"What? The newer nvidia gpu are better than the old amd one's that were just to bring competition in the gpu market?
You don't say!",amd_gpu
\*NVIDIA YES\*,amd_gpu
"Yup. If Nvidia is really going to hit the market with the 3070 for 500€/$, AMD will struggle a lot...

But I guess there will be taxes on top.",amd_gpu
Let's just hope it doesn't end up like another vega,amd_gpu
It certainly looks like Nvidia have won this one. Even if AMD pull something insane. We still have to wait for 3060 + maybe s variants of the 3000 series. I’m scared.,amd_gpu
"AMD was always behind. In my opinion, they will have a good 3070 alternative for less money and that's all. Which is good enough. AMD is the leader for CPU, they can't be the leader for GPU too... I think Nvidia and AMD talk to each other and they are fine with that situation. AMD will probably release a 3070 like for like 450.-",amd_gpu
does it matter for us? as long as there is competition we are getting the best and amd is sure to bring something to the table,amd_gpu
"I was pretty worried as well with the whole smarties VS M&M's war, im going to show my support and only buy M&M's ;)",amd_gpu
"they'll still make some gpu sales, plus the cpu sales",amd_gpu
Funny that we're scared for and but gg Intel gpus.,amd_gpu
MAybe 500w vega 3 cards that can do 16k :) ... Go amd go !,amd_gpu
Wait what happened?,amd_gpu
Y'all forget that Nvidia drivers are shit,amd_gpu
They won't get bankrupt if they cannot compete with it right now. So just relax and we'll see what AMD will present.,amd_gpu
Haven't been this excited for PC and Console releases in ages!,amd_gpu
[deleted],amd_gpu
f the radeon division. they will have PTSD about this in years to come,amd_gpu
I wanna see AMD come out with some nutty dual gpu hmb2 monstrosity with insane raw performance numbers,amd_gpu
RDNA 2 has chances if it comes with very fast memory like HBM2 and upgrade its bottlenecked HDMI and DP ports to the latest versions.,amd_gpu
Does amd have an event scheduled for rdna2? If so when is it?,amd_gpu
"if they have something better than 2080ti at lower price and on time its gonna be competitive, what i serious doubt its something to go against 3090...",amd_gpu
I think if AMD has something competitive they should release it soon rather than later. They are going to be competing with console and nvidia sales.,amd_gpu
"i hope they have something we do know yet but based on the ""big navi"" leaks it seams like they will only have something between the 3070 and 3080, depending on the price it could still be a good product",amd_gpu
"Listen man I have a 5700 XT right now, like the card the drivers were ass when Adrenalin 2020 launched but let's hope that what ever they have planned is going to flip the script. If not I don't mind getting an Nvidia card to play in 4k it's what we've all been waiting for.",amd_gpu
"I posted this else where and I will post it here as well. 

AMD's response should be something that can match performance against the RTX 3070 AND cheaper. Most people that are going to upgrade are more than likely looking at the RTX 3070 and I think AMD's best move is to cater towards that crowd. If the RTX 3070 retails at launch for  $499, then AMD should released a card that can not only match that performance but retail their card at $399.",amd_gpu
"I don't see the purpose of being scared for AMD.

It is simple, we have been told that RDNA2 is supposed to be 50% better Perf/Watt than RDNA1.  

Game consoles are running RDNA 2 and judging by what is proclaimed of the Xbox Series X in raw performance, it sounds like it competes against a RTX 2080.  Of course the console GPU wont be top of the line either as they are usually the mid range of the era of release.  I am completely fine with that performance even if it isn't 3070 for a mid range.  So long as the price is right.

AMD knows it has to compete and it has already been mentioned how its working to integrate use of DirectML and Ray Tracing of some kind for the Xbox Series X (probably Sony PS5 as well, I wasn't that into watching the release info on it).

From what I gathered the major sellers are not the top of the line GPU's but the mid range.

I am more concerned for the drivers, that is about it.",amd_gpu
You weren’t before? Nvidia has always been bigger than AMD. It’s like comparing a castle to a trailer...,amd_gpu
Off topic - but - I’d like to sell my custom AMD/Ryzen powered PC on a third party marketplace. Should I put the part list together on pcpartpicker and list it on Craigslist & Facebook marketplace? Any other suggested sites I could use to find a buyer?,amd_gpu
"i use linux, so Amd rdna2 for me, i have a rx5700 its drivers are excellent.",amd_gpu
Is the 3070 150W? the 3090 250W? What is so scary really,amd_gpu
"Guys, trust me on this - Wait for Big Navi",amd_gpu
"poor soul, stop falling prey into Intel's very basic marketing department. All that i understood from that presentation that currently, the best GPU's are from AMD.",amd_gpu
"I'm scared too but not from Nvidia but from driver issue , I'll buy AMD rdna 2 again ''2nd chance'' if AMD release much better driver with better stability and more useful feature like NVIDIA DLSS 2.0 . I love Radeon Image Sharpening but it didn't add any increase in performance . At least RDna 2 should compete with Rtx 3080/3070 .",amd_gpu
"As long as they will offer GPUs in the future I will buy them. For CPUs I go with whatever is best when I upgrade.  
I really hate Nvidia from the bottom of my heart, so I won't buy GPUs from them again.",amd_gpu
Go look up the graphics demo / breakdown on the PS5. That should give you a LOT of hope.,amd_gpu
GUYS Look don't worry it's AMD I bet they are gonna make a GPU like the 3rd gen ones but I don't think they're gonna be better,amd_gpu
"I've gone AMD for 4 years and have had black screens the whole time. I'm very tired of it and I have to draw the line somewhere, especially when many games support Nvidia more than AMD. It's been great, but I'd rather have my bonus features and stability than go with more black screens for another year. On the bright side, at least my freesync panel works with G-Sync now.",amd_gpu
"Why does it matter though? I mean there's no reason to be defend a different piece of metal, go for the best one!",amd_gpu
I couldn't disagree more. If AMD doesn't BLOW us away they are dead in the water. People are bending over backwards for the 3080... Wait until the 3070 and 3060TI because those are even more budget friendly,amd_gpu
You shouldn't be scared now,amd_gpu
Lmao. Nope,amd_gpu
"It do be looking grim

...

&#x200B;

&#x200B;

&#x200B;

for nvidia",amd_gpu
"They could release a gpu, gerbil processing unit.. powered by two gerbils on a running wheel. Itd still sell out before it released.",amd_gpu
"What in the absolute fuck is going on with every single comment in the launch threads? People are losing their minds over GPUs with no benchmarks yet just because they're cheaper than the leak suggested, but still 500 minimum? Are people just bored because of the pandemic, or these all bots? Even in here, suggesting that AMD is in a grim position... What the fuck.",amd_gpu
"There is no way AMD can do better than this.  :/

100% leap over generation is unheard of.",amd_gpu
Don't discount them yet. If they release a 3070 alternative for $300 and more ram then Nvidia is gonne get fucked on sales.,amd_gpu
AMD will allways be inferior to Nvidia,amd_gpu
They focused too much on the consoles,amd_gpu
"For me they do not have to bring sthg extremelly good. That is the trend that is fvcking all of us. I'm an owner of a 1080 ti and I've decided to not buy them any new 2000 series because of their obscene price segmentation. If AMD brings at least sthg slightly better than a 2080 ti or on pair with a good price? I'm all for it. I'm sick of NVIDIA moving up the prices like no tomorrow, is getting ridiculous, it was quite annoying when I contributed with every Ti I've owned, now is getting beyond that, I'm guilty as fvck, but I won't do it again till they normalize their prices. The worst thing that can happen is AMD joining them in this insane pricing just because they have make a very good card.",amd_gpu
[deleted],amd_gpu
How many RX 480s we need to beat the 3080?,amd_gpu
what's this term that describes the OP? Concern Trolling? Gas-lighting? I forget.,amd_gpu
AMD are probably screwed (again) this gen.  £469 for a card that beats a 2080 Ti is impressive and I can’t see AMD being able to undercut that or match the high end.  I was hoping to switch back to team red but looks like I’ll be getting a 3080.,amd_gpu
"I posted something similar in the Nvidia Megathread but something is off with their calculations.

On the slides it says the 3080 has twice the performance as the 2080 and yet if we compare the 2080 FP32 TFlops, what has traditionally been used other than actual benchmarks, yes can't compare TFlops exactly but you'll see what I meaning in a second, the 2080 has 10.1TFlops, the 3080 has 29.7, just shy of 3 times the FP32 performance and yet they don't say it's 3 times faster? 

That says to me that either they'd done funky calculations in their somewhere, Ampere is actually slower per TFlop than Turing or their comparisons come from Ray Tracing being included which again wouldn't make sense as Ampere's RTX performance is supposed to be a lot better etc. 

So I don't know exactly what's going on but something seems iffy, it's like a Vega moment all over again but for Nvidia, Vega 64's TFlops were higher than the 1080Ti but the 1080Ti handily beat it all while Vega was hot and power hungry, a bit like how the 3000 series looks like with it's high TGP and big ass coolers.",amd_gpu
"RIP AMD & PS5.

$499 3070 faster than 2080Ti",amd_gpu
"I agree it looks like AMD Radeon GPUs are hosed by this if the performance numbers and prices are true.

**RTX3090 $1,499 (up to 50% faster than TITAN RTX)RTX3080 $699 (2x faster than RTX 2080)RTX3070 $499+ (faster than RTX 2080 Ti)**

There is no way RX5700XT prices can stay where they are - they will have to drop to about 250.The above Nvidia GPUs have very likely blown Big Navi out of the water before it is even launched.A Navi 10 refresh looks unlikely now.Since ""Big Navi"" is already very late, might be better to Wait^(TM) until RDNA3.",amd_gpu
"We need them to be competitive. Like, the industry, not just AMD fanboys.",amd_gpu
Jensen has strong cards in his hand,amd_gpu
"No I am not worried. Ahahaha. Looks like the rumour was right that Nvidia fucked themselves over with TSMC. See my post a month back.

Edit: The 195-225% was a rough estimate based on Navi 21 having 72CU. If it has 80CU we c increase that to a 217-250% increase over 5700XT.

>
I don't know. There's been some rumors that Nvidia buttfucked themselves and tried to get discounts from TSMC by playing them off Samsung. But that backfired and then they had to put the whole 3xxx lineup on 8nm (10nm+) as now there is no capacity cause AMD bought it all lol. (Plus TSMC is said to be p/o at Nvidia over these tricks but very happy with AMD) Internally Nvidia is worried that AMD will take the crown this year.
https://www.notebookcheck.net/More-evidence-points-towards-AMD-s-RDNA2-Big-Navi-superiority-over-Nvidia-s-high-end-Ampere-RTX-3000-GPUs.482368.0.html
https://www.youtube.com/watch?v=qMMm9nHFe0Y
Because of this Nvidia is only expecting about a 30-40% increase in performance. AMD is expecting 195-225% increase over current 5700XT. Which would put them about ~50% ahead of 2080ti.
Funny enough AMD doesn't think they will win but I think their expectations are based off off Nvidia having 7nm. Which is understandable because Nvidia DID have 7nm samples which performed 50%+ better but due to their antics they can't launch their high end cards with this node.
So Nvidia will do a 7nm refresh H1 2021. But that means that 7nm capacity is freeing up which means that AMD is switching to 5nm loooool

https://www.reddit.com/r/Amd/comments/hzjpdl/amd_essentially_confirms_5_nm_zen_4_cpus_and/fzjp3xb/",amd_gpu
"This is a big time calling out of AMD's recently discovered gusto. Team green is laying down the gauntlet. And I think AMD got caught with their pants down a little bit. The Radeon team is posturing right now, but I think it's just that. I doubt they even expected the low end 3000, non-ti to out-perform the 2080ti and for less than half the price to boot.",amd_gpu
I would be shocked if AMD can launch a card with performance close to the 2080TI. It'll probably be status quo. $50-$100 cheaper in the mid-range for 10-5% less performance with nothing at the high end.,amd_gpu
They just need to price the 3070 competitor correctly. No one thinks they're going to legitimately beat out a 3080.,amd_gpu
It's sad that the only rumors we have put Big Navi as a product that has the potential to catch up to an RTX 2080.,amd_gpu
Amd already lost. Nvidia came first they will sell shitton of cards before amd makes a step. Really bad strategy from Amd. You either present your cards in the next week or you just DOA,amd_gpu
Let's be honest here. AMD put all their Alpha engineering team on Ryzen and ATI get the left over beta team.  AMD can't afford to fight two wars against Intel and Nvidia at the same time.  The best AMD can do is to offer a 3070 equivalent card at $450 so that they can maintain their 20% market share.,amd_gpu
AMD is at least a generation behind so it's nothing really to worry about.,amd_gpu
"I legitimately don't think I'll be buying an amd card this gen by the looks of it...

I came pretty close to pulling the trigger on a 2080ti but ultimately decided it wasn't worth the money and went for a 5700 XT on sale.

Granted I won't be an early adopter anyways, I think that's for people with an addiction to pulling their hair out... But, I dont see how AMD competes this gen with the prices specs & tech we're looking at. They'd really have to blow me away. Especially since my 5700 XT purchase. The DX9 problems have been a nightmare and the performance isn't much better than my gfs Vega 56 in almost anything I play.

That said, I haven't bought bleeding edge tech in GPUs for almost a decade... But this gen I think I finally want to do that, especially since playing games like Escape from Tarkov and wanting to get as much performance at 4K as possible. I think AMD would have to offer something that can compete with the 3080 for me to stay loyal to the brand, and with their track record, I don't see that happening.",amd_gpu
They haven’t had an answer to Nvidia for like 12 years,amd_gpu
I sent my rx580 back because it was black screeningand got an nvidia and it is so much better,amd_gpu
You can claw Ryzen from my cold dead hands but I would be shocked if I don’t end up buying a 3070 early next year. I don’t see how AMD can compete.,amd_gpu
Eh I’m sticking with AMD GPUs due to their open source contributions. I’m not in need of the ultimate performance of nvidia cards.,amd_gpu
"Say what you want about Nvidia but you can't deny the fact that they're the fucking best at what they do. DLSS, ray tracing, numerous driver level AI features and what not. Their engineers are magicians.

I want AMD to deliver with RDNA2. I hope that they can pull off a Ryzen in the GPU space but unfortunately, Nvidia have set the bar too high.",amd_gpu
Let AMD first fix the 5700XT's please. Would be great if I could actually bloody use HDR and the fans didn't stop working randomly every 4-5 startups until I reload my tuning profile.,amd_gpu
Good maybe AMD can drop the price of the 5700 XT to $200 instead of being greedy fucks who doubled the price of the successor card to the RX 580 and still offered shit drivers.,amd_gpu
"Lisa, we're going to need some info before the preorders are live for the 3070.",amd_gpu
"I'm personally excited. The full Navi 21 chip is probably going to perform close to a $700 3080. That means the full Navi 21 card is probably going to be like $600. What else do we know? TSMC 7nm is more efficient than Samsung 8nm, so it will draw less power. Also, Nvidia is skimping on VRAM, so hopefully the Navi cards will offer more VRAM. Also, there is usually a cut-down variant AMD card that isn't too far off from the full die for $100 less. So you're looking at a $500 graphics card with more VRAM than the 3080 that performs in the ball park. As a GTX 1080 owner, that's exciting. 

I know I made a lot of assumptions, but I've been following PC hardware trends for quite some time now.",amd_gpu
"Looks like we will have to wait^(TM) for RDNA3 for AMD to compete with Nvidia.  
AMD have been saying 1.5xPerf/Watt improvement for RDNA2 versus RDNA.  
Nvidia just delivered 1.9x.  


AMD will likely have to drop RX5700XT pricing to where it should have been all along RX690@\~250.  
Looks like a Navi 10 refresh for lower end is out of the question now.   
RDNA2 ""Big Navi"" likly dead in the water before it even launches.",amd_gpu
As long as it’s an improvement over the 5700XT and not as expensive as nvidia cards I’ll be happy :),amd_gpu
"Time for some wild speculation...

RTX 3080 is looking to be ~1.3x faster than 2080Ti, and ~1.7x faster than 2080. I think for most people, the 3090 isn’t worth considering because of the insane price.

As for AMD: the Xbox series X is supposed to perform similarly to 2080 Super (or about 1.1x 2080), with 52 RDNA2 CUs clocked at 1.825GHz. Big Navi should have 80 CUs (1.54x 52) and clock somewhere between the XSX and PS5, so between 1-1.22x XSX. Doing the back of envelope maths, that gives us (1.1 x 1.54)=1.69x 2080 performance at XSX clocks, and up to (1.69 x 1.22)=2.07x 2080 performance at insane PS5 max boost clocks.

From this, let’s say that Big Navi is roughly 1.7-2.1x faster than an RTX 2080, or in other words 1.0-1.2x the performance of RTX 3080. It won’t beat the 3090, but a Big Navi that’s slightly faster than 3080, runs a little cooler, and is priced at <$700 would be pretty enticing to me at least.

The real spanner in the works is the fact that RDNA2/Big Navi will be on TSMC 7nm, while Nvidia is getting likely very comparable performance on the inferior Samsung 8nm. A refreshed Ampere on TSMC 7nm next year could well clock 20% higher and blow RDNA2 out of the water.

2021 sure is looking to be an interesting year for GPUs.",amd_gpu
"AMD has always been behind in consumers minds. Nvidia is the Apple of GPUs and AMD is the low income option. Not saying that is a true statement but that’s how people see it. 

Nvidia and AMD most certainly have similar tech but it’s the marketing that will kill AMD, not Nvidia with their new GPU.",amd_gpu
Merely being slightly faster and slightly cheaper/less power consumption is not going to cut it. Sure it has raytracing but how does it compare to Nvidia's? Will it have a DLSS competitor? It does not have CUDA or ShadowPlay etc. HDMI 2.1 this time? GDDR 6X? All these features need to be addressed if AMD are to compete. Rasterization performance uplift is just not enough.,amd_gpu
"Whatever it is, I’m buying Team Red. Why? Because if it wasn’t for them we would be having shitty Intel chips and nvidia price gouging everyone. Even if By May chance it’s not as competitive as the 3080, I have spoken.",amd_gpu
"It depends on your point of view. If you want to burn 500 -1500 euro, then maybe AMD isn't for you.

But I'm looking to spend 200-300 euro for my next card, so AMD will be a real option for me even if they can't compete with the 3080 which I wouldn't buy even if I win the lottery.",amd_gpu
RDNA 2 is rumored to have up to 2.25x (225%) the performance of RDNA 1. So 40%-50% better than 2080 Ti. So I wouldn't say that at all.,amd_gpu
Bold for you to assume that every PC builder has 500$ to spend on the GPU.,amd_gpu
Lol AMD GPUs...suckers.,amd_gpu
"relax. AMD have yet to show their hand. nvidias new gpus are just big power guzzlers on yesterdays architecture. much like the old AMD cards when nvidia had the lead.

Expect nvidia gpus to be at about the same or higher performance level than AMD. but AMDs cards will likely be more efficient.

big question then is just the pricing...",amd_gpu
"What you have to remember is the 5700xt has a very small die size (around 250mm2) the amount of performance we get for the size pretty good. (2070 performance at half the size) If you doubled the die size you'd probably have a card that could compete with the 2080ti.
Navi 2x is promising 50% perf per watt. So we could get 5700xt perf at around 125w (I'm rounding up here as its not exactly 50%).
I reckon we could see a card that could trade blows with the 3080 whilst drawing slightly less power. I don't think we'll see a 3090 competitor as I don't think AMD will even try to compete on that price.
I think Nvidia know this hence why they've priced quite competitively.",amd_gpu
"Sorry that's I'm not jumping on the hype train, but I'm not 'scared' for AMD, nor do I think things are ""looking grim"".

* AMD RDNA2 is going to be the GPU architecture of **both mainstream consoles** the PS5 and Xbox Series X (with Nintendo not factoring into the graphics arms race at all). There will be no lack of sales for AMD.
* For me, **mid-range GPUs** are is where it's at, from 250-450 MSRP, and if you look at the best-buy guides right now, most of them are recommending the AMD Radeon 5700 XT for 1440p (8GB), and Radeon 5600 XT (6GB) for 1080p.
   * The lowest priced GPU Nvidia just announced is the RTX3070, 8GB VRAM at **$499** MSRP (or € 520 if you live in the EU).
* AMD supports **all FreeSync monitors and TVs** out of the box (aka: the industry standard *VESA* terms Adaptive-Sync). Once you've used it you don't want to go back. I don't want to go back at least. Xbox One S and Xbox One X already support that standard as well ([https://www.pcgamer.com/xbox-one-s-and-one-x-are-getting-amd-freesync-2-support/](https://www.pcgamer.com/xbox-one-s-and-one-x-are-getting-amd-freesync-2-support/)), as will the Xbox Series X and PlayStation 5.
   * NVidia only has a limited list of  **""G-Sync Compatible"" monitors**, that does not contain a single Iiyama FreeSync monitor for example ([https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/specs/](https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/specs/)). If your monitor is not on that list, and you want to it either requires manual software tweaks or will result in having issues. In any case that is not something most buyers will go for.
* **The minimum PSU requirement** stated by NVidia for the RTX3070 is a whopping **650W** (the other two cards require a  750W PSU according to Nvidia). 
   * I just built a new PC and I put a 600 Watt Corsair PSU in there. Since I like to build quiet PCs and components that would require a more powerful PSU would be more difficult to keep cool anyway. The minimum PSU requirement by AMD for the **5700 XT is** **600W.**
* **I don't care about RTX, at all.** I can't repeat this enough. It is great for polishing up old games with inferior lightning models like Minecraft, but in other games like Battlefield the effect was really underwhelming to me. It will only be used in a limited amount of places since the new consoles, being based on AMD RDNA2 architecture, will not support RTX. Only the standard DX12 (Microsoft DXR) and Vulkan ray tracing extensions. It simply does not factor into my purchase decision at all.
* **Compatibility with AMD features** such as [https://en.wikipedia.org/wiki/AMD\_TrueAudio](https://en.wikipedia.org/wiki/AMD_TrueAudio)   is going to be better since both mainstream consoles, PS5 and Xbox Series X will use RDNA2 with Sony adding Tempest *3D* audio and Microsoft Spatial Audio.
* **I do not care about 4K** since my monitor is on my desk and it is not a TV. I do not have a 240Hz monitor, nor do I see the added value compared to 144Hz. My monitor is 1080p@144Hz. I prefer to game with FreeSync on, of course I prefer to be anywhere from 75Hz to 144Hz. I see no reason right now to upgrade from my RX580 8 GB.
   * If I wanted to upgrade to 1440p there would be an AMD card for me as well.",amd_gpu
[deleted],amd_gpu
"I wouldn't worry too much. The 3000 series is underwhelming when it comes to path tracing. It's ok in normal shader based graphics, but nothing insane. Who is going to buy a 3090? Insanely overpriced.",amd_gpu
"They fucked tbh. Realistically AMD will have to target certain price points like always, but with Nvidias prices so low it will be tough.",amd_gpu
"Am I the only one whos disappointed about the new Nvidia cards?

Abysmal TDP and only 10GB for the 3080? Pricing is also a bit on the high side. I'm surprised that people are ok with paying more. With that logic, we will arrive in a few years at 1000USD for a 5070 while wages are still the same.

Actualkly expected that Nvidia can deliver the same with 250W.",amd_gpu
"I'm not scared for them. The naming setup is just a marketing ploy. They shifted the 3070 and 3080 down 1 card in their tier then added the 3090.

IE it looks like they made the 3060 the 3070, made the 3070 the 3080, and changed the 3080 to the 3090. That's why all these cards seem cheap. They aren't, they were just renamed. Them they jacked up the price of the 3080 by $500 bucks compared to the 2080. I bet we still see a 3090 TI.

On top of all that this tweet has me curious.

https://twitter.com/sherkelman/status/1300842481886662658?s=19

That and I keep seeing people compare the possible 3090 performance compared to AMD's custom APU for the Xbox One X. Some saying it's a monster for what it is.

I recently had a discussion with a few friends of mine that RDNA is a beta chip. All of us that bought the 5700XT were beta testers. Like it or not we were the Ryzen 1 owners of the GPU world. These RDNA chips have amazing potential, AMD just needs to work out the bugs.

An example of this is that I used to have frequent driver crashes, what everyone keeps calling black screen issues. Someone told me to limit my GPU clock to 1900MHz and m Core voltage to 1000mV. When I did that not only did my black screen issues stop, my temps dropped considerably. We're talking 90-94c down to 63-70c.  Sapphire says my GPUs max frequency is supposed to be 1925MHz boost. Well my GPU if left unchecked will reach for the stars at 2027MHz until it eventually suffers a driver crash. This can happen at any temp. This tells me that while my GPU has the thermals to handle that kind of OC the silicon just can't handle the OC and be stable.

I think once AMD gets these GPUs dialed in they will be monsters just like their CPU lineup.

The fact that they're being so right lipped about it and we haven't had any leaks suggests they've got something brewing. Remember they were a leaky ship dropping info about their CPUs and GPUs non-stop... Now we're lucky to get a tease from them.

Have you guys seen the size of that 3090? That isn't them innovating. That's them being desperate to hold the lead. When you're an unthreatened top dog you don't make design changes like that, rebrand your cards, and sell them just to keep the lead.  Just ask Intel.  They didn't improve on shit for years then one day their competition caught up and steadily ran past them. Now days Intel is back to playing dirty with their compiler to try and put on an image of them keeping up.

I think we are about to see a good fight between AMD and Nvidia again.",amd_gpu
"Nah, Ampere is exactly what we thought it was a week ago. All of the new features are useless fluff for 95% of people. 3080 performance is ""*up to*"" about 40% faster than a 2080 Ti, probably ~30% on average. They were very cagey about the relative performance between the 30-series GPUs, which I thought was odd. Didn't give *any* real indication about 3090 performance.

My armchair opinion on the competitive landscape this year is exactly the same as it has been for a couple months now. I actually thought Ampere would have some big new feature that RDNA2 would have to contend with, but that didn't happen. Still just ray tracing and DLSS that people are gonna worry about.

Big Navi could totally match or beat the 3080 in raw performance. If it can actually double the performance of a 5700 XT on average, it's at least in the same conversation.

I'd compare it to the 3090 but Nvidia didn't bother telling us how fast it is. That honestly doesn't give me much confidence in a 1500-dollar GPU. 80-CU Big Navi with a matching 350W power budget might well beat that, too.",amd_gpu
[removed],amd_gpu
Me too. Me too...,amd_gpu
"These shows do nothing for me, I am not impressed at all. I'm convinced that the only thing that will impress me is third party benchmarks for either company's products.",amd_gpu
Why ? You work for Amd ?,amd_gpu
"Not sure why you would suddenly be scared for AMD now.  They haven't been competitive with Nvidia's top tier cards for years now.  It would be great if they could sprinkle some of their magic Ryzen dust on their Radeon GPUs, but I'm not holding my breath.",amd_gpu
I don’t think nvidia would be doing this if they didn’t feel like amd would’ve been super competitive. This is super reactionary,amd_gpu
"Why not both? You can run a Ryzen and still plug an NVidia into it. 

Plus there's a whole area of commercial systems that prioritize cheap GPUs because they buy a shit ton of them and don't need the same things as video games.",amd_gpu
"Tbf Radeon is in trouble.  Mid-range sure, the 5600XT is a great little workhorse, bit it's getting hard to 9wn just the low-end with no high-end competition.",amd_gpu
"Well, at least AMD GPUs work well on Linux.",amd_gpu
Glad you have your priorities straight.,amd_gpu
"Keep in mind the new consoles are packing about 11 tflops for a total price of 500 bucks. I don't think it's over for AMD, but Nvidia AI is enough to justify buying theirs over AMD.",amd_gpu
"I got a 5700xt last year and after that I'm going to sell, today. The used prices here in the uk are still high, hopefully the price doesn't crash overnight. We'll see come October if AMD has anything that can compete with the 3070.",amd_gpu
Hey atleast AMD will always have the CPU sector on lockdown lmaooo,amd_gpu
"Yeah, I use Linux (manjaro btw) and it’s kinda spooky if nvidia starts kicking amd’s ass, as Radeon is the best option for Linux",amd_gpu
"I was an AMD(ATI) stan when they had comparable goods, but they just don't anymore.",amd_gpu
"Eh, I personally think amd should just focus on crushing intel in the CPU space.",amd_gpu
"One thing I'm worried about with the reference 3090... No matter which way you mount the GPU, that inside fan is going to be cooking something.

Mounting normally, the fan will be blowing hot air on the CPU, vertically, it'll be blasting the chipset directly with nowhere for the air to go...",amd_gpu
"I'll put it this way. If I'm not pissed off for paying $400 for a 5700 XT when AMD reveals their RDNA 2 performance/price graph, I'm going to be disappointed.

&#x200B;

So I'll either be pissed off, or disappointed. I'd rather be pissed.",amd_gpu
This is what could happen if Intel took AMD this seriously,amd_gpu
"Let's see how cheap the 5700 xt gets to. Without rtx and dlss,  amd are going to have a hard time selling these anything above 299 ( definitely not worth a penny more right now )",amd_gpu
I definitely won't consider picking a RDNA 2 (or beyond) card for my first build if they carry the same burden of driver issues found on RDNA 1 cards.,amd_gpu
"I know right? We didn't expect the new line up to be 50-60% faster than the previous one. Amd might struggling to compete even with rtx 3070. This is the first time amd is introducing ray-tracing while nvidia has already optimized it so well.

People keep saying about the 8nm stuff not as good as tsmc's. I mean, doesn't matter if the user experience, library support and drivers out-perform amd's. Yes, the wafer is not as densed and yes it is not as power efficient, so what? If amd keeps up their tradition of releasing stuff without completely debugging it, then they are gonna lose margin anyway. Plus, amd is 1 generation behind and can only compete with lower-end cards like rtx 3060 and lower.

With that said, I'm still rooting for team red. I think this competition with nvidia will take years, and we might not know what will happen in the future. One thing that I can predict is that amd might not be able to keep up with nvidia this year.",amd_gpu
"I expect RDNA 2 to be competitive, but I also expect RDNA 3 to completely blow Nvidias asshole out the following year. I'm going to be building a high end rig once 5nm Zen 4 CPU's and RDNA 3 GPU's drop.",amd_gpu
"Anybody watch Moore's law is dead? Todays video(25 minutes in) he states he has some of big navi's exact performance numbers and states that amd may have ""3070 killers and a 3080 competitor""",amd_gpu
F for all the recent 2080ti buyers,amd_gpu
"Imagine being AMD and knowing all the gamers want to you bust your ass to produce the fastest GPU you've ever made, just to compel nVidia to charge a bit less in a price war.",amd_gpu
There's also a potential unseen threat looming of Intel's Xe graphics that might have led to Nvidia launching this pre-emptive strike.,amd_gpu
"Either NVIDIA had so much room to work with and made up for the weak RTX 2000, or they had some insider info on RDNA2 Navi that made them ramp up performance this far.",amd_gpu
gf.me/u/yvxtwp,amd_gpu
least their cpus are way fucking better than intel now,amd_gpu
"Prepare for disappointment. They can't compete. If I were them I'd copmletely ignore raytracing shit for the time being, NVIDA has way too large of a headstart there, and completely maximize raster perf while also massively undercutting the price. Pretty much the only way they will get even slight consideration from me.",amd_gpu
"AMD has no and probably wont have any answer to Tensor. DLSS is the future: its basically a free performance uplift with no visual fidelity sacrifices or even visual fidelity improvements.

Even if AMD comes out with a card that can match the 3070 in pure performance, *including* ray tracing, at a good price, DLSS and tensor will still throw it out of the window.",amd_gpu
"Even if everybody goes NVidia this gen, AMD still wins because Intel doesn't currently have a pci-e 4.0 answer so AMD is the only choice.",amd_gpu
RIP Radeons,amd_gpu
"They just don't have the money to compete on both CPU and GPU simultaneously

I'd expect AMD new GPUs to be good, but they won't be competitive with a 3080 at ALL",amd_gpu
"I really hope they provide GPU without any RTX bullshit.  
They could feasibly provide a card that's faster than a 3090 in 99% of the games (anything non-RTX) for half the price.",amd_gpu
"Twice the performance increase. Nvidia is killing it.

Even if AMD by some miracle releases a card that beats Nvidia by 10%, I still would buy Nvidia. Because Nvidia has been proven. The drivers work, not like AMD drivers and cards which can crash your gaming experience.",amd_gpu
"I don't think AMD will be in any trouble since they have deals with a lot of large companies including Sony and Microsoft. Also, the price point of Nvidias new lineup is insane for most people to just go out and buy one. Most games will take a while to even catch up to needing this level of hardware since most don't fully take advantage of the current hardware. Microsoft's new strategy as well as a lot of devs to work more on optimization will also make the horsepower argument really pointless.",amd_gpu
who wants to tell me who bad i fucked up buying a 5700XT for a Christmas present to myself last year?,amd_gpu
"As one of the many that suffered endless driver issues with my AMD card, I hope they get that sorted. It’s still a massive problem. 


My 2060S was plug and play. No BS. No under volting. No under clocking. No event viewer chasing crashes. Setting stay saved where my RX590 reverted to factory settings constantly(after every driver crash). 


They need to overcome that before I’ll ever consider another one. No matter how good they are. No matter how cheap they are. That left a sour taste in my mouth and they need to convince me they’ve fixed it.",amd_gpu
This driver mess of AMD cards it's a huge deal breaker they better get it together.,amd_gpu
"They are competition at least.

With NVIDIA's new line coming in at 500$ for ENTRY level cards....One can only hope the price goes down with some competition. 

Mining craze = prices skyrocket. 

Mining craze over = prices stay skyrocketed.",amd_gpu
I’m new to pc building and what I saw today makes me want to wait and preorder a 3070 the instant it is available for preorder I’m seeing things on gddrx on 3080 and 90 only can someone explain what that means and if a 3080 is a better bang for buck,amd_gpu
"It do be doe don’t it doe

#BlackLivesMatter",amd_gpu
"I don't think I will be waiting much tbh. It's going to be a 3090 for me most likely, I am just waiting on a release date.",amd_gpu
Who in the broke fuck is still buying AMD GPUs? They were never a viable option for gaming unless you're playing in 1080 on a 60Hz monitor like our ancestors used to do back in the olden days,amd_gpu
"Just bought my first video card, it is a Rx 550. It sucks, mouse lags randomly on average everyday tasks, I'm buying Nvidia next time.",amd_gpu
RIP dr lisa su XD,amd_gpu
I'm sure they are paying less per wafer than AMD is. AMD is going to have to slash profit margins to compete on price.,amd_gpu
"~~it's actually looking like this is Samsung's 7nm EUV node - at least for the GPUs shown today.~~

~~Gainward accidentally leaked ""7nm"" on their website - and today's presentation revealed that Samsung was the fab.~~ 

Nevermind - it's Samsung 8nm, which is even worse than 7nm EUV. It's just an optimized 10nm. 

~~It should be roughly equivalent to TSMC N7, if not slightly inferior. The bigger issues are yield and power consumption, which Samsung 7nm EUV is supposedly really bad at.~~

Density should be worse. Clock speeds will be worse. Power will be worse. Yet, the yields should be pretty good - would explain the huge dies that we saw.",amd_gpu
It must be dirt cheap to be offering a >700mm^2 die.,amd_gpu
"If you look at this [chart](https://i.imgur.com/9BldvO4.png) Samsung's 8nm has little improvements over their 10nm and is half the transistor density of of TSMC's 7nm+. It's probably why it's cheap.

TSMC 7nm+ - 116

Samsung 8nm - 61.2

Samsung 10nm - 51.8",amd_gpu
Don't forget AMD's chips will be significantly smaller in die size,amd_gpu
"Noob here. I've been seeing ""5 nm"" and ""8 nm"" and similar. What does this mean?",amd_gpu
"Must be, because the rest of the card seems expensive to make.",amd_gpu
"Yep, this is what Nvidia can do on a cheap node  
Things are really bad for AMD...",amd_gpu
"Nvidia wants to use TSM, but AMD bought up all the manufacturing time this year. Nvidia will be using TSM instead of the worse Samsung chips this spring, though.

Also, navi 2 should actually be a pretty good gpu.  Possibly right on par with Nvidias gpus until they start using TSM again.",amd_gpu
Or they just have more usable chips out of it.,amd_gpu
">Sounds like Samsung 8nm is cheap

**Sounds like it's not ""renamed 10nm"" either.**

627mm2 3090 has 44 million transistors per square mm.

5700XT, which is on 7nm DUV, has 41 million.",amd_gpu
"Not really but GPU prices are inflated anyway. People are all praising nVidia prices for the RTX3000 and they simply not increased it compared to previous gen. After having spiked them a lot with the RTX2000. They are still far more expensive than they were in the 1000 series and before.

If AMD could put themselves closer to what were prices back then, it could be very good for them. I doubt it of course.

Also nVidia need to step up on the software side : better drivers, something like DLSS, good ray tracing performance,...",amd_gpu
Maybe it was always cheap and Nvidia had been gouging on the back of the crypto craze?,amd_gpu
I have no idea how much truth I’m even spitting but it feels like Nvidia wants to fully avoid what AMD is trying to do to intel. Ryzen has come so far so fast and intel just wasn’t that prepared. Nvidia seems like they don’t want that to happen.,amd_gpu
Maybe... or it's their attempt to gain/keep their mind share by making AMD irrelevant at the high end for a generation.,amd_gpu
"I'm suprised by the pricing, and I don't see it coming as a result of cutting costs or kindness of their hearts.

I think Nvidia want to kill Navi on it's announcement, instead of allowing AMD to claim they have forced Nvidia to cut the price of their cards.",amd_gpu
"I do think this is good for consumers but also smart business by Nvidia.  They release earlier than AMD, they can saturate the market with people willing to buy now while everybody thinks its a great price.  

Then, a few months from now after they get the early adopters, they can release the Super cards for $100 more and sell the cards at the price they intended.",amd_gpu
"Actually NVIDIA's cards use Samsung's 8nm, which are way cheaper than TSMC's, thats why theyre so cheap.",amd_gpu
"The MSRP for these is already pretty expensive IMO, ranging from ""I could buy a next gen console for that"" all the way up through ""my entire last PC cost that much"".  Not sure how we're concluding that the prices are so low it means Nvidia must view AMD as a real threat.",amd_gpu
"We are in a global economic crisis, not the time to raise the prices.",amd_gpu
I think the pricing strategy is more a realignment by Nvidia than an indication they think AMD will be competitive. The 2XXX series didn't sell particularly well given the crap performance increases in non-raytracing games and insane prices. Looks like they are going back to the Pascal model with a 3070 and 3080 in the 500-700 range and likely a 3080Ti will be released around $1000 in a few months.,amd_gpu
"Or they're trying to dominate them knowing that they can't compete, especially at those price points, even if their GPUs are more comparable in performance.",amd_gpu
isn't the 3070 like 500? def interested as to how it benchmarks against the 5700xt,amd_gpu
And the prices are still very high.  $500 for the second-cheapest one?? That's nuts.  I paid that much for the 1080 when it was new. Their price inflation is still there.  They have left the entry and mid-range GPU market to AMD.,amd_gpu
I think they are competing with Turing and upcoming consoles for the sales more than upcoming AMD gpus.,amd_gpu
they probably just had shit sales on the 2000 series.,amd_gpu
"Just feels like Nvidia is stretching their legs here, but I'm glad people can look at this with a bright outlook.",amd_gpu
"Not necessarily. Nvidia was competing against AMD in the form of consoles. So they basically position the products to beat those at prices (excluding the rest of the PC, of course).  
  
IMO, Radeon's real competition is against Nvidia's RTX feature set. I've only used Radeon cards, but DLSS has had me eyeing the other side, since 1.0, even.  
  
However if Radeon can take on the 3080 in non-RTX capabilities, while hitting a lower TDP, it might be a better mix for me. Since I'm looking to stick with mITX, and would prefer to have a full loop as well. The 3080's TDP is a bit prohibitive.",amd_gpu
"It's not AMD bringing a good GPU, it's that people can get a PS5. 

They're not competing against AMD, they're competing *with* AMD against consoles...while wanting to supply chips to said consoles.

What a mess.",amd_gpu
"Don't think Nvidia sets their launch prices with competition in mind. Usually they launch and then adjust prices once anything competitive comes on the market (as the 1060, 1660 and 2060 did). I think their strategy is to entice people upgrade from the 10xx series. Normally you could force a price increase but the global health crisis needs to be factored in.",amd_gpu
Will XBox Series X and the PS5 will likely cost less than the 3080......I think that is where the competition really is (not necessarily for absolute performance....but for where people will spend their money),amd_gpu
"I hope so, but part of me is concerned this is to compete primarily with consoles.

I sure hope there's an 80cu 3080 competitor coming, and even that might not be enough on its own.",amd_gpu
The only reason they aren't higher is because of next gen they wanna compete with it not because of AMD's original gpu's,amd_gpu
"I surely hope so or they just want to hammer in couple more nails on AMD GPU sections coffin. It has been slow but sure decline from the days of 7970.

And man, I don't want to go to the green team as I hate their proprietary shit and their lack of Linux support but this was a show of force which I think AMD cannot answer.",amd_gpu
"AMD fanboys will give amd credit for no reason at all


nice",amd_gpu
"That's an overly-optimistic way to look at it, at least for AMD. Nvidia doesn't need to announce lower costs to keep AMD out of the upper end of the market; AMD doesn't have anything in that end of the market. And remember, these prices are pretty much just marketing junk at this point; they'll be selling for a markup to their board partners, and by the time it hits stores the cards will cost a lot more.",amd_gpu
"I don't think it's to do with that really as much as the rtx cards being a new tech and usually new tech is more expensive too. This same stuff happened with the 8000 cards too where the 8600 was trash and the 8800 cards were a lot more expensive til we got a GT. Normally big tech or process jumps like that don't come at no cost.

People tend to skew things whichever way they want to see it though whatever happens. Prices have always fluctuated a bit though and we were actually at a lower point prior to 2000 (lower as a whole, not just lower than 2000 cards).",amd_gpu
"Not being funny mate, but how many times has this logic been said about AMD? Their flagship has been round the corner for years, but never comes, and their midrange takes ages to materialise. I want healthy competition, but AMD just got fucked, hard. Where can they go from here? They haven't even matched the 2080ti, a card that has just been made redundant.",amd_gpu
"They are not competing with AMD here, they are competing with xbox and playstation.

Any gamer considering one of the next gen consoles could be tempted to buy a 3000 card instead.",amd_gpu
"Nvidia is not competing with AMD directly here, I believe they are competing with the next generation of consoles, hoping to get out ahead of the launch, and lure consumers back with competitive prices and features.",amd_gpu
Doubt it .,amd_gpu
"Nvidia are competing against the consoles this time around. They are a much bigger threat than AMD.

A crap Ampere launch would drive many PC gamers towards PS5 or the new Xbox.",amd_gpu
"I think the pricing on the 3070/3080 isn't about them being worried about competition, but ruining the selling point of AMD. AMD has always had to sell for lower since they can't compete exactly on the tech. If you just forced AMD to sell for less they have less profit and it ruins their business model. If AMD wants to make even a slight profit they can't lower the price too much.",amd_gpu
Aren't they high enough tho? $500 for an XX70 class GPU is a tough pill to swallow.,amd_gpu
">would have been more scared if the 3070/3080 prices were higher.

You have a good point but another one that I have a problem with is how people seems to simply accept these prices.

None of the announced GPUs are even reasonably priced, yet everyone are either praising that price or straight out downvoting anyone that dare say that they are expensive.

I have the money to buy a US$1K + gpu but on principle, I can't justify those prices or expenses.",amd_gpu
"> This tells me Nvidia knows AMD has competition coming this generation and they need to stay price-competitive.

This is what I see too. I'm actually excited. NVIDIA is a non-starter for me due to their hostility to open source and Linux. If anything, this gives me encouragement that the GPU prices are finally coming down somewhat since the crypto-mining craze distorted them.",amd_gpu
"Yeah this, when I saw the nvidia pricing my first thought was they know amd has something competitive coming.",amd_gpu
I think its more that Nvidia knows their main customer base(gamers) have had enough of no new perf per $$$. the xx70 is the same perf as the previous flagship.....you know like how it used to be. Also if they get enough RTX cards out into the wild it will help them strong arm their version of RayTracing.,amd_gpu
"Exactly. 3090 is so much higher than the 3080 because nvidia doesn't think amd will be able to put up anything close to it, so they can charge out the nose for that top end performance.",amd_gpu
"Hell yeah it does brother 

Fuck u/sparty1227 it fucking stayed",amd_gpu
I'm looking forward to seeing what AMD has in store. Right now I'm leaning towards the RTX 3070 but if Big Navi is as good and cheaper I'll definitely go with that.,amd_gpu
"I don't know, I am pretty sure they ran some marketing and saw that $500 is a cap for tons of gamers out there... I mean, that is a pretty high entry cost. If a 3060 is out by holiday I may consider a new gaming pc.",amd_gpu
Which is great.  The pricing is really aggressive.,amd_gpu
Does anybody know when Amd will reveal ist line up?,amd_gpu
"Mark Cerny hinted at that in the PS5 GDC presentation a few months ago. They were developing some tech with AMD, some would be shared, some would be PS5, some would be AMD. He suggested that they might release a relevant GPU sometime around the PS5 launch.",amd_gpu
I feel like these prices are also here to compete with console prices?,amd_gpu
"I think it's less about AMD directly and more about the new generation of consoles coming out this fall. Which of course are still powered by AMD, but it's more or less an indirect competitor of sorts in this regard.

Lots of gamers will have to choose whether to spend \~500 bucks on a new console gaming system or a new videocard. If the prices would have been much higher, that choice would have likely skewed more towards consoles for many. 

Especially since these consoles also get you the new high-speed SSD architecture and GPU decompressing rather than (some) PC users also having to invest in a new PCI gen4 compatible motherboard and maybe a new NVME SSD.",amd_gpu
"We have a new gen of console about to be released...that is why the prices are ""low""",amd_gpu
"They do have competition coming from AMD, but it's in the shape of consoles.

I mean, maybe graphics cards too, but I expect they kept prices in check to avoid having people migrate to consoles for this generation.",amd_gpu
Doesn’t mean that what so ever just means they were able to pack more on one die for much cheaper not warranting a price increase,amd_gpu
"I think they're more afraid of losing sales to the upcoming consoles.

&#x200B;

Can't have your GPUs literally cost a couple hundred bucks more than the entire console.

&#x200B;

$499 on the other hand is reasonable.

&#x200B;

Can't price the 3080 400 bucks higher than the 3070 tho because then everyone gets the 3070.

&#x200B;

And so the cycle completes.",amd_gpu
"Absolutely. I use an nvidia gpu but I am excited for the future of gpus. Performance is going to go up with prices being more reasonable. So, it's definitely going to be great. And when I upgrade in 5 years (using an rtx 2070 super so there's no need to upgrade yet) amd and nvidia will affordable powerful cards.",amd_gpu
More likely consoles are the threat given the release date. They needed to give people a compelling reason to upgrade this year rather than buy a new console.,amd_gpu
"I don't think Nvidia is lowering their price because they feel threatened unfortunately. They're probably just looking to hit AMD where it hurts. If they were truly worried about monstrous AMD performance then the 3090 wouldn't be priced so highly (especially without a Titan brandname behind it this time). Nvidia is probably aiming to try steal customers from the console market with the 3070 releasing a month or two before next gen consoles while hitting AMD's top end cards hard with the 3080 too. Then have the 3090 as the king as usual at a performance range where AMD doesn't offer much competition so they can price it however they want. Not blind AMD hate, but I also don't think Nvidia is as stupid as Intel. Nothing about their strategy reeks of desperation either.",amd_gpu
They’re prob competing with consoles tbh.,amd_gpu
"One theory I read yesterday is that Nvidia is doing this to compete with the PS5, not Big Navi PC parts.",amd_gpu
"AMD's competition is the consoles, NVIDIA wants people to see more value in building a PC than buying a console",amd_gpu
Nvidia might want to stay price-competitive against the new consoles first and foremost. RDNA2 could very well be a non-factor for Rtx 3000 somewhat aggressive pricing.,amd_gpu
"This is a move against Sony and Microsoft. Which is a move against AMD by proxy, but that was not the primary goal.",amd_gpu
"The 3080 TI leaks has it \~3090 perf, price TBD. I think Nvidia cards will drop in price if AMD comes in where leaks are proposing them to be.

Good time to be a gamer.",amd_gpu
Completely agree.,amd_gpu
Nah their positioning pretty much replicated the pricing for Pascal and is quite likely there due to the consoles being released at the end of this year that will offer a pretty steep generational leap.,amd_gpu
"The 3070 is eh pricing.  It's $500 for just the 2080 ti performance, which was already a lackluster generational jump.  It's *worse* price:performance than the 3080 with less and slower VRAM...

3080 is a different matter though.  If it's even close to as fast as nvidia claims it to be then it's even better priced than the 1080 ti was at the same pricepoint (though that's partially because Turing's pricing was so bad).  The last time nvidia did that AMD had nothing and they couldn't even compete on price with nvidia because their more expensive to produce GPUs weren't good enough.",amd_gpu
"Not necessarily.

It also means Nvidia is very confident in their product.
It's not like AMD has anything to beat out Amperes higher-end offerings.",amd_gpu
"I thought the same, the price they have the 3070 indicates that they know something big is coming from AMD. I don't know if they will overtake them, but if nvidia doesn't offer much more performance and they still had a big price premium they would have lost a lot.",amd_gpu
"Big Navi best case scenario rumor has it performing 50% faster per watts than 5700 XT.  Do the math and you will come to the conclusion that big Navi will probably land in the 3070 and 3080.  That's with DLSS.  With DLSS, bit Navi doesn't stand a chance.",amd_gpu
Also rip for the people who bought 2000 series. Overpriced af and 3070 seems to be better than 2080ti and mzch cheaper. 2000 was basically an experiment,amd_gpu
"Exact-fuckingly. Since when Nvidia doesnt gouge customers? Since they had competition. RDNA2 rumors concord with these prices. Nvidia didnt go to samsung first, they got told no from TSMC. This says it all.

&#x200B;

It's gonna be old school ATI shit baby",amd_gpu
"This. If Nvidia could get away with charging $1K for the 3080, they would. They knew they could do it for turing and volta. 

Likely also to be some more flow on effect 1-2 years as new games are with console optimizations which should favor Navi 2.",amd_gpu
I agree. This is a great year for consumers.,amd_gpu
"I feel like I'm in bizarro world. These prices are crazy high, yet so many people acting like they're getting a hot deal. No wonder they've jacked the prices up so much if people are so eager to pay up.",amd_gpu
"I suspect that the 30 series cards aren’t so hot at actually pushing frames if you aren’t using RTX or DLSS.  I would bet that those functions are super well optimized for the new cards but comparing RTX on FPS to current gen gpus that easily get bogged down by those functions mean they are hugely overstating the gains they’ve made.

Given that AMD won the war to supply consoles, that will likely keep developers from investing time into nvidia specific features.  AMD essentially has the field at this point.  And I would bet that nvidia knows it’s going to be boxed out hard which is why they’re pricing these so aggressively.  FPS wise, I wouldn’t be shocked to see more modest gains that are matched or beaten by big Navi.  AMD should be working on it’s own lighting tech but if Unreal 5 engine is as good at the demo showed, nvidia might have created a more specialized piece of hardware than is required to run next gen games.",amd_gpu
"At some point AMD are just gonna go,

Fuck it, you want bigger and faster? \*sniff\* Here you go: a Tower-sized block with 100 RX 5700XT’s that- \*SNIFF\* that you bolt onto the side of your PC. Those who can afford it, that’ll be £500,000. The rest of you can fuck ***riiight*** off. ^(Debra? Debra where’s the rest of my Cocaine, goddammit Debra I told you to— wait is it hot in here)",amd_gpu
"I was thinking this too, why else would they make the pricing ‘reasonable’",amd_gpu
"Yep.

I was expecting the 3080 to be on GA104 (the die that 3070 is on), and the 3070 being on a more cut down GA104 than it's on.

For 3080 to be on GA104 says that 6144 Ampere shader cores wasn't enough to match/beat RDNA2 on presumably 5120 shader cores.

Though I fully don't expect ""Big Navi"" to compete with the 3090, I'm not interested in a $1000+ GPU anyway.",amd_gpu
"Sad thing is if AMD barely keeps up with a 3080 but without the RT performance or DLSS, Opengl, etc then it's a clear win for Nvidia. Even I will be going to the other side after many years of AMD.",amd_gpu
If Nvidia has the ethics of a Mongol invasion I want to know what you compare intel to.,amd_gpu
"Intel is like that 90 year old wall street executive who uses same tactics from 1990s and expects massive results everytime.

Intel is stuck in it's 90s ego mindset.",amd_gpu
Genuinely LOL,amd_gpu
Yeah Nvidia really backs it up with their tech.,amd_gpu
Cringe post for claiming moral superiority between two soulless amoral billion-dollar corporations consisting of thousands of people that will both always sell their products for as much as and effectively as they can.,amd_gpu
"nV's strength is optimization for manufacturing, they can take a digital design, identify the bits that are critical in timing and tune them so you can get high clock rates.

AMD's strenght on the other hand is digital design -- they rather go for adding another GPU instruction that allows better optimization of shaders, and worry about manufacturing later.

So nV's tech is really closely tied to the manufacturing process -- that's why they had these huge issues in MacBooks back then: a small change in manufacturing meant that a lot of redesign was needed.",amd_gpu
4 core is enough died on the beach. Intel deserves to suffer.,amd_gpu
"To be fair, the Mongols weren't too bad - after they conquered you.",amd_gpu
"LoL Bro, so your PC is built around morals instead of cost/benefits?

I have no sides in this, had AMD and Intel, Nvidia and Ati parts in my PCs and I buy whatever is best for my wallet",amd_gpu
Man 3070 is really gonna make AMDs life difficult in the GPU section. I hope they can be competitive.,amd_gpu
You watch broken silicon don't you?,amd_gpu
"I'm amazed AMD still doesn't integrate well with Pytorch and Tensorflow. I would jump ship in a heartbeat because AMD gived you more Vram and actually works well with Linux.

It isn't fucking 2013 anymore and they've had years now. I get that Nvidia had a head start but come ooooon AMD.",amd_gpu
Yeah dlss 2.0 was amazing. Essentially 40 to 50 percent performance increase in ray traced games without losing much quality. Imagine dlss 3.0,amd_gpu
"Unrelated, but the 4K AI upscaling on their streaming device is insane.",amd_gpu
"They pulled out all stops and prices didn't even go up, really impressed.",amd_gpu
"as someone who does work in the ML space this presentation has given me pause.

I was willing to just take the pain and train on my 3950x if nVidia underwhelmed.",amd_gpu
"Partly because if you have a AMD GPU on a laptop, it's literally a luck of the draw if your next GPU driver update will brick your computer.",amd_gpu
"Especially CUDA. At this point, AMD's porting tools to HIP C++ aren't enough. They need to just implement CUDA. Depending on the outcome of Oracle v Google, they might be able to do this for free, but even if they can't, imo it'd be worth the royalties they would have to pay to Nvidia.",amd_gpu
"Learning yes, CUDA is a must, but for running an AI model, not so much power is needed(for gaming).",amd_gpu
"Absolutely. Dlss alone is amazing and if it gets used in more games then that is huge. I'm getting zen 3 for sure, but it's looking like I'm going nvidia again doe my gpu. I'd love amd to compete though!",amd_gpu
"Tensor cores are needed for...

1 - RTX voice \[turns out to be false\]

2 - DLSS \[turns out older DLSS runs without tensor\]

The AI learning so far has been marketing hype. I'm liking what I see from the RTX 3K series. So far the leaked 3080 ti is my fav and probably going to be my go to card, if not the 3090. However, let's not fall for the marketing bull.",amd_gpu
Before September 17th.,amd_gpu
I think the concern is if nVidia blows AMD out they will have little meaningful competition. Think of Intel vs. AMD pre-Ryzen. Intel could charge whatever they want and make only tiny incremental improvements knowing they owned the market.,amd_gpu
It's not a good thing for consumers if one team wins by a large margin. If AMD can't compete then we will be stuck with whatever nvidia decides for pricing(Might be fine for 3000 series but going forward could be worse like the rtx 2000's were),amd_gpu
"yes, exactly this. I've gone with AMD because of their better price/performance thus far, but the moment that changes I'm not gonna suddenly stick with an inferior product. Especially given how AMD has burned early adopters in the recent past...",amd_gpu
Too bad Nvidia support on Linux is shit.,amd_gpu
"Competition is good though. If one brand is allowed to completely dominate the market, improvement stagnates - just look at how Ryzen has forced Intel to be more reasonable with pricing.

There's also some benefits to each brand that aren't replicated by the other. For example, on Linux, there are official open source drivers for AMD GPUs, but the official Nvidia drivers are proprietary. Depending on your goals this can be a pretty big advantage.",amd_gpu
I'm still not going to buy nvidia because of the garbage tier linux support,amd_gpu
"> Brand loyalty is for suckers

It's not so much about loyalty to AMD as refusing to purchase NVidia/Intel. They're comparatively less ethical in their business practices.

Look at the Hairworks/tesselation scandal. Or just all the closed Gameworks/PhysX stuff that has happened over the years. Oh and the 970 ""3.5GB"" scandal. And obviously price gouging while they have a de-facto monopoly.

Meanwhile AMD is supporting open source options for the above.

Ideally the market would have more than two options. It would be good for us as consumers if Qualcomm or Matrox were able to also have a competitive PC GPU.",amd_gpu
"Exactly. I went to Intel during the FX era due to AMD wanting to slam buzz words into product design and it barely worked as opposed to a great overall product. Intel got lazy with that same architecture pretty much for almost a decade, now I’m back to AMDs better product. 

AMD/ATi has always had a ton of great GPUs in the mid range. And they still do well there but even Nvidia has added mid range competitors that do a damn good job as well. I only hope there can be competition and choice at every level.",amd_gpu
"On the one hand, I agree that brand loyalty IS for suckers.  On the other hand, one company having a virtual monopoly on the top end of the industry is really bad for product pricing and future advancement of the technology.  If AMD starts doing badly enough for long enough they may eventually bow out of the PC gaming market entirely. Is that happens, expect nvidia to slow new development to a crawl and jack up the prices sky high (the same thing Intel did with CPUs which effectively froze development in that industry for a decade).",amd_gpu
"You know what else is for suckers? Paying 1500 dollars for a card thats worth 500.

nvidia is taking pricing lessons from Apple, as in ""arbitrarily increase prices for no reason, the rubes will pay for it regardless!""",amd_gpu
"> Shouldn't we all be excited? 

Excited for lack of competition? I'm not sure why that's ever a good thing.",amd_gpu
this is the basic reason why i'm going to the Ryzen/RTX route instead of Ryzen/Radeon,amd_gpu
"Call me what you want, I'll never buy from the green vomit 😎",amd_gpu
"Yup. Not gonna lie the fanboy in me was excited at the prospect of an all AMD machine, but if they can't compete then I'm buying a nvidia card.


Also I'm only a fanboy cause I like underdogs haha. Anything to keep a stagnant market.",amd_gpu
"Exactly.  Even if someone had no intention of ever going to Nvidia, this is just going to drive even better competition between the two brands.  I'm assuming that the 3000 series and pricing is at least partially due to how well ATI has been doing the past year.

When we make the companies fight for our dollar, we all win.",amd_gpu
"You're right, but we need amd to be somewhat competitive or else Nvidia will just have a monopoly on the GPU market....which they kinda do even when Amd has decent gpus.",amd_gpu
"I always gave them a few extra points during hardware purchases because they were an underdog. 

But the usability and value of their products have fallen and my next purchase will 95% be an Nvidia card.",amd_gpu
"There's not that much to be excited actually. Without competition consumers will pay more to get less, so it's really important that AMD releases good cards.",amd_gpu
"I feel the same. However, I am welcoming Intel on the GPU side of things 2021.

That will mean we will have a Team Red vs Team Green vs Team Blue situation. Literally. Which can only be good for consumers.",amd_gpu
">Brand loyalty is for suckers

Based",amd_gpu
Brand loyalty is for suckers but so is being blind lol. No way AMD will compete at the high end even if their card is a NAVI killer. If the 3070 is indeed the same as the 2080ti that will put amd's highest card  still 3 tiers down. Only way AMD would be able to compete would be to lower the price of the card to $400 again.,amd_gpu
"Exactly. I had to return my ryzen laptop to a bestbuy recently because it was defective and would overheat within seconds of being turned on. When I went to the counter to get a replacement, the employee said ""o, this is only an issue for amd processors. If you had intel you wouldn't be having these problems. I can get you the model with intel instead if you'd like"". I was honestly baffled that someone was that much of a shill.",amd_gpu
I'll still get AMD because I loathe Nvidia and it's a two-horse race -- and I'll benefit from lower prices. :T,amd_gpu
"Trueeee. If I need a new GPU, I'll be looking at the best product, not the one that gets me kudos from internet strangers. Intel vs Amd on the other hand...",amd_gpu
"As a Linux dude, the choice is a lot tougher for me. AMD is the only GPU brand with good Linux drivers (ironically because AMD doesn't fully maintain their Linux drivers themselves).",amd_gpu
"Not only that, but used RTX2080's and 2070's are dropping in price like crazy.

This is really a good time to get a good GPU for ""cheap"", people is getting desperate by the launch prices of the 30xx series.

If you don't believe me, go check out /r/hardwareswap",amd_gpu
That 3070 looking juicy,amd_gpu
"As an AMD fanboy I'm scared for them.

As a PC gamer, I'm not going to continue to be one for long because Xbox Series X is just too good of a deal to pass on. 😂

And I can continue to play PC only games or games that are cheaper on PC on my current system, just at lower settings. :D",amd_gpu
This.,amd_gpu
I'm loyal for as long as I'm not insulted or fucked with. So I jumped of the intel boat years ago. I know use Ryzen CPUs and RTX GPUs. Seems to be a good combo. Haven't heard anything about the next-generation  AMD GPUs yet. Hopefully theyvate more competitive on performance than the last line. Ryzen sure is doing well for me though.,amd_gpu
"Brand loyalty is for suckers except in certain circumstances/industries. 

But I think people are over hyping the RTX 3000 announcement based on vague marketing and that AMD's upcoming RDNA 2 products will be *quite* competitive with them. 

But only time will tell.",amd_gpu
"Yes choose want us best price /performance for your budget but we need 2+ players in the game for the field to push innovation, competition, fair pricing etc.  I’m not a fan of intel but I hoped their gpu would compete as that’s best for consumers",amd_gpu
3070 seems like a really good deal. It will all come down to AMD making a comaprable product for less money.,amd_gpu
U shoulda been switched to Nvidia everyone's laughing at you,amd_gpu
">Brand loyalty is for suckers

Maybe so, but boycotting NVIDIA is, in my mind, entirely justified. If AMD cannot compete, then I'm screwed.",amd_gpu
"They can compete. Unless you are talking about the ultra high end. Do you purchase in that segment?

Any other segment, you have choice.",amd_gpu
"It’s not always about *brand* loyalty. We’re often in a situation where we can choose to buy from the “market leader”, which may have better specs and all that, but are acting as complete assholes towards their customers just because they are in a dominant position. Nvidia with their lock-in monitor chips (G-Sync), their “if GPU != Nvidia then performance = tanked” stuff like Hairworks, and not to mention their completely bonkers state of their Linux drivers, isn’t getting my money anytime soon. 

I choose to buy AMD, not because of brand loyalty, but because they provide good, open source(!) drivers on my platform, and they aren’t acting the same level of douchebag that Nvidia is. 

(That said, I don’t preclude the possibility of AMD going asshole if the tables were to turn, but atm they are acting the part of somewhat-good-guy-underdog, compared to Nvidia (and Intel)).",amd_gpu
"we should wish to have competition in the space. For that purpose, I hope Intel releases their GPUs and it's actually potable.",amd_gpu
Brand loyalty is for poor people that can't afford to have one of everything. /s,amd_gpu
"Thing is, if AMD has nothing this gen, fair enough we get decent prices from Nvidia this gen, but next gen will be back to over priced stuff like the 20 cards.",amd_gpu
"I wish I didn't have to be loyal, but until NVIDIA decides to stop being cunts about open-source drivers, I'll buy AMD, where I can fix what I want to fix, and tinker with what I please.

I'll probably pick up a 3080 to play with it and test a few performance benchmarks for VR, fall in love and wish it wasn't a closed-source-driver nightmare, then crawl back to my 5700XT in tears, but loving the tinkering even more.",amd_gpu
Especially with 2080ti performance for 500 bucks. Just insane if the reviewers confirm this,amd_gpu
"Yes, but also I’m using a Mac mini with an eGPU, so nVidia cards won’t work on Mac OS. I’m hopeful though",amd_gpu
"For real, i love my 5700 XT but i wouldn't have bought it if the price/performance wasn't great. Now i'm considering it selling it and buying a 3070.",amd_gpu
"There is such a thing as a company being morally bad, and that's enough for me to have brand loyalty for any brand BUT them.

Nvidia does shitty things, with their technology (fucking up standards) and with their company and sales.

No thanks. I'll take AMD.",amd_gpu
"Turing happened because Nvidia was confident AMD couldn't compete. No-one wants to see another Turing, we want more Pascals (where Nvidia was worried AMD would compete).",amd_gpu
"Just worried long term. Have used Nvidia cards mostly but the 20x price hike was disapointing and worrying. Now people are super happy it hasn't gone up further for 30x...
at least the performance increase is more this gen supposedly.
Would price have been worse without AMD and the new consoles? Who knows...

I'll still wait for AMD showing. NVIDIA will probably be sold out for months anyway heh.",amd_gpu
"Yeah, you just want competition so that the market leader can't artificially inflated prices like NVIDIA did for that period were AMD just couldn't compete. We all win when their is good competition.",amd_gpu
I expect RDNA2 could be in the same performance level of 3080 with way better power consumption. Probably not 3090 tho. One big factor to consider is if DLSS means something to you... Otherwise I'll choose waiting for RDNA2.,amd_gpu
"I'm very happy for Nvidia and the cards look like they will be great. But I do hope AMD can at least get a good spot somewhere in the market, as we do need the competition to keep things going. The 3080 and 3090 look like they'll be able to handle the next-gen VR that might start coming out in a few years (90+hz, full FoV, more pixels than you can shake a stick at), etc. It would be great to see the GPUs required for that shift down to the upper-mid market range, even if the headsets will be very expensive.",amd_gpu
All about the product 100%,amd_gpu
">I'm an AMD guy but if they can't compete then I'm going to go to Nvidia. 

Same here but reluctantly. Mostly because Nvidia is a little on the shady side recently. Its not something I want to support, but I'm not about to gimp myself because of it.",amd_gpu
"Brand loyalty is fine. Show it by buying shares, not the actual products if you want to benefit.",amd_gpu
I’m brand loyal as in I will wait on he next generations until they have something of value. I know I’m stupid but I don’t to have to switch to G sync and support them.,amd_gpu
"Yeah, that's what I love about the PC market, it's always moving ahead and it's not always the same brands coming ahead. AMD/ATi vs Intel vs nVidia has always been fascinating.",amd_gpu
"This. Personally I would like to support AMD more than Nvidia, just because of the BS Nvidia has pulled over the years (not saying that AMD are angels, they've also done their fair share of BS in the past, but not as bad), but if they cant compete with Nvidia this year, I'll be switching to team green for my GPU. I'm currently using an rx vega 56, it has served me well but for 144hz gaming at 3440x1440 its pretty lacking.",amd_gpu
"Exactly same here. Always swayed to AMD for their price to performance but depending on what big navi brings, I could be a first time Nvidia user",amd_gpu
I just bought my 5700 a year ago and am not looking/expecting to upgrade in the next 4 years tbh. So I'm just grabbing my popcorn and hoping something good can come out in the upper mid-range down the road,amd_gpu
Try saying that on the Apple sub.,amd_gpu
"Exactly. I'll admit I'm new to the PC gang, but my first build uses a 5700XT. For building a system from the ground up, it was a perfect price/performance option for me at the time. But when I upgrade (probably next years holidays) and am only buying a GPU... I'm not really going to be so concerned with the AMD savings if it doesn't match-up to a 3080.",amd_gpu
Only matters to us brand loyal suckers who also use Mac! New NVidea is pcie4 so it should make Ryzen fanboys happy.,amd_gpu
Nvidia to AMD https://imgur.com/a/OHic2f2,amd_gpu
2080 Ti should've been a 799 card at max.,amd_gpu
"Holy shit you guys got brainwashed into accepting Nvidias pricing shenanigans so fast.

The 970 offered 780ti performance at like ~350$.

The 1070 offered 980ti performance at ~400$.

And now you call 500$ for a x70 ""dumpster pricing""?? Just because the 2080ti was ridiculously overpriced?",amd_gpu
Didn't consider this. You might have a point there friend.,amd_gpu
"I have been saying for months that it's stupid to spend $800 on a GPU alone (2080 Super) that doesn't appear to give better or much better performance than an entire console that will cost less, yes.

A $500 card needs to be significantly better performance than a $500/$600 console.",amd_gpu
"499 for a card that’s 41% faster than 2080ti
FTFY",amd_gpu
Sensible.,amd_gpu
Power efficiency is where I really hope RDNA2 will shine. The new 30x series cards look incredible but TDP on the 3080 is insane and I find that to be a real turn off as a consumer.,amd_gpu
What? Isn't the leak that RDNA is 40-50% faster than the 2080 not the 2080ti?,amd_gpu
"This is valid, I’m just worried that they won’t be able to reach similar performance in ray tracing. A lot of big upcoming games are utilizing it including the consoles. 

Now that I say that, the graphics technology in the consoles is made by AMD so that could be a good sign honestly.",amd_gpu
That's already available. These new boards will do a lot better than that.,amd_gpu
"1440P @ 144FPS thank you very much, it's 2020... we should be expecting that _at a minimum_.",amd_gpu
"FYI: a 5700XT hits 100+ FPS at 1440p in ~98% of games.

Edit: maybe I don't play enough AAA games but the vast majority of games I play with my 5700XT go over 100",amd_gpu
"The damn 3080 has %80 performance increase compared to the 2080ti. Thing is mental. I'm waiting to see what AMD does but fuck man, I'm digging the 3080",amd_gpu
"> Maybe we'll see a $600 AMD GPU that approaches that performance.

Unless Nvidia was highly misleading with their performance claims, it just isn't possible for AMD to get near the 3080.

They're saying the 3080 is ~60% faster than a 2080 Ti, ~1.9x the perf/W, and ~320W power draw.

AMD have officially said RDNA2 is 1.5x the perf/W of RDNA1. They just can't get close to Ampere's top-end with that figure.",amd_gpu
My GTX 1080 already does that. They can be had on eBay for $300.,amd_gpu
"I don't think so.

I think they can easily match the 3070 in price and performance, WITHOUT RTX.

RTX is going to be a thing now, a thing AMD is definitely going to be worse at.

Then the 3060 is going to come out, it's gonna offer worse performance than whatever AMD has, but still better RTX performance. 

AND if DLSS were to get more popular, AMD GPUs would be completely defeated.",amd_gpu
For it to competitive it would really need to be AMAZING. I feel like anything less would be an easy choice for team green,amd_gpu
"I am really skeptical on the performance numbers. On the bottom they only write average of multiple graphic-intensive games in 4k. They could easily take a few dlss games and suprise: the new cards are so much better than a 1080ti. No wonder, when they are only rendering 1440p and upscale that shit, while the old cards have to render 4k.

Edit: They might be even shittier and really averaged a few games with raytracing and dlss. ""graphic-intensive""",amd_gpu
"A step down in power, maybe 20% or so, but at literally half the price, would be an absolute knockout. A great gpu at a good price would *move*",amd_gpu
Like RDNA cards were competitive?,amd_gpu
I honestly think AMD is pretty fucked on GPUs. Nvidia just decreased prices massively and like almost doubled performance. AMD couldn't even compete with the last overpriced gen. They'd have to have such a giant leap in tech this gen. I just don't see it.,amd_gpu
"AMD needs to absolutely dominate the non-RTX market.

&#x200B;

If they can offer non-RT 3070 performance for $350, and non-RT 3080 performance for $599, they'll have something. Sweep the legs with 3060 perf. at $249.",amd_gpu
Turing also happened because they went with TSMC and it didnt work out.,amd_gpu
Feels more like 2005-2006 when nVidia's 7xxx and especially 8xxx series mopped the floor. But yeah.. this is going to be an interesting fall.,amd_gpu
The last leak we got from AMD was “poor Volta” so I’m not too keen on them leaking anything,amd_gpu
"dude, what?

the radeon 9000 series in the early 00's were the kings of the GPU world

It wasn't until the nvidia 6800 came out that they took the mantle.   And that was 2004, which I would call ""mid-2000s""",amd_gpu
"If AMD doesn't have something good to show by September 17, I may have to make the jump...",amd_gpu
2.5x p/w or sth would be good.,amd_gpu
"\> if they're smart

So you're saying you're smarter than the whole AMD marketing department?",amd_gpu
You mean the latter 2000's; ArtX tech made NV30 a goddamn joke.  NVIDIA has done a good job of being a step ahead for nearly a decade but performance aside they've got features that are really nice and I would like to see AMD polish its featureset and just offer solid options as they have been in the mid to upper range.,amd_gpu
lol no,amd_gpu
The reference card is 313 mm long and triple slot. It's a big boi.,amd_gpu
Their official term is 'Big Ferocious GPU' but we all know what the F means.,amd_gpu
Jensen is a marketing G,amd_gpu
Ever since they bought out 3dfx their mantra has been more power = better graphics.  So far they've been right.  We'll see how it goes from here.,amd_gpu
Need that BFGPU for your BFGD monitors,amd_gpu
I thought it was big friendly GPU,amd_gpu
That Nvidia broadcast they showed was actually really cool,amd_gpu
I'm not sure why people always throw out these kinds of scenarios. Has nvidia ever done that? And even if they were to we wouldn't be seeing that for 6-8 months at the earliest.,amd_gpu
"Not possible, they cant use TSMC 7nm and Samsung 7nm is broken. Thats why they have to use Samsung 8nm.",amd_gpu
"Ampere is on Samsung ~~7nm~~ 8nm 

edit: doh",amd_gpu
3080 super will be insane,amd_gpu
"Driver support, plugins, streaming, recording, it's all on Nvidia's side right now. Even if AMD drops a comparable card to the 3070/80 for the same price, what I just mentioned tips the scales against them.",amd_gpu
Honestly half the reason I've never bought an AMD card is because I know AMD's software doesn't hold a light to nvidia's offerings. I love Nvidia shadowplay.,amd_gpu
[deleted],amd_gpu
AMD should definitely be on 5nm RDNA 3 ASAP. Nvidia is taking advantage of every month it can get to hype up its cards.,amd_gpu
They copied amd anti lag and amd link..,amd_gpu
[deleted],amd_gpu
">Thinking more about it. 2080ti performance for 499$ is fucking insane though.

No, what's insane is the 2080Ti for $1200.",amd_gpu
Imagine the people who bought a 2080Ti in the last 60 days...,amd_gpu
"> But i would be lying if i said a 3080 for 700$ offering better performance then a 2080ti isnt spectacular.

>And so is the 3070 offering 2080ti performance for 499$

wasn't that reference to the performance just in regards to RT performance though?",amd_gpu
"All the recent 2080ti buyers though, the massive losses.

I think Nvidia did the price drop to mirror what AMD did with the 5600XT? But the pricing is amazing this time around.",amd_gpu
"I'll wait 3rd party reviews but prices are somewhat reasonable at least (it only looks good because as expected, consumers got used to Turing prices)

Hope the 60 tier is back to $300",amd_gpu
"Initially I thought the guy who sold his 2080ti for 500 dollar on FB marketplace this morning is dumb.

Turns out, he made a good call.",amd_gpu
"If you're looking at it from the ""savings"" perspective, it seems that way. But from a generational price to performance? No. Bearing in mind that:

- The 2080 Ti was a whopping 70% more expensive than the 1080 Ti (the 1080 Ti was $50 more expensive than the 980 Ti).
- The 2080 Ti was at best only 35% better than the 1080 Ti (the 1080 Ti was on avg 50% faster than the 980 Ti).

The 2080 Ti wasn't that impressive to begin with. So that ""2080 Ti for $500"" 3070 means even less, without even considering that the 3070 has less memory, and doesn't even get the GDDR6X.

$500 for 3070 also means the 3060 will likely be $400. Below that? I don't even wanna guess.",amd_gpu
Well shader performance says YES. Memory Bandwith says NO.,amd_gpu
*cries in RX 5700XT*,amd_gpu
"> I wouldn't say R.I.P before we see what AMD has to offer.

They still haven't released anything that outperforms the 1080ti. I got mine for $445 back in August 2018, If their 3070 competitor isn't $400 I'll be paying the green tax this time around.",amd_gpu
">or 499 you'd bought it in heartbeat. Of course, that is assuming the 3070 is faster than a 2080 ti.

Im still waiting to see if that only Ray Tracing performance or if its overall.",amd_gpu
"Well, we don't have verified benchmarks yet do we? Just marketing materials? Everything I have been reading keeps comparing a 2070 to a 3070, not a 2070 super to a 3070 which is what they should be comparing to (fit in the same price bracket and the 3070 replaces the 2070 super, not the 2070).

Be curious to see if the gen on gen gains are real because the 2070 should have been a 2060 last gen. The super cards are what we should have received on launch. It'll be interesting to see if they gave us the super cut down versions this time again which would imply they have a Super series waiting to drop a year out.

My gut tells me that no, they won't. That these are what we'll get this round. Hence why we get a 3090. There isn't even room in these chips for a Ti or Titan (yet).

Can't wait for reviews of both these and RDNA2 to see what is worth purchasing this fall.",amd_gpu
"Its 2080Ti performance in raytracing. Remains to be seen how it stacks up in non-RT titles, which is still the vast majority.",amd_gpu
"> Thinking more about it. 2080ti performance for 499$ is fucking insane though.

That would be halway return to what the GPU market used to be for over 20 years: Upper mid-range cards offering the same performce as previous gen high-end cards at mid-range prices.

We are still not quite there yet though high-end used to be $500 with enthusiast-grade products at $700 or $800. Unfortunately AMD took NVidia's price hike as in invitation raise prices too.",amd_gpu
"While going back to 60\~80% performance improvement is nice, this kind of gen gap is what we expected back in the days when AMD was competitive. Pascal managed 70% improvement in roughly the same TDP class, Ampere is doing 80% with 80\~100w increase in TDP.",amd_gpu
The 20xx series was a joke. Nvidia was trying something new and with 30xx they have perfected it. Both software and hardware.,amd_gpu
$499 is still very inflated for midrange. You are being conditioned like dogs.,amd_gpu
">	better performance then 

Than*",amd_gpu
Why would Nvidia suddenly do this after they shit on people with Turing?,amd_gpu
Those performance numbers have been massaged. Rtx on with dlss will destroy 1xxx performance. Their website lists 3080 vs 1080 with RTX enabled.,amd_gpu
Every 3070/80 to 2080ti comparison was with RTX on. I'd hold off on reviews til you think the price/perf is truly insane. We won't know the whole story til the rasterization comparisons drop.,amd_gpu
and amd can now beat the 3070 with big dog navi at $500.,amd_gpu
">But i would be lying if i said a 3080 for 700$ offering better performance then a 2080ti isnt spectacular.

Not better, 2x. It is spectacular performance in every sense of the word.",amd_gpu
"> Thinking more about it. 2080ti performance for 499$ is fucking insane though.

Probably will be $600 at launch, but still not bad. 3080 will be $800 at launch. About 30% value/perf improvement.",amd_gpu
Double the performance of the 5700xt is still significantly slower than the 3080. As long as the price is right it will be ok but it sucks that AMD can't compete on the high end.,amd_gpu
Still not enough sadly. 3080 is still faster by quite some margin,amd_gpu
They probably will,amd_gpu
"You may actually be able to score a new one for almost half the price if AMD is forced to pull a new ""HD7870 -> R9 270"" moment - which looks likely now.",amd_gpu
I would love to score a 5700XT for 200-250$... Let them wait for the launch prices jump and then the Holidays season shortage while chilling with an excellent GPU...,amd_gpu
2080tis are as low as 300$ rn. Mental af.,amd_gpu
Nah my 5700 xt is still a king,amd_gpu
I may sell my Radeon 7 with water block in a month.,amd_gpu
"Since I don't have a >100hz monitor I'm waiting for two 5600XT variants do drop sub 240$.

I had luck back then with my RX570, got it 30$ cheaper in a sale and could sell the two game keys for 15$ each (when this was still possible).",amd_gpu
Budget gamers rejoice,amd_gpu
Used prices just fell off a cliff.,amd_gpu
I feel a pc overhaul incoming in January/February!! Goodbye my 580...,amd_gpu
"I'd like to stay red team, but the driver issues I've had over the last 5 years have soured me on AMD gpus.",amd_gpu
Yes this 5700xt will be up for sale for sure,amd_gpu
3090 quaking in its boots rn,amd_gpu
"well, price-to-performance",amd_gpu
"Exactly. We know the 3070 is going to be really good for $500 and it'll be hard for AMD to match it. But I'm not spending $500, I'm spending $200-$350. What will the 3060 be? What will the 6600, 6700, etc. be like? If AMD can compete at the budget to midrange space they'll be fine. You can't always win in every segment of every product type.",amd_gpu
Hopefully less heat and power usage. The 3000 GPUs require a 750W PSU recommendation and the AMD GPUs in the past were running hotter and louder than a jet turbine engine.,amd_gpu
I'm relaxed. Doubt AMD is though.,amd_gpu
" They've simply returned to how pricing used to be.  Previous gen flagship at the 70 pricing.  Still $100 higher than the 9 and 10 series.  But I'm assuming that's more because of inflation, tarrifs, etc.  They went back to try to really hurt amd.",amd_gpu
They dropped their prices because Turing didn't sell anywhere near as well as they expected. It is not because they feel threatened by AMD.,amd_gpu
I am with you except if AMD doesn't release more details prior to September 17th or shortly thereafter I am going to assume that they don't have anything competitive. It would be absolutely insane for AMD to have something competitive and not try to stop people from buying RTX 3000 by publicizing info about their cards and trying to convince people to hold off on purchases for their cards.,amd_gpu
I imagine with this pricing nVidia can either change nothing if big Navi flops or “release” super versions at similar price points to compete with any edge big Navi may have.,amd_gpu
"Exactly, people's perceptions have been distorted by Turing pricing.",amd_gpu
"It’s weird everything, kinda got moved down a name. Or at least they wanted to get rid of the “ti” naming scheme to confuse less people if the rumors are true, so (basically) The 3090 is the Titan, the 3080 is the 3080ti, the 3070 is the 3080, and so on and so forth. And also look at the dies. The 3080 has a cutdown 102 die, like how the xx80ti’s cards usually did and the 3070 has a slightly cutdown 104 die like how the xx80 cards usually did. It’s just dumb naming schemes",amd_gpu
I remember when you could purchase a 60 GPU from Nvidia for less than 250 bucks.,amd_gpu
"I think I paid $200 for my 6950 back in the day and remember it being ""high end""",amd_gpu
"Yeah, around $400 is my limit for a GPU, so the 5700xt has been in my sights.     However, the 3070 looks like it provides quite a bit more performance and features for only $100 more.     I'll wait for AMD's reveal.   Hopefully they have a Navi 2 that beats the 3070 price/performance wise,  just like the 5700xt beats the 2070.",amd_gpu
"What do you think the 3060 will be, 299?",amd_gpu
"> The 2080TI is about 25% faster than a RTX 2070 super

37% faster aprox. https://tpucdn.com/review/evga-geforce-rtx-2070-super-ko/images/relative-performance_3840-2160.png",amd_gpu
"They got the *intel* and acted on it.

Still $499 is a little to pricey for my taste. It would need to run 1440p ultra on 100fps to make sense.",amd_gpu
">Nvidia are going with a much more aggressive pricing schedule this time. 

No they aren't.  It's the same prices at Turing.  

The performance just doesn't suck this time.",amd_gpu
Poor Ampere incoming?,amd_gpu
"From big dick navi

To. Boyfriend penis navi

Sure we're not the biggest out there. But we're all you need to stay happy",amd_gpu
The problem is I don't think they can.,amd_gpu
"It's not good for AMD, but it's outstanding for consumers.",amd_gpu
"Yeah that's true, it's just this is REALLY FUCKING GOOD, and AMD will really have to show something amazing, I just don't think they have anything as of now to compete, or make me wanna get an AMD GPU as opposed to Nvidia",amd_gpu
"Nvidia has been blowing Radeon out of the water for generations. At one point AMDs best card was a 1060 competitor. Even their best right now is what, a 2070 competitor in the 5700xt? 

They're not getting that upper level enthusiast market and it seems like they're not trying.",amd_gpu
I mean if they're so behind that they can't catch up then maybe they give up at a certain point. I guess consoles will keep them going this gen for sure though.,amd_gpu
"> Why? This is good for amd. Nvidia is blowing them out of the park. They are being forced to innovate. I just hope they can respond.

With an R&D budget 50x smaller? Already forced to adopt certain tech like RT and DLSS implementations or fall behind further? 

And even when they put out cards of a similar performance and price they get outsold by Nvidia cards 4:1? 

Yes yes, this is GREAT for AMD.",amd_gpu
[deleted],amd_gpu
"I believe that their new “Super” version of cards will be called with a “Ti”. 3060 Ti, 3070 Ti, 3080 Ti. Hopefully 3090 can drop in price.",amd_gpu
everyone who bought a card in the last couple of months punching the air rn,amd_gpu
Everybody would have told you that that was a dumb decision...,amd_gpu
Glad I only have a 2060😄,amd_gpu
Hello this is the 2080Ti disaster relief program. Please mail your graphics card to our location.  You are eligible for a for a $200 reimbursement for every 2080Ti within your household,amd_gpu
"There was no point that buying a 2080ti made sense. 

At 2080ti launch, the best 1080tis were selling for 450 USD and some founders cards 350 USD.

2080ti is only 10-25% better in most games for almost 1000 bucks more.

On top of that it still uses the old hdmi standard.",amd_gpu
"Rumor is RDNA2 is 40-50% faster than a 2080Ti

https://www.tweaktown.com/news/73772/amds-next-gen-rdna-2-rumor-40-50-faster-than-geforce-rtx-2080-ti/index.html",amd_gpu
give you 150€ for it.,amd_gpu
"I'm selling my 5700 XT stat cause this is K.O. fot its resale value.

Edit: I'm probably a week late already.",amd_gpu
"Yup, I'm out too. Especially since the card has been nothing but trouble anyway. This only cements my decision.",amd_gpu
Those graphs are rtx and dlss on performance. Expect much less performance from older titles or titles that don't support DLSS.,amd_gpu
"Correct me if I am wrong, but we really don't have any information about Xbox GPU outside of ""teraflops"" which (if is alone) is next to useless for us.",amd_gpu
"I feel like Nvidia is timing this really well, but AMD is just a bit off.  I'm sure I'm not the only one who has been putting off upgrading to hear about new gen stuff, and also not the only one excited for things like Cyberpunk coming out in November.  It looks like neither new gen ryzen nor RDNA 2 will hit the market before then, so I may just default to whatever looks best at that time (aka, not AMD's new stuff)",amd_gpu
"> The 3070 is spot on in price-performance ratio.

When they had no competition, NVIDIA raised prices. They're launching these lower for a reason. I actually don't think from bits and pieces that they'll match the 3080 (going by NVIDIA information today), so hopefully they can do some great pricing on the 3070 competitors.

Placing their flagship card here actually makes sense from where AMD has tried to position itself recently.",amd_gpu
"RDNA2 is rumored to have 40-50% better performance than the 2080Ti, yes Ti. That would put it on par with a 3080 I think, with less power consumption, and possibly even cheaper. I wouldn't count AMD out just yet.",amd_gpu
I was so close to getting a 5700 XT 2 months ago I'm so fucking glad i didn't.,amd_gpu
"> The 3070 is spot on in price-performance ratio

Is it? $100 higher than it should be? You've been absolutely fooled by Turing's insanity. Go back years and $499 was the absolute top class GPU available.",amd_gpu
Hey! Their CPUs are still good lol. Ask Intel.,amd_gpu
"I think you're right. Their bigger problem is with the all the added features Nvidia has that that AMD doesn't. DLSS 2.0 and Ray Tracing are going to be huge issues for AMD to overcome. I don't think AMD has anything even close to ready to compete with DLSS. If that's true they'll have to stay the budget option to even have a chance. 

I don't think AMD will be very far behind in this generation as far as performances goes, if all of Nvidia's extras are disabled. Once you turn on DLSS and Ray Tracing it's going to become a different story.",amd_gpu
How many games use DLSS?,amd_gpu
"RDNA 2 is only 1.5 the perf/watt.

Ampere is at 1.9 perf/watt. Even then, 3070 220w just barely beaten 2080ti 260w. 

And even then, 3080 320w is like 35% faster than 2080ti 260w.

The assumption of RDNA 2 having twice or even 1.8 perf of 5700xt is already in the realm of fairyland. Never in the history of GPU release thay there is a card released in RECENT times that has more than 50% increase on same node. Even Pascal which has otherworldy increase did it (980ti to titan x, only 60% increase) but from 28nm to 16nm. Rx 5700xt 225w is only 20% faster than vega 64 (300w) while having significantly reduced compute capabilities. Big Navi is on the realm of 3070 as safe guess.

Polaris is much better 2.8 perf/watt. What did we get? Rx 480(150w) with a perf of r9 390 (275w). 

One thing right now is real, AMD tech insanely lags behind nvidia right now and its even understatement. 8nm vs 7nm, 50% faster at same power (3070 to 5700xt at 4k) whilenhaving significantly less hardware.",amd_gpu
"DLSS is an anti-feature really, not a bonus. AMD can use their GPU die for more regular compute units, while Nvidia has to reserve space for DLSS.

So lack of DLSS isn't a bad thing, it actually improves performance, at least if you care about good image quality.",amd_gpu
It will be hard consider NVIDIA is not Intel. They actually improve themselves and acknowledge their past mistakes.,amd_gpu
"Hackintosh prospects are not looking great with the direction Apple is taking. I kind of gave up on my opencore build, despite having had everything working flawlessly. I'm just going to deal with not getting my iMessages on my desktop.",amd_gpu
You’re most likely not gonna get official driver support for RDNA2 card either unless a real Intel Mac releases with them installed (or Mac Pro gets an MPX Module with something similar),amd_gpu
I want that 3070 for 499$! And I might buy a 380$ 5700xt today might not now,amd_gpu
"Yeah, I'm tempted to sell my 1080 Ti and put money for the 3080. I'm just having a hard time justifying that choice lol",amd_gpu
And/or a shareholder.,amd_gpu
"yup, gonna be running a 3080 alongside my 1700x. Next processor is still going to be AMD",amd_gpu
Can you use Optix? A 3060 might offer better price performance.,amd_gpu
"Exactly. I can't understand how Nvidia has been so problematic for drivers in Linux. Why or how could you be so closed with drivers, THOUGHT you'd WANT PEOPLE to use your gpu with a fully functional.driver in Linux. Maybe a similar issue as to why apple stopped using them.",amd_gpu
"> This will make AMD be more competent

Or straight up kill their gpu division.",amd_gpu
Yes. But we still have to wait for individual reviews. But yes. It's looking good.,amd_gpu
Big F,amd_gpu
[deleted],amd_gpu
"At that price, the 3090 seems a bit too heavily invested in raytracing for me, which is stinker tech. With unreal 5 engine handling the raytracing for future games, it feels like the 3090 will be left behind very quickly once Nvidia starts releasing fully dedicated rasterization GPUs.",amd_gpu
"If they don't leak anything, I think it is fair to assume that they can't compete. They would be insane to not tell the public about what they have coming with the excitement nVidia's announcement has generated. Once people drop their money on nVidia, AMD will have missed the boat on most of the PC gamers with expendable cash. I being one of those people. I am planning on a 3080 if I can get one and unless AMD announces something that is better or is cheaper for similar performance, I am dropping my money on nVidia. This totally forces AMD's hand and if they are bluffing, they will be forced to stay silent and fold their hand.",amd_gpu
"Did we watch the same presentation? Nearly every chart had grey graphs for RTX off and Green graphs for RTX on.

3080 grey graphs were all at or above 2080ti grey graphs, and the green graphs were 1.7x-2x above 2080ti.",amd_gpu
"They showed it in the slides 

https://images.anandtech.com/doci/16060/20200901173013.jpg",amd_gpu
They talked about pure rasterization performance as well.  It's more than double previous gen.,amd_gpu
DLSS was on for turing too though...,amd_gpu
A good indication of whether a company is confident in its product is whether they are honest about the company's previous shortcomings. The statistics they reported for previous generations were in line with reviews and were not inflated/purposefully deflated. I think that's a strong indication of Turing performing within \~5-10% of reporting.,amd_gpu
"Sorry buddy, but RTX off is also 2x.",amd_gpu
Digital Foundry benchmarked the 2080 vs the 3080 at 4k.,amd_gpu
Why are DLSS and RTX on a problem? That will likely be the case for most AAA games moving forward,amd_gpu
No they have showed borderlands 3 with no ray tracing @ 4k. It was like 80-90% faster than the 2080.,amd_gpu
We know this.  They are obviously quite a bit faster in those areas.  Would be interesting to see them compared with those features off.  But I have a hunch we'll still see 3070 match a 2080ti.  But I'm excited for reviews.  And I hope amd can actually match.,amd_gpu
"Digital Foundry tested the 3080 without RTX. It's 60-80% faster than the 2080. https://youtu.be/cWD01yUQdVA?t=382

I imagine it's faster if you enable ray tracing. Also, he is testing with pcie 3.0 which we saw recently does affect high framerates. It's bottlenecking the card here for sure.",amd_gpu
"The pricing of these cards does not make sense unless (1) the slides are very misleading or (2) AMD's Big Navi will be competitive with Ampere.

If the 3070 is truly faster than the 2080 ti, then there is no way Nvidia would be selling it for $499. At those performance levels, cards will be sold out for at least 3-6 months. Why not start with a higher price and lower it after AMD makes a move?",amd_gpu
[deleted],amd_gpu
"3080 is 60-80% faster without rtx and 80-100% faster with rtx, than the 2080,  from digital foundry.

Considering higher end cards traditionally have lower price performance, that would make the 3070 have an equal or higher margin of gains over the old 2070.

Like 20% behind the 3080 I would guess.",amd_gpu
Yeah,amd_gpu
"Press x to doubt.

x. xbox RDNA 2 with 52 CU at 1.825 is 12 tf. If it were 80 CU at 2.000 ghz it will be around 20 tf assuming generous linear scaling. Thats about rtx 3070 lvl of perf. So they need to be 2.1 ghz and 100$ cheaper. From PS5 we know that it can be clocked upto 2.23, but that would need a liquid nitrogen.",amd_gpu
[deleted],amd_gpu
Yeah but also features. AMD doesn't have these new features except maybe Anitlag like Reflex. Also Nvidias encoder is so good.,amd_gpu
"Depends on the brand, not being loyal to daves greengrocer and John's butcher eventually leads you to having a choice of walmart or amazon...",amd_gpu
"my 480 was rocksolid until it blew up (??) and I got a 580 thru rma, which has been rocksolid as well

also eyeing the 3070",amd_gpu
"My issues with Powercolor caused me to go green. Until quality control and drivers are better, I can't go back to AMD.

REALLY worried about their GPU business falling too far behind.",amd_gpu
"AMD CPU's are great lately, but also close to end of the road.  


Nvidia is unbeatable for GFX though.  I",amd_gpu
"2.3X pure rasterization processing,  before you enable raytracing or DLSS.  It's nuts.",amd_gpu
I disagree. nVidia knows that historically AMD can't compete on the high end which explains the 3080 and 3090 pricing. AMD might have a card coming to compete with the 3070 but I think that the 3070 price is more influenced by the pending release of the next gen consoles.,amd_gpu
"I don't think its only Navi in this sense. 

At this point, Nvidia is also competing against consoles so they had to do something. Not just strictly in the PC GPU sphere anymore.",amd_gpu
"To be fair, the 3090 is three times the cost of a console.",amd_gpu
"Not really, the consoles' performance should be between 2070s and 2080s. Meaning they're probably gonna fit between 3060 and 3070 performance (technically midrange but still $300-500 worth of GPU power). consoles won't be more expensive than $500. 

Clearly AMD has been able to get ~2080 performance for cheap, falling in line with the leaks saying the GA104 can't touch Big Navi. 

As always we'll have to wait for benchmarks but the consoles are far far from obsolete.",amd_gpu
8K with dlss*,amd_gpu
Or consoles are going to be insane...,amd_gpu
"To be fair, some of this is meaningless terminology.  If the 3090 can run RDR2 maxed out at 8K 60FPS, it would require the largest generational performance increase ever, by a lot.  Will it run Minesweeper at 8K 60FPS? Certainly.",amd_gpu
"obsolete? lol why, why you need more than 4k@60 or 1440p@120/144? Very small percentage of people have 8K60, and is there a source saying that big navi can't do it?",amd_gpu
"$1499 card beats ~$400-600 consoles

Astonishing",amd_gpu
Or maybe it's because the World is in an economic crisis right now and they would be shooting themselves in the foot by raising prices this year.,amd_gpu
"Destroy the competition by taking even more market share. Stop gamers from moving to consoles. Economic downturn, so make the gpus a bit cheaper. Also, nVidia has a lot of cash to burn, it's not like their stocks will drop with these prices. Win win win .",amd_gpu
"Consoles, most likely.  They aren’t just competing against AMD but also Sony and MS as the new gen is pretty damn powerful.",amd_gpu
Or the pending next gen consoles?,amd_gpu
"Could also be that they want mid tier gamers to choose to spend money on upgrading their video card as opposed to getting a console instead.

They can always go back to ridiculous prices the next gpu gen to target enthusiasts who want to play at even higher specs.",amd_gpu
"I don't mind it, lowers expectations.",amd_gpu
There's more evidence than not that suggests RDNA2 could match or surpass the 3080 in terms of raw performance at both lower price and lower TDP.,amd_gpu
"There's a lot of reasons why AMD can't, and most of them are related to budget.",amd_gpu
"I’m an AMD fan but to wonder how they wouldn’t hit this level is naive. Nvidia has the software, AI know-how, and track record. I’m not saying it’s impossible, but the chances of them beating the 3080 and 3090 just went down. Especially with the $700 3080, maybe if that were at the $1000 price point, but Nvidia just jumped ahead of them with that price/performance bomb. 

Add on top of that the strides that Nvidia has made in just the last few years with DLSS. Hate it if you want but, DLSS 2 looks really good in some applications and can keep the frames up and 3.0 looks like it will be available with any games with TAA.",amd_gpu
2080ti was grossly overpriced. not really a great pricing benchmark.,amd_gpu
They’ve just overpriced/raked the money in for a long time and have to compete this gem with the new consoles. My guess is they are trying to curb console sales.,amd_gpu
"Ah yes, these are the only two reasons in existence.

The one that support your wishful thinking.

&#x200B;

Nothing to do with console pressure, samsung 8nm being a cheap process, having learned from Turing mistakes, nope sir!

&#x200B;

THEY'RE UP TO SOMETHING AND AMD WILL RELEASE SOMETHING BETTER!",amd_gpu
The process is cheap. Samsung has a thrift process lol.,amd_gpu
"Some tweets saying 3070 cannot compete with Big navi and 3080 will regret it, or something like that. But need to wait until November.",amd_gpu
9/17 for 3080,amd_gpu
"go onto ebay and search by ""sold""",amd_gpu
"Massive day one price cuts and ""jebaited"" v2 marketing campaign to cover up the lack of performance.",amd_gpu
The storage compression tech is built on Microsoft's vendor agnostic Direct Storage API so I'd be surprised if AMD didn't have something similar.,amd_gpu
We don't know that their RT implementation is significantly worse yet.,amd_gpu
"> 2080/5700xt 

The 5700xt doesn't have the same performance of a 2080, what the fuck?",amd_gpu
It's publicly traded though???,amd_gpu
"Nvidia is good at marketing and nvidia has a good track record of not lying in their numbers. Definitely cherry picked, but not misleading.",amd_gpu
"What confuses me is how 3080 is almost more efficient price performance wise than a 3070, the perf difference between them, and how the 3070 looks overpriced because of that.",amd_gpu
Lmao,amd_gpu
"> he 2080 was 15% better than the 1080 for +16% price, literally a DROP in price/performance gen over gen.

All for bullying Turing but you dont have to lie https://tpucdn.com/review/amd-radeon-rx-5700-xt/images/relative-performance_3840-2160.png

The 2080 is 46% faster than a 1080.",amd_gpu
I think most people only care about efficiency if performance is equal. I personally couldn't give a fuck. If i can get 50% more fps for double the watts juice me up jensen.,amd_gpu
It probably will be. 7nm tsmc is superior node. And rdna2 is supposed to be a huge perf/watt increase over rdna1,amd_gpu
Unfortunately we're back to the mid 2000s.,amd_gpu
And why should they? This is a desktop card. As long it stays cool power is not an issue.,amd_gpu
Very few people care about how power efficient their hardware is. It's why people end up buying PSUs that are overkill for their setup.,amd_gpu
"They do when it's AMD, not when it is Nvidia.",amd_gpu
"> I think Big Navi will be more efficient 

Considering AMDs 7nm is only slightly more efficient than nVidia's 12nm. I doubt that.",amd_gpu
Ampere is supposedly also much more efficient,amd_gpu
"Why is this down voted it's true, AMD software is basically non-existent currently. Just look at RTX voice and RTX camera software, it really is amazing.",amd_gpu
People aren't going to be interested in Navi2 if they have already dropped money on RTX 3000 already unless it has higher performance(doubtful) or is way cheaper. AMD better release some more details before everyone buys nVidia if they want to capture market share.,amd_gpu
"Navi2 rearing its ugly head is a good analogy

&#x200B;

Stop thinking AMD is your friend. Both companies are in the money making business, not the friendship business.

&#x200B;

If Nvidia prices go up, so do AMD prices.

&#x200B;

After the Ryzen XT launch you really still think the AMD CPU segment will stay so affordable if Intel can't compete?

&#x200B;

They will fuck us. Because it's profitable. And because they can.",amd_gpu
"Yeah no Rt or tensor cores tho. 
No DLSS either ,which is going to be the deciding factor from now on.",amd_gpu
"If 3070 is pretty much a 2080 Ti, then 3080 is about 90% faster than 5700 XT, so doubling its performance will make a very good competitor against 3080.",amd_gpu
Who is this charlatan talking about Consoles as an alternative to graphics cards and the PC Master race.,amd_gpu
A lot of it is astroturfing,amd_gpu
"There is the Digital Foundry video that puts the 3080 about 70% above the vanilla 2080 in rasterisation, up to 2x in full path tracing (Quake 2 RTX).",amd_gpu
"According to the very reputable leaker Kopite7Kimi, he says that RDNA 2 will be very competitive, basically outright beating the 3070 and having a strong competitor to the 3080: [https://twitter.com/kopite7kimi/status/1300465985602813972](https://twitter.com/kopite7kimi/status/1300465985602813972)",amd_gpu
"That's the issue, Lisa's own numbers are significantly worse than what Nvidia has. AMD said a 50% increase in performance per watt while Nvidia said 90% increase and cranking the power to the max.",amd_gpu
Well they won't if no one buys their cards.,amd_gpu
"Idk why dlss is getting written off as a gimmick

It’s free frames",amd_gpu
"Just like when AMD fanboys believe that the soon to be released that time vega 64 is the reason why 1080ti is only at 699?

The reason is simple, turing did not fare well pricing wise. Period.",amd_gpu
Jusy like 1080ti and the soon to be released at that time vega 64? Lol,amd_gpu
Realize 3080 comes out in 2 to 3 weeks right?,amd_gpu
"> RDNA2 is going to surprise you. 

Nvidia surprised me. There is no way AMD can surprise me any longer unless they offer even better performance which is impossible.

Their $400 little card is what people will settle with but that's not impressing anyone.",amd_gpu
I know it doesn't help you but I had zero driver issues on my Vega 64.,amd_gpu
I will believe when AMD announce their cards. Fingers crossed,amd_gpu
I drink the purple kool aid,amd_gpu
It's hilarious. Just rename this sub to r/nvidia at this point.,amd_gpu
"it's not about brand loyalty, its about who makes good products",amd_gpu
"LOL.   If this is not a copypasta, it needs to be.",amd_gpu
The fact that you're not one of the most upvoted comments on this subreddit right now doesn't speak well for this community.,amd_gpu
I think you might be taking this a bit too seriously.  Don't worry Nvidia wouldn't have priced their cards like this if they didn't expect AMD to be competitive.,amd_gpu
Wut,amd_gpu
Their assessment was a very theoretical one tho.,amd_gpu
Yes but you forget about DLSS .,amd_gpu
"I thought that was built on Microsoft's vendor agnostic Direct Storage API, a bit like how AMD will be able to do raytracing through DXR, they will not need to use Nvidia's RTX.",amd_gpu
Turing is at 12nm and it shats the floor with navi 1. The technology gap is astronomical right now.,amd_gpu
"Me too, let's finally buy it for its real price.",amd_gpu
"There is a PS5 patent for AI upscaling, XBOX Series X is using DirectML to inject great HDR support into games old and new using AI, who's to say RDNA 2 doesn't have AI tech?",amd_gpu
"It's about 70% for the 2080 vs 3080, check out Digital Foundry's video.",amd_gpu
"Turing rt is a joke, not exactly difficult to beat it. It's pretty much another dx12 and keplar moment",amd_gpu
"\*Looks at the last 20 years of ATi gaming cards...yeah, no.",amd_gpu
Nvidia can always bring out a 3080TI.,amd_gpu
The 3080 is 35% faster than 2080ti according to DF,amd_gpu
Sounds about right. The 3090 is a TITAN absolute behemoth,amd_gpu
Return it.,amd_gpu
"Agree. They don't have to beat Nvidia in raw power, but in drivers/technology too, which is kind of impossible right now. 

DLSS, RTX and the newly announced Reflex for low-latency and GPU Auto-Tuning feature which they 'highly recommend'. Holy shit! You can't beat that.",amd_gpu
Of course you do. Every Arch user has to say they're using it. It's like... tradition.,amd_gpu
"They already did that with NAVI.  It covers low to mid-range. 

They have to now focus on the high-end, and they waited so long that their challenge RTX 2080, RTX 2080 Super, RTX 2080 Ti has now turned into RTX 3070, RTX 3080, and RTX 3090 that are far more powerful than Turing.",amd_gpu
"Jensen saw that comment, so he updated the Marbles game to run fully in realtime with absolutely nothing baked and hundreds of ray traced light sources and ran 4 times faster than the Titan RTX

&#x200B;

3 months ago when the 4x RT performance rumours started, no one believed it, it was a running joke all over the internet... yeah about that...",amd_gpu
"sub 500$ is now a used market  
you can buy 1080ti for 330$  
People need to forget about 200-300$ new good videocards, those times are over",amd_gpu
"3060 launches next year, probably January. Should be 2080 super performance for something between $300 and $400",amd_gpu
"Tax in most EU countries around 20% and that GPU is already a 600€ card. And all the ""Gamer"" and OC editions will probably be in the 650-700€ range.",amd_gpu
what?  I've had zero issues with my 2070s.  The largest issue i had was removing all the damn screws to install a waterblock.,amd_gpu
The 3070 is just north of a 2080ti. A freaking series x can nearly match that,amd_gpu
how are they competing with console when consoles are using amd gpus,amd_gpu
Use r/hardwareswap,amd_gpu
What are you talking about?,amd_gpu
Technically the DF video has plenty benchmarks.,amd_gpu
"There is benchmarks, DF confirmed 80-90% in NON RT and DLSS games over a 2080, and Nvidia just dropped benches for Doom Eternal with the 3080 running 45%  faster than the 2080ti.",amd_gpu
100% leap over what? Raytracing? There's no way the 3090 is 100% over the 2080Ti.,amd_gpu
Most leakers suggested that the big navi will be on 72 CU and 80 CU. So most likely it's gonna be at least 500~800 dollars in price.,amd_gpu
"> If they release a 3070 alternative for $300

I don't think they can afford to.",amd_gpu
"Nvidia getting fucked on sales

There is optimistic and there is delusional.",amd_gpu
"You got downvoted because you mentioned DLSS. Can't do that on this sub. 

&#x200B;

Don't do it again.",amd_gpu
Atleast 5,amd_gpu
"DF tested the 3080. It's between 60-80% faster than the 2080 in traditional rasterization and 80-100% faster with ray tracing and DLSS.

It was benched with a 10900k so I believe pcie 3.0 was bottenecking the 3080. With pcie 4.0 who knows, it might actually hit the consistent 100% increase with ray tracing that Nvidia claimed.",amd_gpu
"Well good thing it happened now and both vendors didn't come out at the same time.

&#x200B;

Means AMD will probably readjust on their pricing, hard.",amd_gpu
So basically Navi.,amd_gpu
"Well, sorta. They do put the effort in to create appropriate GPUs or rather APUs to sell to Microsoft and Sony. 

&#x200B;

Then they try to leverage that technology into the PC GPU market. It works, it makes affordable low power(ish) GPUs that can compete at least somewhat.

But it can't compare to the full focused effort of a gigantic company that does nothing but GPUs.

&#x200B;

And that's fine for AMD. They need a GPU presence so nvidia has to try and AMD doesn't lose out completely on that branding. 

But their money is in CPUs and consoles.",amd_gpu
"AMD got CPU magic, nvidia got GPU magic.

It's not a bad deal for us gamers. As long as they have at least some competition.",amd_gpu
"1.9x with rtx and dlss, yeah.

3080 is 1.3x 2080ti at 320W vs 2080ti's 250W. Not so good eh?",amd_gpu
"In summary, I'mnin DENIAl stage..",amd_gpu
The RTX 3080 will be $700 and it's twice as fast as the $1200 2080ti lol. AMD will need to bring really good prices to compete with that,amd_gpu
"No, but goals changed again, power consumption is not important.",amd_gpu
"This makes no sense based on the power of the cards and the prices they are charging. The 2080ti is nothing compared to the 3090. Even if this is just a “marketing ploy”, nvidia still dropped some amazing cards for amazing prices today.",amd_gpu
"Could you be more in denial, if the DF video didn't clear it up for you, you don't want to believe.",amd_gpu
Did you look at the specs? 2080 had 2944 shaders. 3080 has over *8000* Even the raw performance of the card is literally more than double.,amd_gpu
https://www.reddit.com/r/HailCorporate/,amd_gpu
"No friend no. If you weren't impressed at the engineering Marvel at that demo then.... Maybe you are just a little boring, without meaning any offence",amd_gpu
"If that had been a AMD presentation you would literally be celebrating right now.

&#x200B;

Also DF released third party benchmarks.",amd_gpu
"Nobody outside of AMD really knows what big navi is gonna be like

&#x200B;

But everyone knows what the consoles will be like and their probably prices

&#x200B;

There's your cause for reaction.",amd_gpu
Nope. They can definitely still do both.,amd_gpu
Yeah we’ve been saying that for years. AMD GPUs are always a generation away from being amazing. I hope I’m wrong.,amd_gpu
I'm sure is not.,amd_gpu
"DLSS does come with fidelity sacrifices, it's not for everyone.",amd_gpu
They benchmarked on a i9...,amd_gpu
"The only choice i can see here is if the new amd gpus are cheaper, and take that lower \~200 bucks gpus.",amd_gpu
"It would be rather pointless because the next gen consoles have raytracing and games over the next few years will be built from the ground up for it, it will save a lot of developer time on hacks that they have to use to make rasterisation look good.",amd_gpu
"5700xt is great for price to performance, you made the right move",amd_gpu
"Why? You owned a great card that has served you for 10 months. You didn't spend an arm and leg for it and supported AMD and it's effort to come back. 

You did great. Sell the card for a $200, save a little and come out swinging with a new card that fits your gaming.",amd_gpu
Why not just say 'its looking' like a normal human being,amd_gpu
"Yah, your gpu isn't what's makeing your mouse lag.",amd_gpu
Errr....,amd_gpu
"Nvidia are paying less per GPU than AMD.

AIB's working with Nvidia's GPUs? Poor souls. GDDR6X murdered their margins in cold blood.",amd_gpu
"Margins are inflated anyway. It's not like there is no wiggle-room. I, for my part, am hoping for prices that both the consumers and AMD can call fair.",amd_gpu
"Maybe, maybe not since AMD have lined up millions and millions chips for consoles.",amd_gpu
I like the pink wafer,amd_gpu
Heard Samsung is 30% cheaper over TSMC,amd_gpu
"Well, there are no profit margins currently on high end, because they don't have those. So... :p",amd_gpu
"AMD are still using 7np from TSMC, meaning this is the 3rd year for the node and AMD's second graphics generation with it, I'm sure the cost has gone down significantly. 

We also know that RX 5700 and RX 5700xt are basically RX 580 die size, so their mid to upper tier cards that compete with the 2060s and 2070s are essentially RX 580 replacement cards, AMD can go much much bigger on the die size, they can literally pack 3x the amount of shaders, now a lot of the space will go into ray tracing, higher clocks, power routing, etc... but they still have ton of room, they can easily use 400mm big die and pack double the shaders over RX 5700xt.",amd_gpu
"I bet they are paying same per transistor, given how big of customer amd is and will be.",amd_gpu
"That's exactly the problem. With these low prices for the 3070 and 3080 AMD will have to price their GPUs accordingly, even if they are just as good.",amd_gpu
"AMD probably pays less than Nvidia do for 7nm wafers. Thats because AMD is one of TSMC’s top customers now. But still, Samsung is cheap. So AMD probably needs to really think how they will take on Nvidia this time.",amd_gpu
"They are paying per viable die due to Samsung's yield problems; and they are getting a really good deal.  

&#x200B;

Samsung 8nm is a true half node behind tsmc 7+",amd_gpu
"It's all about availability, and i think TSMC is worth on that front, since they do have the capacity to produce. i am pretty sure NVIDIA will be a paper launch, if AMD can overwhelm them with stock in the shells its pretty much job done.",amd_gpu
Yet the presentation said it's 8nm. :D,amd_gpu
The 3080 being 20% cut down shows that yields are not better at all.,amd_gpu
Samsung 8nm is inferior in density to tsmc 7nm.,amd_gpu
"The yields are still horrible. According to Moores Law Is Dead availability will be awful. The pricing is how it is because 8nm is so bad and we'll, it's Samsung. They needed to get some big orders and thus made the wafers very cheap.",amd_gpu
"> Density should be worse. Clock speeds will be worse. Power will be worse. Yet, the yields should be pretty good - would explain the huge dies that we saw.

No one cares about any of those things in the real world. It's just whether it delivers the goods.

That said, there's no particular reason to expect clock speeds to suffer. One advantage of a large die is the heat is automatically spread out more. And if Intel can top 5ghz on 14nm, there's plenty of potential headroom.",amd_gpu
8N is not the garbage node everyone think it is.,amd_gpu
You could have made your comment look like less aids if you deleted it.,amd_gpu
Nvidia's architecture is a hell of a lot more efficient than AMD's though. The 7nm 5700 XT was competing against the 16nm GTX 1080 for power efficiency.,amd_gpu
Previous gen was 12 nm vs 8 nm right and they still had the better product.,amd_gpu
"sad how nvidias ""optimized 10nm"" still beats amds 7nm. 5700xt is also hotter than comparable nvidia cards of last gen yikes",amd_gpu
yeah I mean it's not as critical to have a high density like CPUs do so they can afford to go with Samsung's inferior process to save a ton of money while still delivering pretty good performance,amd_gpu
"It also has TERRIBLE yields.  

&#x200B;

So we're talking at least half a node behind TSMC 7p/7+, with only 30% of the yield.  nVidia did get a good deal - and are paying per viable die instead of per wafer, but availability is going to be ZERO until Q1 2021.",amd_gpu
"They are just marketing terms and the actual transistor density, which also depends on the type of transistors, are in one manner similar.",amd_gpu
....but they weren't even using Samsung before?,amd_gpu
"They are fabless, so what happened to Intel cannot happen to them basically...",amd_gpu
"I also have a feeling that these prices are NORMAL, and we all got used to outrageous inflated prices over the last 2 years from crypto and then covid shutdowns.

I bought my 1070ti for $530 in 2018. The 3070 SHOULD be priced just under assuming a 3070ti will be priced around $525 - $550.

AMD has always focused on the budget area, not industry flagship. So I would anticipate that AMD's flagship will have something FPS competitive to 3070 in the $399 - $449 range. And that NVDA will justify their higher prices because of all their ""features"" like DLSS, the streaming stuff, the add ons that some gamers are willing to pay for.

Overwatch FPS gamers like myself won't really care since I don't typically play AAA titles or have that nice of a monitor. I just want the FPS.",amd_gpu
"Ive said this before.. AMD has actually been following a game plan for years for its GPU's. Nvidia was obviously well in first place during the GTX 9xx series days. The RX 480 came out with perf/cost and traded blows with the GTX 1060. Later, the 5700XT was released, firing warning shots at the 2070. Biggest Navi has been rumored to be on par with the RTX 3080. Well have to see if that pans out, but if it does, there will have been a clear track record of gaining on Nvidia in every generation.

Im sure Nvidia has been watching this too, so I really hope RDNA2 comes about soon so that I can see if i was right or not.",amd_gpu
"The NVidia and AMD competition is dofferent from intel vs AMD though.  
AMD GPUs, while not the best could at least be considered as a good option while those amd cpus during the dark times....well we better don't talk about them.  


It is more likely that pricing is due to the new console releases than any fear of AMD chips. Nvidia profits from this competition as much as AMD does they don't want a monopoly. The new consoles though...well they are not more powerful but many people game on more than one system. The next 2-3 years are the years in which people would also upgrade their console and those people don't have infinite amounts of money.  
It is  lot easier to sell your gpus when people have to decide between buying a new console or buying a new gpu as they are priced somewhat the same.  
With pricing like the 2080 the decision would be between buying a gpu and buying both new consoles, an additional nintendo switch and a new 65"" tv to go along with it.",amd_gpu
Not going to happen.  Nvidia would have to fuck up for 5 years for that to happen.....,amd_gpu
Even competition is always a good thing for innovation and price.,amd_gpu
"If after yesterday you're still somehow convinced AMD is a real threat to Nvidia in any way you're holding on to the fanboy hype a little too much.

I'm hoping they'll still be competitive in some price-ranges as they've always been. I could imagine a new mid-range card that performs on the same level as the 3070 but might be a tad cheaper (which would be absolutely marvelous for us consumers). Imagine a card at that level for say, 350 to 400 dollars rather than 499. Although I'm pretty certain it will come with a few drawbacks, such as maybe lesser raytracing performance and obviously no DLSS.

But it's doubtful they're going to beat the 3080 or 3090 performance. Of course, the 3090 price is absolutely insane even for the power you're getting, so there might be room for Big Navi's flagship to land somewhere on the charts where it has lesser performance than a 3090 but a far more reasonable price. If that price vs performance ratio is positive then AMD could still have some viable options for this gen, but to imagine they're still going to put out an ""NVIDIA killer"" at this point seems highly unlikely.

I do hope we're getting some info soon though! I'm extremely curious about what they're going to bring to the table.",amd_gpu
This is good for consumers :D,amd_gpu
If that happens to nvidia it will likely give amd a huge monopoly and they will jack up the prices,amd_gpu
"*Has done, ftfy",amd_gpu
"NVIDIA has never been complacent.

They may pretend to be, by keeping their R&D secret and holding products back by *years* for lack of competition, but you know how NVIDIA *always* has a better product to release whenever AMD does a release? They probably have a stockpile of tech waiting to drop that's 5 years ahead of anything AMD is currently working on.",amd_gpu
"Late reply, sorry bout that. Nvidia never got comfortable with their position like intel did. The 20 series was priced terribly but nvidia was still trying to push the market forward. Amd won't be able to catch nvidia off guard like they did intel. I'm confident that AMD is closing the gap though.",amd_gpu
"> making AMD irrelevant at the high end for a generation.

To be honest, AMD doesn't need help with that.

I have been looking at my upgrade options from a Vega 56 now that I'm doing VR gaming. The 5700 XT compares somewhere between a 2060 super and 2070 super. Granted, it is priced appropriately. But if you're purely motivated by performance, there's still the 2080 super, and if your wallet has no bottom, the Titan RTX.

AMD hasn't had a top-end card for a few generations now. They are very competitive in the upper-mid market though, which realistically is where I've always bought anyway.

To be clear, I prefer AMD personally and an nvidia GPU of any type would be a functional downgrade for me (Linux user).",amd_gpu
They know how quick it is. Word spreads amongst people in the know and big navi production candidates will be in 3rd party hands by now. Loose lips and whispers everywhere. The 3080 & 3070 pricing tells us exactly where big navi will slot in. It's a 550 dollar card.,amd_gpu
"I mean, and hasn't been relevant at the high end for a while now.",amd_gpu
"The issue in the GPU market is Nvidia is not the fuck up Intel is. 

They very much have their shit together, their driver support is extremely tight and they are keeping on the bleeding edge of available tech on the hardware side.

I have a Ryzen CPU and I love it but I wouldn't touch an AMD GPU. I tried putting an RX480 a year or so ago on a Windows Server 2019 machine (since repurposed into a FreeNAS box) and it was pretty much fucking impossible without manually modifying the driver inf's myself to allow it to even install on the OS. Which I was absolutely not going to do every time there was a driver update. I took it back and swapped it for an Nvidia card and the Nvidia drivers installed on the first shot, no issues at all. On my Plex box same issue, drivers won't install (another Windows Server 2019 again) and even if I did force it to install Plex doesn't support hardware transcoding on AMD.

Unless AMD seriously ups their support game on the GPU side they are a non-option for me.",amd_gpu
Would be a big shame for AMD graphics cards to be downgraded back to the mid range segment right after the boost it got with RDNA,amd_gpu
">I'm suprised by the pricing

Same pricing as Turing.  

It's crazy - everybody just irrationally assumed prices would just keep going up and up and up and so even just staying at the same 'already increased' pricing makes people think the pricing is good. 

smh

Really frustrating to see.",amd_gpu
"I'm not sure they are priced to kill.  Just because Nvidia doesn't double prices this generation doesn't make them a bargain.  We haven't even seen if the pricing Nvidia has given includes the founders edition tax of $100 extra or not and let's be honest, that extra $100 is added to every card whether it's founders or not.",amd_gpu
"I doubt that. When Supers released for Turing, they were the same price as the originals, and they just dropped the prices of the non Supers before phasing them out.",amd_gpu
"Also, since they released the cards now, those who bought it won't buy RDNA2 even if it's slightly better.",amd_gpu
"They're not going to saturate anything except paper.

&#x200B;

Availability is going to be so low that it might as well not exist until Q1 anyway.",amd_gpu
"I think supers will be a year out and be relatively minor upgrades, to make the 'generation' jumps look attractive to a wider market.

But we could see in between 'ti' or I could imagine 30X5 cards (Seeing as they've decided to stick to numbers for the 3090 instead of stupid naming schemes :P).",amd_gpu
"There'll be no stock, and the price will be driven up.",amd_gpu
">Then, a few months from now after they get the early adopters, they can release the Super cards for $100 more and sell the cards at the price they intended.

Literally none of this is precedented or at all realistic.  

I dont know why y'all think the prices are so fantastic to begin with...",amd_gpu
"Companies don't have a desire to lower prices. The only reason to lower prices is that another company has lower price or if you go higher people won't buy anything at all.

Cost of production has basically nothing to do with it, it's just a price floor.",amd_gpu
"No, that's not the reason they're so cheap. It sure as hell helps but if NV could price them like before they would. Increasing margins is almost always preferred to lowering prices.",amd_gpu
"way worse too. look at the obscene power they're throwing at em.
350w for a 1700 clock. Watch that hot spot trying to o'clock them.
Get a waterblock for this lot and they should be good.",amd_gpu
How on earth can you know that. You cannot.,amd_gpu
probably because they just knocked the performance cost of a 2080 ti from ~$1200 down to $500,amd_gpu
Idk... I bought my GTX 1080 during the last Bitcoin AllTimeHigh for nearly $700... I'm very excited about the posted MSRP considering what an RTX 2080 super is running right now.,amd_gpu
I think if Nvidia viewed AMD as a threat all their cards would be priced low. The fact that the 3090 is so expensive is disconcerting because it likely means that Nvidia will be king at the top again with no challengers.,amd_gpu
I would say that people that are hit the most by this pandemic dont play games on High end PCs.,amd_gpu
"GPUs are luxuries, a pandemic doesn’t change that",amd_gpu
Rtx 3090 $1500,amd_gpu
They didn't really raise the prices. Price/performance it's still great... they just shifted the names. If they extend this price/performance ratio down to the 3060 range and that area is what is needed. But they wont' release those first because people would just buy the cheaper ones.,amd_gpu
Exactly why Nvidia would want to maximize their profit margin.  BigNavi definately had some sway on nvidias aggressive pricing.,amd_gpu
Stimulus checks going straight to 2080 Ti's even if that meant you starved tells me the GPU market doesn't really play by global crisis rules.,amd_gpu
"Lol, not according to Nvidia's shareholders. Stock doubled since March. If Nvidia didn't expect AMD to bring anything competitive at $500+ GA104(3070) would've been the 3080 and the cutdown GA102(3080) would've been $1400 and the full fat GA102 would've been a $3K Titan.",amd_gpu
I think they are trying to keep people from jumping from expensive PC's to Shafordable consoles......their 2nd competitor this year.,amd_gpu
"Yeah, but people are at home playing more games...",amd_gpu
 if anyone hit by that is considering a $700 or even a $500 GPU they need a financial counselor,amd_gpu
hyper inflation that's coming will take care of that.,amd_gpu
"So here's the thing - most people with high incomes are ok right now. 

It's mostly the poor who are struggling.",amd_gpu
"The 3090 is $1499, up from $1199 for the 2080Ti.",amd_gpu
Still an increase as the 1080 was $600 and the 1080 Ti was $700 but I agree.,amd_gpu
"Yeah, the first round of Turing cards didn't meet Nvidia's sales expectations, which was a big part of the reason for the Super cards. Nvidia is too proud to lower prices explicitly, but the better price/performance of the Super cards was effectively a backdoor price drop to bring the cards back to a level that would be more appealing to customers. I don't think AMD had a lot to do with that, or with their pricing strategy for Ampere either.",amd_gpu
"I seriously doubt the 3080ti will come out, Jensen called the 3080 the 'flagship' implying there won't be a higher sku in a few months like with the 1080ti. the performance gap between the 3090 and the 3080 already on GA102 simply isnt there, its 15-20% max. Him saying that is basically telling people ""don't worry, you can buy this now and not worry ab it being upstaged in 6 months"".

That leaves no room for a 3080ti. The only thing that might happen is possibly a 3080 with 20GB vram, would probably be $100 more or so. There is a gap in price but not performance, also I don't think Nvidia wants the 80vs 80ti vs 90 confusion, they want to simplify it.",amd_gpu
"The 1070 did not cost $500.  And the 1080 did not cost $700.

These are TURING prices.",amd_gpu
"yes. nvidia never intended to raise prices again, this was only stupid rumours from idiot who just think that higher prices = higher profit and just spread everywhere after that. this is entirely in line with what i was expecting.

besides, jensen specifically talked about pascal when announcing the pricing.. not AMD.",amd_gpu
They didn't sell well? Where did you pull that lie out of it?,amd_gpu
Unlikely. They'd be hurting their revenue just out of spite and their shareholders would have Nvidia management over a barrel for that,amd_gpu
It annihilates it.,amd_gpu
"It crushes the 5700XT, and 2070S ofc. Both cards are a generation older.

However, what remains to be seen is how good Navi 2 is.",amd_gpu
You sure about that? Sounds to me like they'll just wait and announce the 3060 to fuck over AMD again.,amd_gpu
"Just looking at the sizes of the new cards, I'll need a new case at the minimum to even fit one, and I just got a new case three months ago. Fun times for my wallet",amd_gpu
Either way it's win win for us,amd_gpu
"One shouldn't compare the new cards to old ones over multiple generations just going by the naming scheme. The 3070 will have 2080Ti performance which was still over 1000$ up until now and far ahead of everything else performance-wise. So this is a huge jump for a really good price, I expected less for more.",amd_gpu
"They're the same pricing model as the 20 series launch. They were too high then and they're still too high IMO. Don't worry though, when AMD does finally release something probably next year at this point, NV will drop the prices on these cards and release the S lineup again and everyone will be salty.",amd_gpu
">I have the money to buy a US$1K + gpu but on principle, I can't justify those prices or expenses.

I fail to see how that's a problem.

On principle, then, you shall not own a high-end GPU. It's simple enough.

Also, 3080 is $700, not $1000.",amd_gpu
Hell yeah it stays brother,amd_gpu
What 3080 Ti leaks? I'm hoping for a 3080 Ti for like 1000$ and with 20gb vram,amd_gpu
"The much more logical conclusion is that they are confident they can shut AMD out of the GPU market completely in this gen, and are positioning prices to do so. AMD benefit is always that you get better performance per $, but why buy AMD if you get the same performance per $ and have a higher overall performance level from NVIDIA?",amd_gpu
Tapeworm.,amd_gpu
"I'm not prepared to know. That's too much, even for 2020.",amd_gpu
"Realistically I'd rather buy an Intel GPU than an nVidia GPU.  If AMD, Intel, and nVidia all released nearly identical GPUs for nearly identical prices, I'd buy AMD.  If it was between Intel and nVidia, I'd absolutely buy Intel.  Intel does some terrible stuff but I don't think they're as bad as nVidia.  Intel actually develops open source drivers for their iGPUs on Linux and those drivers are fairly good, in some cases better than their Windows drivers.

Does it mean I like either Intel or nVidia?  No.  Both do some horrible stuff to try to control their market unfairly, but at least Intel doesn't also try to screw over the users and the open source community at every step.",amd_gpu
LiTteRaLLy hiTLeR,amd_gpu
Nazi Germany.,amd_gpu
[Literally](https://i.redd.it/0x2v21x135i41.png),amd_gpu
Piranha?,amd_gpu
"A company dominated by a few super rich white dudes, focused mainly on trading with other super rich white dudes and a sideline of fleecing the masses with subpar products? 

Look outside, you probably live there.",amd_gpu
So like Nintendo before the Switch.,amd_gpu
"Who's claiming moral superiority for anyone? My friend, when the day finally comes that you leave behind fanboi battles on the Internet and finally step out into the big bad adult world you'll realise there's potentially, and probably, arseholes on every side of everything.

That fact doesn't make nvidia's business practices any more palatable.",amd_gpu
Sounds like a reasonable way to make purchases.,amd_gpu
If they can slam 2080 equivalent graphics cores into a 8 core zen 2 Apu with 16 gigs of Gddr6 and fit that under 500$ it should tell you what's cooking.,amd_gpu
[deleted],amd_gpu
"Yeah, the 3070 looks nice.  I've always bought ati/amd for me and nvidia for my wife since the eq days.  There's a chance I might go with nvidia this time.",amd_gpu
Lol,amd_gpu
"Yup, the 3070 killed it, if you buy anyone higher than it for gaming you're a complete show off.",amd_gpu
"Don't worry, Navi is getting 2x the CUs of 5700xt which equals 5120 stream processors each with its own TMUs and ROPs which is pretty much equal to the 10500/2=5250 cuda cores in the 3090. Although this generation AMD is loosing on the compute side I doubt anyone cares since they have the MI100 AND 200 CDNA cards. Also it will be much more efficient than nvidia which will make the cooler around $30 rather than nvidias $100.",amd_gpu
They have a barely functional OpenCL. ROCm doesn't even work on Navi and isn't even included in the driver.,amd_gpu
There is support for pytorch and tensorflow called ROCm. I got it working on my linux distro in a few hours.,amd_gpu
I dont understand it either. AMD is sooooo far behind in that field its not even funny. Yes consumer gpu for deep learning is a small market but they also do not have anything of the cloud market which is pretty big and will scale with the demand for AI tech in companies. And all this is fueling Nvidia's own AI development to increase the gap even further.,amd_gpu
"Same here, this is my daily bread and butter and there just is no other option than Nvidia cards atm.",amd_gpu
"Mate, some games look better with DLSS on than Native... that is certainly very impressive",amd_gpu
But first you have to imagine games actually supporting it.,amd_gpu
Dlss 3.o whennnn,amd_gpu
"They need to find a way to make it compatible with EVERY game, else it's just a glorified AAA game reshade.",amd_gpu
[deleted],amd_gpu
[deleted],amd_gpu
Even its not before 917 it should be before the end of Sep. If the 3070 drops first they are doomed.,amd_gpu
That's my birthday!,amd_gpu
A real concern for sure. Let’s wait and see if AMD can continue their price-to-performance argument.,amd_gpu
"Difference is intel didn't improve for 10 years, Nvidia actually does.",amd_gpu
Even if Nvidia walks away with a clean sweep there is always a market for value cards.,amd_gpu
Just look at the 2000 series. Zero improvement in perf/$ over the 1000 series.,amd_gpu
"There have been times in the past when ATI/AMD couldn't keep up with Nvidia. Nvidia still kept cranking out great stuff. It's just their corporate culture, they don't rest.",amd_gpu
I mean AMD isnt terrible like it was on the cpu side They are very competitive on the medium high range so intel could only increase on the very high end,amd_gpu
"This is what I keep trying to argue with people, if you are a true PC lover or really just a tech fan in general then we should be supporting more the under dog more often when we can. Keeps the market honest and makes sure the guys on top aren't just sitting there making profits off the same old re-branded tech or slightly upgraded.

AMD is putting pressure on two huge monopolies that have a lock on their world markets, no one else is doing that and no one else is even going to try to at this point.

Help AMD keep the market honest with competition, we could start producing tech of the future and stop wasting so much time and resources on yearly upgrades that are barely able to be called upgrades.",amd_gpu
This has been the narrative since I built my first PC in 1998.,amd_gpu
Pave the way for a 3Dfx Voodoo comeback!,amd_gpu
In reality a lot of comments seem to be hooray AMD is competitive so i can pay less for my nVidia card! Which of course means AMD underachieve again and the cycle continues. Dread the RTX4000 prices if that comes to pass.,amd_gpu
"I mean, look at the cost of Turing.",amd_gpu
"Nvidia has already been doing that.  Everyone seems to forget how shit Turing was.  Terrible pricing, average gains in rasterization, and RTX basically making games unplayable for negligible visual gains, even on the 2080Ti (in what games even supported RTX—as there are only even a handful at this exact moment, at the end of Turings life-span).  Did I mention the terrible pricing?

Anyways... I am a 1080Ti owner myself, but refused to upgrade to a 2000 series card due to the facts stated above, mainly though, because I refused to pay the ridiculous pricing they had set.

The trend used to be, you got an x70 card for $300-$350, and it performed close to around the previous generations x80Ti. So, even with the great gains were supposedly getting with the new 3070 performing about 2080Ti levels of performance...the fact that it’s $500 is a huge turn-off.  The 3rd party cards are most likely going to be like $50-$100 more expensive than reference, once a good cooling solution and overclock are applied. The only way the 3080 should appeal to anyone, is if there never is a 3080Ti, and the lineup has just been shifted—as in the 3090 is the new Titan model (just kept in line with the series naming model), which would make the 3080 be the new “Ti” variant, and the 3070 is actually the xx80 variant.  Because that would put the GPUs back into their rightful pricing range, where the Titan is over $1,000...the flagship Ti card is $700, the xx80 variant is $500-$600, and the inevitable 3060 (really the xx70), would be $300-$400.

But...we all know nVidia left that huge price gap between the 3080 and 3090 so they can release a 3080Ti for about $900-$1,000.  Why else would they only give the 3080 10gb of vram?  That gives it less than the 1080Ti, and 2080Ti.  

With all that being said, even with the dumb ass pricing and possible shift in naming which would help to make the prices actually make sense—I really don’t think AMD can deliver a 3070 contender...EVEN WITH its supposed BIG-Navi GPU.",amd_gpu
The fact that Nvidea is charging so little for these cards is interesting.  If Nvidea really had that kind of advantage I'd expect then to charge whatever they wanted.,amd_gpu
[deleted],amd_gpu
"I don't think it's a big deal if AMD can't match 3090 performance, but I think they need to at least match 3080 performance to be taken seriously",amd_gpu
"AMD has until 30XX releases to impress people, if they dont, there wont be many people left to buy RDNA2.",amd_gpu
"If anything, revealed pricing hints at cards that AMD will likely compete with.",amd_gpu
"What good is a competitor that isn't competing? And I doubt nvidia will let AMD fail completly, remember MS assisting Apple back in the day?",amd_gpu
AMD can compete though. Lower the price. Win for customers.,amd_gpu
If you continue to support AMD despite them not keeping par with Nvidia then you're just sending the message that they don't need to do anything to keep people buying their products. Vote with your wallet,amd_gpu
[deleted],amd_gpu
This. If AMD fails then Nvidia will fuck us next generation.,amd_gpu
"Yeah, I can't wait to spend $1000 on the RTX 5050.",amd_gpu
"Nvidia is already winning by a large margin. They have 80% market share in GPU. 

Whether AMD can compete or not is solely upto AMD. They need to prove to consumers they have a competitive product. If they can't do that. The fault falls on AMD not consumers to bankroll a bad product just for the sake choice.",amd_gpu
People don’t seem to get this.,amd_gpu
"Vote with your wallet, if nvidia pull that card again we will just skip it again and again while looking for alternative. So far I am pretty surprised with the spec, we expected that 3080 only has 4352 cuda cores. How could the leaks were so goddamn wrong, nvidia did this on purpose?",amd_gpu
Nvidia learned that they can't just charge that high again. They were basically begging Pascal owners to upgrade.,amd_gpu
But it seems 2000 series was a test. That is why 3070 is now a high end card like in the old days and 3080 is the 2080ti equivalent and both cost like 200$ less than 2000 versions,amd_gpu
"It is because they have a new goal post, Making a Gpu that people will buy for $1500. AMD and Intel are taking notes and will look to get a piece of that pie.",amd_gpu
"If the couldn't compete the 3080 would be $2000 and the 3090 wouldn't exist until after AMD responded.

The fact they're going so cheap, is likely due to the fact they think AMD has a good hand.",amd_gpu
"2000 series was a pretty large technical accomplishment. Some of the price was due to cost recovery, early adopter tax, etc.",amd_gpu
"> It's not a good thing for consumers if one team wins by a large margin.

Right and that is their job, not mine.",amd_gpu
AMD hasn't been competing in GPU space for last half of the decade....,amd_gpu
"Or you could just, you know, not buy the goddamn GPU.

Who are these people who need 120 FPS at 4K with raytracing?

Answer: Nobody.

If nobody buys the goddamn things, I guarantee they'll go down in price.",amd_gpu
"Hmm yea weird stance when y'all cheering on for every gen Intel can't compete.

&#x200B;

You guys just love your underdog. It is brand loyalty. It has nothing to do with healthy competition.",amd_gpu
Fury and Vega 7. Dropped dead shortly after launch.,amd_gpu
"Well, the power draw is one hell of a deal breaker. Im NOT FUCKING EVER getting a 300+ watt GPU.

Now, if AMD releases 300+ watt GPUs, i guess im fucked",amd_gpu
"Exactly, at this point I don't care what nVidia craps out.  No matter how shiny it is it's still a turd if it doesn't have good Linux drivers.  I got a 1080Ti when Vega turned out to be a flop and it's a great Windows card but it's garbage on Linux.  I'm going to buy big Navi no matter what so I can get rid of this 1080Ti and be able to run Linux comfortably on my main desktop again.

Built up a second Linux-only rig with old parts and grabbed a used RX580 for it, it is so much nicer to use AMD for Linux.",amd_gpu
This is one of my main reasons for avoiding NVIDIA like the purple plague. Open-source driver or GTFO. Proprietary drivers are a ticking time bomb.,amd_gpu
"Yep. I've basically decided that no matter what they release, my next GPU is going to be from AMD. They have nice hardware, but treat Linux users as though they're idiots and do whatever they want.",amd_gpu
The cost of being stingy and closed-source with your proprietary drivers and SDKs for decades. I can't imagine Nvidia will ever go open-source. They've done it on purpose for such a long time.,amd_gpu
Have you tried Pop OS?,amd_gpu
I mean I use Pop OS Nvidia build for work every day and it works perfectly. I know it's not open source but such is life. Definitely better than the blue screening AMD drivers for 5700XT,amd_gpu
Just use windows like a fucking normal person nerd,amd_gpu
[deleted],amd_gpu
RGB,amd_gpu
"Yeahh we are all aware that the 20 series was a smol brain move anyways

The 30 series is where things get real",amd_gpu
"When did high end gpu pricing get so insane? I never remember top tier gpu's being so expensive. Costly for sure, but not this $1k nonsense.",amd_gpu
"They couldn't have sold a 775mm^2 die for that much and made much of a profit. Heck, that's a full 50% larger than the 1080Ti that came before it. And why would they bother when AMD had (and still has) no answer for it?",amd_gpu
"Exactly that. 3070 is still overpriced and quite power hungry.

The difference between 3070 and 3080 is enormous too, which hints at short coming 3070 Ti/Super/Whatever at 500 usd with like 7.5k cuda cores, while 3070 will be shifted at 400 usd.

And those 320-350W tdps for 80/90... Insane",amd_gpu
Yeah Nvidia were still cashing in on the crypto craze when they priced that,amd_gpu
But boring! I’m buying now and going to ride that emotional rollercoaster of post-purchase anxiety all the way to RDNA2. Yee-fucking-hawww!,amd_gpu
"https://www.tweaktown.com/news/73772/amds-next-gen-rdna-2-rumor-40-50-faster-than-geforce-rtx-2080-ti/index.html

No, which I think would put it on par with a 3080 with lower power consumption and possibly lower price.",amd_gpu
And that 2% being 2018+ games.,amd_gpu
"In TODAY'S games though.  I want this type of performance for the next 2+ years...  A lot of the reviews I've seen of the 5700 XT say it's indeed great for 1440p, but won't be all that great for future titles.",amd_gpu
Can it do it in Tarkov?,amd_gpu
It barely hits 100 fps at 2560x1080 in Outward and Monster Hunter World on high settings,amd_gpu
"That 320 watt power draw. That explains a lot.

Nvidia is pushing their shit to utter insane limits. They NEED the performance. Nvidia usually doesnt do GPUs like this. If they are willing to make a 320 watt GPU as their second best, that means they are genuinely predicting a strong competition.",amd_gpu
"Where did you get 60% faster than 2080Ti from? On the ""Greatest Generational Leap"" graph they showed, the 3080 is at \~4.5x and the 2080Ti at 3.25x. This delta makes it that the 3080 is \~38-40% faster than the 2080Ti.",amd_gpu
"> AND if DLSS were to get more popular, AMD GPUs would be completely defeated.

Honestly, this is the biggest issue AMD has to deal with. The AI upscale tech is dramatic. DLSS2.0 is GPU wizardry. If the rumors about DLSS3.0 making it easier to utilize (by game devs) are true, whenever that gets added to the driver nvidia is gonna get a nice performance boost without any hardware changes.",amd_gpu
"If the console announcements were anything to go by, AMD was matching a 2080 with *ease* in the consoles, using RDNA 2.

I wouldn't give up on them just yet.",amd_gpu
"Until they break the APIs.

Bought a new 2070 to replace a 1070 that was making my PC bluescreen. Now I have to disable advanced graphics settings that worked on the 1070, but make a game (Fallout 4) crash under 20XX series.

I'm wary about buying a 30XX because what will break then? Backwards compatibility with released products is kinda important.",amd_gpu
"I don't think AMD is easily beat in the RT department, they have worked with Sony and Microsoft to develop their consoles' ray tracing capabilities and they should get better with Big Navi",amd_gpu
"if you're playing games that utilise them then yes nvidia is the way to go, but those are far and few between",amd_gpu
Can we stop with the marketing memes that only appear half-baked on 5 AAA games per year?,amd_gpu
"I think they wont have any major problems with the DXR implementation but they cant compete against DLSS that well, unless they shove more raw power in to their cards, which might be doable since rtx3000 series has quite high TDP.",amd_gpu
Looks like you were terribly wrong,amd_gpu
I can easily see the 3060 being at least *as good* as a 2070 Super but at a price around the $350-400 mark. Combine this with the software improvements Nvidia has with the 3000 series and I honestly think second-gen Navi is in trouble.,amd_gpu
"AMD doesnt have AI cores yet, unless they are hiding them so I honestly dont expect their RT to be Ampere destroying, but if they can nail that 3070 - 3080 market with similar performance and better prices then thats a great start.

All AMD needs to do is offer similar performance at better prices and they will net a lot of customers.",amd_gpu
"Well either that, or it needs to be really fucking cheap. What I am looking forward is 5700xt price dropping heavily.",amd_gpu
"Well in a sense 5700 and XT were competitive to the 2060/70 and super, where in cases of a maximun of 15% that honestly the people who play at 60hz won't notice at all it was a tough choice.

5700 is a good performing in the sales department, the 6700xt of this gen could be about 2080ti perf for idk 400 or even 450 and could be still a good buy.

Yes raytracing is becoming someting to look at, but the majority of 3rd parties won't launch games with that until the marketshare has enough hardware to do it even if they care at all.",amd_gpu
"but they are showing the 2080 Super just a notch above 1080Ti .... so thats your 3 point scale... 1080Ti to 2080 was meh, and it shows here on the chart... but 3080 is WAY higher up there.

all that said though, its a marketing slide...",amd_gpu
Digital Foundry has an actual raster performance review.,amd_gpu
Digital Foundry already benchmarked 3080 performance and found 60%-80% performance increase over 2080 without raytracing/DLSS at 4k. [https://www.youtube.com/watch?v=cWD01yUQdVA](https://www.youtube.com/watch?v=cWD01yUQdVA),amd_gpu
Is Nvidia known to lie about performance graphs? They didn't lie with the Super releases.,amd_gpu
">They could easily take a few dlss games and suprise: the new cards are so much better than a 1080ti. No wonder, when they are only rendering 1440p and upscale that shit, while the old cards have to render 4k.

No they couldn't easily do that, because that'd be extremely disingenuous an a shitty thing to do, it's a straight up lie basically. And it's not that people won't ever find out. It's not worth it at all.",amd_gpu
"Digital foundry tested the 3080 in 4k with dlss off against the 2080 and it's 60 ti 80% faster..in games likes Borderlands 3, Shadow of the tomb raider..I did some math..the 3080 is 30 to 50% faster than a 2080ti basically in rasterized performance..",amd_gpu
"Upscaling makes a ton of sense, conventional methods of increasing performance have .. hit the wall, you cant keep increasing die sizes as a way of increasing performance so they went the other direction.

Even AMD is doing it, why ? because it works.

as for the old cards ...what do you want them to do ?",amd_gpu
"Highly doubt for two reasons:

\- they have marked other slide sheets with ""DLSS"" in the same announcement

\- this would just raise expectation and shoot them in the leg incredibly bad for literally no reason",amd_gpu
I *guarantee* you that's what they did.,amd_gpu
"I think the biggest reason for Turing flopping was nVidia banking on RTX so hard to sell the cards.

The mining boom and bust didnt help either with driving prices up and causing consumers to keep what they had.",amd_gpu
"Exactly. The 8800GTX/Ultra was insane. AMD's 2900XT didn't even come close.

Let's hope this isn't a repeat.",amd_gpu
"We need ""low ampere"" memes",amd_gpu
I am very tempted to sell my Red Devil for a 3070 or 3080 but will wait,amd_gpu
"AMD is already behind Nvidia and they promised 50% increased in performance per watt. Nvidia just announced a 90% increase.

This puts Nvidia at almost twice the performance per watt. I assume that's with the 3090 but still.",amd_gpu
yea obviously...,amd_gpu
"to which part? genuinely curious.

I'm a fan of both, but I don't see AMD pulling ahead on this one at all.",amd_gpu
Can't wait for the 4-slot 3rd party cards that changes the center of gravity for the entire case when vertically mounted.,amd_gpu
Big Chungus. Chonker. Absolute Unit.,amd_gpu
"The dude talks well. Holodeck, time machine... Paints a cool picture.",amd_gpu
"I mean, Microsoft Teams does the background replacement thing already? Maybe not quite as well, but it's not as groundbreaking as they are trying to make it seem.",amd_gpu
Couldn't help thinking that the chair is cleverly framing his face. That's where background replacement normally struggles.,amd_gpu
Link?,amd_gpu
"Cool tech but not going to be used much unless they pay streamers to showcase it while streaming, just like RTX Voice",amd_gpu
"It wasn't a fab change, but before the 2XXX series it was common for them to release Ti editions with a spec bump 4-6 months after launching a new generation. I could see a 3080Ti and 3070Ti with a 7nm fab. 

I highly doubt they'll just release an updated 3070 or 3080 on 7nm. Its bad branding and makes it hard to increase the price.",amd_gpu
"Who says it's gonna be broken for a 3080Ti release in 10-12 months tho?

Fyi they are tripling 7nm EUV chip production rate by year's end.",amd_gpu
Pretty sure Jensen said 8nm during this presentation.,amd_gpu
"A 3080ti probably right? same memory, more cores.",amd_gpu
"They will be using Samsung full 7nm EUV node.

AMD dropping nodes doesn't necessarily mean shit either. They got wrecked by 12nm Nvidia when they were at 7nm.",amd_gpu
"I thought Nvidia already had a link/streaming thing? And anti-lag is understandable, it's actually a great feature.",amd_gpu
"How's that a bad thing? As a consumer, you should not give a shit about who was the first one to come up with an idea, the more companies compete to nail the same concept, the better.",amd_gpu
And AMD are trying (and failing) to copy DLSS and Raytracing. Your point?,amd_gpu
"Nvidia software is far superior and that's coming from a 2080Ti owner and a Zephyrus G14 (AMD) owner. 

The RTX voice, and freestyle filters were already amazing (filters in warzone was awesome). Plus their nvencoder was/is amazing in OBS.",amd_gpu
I've always bought nvidia cards for the software and its features.,amd_gpu
"Hah maybe this was the marketing strategy all along

Get us used to absurd pricing then step it down",amd_gpu
Can't upvote you enough for that comment. 2080ti is still sitting at \~1200 euros after two years - which is insane. I really hope AMD has something in their pockets that can rival the 30-series. That Nvidia keept the launch prices of the 20-series (for 3070 and 3080) \*could\* be interpreted that way.,amd_gpu
"I think they're both good. The 2080ti should've been a 700-800 card. IF that had happened, we'd be seeing a 70 class card replacing the flagship at 200-300 cheaper. That's a solid generational leap.",amd_gpu
"Exactly. They sell us shit one gen so next gen they can claim it's amazing because it's better than previous gen, but it's not hard to look fast in a car when ya racing against a shopping trolley",amd_gpu
"Only possible because AMD is taking 2+ years to catch up. The longer AMD takes, the less competition there is and the prices go up.",amd_gpu
"And the only reason why it isn't is man if there aren't a lot of people that still bought it. Streamer specs - 2080ti. Various subreddit flair 2080ti, it's like everyone had one! :) People with the money will spend.",amd_gpu
"Completely agreed. Fuck Ngreedia's stupid pricing strategy, *OH LOOK RTX 3090* well I'm sorry, $1499 isn't a sane price for a GPU. Any GPU.",amd_gpu
"They can price it like that because AMD comes late and barely matches performance. 

Plus there is nothing else in that sector of the market, so nVidia decides the price.",amd_gpu
">No, what's insane is the 2080Ti for $1200.

Not really. When you have no competition in a market segment, it makes sense to turn the price up to eleven. Nvidia is doing the same with the 3090, which suggest to me that they expect competetion in the 3080 performance range, but not above. They are also charging extreme prices in the server-gpu business, or for workstations because AMD got nothing there. An rtx quadro 8000 cost 5500$, and their A100 cost twice that.",amd_gpu
And the 5700 XT for however much it costs. Garbage GPU like I've been saying all this time. AMD really are fucked on the GPU side if they don't lower their garbage prices with RDNA2.,amd_gpu
Those that bought a 5700xt for $400 in the past month too. Can't say they weren't warned. Everyone told them to wait.,amd_gpu
"If it was EVGA, they can step-up to a 3080, 3090...  That's one reason I always buy EVGA Nvidia cards.",amd_gpu
"Well, either they never cared or they are idiots to buy an overpriced card like a 2080ti so close to the release of a new gen of cards.",amd_gpu
Fair few on UK eBay purchased today for £850-£900. I've seen them selling for £500 on Facebook since the event. Just sold my 1080ti for £400. Gimme that 3080.,amd_gpu
I sold mine yesterday and am so damn happy.,amd_gpu
"I feel like there are only two types of people who would have done this. 

A) people who knew exactly what they were getting into with buying a card so close to a new Gen and deemed themselves fine with spending the money (professionals, etc) 

Or 

B) People who didn't care enough at the time and likely won't hear anything about the new stuff or do research into it. 


If you did research and still spent $1200+ on a card you knew would be replaced by the end of the year, I can't feel bad for you.

No one who isn't decently well off buys a $1200 card without doing research. 

Anyone who does likely doesn't care enough about it to be affected by the ampere stuff.",amd_gpu
"Imagine anyone who paid for a 2080Ti.

The Entire 2000 series was a ripoff. Anyone with sense knew it.",amd_gpu
"That's on them for making an uninformed purchase, it's been known for a while now that Nvidia were on the brink of announcing new GPUs.",amd_gpu
Imagine the people buying a 2080 today for their kid's birthday.  It's still over $1100 on most sites.,amd_gpu
"Gordon was talking about this just now in the PC World stream. He thinks it's not just RT and should include traditional rasterization, because the slide clearly said ""popular games"", which one would assume include non-RT titles like DOTA and Fortnite.

It would be quite disappointing if they meant ""popular games like Control"".

Edit: Also found this slide in the ""performance"" section of the 3080 microsite. Below Control (RTX ON) and Minecraft (RTX ON) there's Borderlands 3 without RTX also showing a 2x performance increase over the 2080.

https://www.nvidia.com/content/nvidiaGDC/us/en_US/geforce/graphics-cards/30-series/rtx-3080/#perf-chart-section

Edit2: Digital Foundry has a video up comparing 2080 to 3080 in all sorts of stuff

https://www.youtube.com/watch?v=cWD01yUQdVA",amd_gpu
"Correct. RT was on. So we don't know what non-RT performance gains will be. Probably not 2x though. 

This is why you should always wait for benchmarks and reviews.",amd_gpu
"That's my big rub at the moment. It was really unclear, at any given point, if performance deltas were RT on or off, DLSS or not, or any other combination therein.

Benchmarks will be interesting to see.",amd_gpu
"yes, it's including DLSS 2.0 and RT. The generational improvement without these shouldn't be as big, but they're the big killer features, most new games where performance matters at all are implementing them.",amd_gpu
"Exactly this. I have zero interest in raytracing if it still results in a huge loss of FPS (>30%), and I didn't see any graphs for performance with RT off.",amd_gpu
"2080TI has  4352  cuda cores

3070 has  5888  cuda cores

I think its overall performance, unless they faked the spec.",amd_gpu
[Digital Foundry already benchmarked](https://www.youtube.com/watch?v=cWD01yUQdVA) 3080 performance and found 60%-80%   performance increase over 2080 WITHOUT raytracing/DLSS at 4k. Extrapolating that puts the 3080 around 30-50% faster than the 2080 Ti.,amd_gpu
No,amd_gpu
[deleted],amd_gpu
"Tbh, buying a flagship GPU with terrible price/performance compared to the rest of the generation so close to the reveal of a new generation isn't very smart.",amd_gpu
[deleted],amd_gpu
[deleted],amd_gpu
">All the recent 2080ti buyers though, the massive losses.
>
>I think Nvidia did the price drop to mirror what AMD did with the 5600XT? But the pricing is amazing this time around.

Nvidia must know something about what amd is going to bring out

No reason to price so sharply otherwise",amd_gpu
"I like to think 80% of them don't care, cost of a hobby and if you are really sweating you probably shouldn't have bought one to begin with, punching above your weight.",amd_gpu
I bougth my 2080 Ti at launch and it still hurts to see how much value it'll lose. I guess if I can get like $500 for it then I paid $350 a year to have a top tier card. Could be worse. I used it enough where I'd easily pay $350 a year to have the highest fps possible.,amd_gpu
no one remembers the fiasco with the titan XP? 1200 for it to be replaced a month later get the same performance for 700 then another titan Xp lol,amd_gpu
">I think Nvidia did the price drop

THERE IS NO PRICE DROP",amd_gpu
"Still very dumb, he should have done that two weeks ago and sell it for much more.",amd_gpu
Still pretty dumb,amd_gpu
"Couldve gotten a grand for it. 

Going to be some very unhappy people over at r/hardwareswap",amd_gpu
Not broken?,amd_gpu
Maybe... The 3070 will be as fast but has way less memory. GPU prices tend to dip the lowest right after the next gen is announced. They go up again once the new cards start shipping and there are issues with inventory.,amd_gpu
"Hell, somehow there are still people on eBay buying 2080 Ti's for $800-1000 right now.",amd_gpu
AMD has plenty of room to set up their SKUs and pricing.,amd_gpu
"I don't' think they are, Digital Foundry already benchmarked 3080 performance and found 60%-80%  performance increase over 2080 without raytracing/DLSS at 4k. [https://www.youtube.com/watch?v=cWD01yUQdVA](https://www.youtube.com/watch?v=cWD01yUQdVA)",amd_gpu
">Double the performance of the 5700xt

double the performance of 5700xt at $399 would make it very hard for me to choose between that or a 3070 at $499",amd_gpu
">Double the performance of the 5700xt is still significantly slower than the 3080. As long as the price is right it will be ok but it sucks that AMD can't compete on the high end.

Looking at the chart, 3080 is about double 2070s little under? And 5700xt isn't far off 2070s?

But yeah would need to more than double to be GOOD.",amd_gpu
Double the die size of the 5700 XT and it'd still be smaller than the 3080 on the current node.  Nonwithdstanding a new node and new architecture.,amd_gpu
">Still not enough sadly. 3080 is still faster by a long shot.

I'm gonna bench patiently for waitmarks

There's probably some caveats to the marketing",amd_gpu
"They don't need to compete with the 3080, I mean sure it'd be good but midrange is where the market's at.",amd_gpu
I bought both my old ass 270 and my 480 for $160 new. Sucks these things aren’t as cheap anymore.,amd_gpu
"5600XT is a fantastic card,  I've been super happy with mine at 1080p 60hz. It can manage way more than that too, I just need to pick up a monitor that it won't be wasted on.",amd_gpu
"Even if you can't see it, you can \*feel\* a higher framerate.",amd_gpu
*3090 nervously spinning fans noise*,amd_gpu
"No, price. Not many people would pay $50,000 for a GPU, even if it gave 5,000,000x performance.",amd_gpu
"I spent $400 on a 1070 two generations ago, I think $500 for better than 2080 ti performance is a no brainer, especially if you can sell of your old card.",amd_gpu
AMD will easily match the 3070.,amd_gpu
"yes, i'm in the same boat as you!
     
but do you remember Navi pricing? :/",amd_gpu
[AMD right now.](https://i.imgur.com/mOnvOJG.png),amd_gpu
"I like AMD, but it's these mean spirited attempts to break your main competitors kneecaps that gave us things like the 1080 TI. As a consumer I can't complain. :(

I'm pretty excited to see what Nvidia was so worried about though. Spin up the hype machines, it's new GPU season!",amd_gpu
"> Still $100 higher than the 9 and 10 series. But I'm assuming that's more because of inflation, tarrifs, etc

Nah, Nvidia raised the price tiers because they could.  Plain and simple.",amd_gpu
"Turing GPUs have been selling out everywhere. Gamers nexus, in one of their videos, was able to confirm from AIBs that there isn't a selling Turing problem, like at all.",amd_gpu
Yeah perhaps but their stock like AMD's was on fire nonetheless.,amd_gpu
"or simply supply and demand, they may have more stock at Samsung",amd_gpu
">They dropped their prices

How in the fucking hell are so many people saying Nvidia 'dropped prices'?",amd_gpu
Good point.,amd_gpu
I was messing around on the wayback machine and decided to look at [newegg in 2011](https://web.archive.org/web/20111021064123/http://www.newegg.com/Store/SubCategory.aspx?SubCategory=48&name=Desktop-Graphics-Video-Cards). $500 was a top of the line card and about $150-$200 would get you something great. It really put these current prices in perspective for me.,amd_gpu
Theres another lineup to fill that price point now. The next generation of 16xx will probably come along with a 3060.,amd_gpu
"Hmm, I'd say it'll be in the 300ish range to be sure if you ask me. Maybe matching a 2080/s in perf...",amd_gpu
"I always use several sites to evaluate performance but as stated it is an opinion. 37% seems a bit too much and i think it is closer to the 25- 30% range.  [https://www.computerbase.de/thema/grafikkarte/rangliste/](https://www.computerbase.de/thema/grafikkarte/rangliste/)

[https://www.youtube.com/watch?v=jkoul9HRGdg&t=968s](https://www.youtube.com/watch?v=jkoul9HRGdg&t=968s) (min 16)",amd_gpu
"Sadly, $500 for a '70 is ""good value"" these days.",amd_gpu
"Agreed. Nvidia has been focused on AI and deep learning and it's showing to have helped them in making the best video cards out there.

AMD is just a bunch of human engineers. Can't compete with AI.",amd_gpu
"I don't know anything about the tech race between Nvidia and AMD, but I bought AMD stock back in August, 2019 and it's up 195.64%, and it looks like Nvidia is up 218%. Is this recent news not enough to move the price, or is the demand for both their products so high that everyone will get it wherever they can? I just don't see this bad news reflected in their stock price. Maybe it's because video cards make up a small portion of their overall sales?",amd_gpu
"I think AMD is focusing too much on beating Intel, be interesting to see where they make more money, cpu or graphics card. 🤔",amd_gpu
"Only for a little bit. If AMD can't catch up, then Nvidia becomes a monopoly and customers will be fucked for years or decades.",amd_gpu
"For a generation or two, until AMD withdraw.",amd_gpu
You're right,amd_gpu
How is less competition good for consumers?,amd_gpu
"They can't

Lisa already said CPU profits are mostly being out back into CPU development

GPU just can't get the money it needs",amd_gpu
Same performance without same features for $200 less is a good start. I'm not a streamer or content creator so I don't need every feature. That fast ssd read and dlss2 was quite interesting tho,amd_gpu
With them working with Microsoft and Sony I don't know if they even need to bother anymore with high end. Over 150 million consoles have their GPUs in them and next generation will be the same. On Steam Survey their GPUs are 15% while Intel is at 10% and Intel isn't even making gaming GPUs. And I'm saying that while using ATI/AMD cards since 2005.,amd_gpu
"The enthusiast market is like 1% of the sales, it would be nice if AMD had something to compete, but honestly, is almost a waste of time. The real money maker is the professional and machine learning market, but we need to see if AMD has something to offer there. 

The real problem in my opinion is that AMD is just too small to compete with Intel and Nvidia at the same time, and looks like they are more focused on keep the momentum going against Intel right now.",amd_gpu
"I just recently bought an AMD one because they offer the best support for Linux and I'm not planning on going back to NVIDIA as it is today. Then again, I'm not a big gamer and FPS games are horrendous to me.",amd_gpu
"3090 probably won't drop in price. It's got that ginormous VRAM, and unmatched performance. That's alright though, the 3080 Ti will probably come very close slotting in at $1000. I'm not going to wait for that though, gonna shoot for the 3080. 

Oh and remember your predictions for the 30 series. I think with the launch slides, performance may even exceed them lol. Now we wait for the actual stuff to be released.",amd_gpu
I don’t think there will be Ti cards this generation unless amd can match or beat the 3080,amd_gpu
"I didn't believe the leaks, felt it was too good to be true. I really just didn't believe it would be that powerful. I figured at best the 3080 would = the 2080ti and the 3090 would be like 20% faster, I didn't expect a $500 card to punch my taint into oblivion.",amd_gpu
🖕🥺🖕,amd_gpu
"There was a point, if you didn't think the new cards were going to be THIS much more powerful. I was expecting to still get at least...$700-$800 for it, not $500 lol. It also let me play most of my games at 4k/60.",amd_gpu
"I sold my Vega 64 before the event and got £230+ for it.  I anticipated this, lol.",amd_gpu
I'll pay 150€ and a nutter butter,amd_gpu
"Sold my 1080Ti for 630USD 3 days ago, imagine how much they would cost today lol",amd_gpu
Just get a new power supply bro,amd_gpu
source? you already have benchmarks?,amd_gpu
"Wrong. You can watch the new digital foundry video.

In non rtx and dlss titles you see 80% to 100% increase in performance",amd_gpu
5700XT is already pretty close to a 2070S so I don't think it's too unreasonable for the Series X to be at least as fast as a 2080 considering it's also on RDNA 2 and has more CUs than the 5700 XT,amd_gpu
"We have a decent amount of information about the xbox series x gpu. Check out digital foundry's videos about the xbox series x. (Specifically the video where the xbox series x out performs a 2080 in gears of War 5 on a build they created within a few weeks)

There's enough information to infer how fast it will be and what kind of wattage it'll suck up. Chances are the xbox series x is getting a mid-range gpu. Likely the successor to the 5700xt. If amd decides to create a big Navi card with rdna 2 this time around we can expect it to be at 3070 performance at the minimum. Likely will be closer to a 3080, but lacking a few features.",amd_gpu
TBF Ryzen 3000 is still pretty great but I would not be buying anything other than nVidia 3000 unless you get it for 50% of current retail at this point.,amd_gpu
"This rhetoric happens with every launch, and AMD never deliver. Poor Volta lol? I want competition but AMD have literally nothing but rumours and hollow dreams.",amd_gpu
"Hey its parallel universe you.  Got one on August 3. Highly debating returning it, but I only run 1080 75hz so I really dont think I need 3070 levels of computing.",amd_gpu
"> Go back years and $499 was the absolute top class GPU available. 

So what, costs of further improvements and inflation are a thing, you can't just expect nvidia to click a button with +30% performance every 2 years and keep selling GPUs at the same price. What we're about to get now is very reasonable, bitch about it all you want, it won't change anything.",amd_gpu
"I don't think you've been a PC gamer for very long if you're making statements like that.

This pricing bracket is absolutely correct, turing was the only outlier.",amd_gpu
"That’s true, hopefully ray tracing doesn’t kill performance like it did with the 20 cards. DLSS is such a great feature that I’m not sure AMD could ever get close to. They’ll catch up one day haha, very excited for these 30 cards tho!",amd_gpu
"Raytracing is the easy part. The DLSS much harder. Development of this tech is bascially fully funded by *gauging* the ai cloud market with having the only server gpus that can lower calculation time from 10 days to 10 minutes.

Since AMD has issue with their software skill set since like forever, taking the competition into a field they can't easily follow makes sense. AMD would have to invest in own ai systems to get enough cash flow going so they can invest 100s of people to make game scale up *nicely*.",amd_gpu
"How long has it been since it came out, and how long does it take games to develop, again?

By this logic should no one care about DX12-Ultimate, or assume RT won't be used in any games?

We're at a console generation changeover. Likely every game which uses RT will have DLSS, and the uptake of DLSS in general should be much larger also.

It's ""free"" performance and easy to implement, it just didn't exist when 99% of games were being developed.",amd_gpu
[deleted],amd_gpu
"1.5 perf/watt, but you didn't factor in that Big Navi is 80CU, not 40 like the 5700XT. Assume a 50% increase from CU count, in addition to the 1.5 perf/watt figure and you get way more than 2080ti performance.",amd_gpu
"Where are you getting 1.9x perf per watt

Take a good hard look at the TDPs",amd_gpu
gtx 680 to 980ti was much more than a 50% increase on the same node. A jump from 2 generations but the 700 series was also a 600 series refresh,amd_gpu
"Except it takes up much less die space than the same amount of FP32 cores would.

DLSS is like a whole node generation worth of performance.

> at least if you care about good image quality.

You must not have got the memo about DLSS 2.0.

With 2.0 you can get ~50% more performance for roughly the same image quality. Or ~35% more performance for objectively better, in some ways, image quality.",amd_gpu
"Yeah I have been running Hackintosh for years, but assuming Apple will ditch Intel at some point I don't know how long it will be viable.",amd_gpu
"I just love using Final Cut Pro, so that’s the main reason for me.",amd_gpu
"Yeah I’m hoping they make modules for the Mac Pro with them. Then again I could just get a much beefier PSU and run both my 580 and one of these cards, with the 580 only used in macOS",amd_gpu
Only thing that bothers me about the 3070 is the 8gb vram,amd_gpu
"Unless you have 1440p 144hz or better, II say wait it out.  Hopper will be the real upgrade for you.",amd_gpu
Gonna keep my 1080ti for a VR mini pc and get a 3090 for my main,amd_gpu
"It do be looking like a good choice doh don't it
>Yeah, I'm tempted to sell my 1080 Ti and put money for the 3080. I'm just having a hard time justifying that choice lol",amd_gpu
Bottleneck issues?,amd_gpu
No idea. Vray and Enscape (two renderers that I use) I don't think offer this,amd_gpu
IKR lol,amd_gpu
"The power draw of the Navi 10 dropped 75W going from the 5700XT to the 5600XT without any undervolting. You're going to be a sad, sad clown when Big Navi is released.",amd_gpu
"

Fully dedicated razterization gpus? You mean every gpu from the past 20 years other than turing?",amd_gpu
"They also had charts featuring Borderlands 3, Doom Eternal, and RDR2, which have none of the RTX features.",amd_gpu
"Yup, and this graph wouldn't make sense if RTX and DLSS were enabled, because then they wouldn't have plotted Pascal nor Maxwell.",amd_gpu
And I'm sure you only play games that support DLSS?,amd_gpu
It is not a good indication since all nvidia did was use DLSS and rtx in their comparisons..,amd_gpu
"It's a problem for AMD fanboys because AMD has nothing out in that category yet.

If AMD does better in ray tracing, you will see the same people that called it a ""gimmick"", praising the realism of bounce lighting, sample counts and so on.",amd_gpu
"The only upcoming AAA game we know will support DLSS 2.0 is cyberpunk. 

MSFS2020, the poster child for next gen games, doesn't have RT or DLSS. Until it's an open standard it will just turn into another hairworks Nvidia tech.",amd_gpu
https://youtu.be/cWD01yUQdVA?t=382,amd_gpu
Meaning it is 32 percent over the 2080ti in nvidia selected titles..,amd_gpu
There has to be a upper limit nvidia is gonna reach. They cant just keep making their gpus more powerful somethings gotta give.,amd_gpu
Destroy the competition completely. Ruin them. Make the market share 90 percent. Then let AMD fight back from the hole you've dug them in. nVidia has a lot of money and can even take a loss. Also stop people from going to consoles. Win win win.,amd_gpu
Get huge buyin on this generation of cards.  Then push the DLSS feature with game developers (since such a large portion of the audience can utilize it).  That puts Nvidia in an even stronger position when AMD has cards out that compete closely with Nvidia's (minus the DLSS)?,amd_gpu
"> Why not start with a higher price and lower it after AMD makes a move? 

If people buy 3070 now, they won't buy AMD with similar performance later. AMD has historically shown that they can't compete on the high end. Also next gen consoles are coming out very shortly.",amd_gpu
"same thing applies to pretty much everything else. nvidia cards, intel chips, doritos, teslas, etc. etc.",amd_gpu
"Tflops doesn't mean performance. Vega had more tfllops than nvidia counterparts, still it was priced relatively to it's gaming performance, not tflops",amd_gpu
"Because Nvidia has clearly stated in their presentation that the RTX3080 is their flagship and the RTX3090 is a Titan. Flagship to flagship the RTX3080 is only 30% improvement over the RTX2080Ti, which is great, especially for $700.",amd_gpu
What features are there to care about?  I have typically seen Nvidia's features more as quality cheats than improvements.,amd_gpu
Anti lag isnt reflex. Reflex is beyond what amd and nvidia currently have.,amd_gpu
Don't buy PowerColor?,amd_gpu
"The pricing of the 3080 is amazing. 60-80% increase in traditional rasterization. https://youtu.be/cWD01yUQdVA?t=382

I  was expecting 30-40% so I feel like I got 2 gens instead of one.",amd_gpu
"In the past 20 years, there has been plenty of times where Ati have won against Nvidia. I would agree that the consoles must have played a role in the price.",amd_gpu
[deleted],amd_gpu
If they're competing against consoles dosen't that mean they're still competing against AMD?,amd_gpu
3070 isn't though. I'm shocked it's not $100 more,amd_gpu
"Not including case, PSU, CPU, RAM, motherboard, storage.",amd_gpu
You have seen the rumors that came out this week that the PS5 was listed on a German site for $1250 USD right? The article said they are expected the console to be around $750 and sale that's it's still cheaper than a PC.,amd_gpu
"at this point, dlss is better than native.",amd_gpu
who cares. that DlSS boost applies to 4k images too,amd_gpu
"Console specs are already out. They were really good before the ampere launch, now they are mid range.

I wouldn't call a mid range gpu ""insane"".",amd_gpu
cmon dude... if you think amd can do 8k 60 you are delusional,amd_gpu
[deleted],amd_gpu
"Because new games will come out and push the boundaries, always want the top of the line to be doing crazy because it trickles down.",amd_gpu
You hit the denial bingo in one short comment. Amazing.,amd_gpu
$499 3070 beats consoles.,amd_gpu
"GPU's are a luxury item, raising prices or even keeping them at the same levels would have had very little impact on sales numbers. Even if there was some sort of massive cost saving in production prices would not drop without some reason to drop them down.     
Nvidia has to have seen the price/performance estimates of RDNA2 based on the PS5/Xbox specs and decided they need to go with lower costs. If AMD did not have something coming to push them that way then they would simply keep prices at the same level.",amd_gpu
the crisis mostly affects those who would not be buying these cards (or gpus) at all.,amd_gpu
"Then why didn't they try this last gen? Why didn't they price the RTX 2060 at like 200 dollars, and the RTX 2070 at like 350? 

Your point is true, but this doesn't seem to be very common, at least in the GPU/CPU market. Intel could have squeezed AMD into nonexistence by slashing the prices of i3s and i5s, but they just didn't.

Companies usually do this, not out of a desire to carry out a coup de grace, but out of a fear of increased competition from the other side.",amd_gpu
True. I like this perspective,amd_gpu
Ill wait and see tbh. AMD rumors have always promised alot and always ended up either a large disappointment(Vega) or pretty good(RDNA 1).,amd_gpu
"AMD will never catch up to intel because of budget.... then the zen line up hit and now  Intel can't catch up.

All it takes is an innovated  feature and they can come back",amd_gpu
"I think they've got a good chance of at least matching the RTX 3080 - don't think they can beat the RTX 3090 though. 

And DLSS isn't really a big factor unless you can just automatically enable it in every game (which nvidia is supposedly working on, would love to see that)",amd_gpu
"AMD could have the faster chip or the faster chip at traditonal rendering. We really don't know. Also remember that MS and Sony both have a lot of eggs in the AMD basket. So in terms of features there will be things that those companies will help with.

microsoft is big on AI they introduced special AI into their arm collaboration and they have been pushing AI and machine learning in lots of areas. So it would make sense that AMD will be helped along by that. 

We have to see what happens. I hope amd is competitive as i haven't bought an nvidia card since the fx",amd_gpu
Thats before nvdias announcement today,amd_gpu
More or less. 5700xt/2070s/2080 perform within 10-15%.,amd_gpu
Publicly traded != Publicly beneficial. Unless you're a major stockholder or they pay your salary it legitimately looks pathetic that someone would lose sleep over it.,amd_gpu
"I didn t say they lie. Cherry picking might mean that the increase in performance(2x) might be very clear in some niche scenarios while most every day tasks will see a ""much smaller"" increase of 25-35%. Don't get me wrong, I'm excited for these cards. The 3080 especially seems to be in a sweet spot pricewise for these times.

All I'm saying is wait for benchmarks :)",amd_gpu
where did you see 3070 results?,amd_gpu
Little Navi wasn't very efficient at all and it was on 7nm.,amd_gpu
"Some people are sensitive to electricity costs, and others are sensitive to the heat and/or noise.

I loved my desktop computer when I was living in a basement room. But when I moved to a small room in an apartment in a 90-degree summer, I hated having my computer on because it would bake my whole room. I would have loved it if I'd had a power-sipping laptop to use, instead of running my 500+-watt space heater.",amd_gpu
320W TGP for the 3080 and 350W for the 3090 doesn't look like it.,amd_gpu
"It is unfortunately true. I was hoping RDNA was going to shake things up but Nvidia kept pulling ahead with software improvements and innovation for the RTX series. AMD still has no answers.

I really really want AMD to have a Zen2-like comeback against Nvidia. The competition would push innovation even further. We already see the amazing things Nvidia is providing, but imagine what us consumers would be offered if they had a competitor they actually needed to give serious worries to.",amd_gpu
I think you're replying to someone else...,amd_gpu
"RDNA2 will have RT, there are rumors that cards will have some form of ""AI acceleration"", which tensor cores are (and are used for DLSS), so that remains to be seen.",amd_gpu
"According to Nvidia slides 3080 is double 2080. So doubling 5700xt may not be enough. Specially considering the rest of the featureset.

Of course we should wait for benchmarks to confirm.",amd_gpu
"The won't if they don't deliver innovation and performance and reliability at a better price, which they really haven't lately.",amd_gpu
biggest issue is only 10% of games support it,amd_gpu
It's consoles too but they don't want to make the Turing mistakes again as well.,amd_gpu
Just like 260/280 :) Sure NVIDIA will have first to market edge but don’t rule out RDNA2. Upcoming Console/2080Ti should be the base for next gen GPUs. I mean we knew this level of performance months in advance if you are following tech tubers. 40-50% over 2080Ti,amd_gpu
"Time will tell. People have short memory here. AMD has impressed before. 9700/9800, HD4000, HD5000 even HD6000 was not bad, HD7000, R9 290",amd_gpu
"The alternative is to believe Nvidia restrained throes pricing — relatively speaking — out of 'good will towards men'.

Of course, it's up to you. I hope you're pleased by the way things unfolds. :T",amd_gpu
Tell me about it... I m getting downvoted for telling someone to keep his 5700XT instead of losing 200$ on a brand new card to wait for the 3070....,amd_gpu
">a

Not looking good. Mostly Nvidia posting in an AMD sub. AMD themselves will be seeing & reading this.",amd_gpu
It is but he modified it a bit for the topic at hand,amd_gpu
"It is, and Direct Storage is being used in the Series X with AMD hardware (obviously). I would be surprised if AMD didn't have the same tech in RDNA2",amd_gpu
well then - sounds like Big Navi has more than just a chance of outclassing the 3080.,amd_gpu
I defy.,amd_gpu
Nvidia lists the 3070 for 499eur on their german site.,amd_gpu
Well I'd imagine they make more money per gpu than console but with the volume of console sales idk I'd have to look at earnings reports. Also the consumer is usually looking for one or the other not both. But yes amd makes money either way.,amd_gpu
"The 3080 is 100% over 2080, for $499.  RTX OFF.

I mean, the 3080 is twice as fast as a 2080",amd_gpu
"isn’t 5700xt only 40cu? leaves room for 56, 64 cu models if the dies work out. time will tell",amd_gpu
The PS5 has already got a small RDNA 2 GPU and I believe it will be 2080 performance at least.,amd_gpu
"Go look at Borderlands 3 numbers RTX off no DLSS.
You should be comparing RTX3080 versus RTX2080. 
In that case rasterising performance is ~1.8x faster in BL3, which has no RTX or DLSS. 
I do not know how much power is taken on that game since it is just using main GPU core. 

Pretty funny to hear an AMD GPU user complaining about Power Consumption though. 

RX5700XT pulls 260Watts on Gears 5 at 4K Ultra just through the GPU Core. 
It looks like the rest of the card is pulling another 70 Watts based on Corsair iCUE Power Output Reporting. 
Hard to tell. 
AMD do not even monitor or control GPU card power input, unlike Nvidia.",amd_gpu
"""I'm not worried! Here's a lengthy novel desperately justifying why!""",amd_gpu
"The RTX3070 looks like a good card performance wise, but most won't have the PSU to upgrade to it. Or the G Sync compatible monitor that it's compatible with for adaptive sync. 

That's not denial. That's me looking forward to a RX 3060 and especially what AMd is going to come up with.",amd_gpu
"Amd we already have idiots hyping up the product more than it is.
Its twice as fast as the 2080. Not even the 2080 super let alone 2080ti",amd_gpu
"They increased the prices of 20xx cards, and came out with a big generational leap with 30xx at same level of prices per card tier. 

3080 price is fine, but considering how it's the same price performance as the 3070, 3070 looks 100$ overpriced.",amd_gpu
"I could be wrong, the 3090 could just be a Titan like everyone else is suggesting. I probably am too. Either way, I'm not worried about AMD. This recent development my Nvidia suggests to me that they're scared. Up till now they have been able to charge what they wanted because AMD couldn't compete. So why the sudden interest in lowering prices to compete?",amd_gpu
"I don't know what I said that's so offensive.

At the time I posted that original comment, the DF video hadn't made the rounds yet. I looked at the closest thing Nvidia gave us to performance numbers, which was a chart with price on the x-axis and performance relative to (I believe) the 980 on the y-axis. They didn't have any grid lines for easy comparison, but you could grab a straight edge and see the 2080 Ti was at about 3.2x and the 3080 was at about 4.5x and featured the phrase ""up to"". That's about a 40% increase, and that's where I got my number from. The 3090 was notably absent because the price scale stopped at 1400, so the 3090 is literally off-the-charts expensive, even when it's Nvidia's chart.

Then the DF video popped up and showed about a 70% increase from the 2080 to the 3080 on average. According to Anandtech's GPU comparison page thing, a 2080 Ti is 25-30% faster than a 2080. We'll call it 125%, compared to 170% for the 3080. That's about a 36% increase, which is pretty much what I said before. And pretty much what rumors have been saying for months at this point.

Other than that, they didn't introduce any new features that I expect a majority of potential customers to care about. So, if you thought 2 months ago that AMD needs 40+% better performance than a 2080 Ti, decent ray tracing performance, and some kind of answer for DLSS, then nothing has changed. The hill is exactly as tall and as steep as it was a week ago.

The hysteria around here is unfounded. It's successful marketing hype by Nvidia. If you've been following the leaks, this is exactly where we thought we'd be right now. There's no reason to believe RDNA2 is dead in the water before they even show their hand.",amd_gpu
"It does not have 8000 shaders. It has half that number, where each shader has *some* unspecified capacity to do two FP32 ops per cycle instead of one. That's what Jensen said. Even some of their board partners advertised the cards with 4-5,000 shaders and not 8-10,000. This would suggest they weren't sure how to market this new architecture until very recently, which tells me they're not ""full"" shaders with all the throughout you'd expect from full shaders.

Regardless of what they call them, if that translated to double the performance, the ""20 Shader-TF"" 3070 wouldn't roughly match the 13-TF 2080 Ti, it would be 50+% faster.

The actual performance that was shown off was exactly what we expected from leaks.",amd_gpu
"Yes I am boring but that is beside the point. I've seen plenty of tech demos, overpromising, over selling and doing flashy things all of my life only to get my hands on the actual product and witness a flop (not saying this will flop). Just like the iPhone 1. Now I know that Nvidia isn't Apple but I will save my enthusiasm for when I see third party reviews. These tech previews do absolutely nothing for me, show me the real world benchmarks. I am impressed more by actual benchmarks not run under ideal settings for the particular piece of hardware being shown. TBH, I probably won't be impressed with whatever demos AMD (RDNA2) or Intel (Xi) puts forth either.",amd_gpu
"As someone who currently owns Nvidia GPUs and have only bought Nvidia GPUs for the past ~25 years I don't think you know me well enough to make a comment like that. The last AMD/ATI GPU that I have ever owned was an ATI rage pro II back in the 1990's.

Thanks for the heads up on a third party benchmark I'll check it out.",amd_gpu
"Now that the card has been out for about a month, and third party reviews have been publish, reports of the cards crashing, not a lot of people were able to even buy the card, and other such issues how do you feel about Ampere? Granted I still believe that that Ampere is good but I now we have a more realistic look on how the launch was handled, build quality of the AIB cards and more down to earth performance benchmarks. I am not saying that the cards aren't good, I'll probably buy one once AIB cards are restocked and initial build quality is improved but I have been building computers far too long to fall for the hype built up around NVidia's marketing.

I hope people finally learn to not get over-hyped by some mega corporation's marketing and wait for third party reviews.",amd_gpu
"To be clear, I think RDNA2 is going to put up a fight and be competitive, I just think RDNA3 will be their chance to actively pull ahead.",amd_gpu
Raja would beg to differ.,amd_gpu
"Good luck making use of RTX IO / Microsoft DirectStorage and getting the most out a 3080/3090 with a gen4 NVMe SSD on a i9 10900K box lol. Just because the i9 10900K can achieve a higher clockspeed doesn't mean it's not crippled by it's peasant class pci express offering.

https://www.nvidia.com/en-us/geforce/news/rtx-io-gpu-accelerated-storage-technology/",amd_gpu
"Not gonna happen

Maybe a bit cheaper, but AMD needs to make money....",amd_gpu
[removed],amd_gpu
"It was, uninstalling the AMD drivers used to fix the issue. But the issue is long gone since I did sell the card last week and bought an Nvidia one.",amd_gpu
3070 is not using X. Hopefully AMD is using X on their top card.,amd_gpu
[deleted],amd_gpu
"but 600+mm\^2 vs big navi 500mm\^2, defect rate on nvidia top chip probably equalizes the wafer cost, or closer to it.",amd_gpu
"I mean who are you going to trust, the founder and CEO of Nvidia or a random guy on  reddit",amd_gpu
And Intel says their going to use 10nm but it's actually just 14nm+++. Don't believe everything you read on the internet..,amd_gpu
The way they measure transistors are not the same. TSMC 7nm is bigger than if intel had a working 7nm process for example.,amd_gpu
"I was referring to 8nm compared to 7nm EUV, not TSMC N7. 

N7 is a very mature process at this point, with extremely high yields. I don't think anything can beat it in yield (except for maybe Intel 14nm??) at the moment.",amd_gpu
"[https://imgur.com/a/I6KN3SV](https://imgur.com/a/I6KN3SV)

Not quite. TSMC N7's HP track is below 65MTr / mmsq which is why Navi10's density is 41MTr / mmsq  [https://www.techpowerup.com/gpu-specs/amd-navi-10.g861](https://www.techpowerup.com/gpu-specs/amd-navi-10.g861)

This Samsung 8N node has similar density on paper, and GA102 is actually around 45MTr / mmsq. So it's just as dense as N7.",amd_gpu
"~~Didn't Gainward accidentally leak that it's 7nm yesterday?~~

~~Or is Nvidia doing different nodes for different GPUs? That's also possible?~~

~~Or is Nvidia using TSMC 7nm for their top end GPUs?~~

Nevermind, I found it. It's 8nm",amd_gpu
"Probably doesn't matter, TSMC N7 is better than than TSMC 16FF, yet nvidia was still winning in clockspeed, power and efficiency...",amd_gpu
">According to Moores Law Is Dead

...",amd_gpu
">No one cares about any of those things in the real world. It's just whether it delivers the goods.

Consumers very much care about power usage. The 3080 and even more so the 3090 are pure room heaters.",amd_gpu
"Of course it's not something consumers care about, but the semiconductor industry has been an interest of mine - it's fascinating to see the different characteristics of each node. 

The heat isn't the issue - it's the power. That's why you see larger dies usually clocked lower than their smaller counterparts - more transistors means more power. 

Intel can hit 5 GHz on 14 nm because they pump insane amounts of power into their CPUs. That's not an ideal solution.",amd_gpu
"It shouldn't be too bad in terms of density, but the frequency/voltage curve on 8nm is apparently pretty bad. That's why TDPs are so high - 320 watts for the RTX 3080 if I remember right. Nvidia just has to pump more power into their cards to hit the same clocks they would have had on TSMC N7",amd_gpu
I'm sorry I offended your eyes? Thought it would have been useful to show my original thought process.,amd_gpu
"https://www.reddit.com/r/Amd/comments/cf27xf/navi_powerperformance_study_5700xtstockuvoc/

Navi had an issue of being pushed to the breaking point in terms of frequency/power. AMD always does this - they pump lots of power into their cards for that last 5% of performance. 

A properly tuned RX 5700 XT draws 40% less power for 7% less performance. Of course, that's a combination of lowering clocks and undervolting. But my point still stands.",amd_gpu
"""hotter"" is subjective.

For Navi AMD switched to Tjunction, which measures the die temp at the hottest point.

I think Nvidia still uses the old method, which is measuring temperature at the end of the die. 

And also, AIB 5700XTs had very good temps. An example would be the Powercolor Red Devil.",amd_gpu
Oh,amd_gpu
"Lmao, imagine if they were considering fab construction and took one final look at Intel, picked up the radio, and said ""scratch that, guys... it's gonna be a flower garden or something instead....""",amd_gpu
Can happen if you cannot introduce something better than ringbus stretched Skylake.,amd_gpu
"They're still somewhat limited given AMD is already at TSMC and the fact Nvidia tried and failed to squeeze TSMC out on price before switching to Samsung.

They might not have burnt their bridges with TSMC but TSMC has seen them carrying torches. If they go back to TSMC for consumer graphics they're more likely to end up paying through the nose.

(It's looking more like the TSMC capacity they have is going to quadro cards, so pricing/capacity is less sensitive)",amd_gpu
I don't follow. How can a manufacturer be fabless? How does this help them be more competitive?,amd_gpu
"yes, fabless tho means you may not lock the best chipmaker... which actually happened to Nvidia trying to get TSMC and fail. Interesting times ahead",amd_gpu
LOL!@!!!! dude; they got ejected from TSMC and had to scuttle away to samsung because they acted like they had the only big dick in town.,amd_gpu
"Not true. If they can't get TSMC capacity, they have to use something worse. Ofc, atm they have been doing well with worse nodes.",amd_gpu
but real men have fabs,amd_gpu
I would be surprised if AMD remains fabless in 5-10 years at this rate. They might start fabbing again.,amd_gpu
"It still could if TSMC stalled out like Intel.

We're still approaching that for everyone anyways. The end is is still approaching for silicon size drops. And none of the alternatives have shown up at scale yet.",amd_gpu
"Yes but amd is gonna to support those features though. How well it remains to be determined, but since AMD gpus are being used in next gen consoles, it should atleast be sufficient.",amd_gpu
"Agree, though I think it's more than just crypto - for the last couple generations AMD fell *way* behind which let Nvidia set prices as they wanted. Prior to that point, while Nvidia was consistently ahead, AMD was *close enough* that they could exert pricing pressure.

I for one am glad that AMD ran the entire board for the next-gen consoles with RDNA2 - the ideal situation is competition without either player ever completely wiping the other player out. Even if Big Navi proves to be a disappointment, the console GPU contracts mean that AMD's GPU live to fight another day.",amd_gpu
"Wait you’re an Overwatch player? Next time put that at the top so we all know the wall of text is garbage opinion. Thanks! :)

ps it’s a joke.",amd_gpu
"This is the correct answer. Nvidia ""anchored"" higher pricing with 20x0 series allowing them to look like good guys by now reverting to normal-highish pricing with 30x0. Well played Nvidia.",amd_gpu
I got my 1080 new in 2016... for $505. These prices now are so fucking inflated...,amd_gpu
Inflation is a thing though,amd_gpu
I think Ryzen has done so well  because there is lower overhead at least in terms of gaming for CPUs. Your return on investment diminishes more quickly compared to GPUs so it makes sense to shift your budget to a relatively more expensive GPU. That's why I am worried about AMD GPUs as well.,amd_gpu
"I still remember when a 680 was going for under 600 dollars, and buying a 770 (which was basically just a 680), for $340",amd_gpu
Overwatch gamers and gamers of all types who enjoy FPS games will care to buy Nvidia if that reflex tech they briefly revealed turns out to be anything at all,amd_gpu
"Why do you want the fps, if you don't have ""that nice"" of a monitor?",amd_gpu
"Be careful though, I play mostly Overwatch and this generation I went with the 5700 XT, but Overwatch actually doesn't run as well as it would have with a 2070/super since the 5700 XT's clock speed doesn't flex it's legs when settings are all low like I have on every competitive game I play - a symptom of AMD's somewhat iffy GPU drivers. I'd say wait for benchmarks in overwatch specifically to see whose drivers allow for max fps at your resolution.",amd_gpu
"Performance and features have gone up. There is no reason the 2013 Toyota Camry should cost the same as the 2019 Toyota Camry.

Say what you want about DLSS 2.0, but it's the kind of technology that has a huge potential to go from useless gimmick to absolute game changer.

AI is a strange beast but one thing is for sure. This absolutely has the realistic potential to 2x your performance at a similar quality level.

Just look at the improvement that gaming AIs have made over a generation (AlphaGo, AlphaStar,  OpenAI Five etc).

They all went from gimmicky toys/research project to being unbeatable by human beings in 2-3 years.

I for one am cautiously optimistic and I will wait for the benchmarks.",amd_gpu
This. Plus the market has adjusted properly for demand.,amd_gpu
"Oof, I got a oc’d 2070 on NIB clearance in 2019 for like $270",amd_gpu
"Polaris and Navi were the first generations that didn't have a flagship on Par with Nvidia.  Before that flagship models from AMD were in the lead more often than not.

This all changed under Raja konduri.  Honestly I think Raja failed at his job.  The problems that Polaris and Navi have had are the same issues that Intel is having.  The cards are efficient to a fault and almost entirely being built for the AI markets.",amd_gpu
"Don't know why you have features in quotation marks, DLSS is a big deal and hopefully AMD can bring something similar to market. Cyberpunk 2077 will be DLSS enabled and I can't wait.",amd_gpu
">I also have a feeling that these prices are NORMAL, and we all got used to outrageous inflated prices over the last 2 years 

Absolutely. But it still comes as something of a relief because many of us who might not read quarterly reports are assuming these companies are simply making big bucks with these new prices, and being the market leader in what's pretty much a duopoly Nvidia does get to set the 'standard'.

It's good to see we're slowly going back to the 'old' prices but I don't think anyone expected this to happen over the course of a single generational upgrade (especially because it feels like a middle-finger towards the people who've just recently bought a 2080ti for instance), and especially not at these performance levels (considering the performance-jump from Pascal to Turing was laughable at the prices they were asking).

You'd assume they'd slowly ween the customers off of these huge markups by incrementally going back to old pricepoints over the course of a generation or two, maybe three.",amd_gpu
">AMD has always focused on the budget area, not industry flagship. So I  would anticipate that AMD's flagship will have something FPS competitive  to 3070 in the $399 - $449 range.

AMD has already said that they were returning to the high end with RDNA2.",amd_gpu
"> I would anticipate that AMD's flagship will have something FPS competitive to 3070 in the $399 - $449 range

they could do that with a glorified Xbox GPU, much less some ~500mm^2 big boi

Nvidia would never price such a huge improvement like they are if AMD didn't have a fatty to beat them over the head with",amd_gpu
"The prices are still $100 above ""normal"". They used the poor value of the 2000 series to anchor the prices so that this would seem better than it is.

SKU|MSRP|Year|InflAdjust
:--|:--|:--|:--
3070|$500|2020|$500
2070|$500|2018|$515
1070|$380|2016|$410
970|$330|2014|$360
770|$400|2013|$445
670|$400|2012|$450
570|$350|2011|$405
470|$350|2010|$415",amd_gpu
"The normal was when 250 usd cards were considered high mid-end tier and were the flagships of both AMD an NVIDIA then.

Now it's 500 usd for the same tier of graphics card.",amd_gpu
"Nvidia must also know that there's going to be hyper inflation in the next few months,",amd_gpu
">AMD has always focused on the budget area, not industry flagship.

I wouldn't say always, AMD has more than once beaten Nvidia in performance and fastest product.  I owned a  GeForce FX 5600 and it was just hot F\*&\^king garbage back then, loud as hell blower... and the 9800 pro was the clear winner.  


The 295x2 was also a monster, it was just shear brute force to claim fastest card.",amd_gpu
"Why did you lump DLSS with “features” in sarcastic quotes? DLSS is basically magic. Unless AMD does in fact implement a competing tech I’m honestly switching this gen for that alone.

I know there are theoretical open alternatives but I just want to see those actually used ya know?",amd_gpu
">AMD has always focused on the budget area, not industry flagship.

That's not true. Consumers just ignore everything high-end that they release.",amd_gpu
they did say fps doesn't matter as much as lower pc/render latency for perceived/actual smoothness and re-activeness. (500fps without new tech let's say 18 ms valorant vs 400 fps with new tech 12 ms valorant ),amd_gpu
"Yeah I really don’t think AMD is a big threat for the time being, I’m hoping in a generation or two that AMD will be more of a true competitor because that will directly benefit the consumers. The difficult part is now I really want a 3070 even thought I got a 5700xt a little under a year ago I have just had an annoying amount of issues with the drivers or sometimes AMD’s software. I really miss how Nvidias software and drivers were so much more stable.",amd_gpu
Tech enthusiasts know about what AMD has done but intel has so much behind there name. A lot of people don’t care about releases and tech news they just want a good product. I have recommended the new amd laptops to people and quite often they haven’t heard of it and only recognize the little blue sticker that says intel inside or I-whatever series. It’s going to be a lot time before people recognize amd over intel which goes a long way.,amd_gpu
"Linux VR gamer here. I had to sell my GTX 1080 and buy an RX 5700. Nvidia has no apparent intention to support VR on Linux so if you want async reprojection (which helps prevent motion sickness), you're best bet will be AMD for the foreseeable future.

Nvidia looks really awesome for Windows gamers, but unless you're buying a card for machine learning, Nvidia doesn't seem to care about Linux.",amd_gpu
"That is my future issue. I want to swap to Linux full time, but Nvidia seems to be making that very difficult with my multi monitor setup. It just does not want to play nicely with many distros, or the driver seems to outright break things like logging into the OS (Ubuntu).",amd_gpu
"AMD basically has to beat 3070, which seems to be better than 2080ti and priced reasonbly. 3080 is the new 2080ti and 3090 is the titan card for people who are into that.",amd_gpu
20 series are dead and just like the 5700xt. The 3070 at the same price point destroys the 2080ti in terms of performance and value,amd_gpu
"Can u tell me why you'd wanna upgrade from a vega 56? i have it and i wanna buy vr, is it not good enough? what games is it not able to run?",amd_gpu
"Upper mid market is where the actual sales and money are, so this is a very wise strategy for AMD. 

Conversely, brute forcing the high end for maximum prestige and ""mind share"" is a wise strategy for nVidia because they can't compete all that effectively in the low-to-mid range due to the inferior efficiency and being weighed down by RTX features.",amd_gpu
I would also prefer to use AMD.  But their windows drivers are terrible,amd_gpu
"I'm also a long time Linux user. Historically Nvidia has been WAY ahead on Linux for OpenGL. Many earlier Linux ports required Nvidia. The last AMD card I got was terrible on Linux, but that was 7-8 years ago. Is the driver situation for AMD really good vs Nvidia on Linux today?

I mean, Nvidia cards get day one Linux support regardless of your kernel. I don't believe AMD has that, unless you compile an RC kernel.",amd_gpu
Not with a distro like Pop OS,amd_gpu
I don’t know where these comparisons are coming from. My rig with a 3700x and 5700xt ranks even or above my friend’s with a 3900x and 2080Super in FireStrike. A 2060 would be far below.,amd_gpu
Yes the 5600 XT is quite good for the price.,amd_gpu
"Hopefully we get the path of Ryzen. The 5700 series came out and was okay, competed well in the mid range like Zen & Zen+. Then Zen 2 came out and smashed into 9th Gen intel so hard that 9900k in Australia dropped $500 overnight.

They've shown they can compete with the untouchable Intel in the CPU market, so I'm hoping for a repeat in the GPU market to get the competition right back",amd_gpu
"Where I live a 2070 super is twice the price of a 5700xt and like u said, the gpu fight really close to a 2070 super.

Yeah amd don't have the hyper maximum card of all times, but they have a awesome card that at least for me is WAY CHEAPER than fucking Nvidea hyped",amd_gpu
"I've got a vega64, my only concern in life is Cyberpunk 2077... now I'm wondering whether I just get a PS5 or go over to green. Sure Vega could run in probably, but I want some 4k with ray tracing for this thing.

Or I could just upgrade my trusty ryzen 1600",amd_gpu
"Then to compound that issue, proprietary Nvidia stuff is getting more and more common.  If you are going to be rendering anything, even at a hobbyist, many of renderers will only make use of GPU power if it's  Nvidia. 

I went with a Ryzen CPU on my last build, but an AMD graphics card wasn't even ever really even a consideration.",amd_gpu
Do you do VR on Linux with your Vega? Asking for science.,amd_gpu
Anything that comes close to a 2070S is high end even if there are (4) better cards. The drivers for the 5700 suck but AMD are hardly irrelevant at the high end this generation. I will probably buy a RTX 3070 on release and pray the Nvidia propietary drivers and adaptive sync Just Work^^TM on Linux and my monitor...,amd_gpu
"Hey, I was like you, looked at the benchmarks, saw where the 5700 XT stacked up versus the 2060 and 2070 and then ordered the 5700 XT Anniversary edition.  While waiting to try to score a 3900X (obviously this was at launch last year) I looked up VR specific benchmarks.

And then immediately filled out the return authorization form for the Radeon.

Nvidia cards have a number of optimizations in them that translate to a 50% uplift versus AMD.  Maybe it's a driver situation or extensions that developers are only taking advantage not the Nvida hooks but it's a bad showing for AMD on VR.

And because everybody is using them VR on AMD has a lot more reported problems with bugs and crashes due to that combo bring largely untested.  Much of VR space is filled with indie developers without multiple hardware combos let alone large validation teams.  They pick what's popular and test on that.

It's a cycle where most people use NVidia for VR so it's developed and validated with those cards only so the other one perform poorly and therefore people don't buy them... and on and on.

Go look at the Blue Room, Cyan Room, and Orange Room benchmarks, or any other VR-specific benchmark, but do NOT use flat gaming as a viable proxy for PCVR benchmarking because it's not.",amd_gpu
Are you forgetting the radeon VII?,amd_gpu
"Well, don't forget that nvidia is not only competing with AMD but also with Sony's and Microsoft's consoles.  


I am one of those guys that see the price of the graphics card, see the prices of the consoles and buys the cheaper option.  

Putting the price on the same range of the consoles makes my choice a little bit more difficult.",amd_gpu
"You're looking at the xx70, xx80 numbers and judging by that. But if you look at the actual dies and how much they cut them down it's a whole different story. The 3080 is effectively what a 2080ti was before. The 3090 is almost what the Titan was. Pricing has gone down again.",amd_gpu
"If nvidia's availability is low on a node basically nothing else is made on, i'd rather not even think about AMD's availability when having to divide 7nm between themselves but also all the other people using it.",amd_gpu
"I think they'll rather do a ti than SUPER again. The current lineup without ti is because they noticed that their last lineup was ""surprisingly"" very confusing for consumers and they partly blame their lower-than-expected sales on that.",amd_gpu
"These ""fantastic"" prices are all relative to our expectations.  Unfortunately, as consumers we expected these prices to be higher. This is based on what Nvidia has done in the past and what the rumors were telling us. 
Just imagine if the PS5 finally releases their price and instead of being $499 like everyone is hoping they announce a price of $350. Everyone would talk for days about how ""fantastic"" the price is. But it's only because we expected the prices to be higher. 
And just FYI, I am completely speculating about the release and price of the Super cards, but this is exactly what Nvidia did last year when AMD released their cards. So it is precedented and realistic.",amd_gpu
"https://semiwiki.com/semiconductor-manufacturers/samsung-foundry/7926-samsung-vs-tsmc-7nm-update/
> Pricing. Samsung has the best wafer pricing the industry has ever seen. Being the largest memory manufacturer does have its advantages and wafer pricing is one of them.",amd_gpu
"That just shows the relative overpricing of the 2080ti. They put ""35% better than the $400 5700XT"" performance to $500. 135% * 400 = 540. In that light is not as impressive anymore, is it?",amd_gpu
"I was blessed to nab my 1080 before it all went to shit for $550 brand new.

So dropping $700 to likely come close to tripling my 1440p performance is a no brainer.",amd_gpu
The 3090 is more or less a Titan. I mean it has 24gb of VRAM for $1500. That will absolutely be a dream for the rendering crowd.,amd_gpu
But they do spend $1200 stimulus checks on them...,amd_gpu
Halo products like these sell lower spec cards though.,amd_gpu
You are wrong my friend.,amd_gpu
"Really? Plenty of people were 'hit' by the crisis by simply losing their job or making less money than usual if they are self-employed. You don't have to literally catch Covid (and be in an at-risk group for adverse health effects or even death) for it to affect you.

Many people who maybe used to have expendable income to put into PC gaming (or any type of gaming) as a hobby might not have that opportunity now.",amd_gpu
Sure but there's a big scale from homeless to rich. Tons of people are stuck at home and can scrape together $400-500 to get tens of thousands of hours of entertainment out of their games. I mean the whole point of this subreddit and /r/nvidia is that this whole thing is fun and it's the ideal time to have it as a hobby really.,amd_gpu
"I own a high end gaming pc and i've been hit really fucking hard...

I'm self employed... i am getting very little on unemployment (not even enough to cover half the mortgage), jobs in my area are hard to get right now, and even if they weren't difficult to get my self-employment over the past few years would be questioned by any employer who hired me.. and even if i did get a job, i'd most likely be making less than i was before.

don't gatekeep high end gaming.",amd_gpu
"TIL that humans don't play games on High end PCs. 

Everyone was hit by this pandemic. From Doctors and engineers to black jack dealers.",amd_gpu
"Considering the 3090 is practically the new Titan, even it's a good deal relative to the RTX Titan.  IIRC, the RTX Titan launched at 2500.00, so 1500.00 is reasonable if you're one of the people who could utilize the upgrade over the RTX Titan.",amd_gpu
It can game at 8k 60fps and has 24gb of vram . It's a showboat card for people that have more money than sense.,amd_gpu
"The 3090 is only going to be 10-15% faster than the 3080 in gaming.

It's only ~10% higher power draw and ~20% more cores, but at an already very high core count so won't scale 1:1.

The 3090 isn't for gaming, it's for prosumers.",amd_gpu
It's the titan which was $3000 for Turing.,amd_gpu
Its 1000 dollars less than the previous same level card. Which it replaces so actually a damn good price,amd_gpu
That's a Titan replacement. Some Titans were priced even higher.,amd_gpu
"Because with 3090, NVidia's lead on raw performance will remain uncontested, so it gets whatever price tag NVidia deems borderline realistic.  
Radeon getting back to compete with NVidia's XX80s would already be a huge achievement and enough to shift the tide of the battle.",amd_gpu
Isn’t it like... always the case?,amd_gpu
"The 3090 is a Titan replacement, not a 2080 ti replacement.",amd_gpu
"1080ti was a year later.
The old times with performance chip first and high end later",amd_gpu
"I don't think the 1080 got that low until after the TI launched, who knows, maybe big navi/ 3080 20 GB will bring it down there.",amd_gpu
I'm fucking praying that the 3080 ti is priced at 699. But I am an agnostic so,amd_gpu
"I heard a lot of rumors over the last few weeks that Nvidia wanted to simplify their lineup this time around, and realized that their Turing line was too confusing for most consumers.

I agree it's unlikely to see anything in the middle this time around other than a *possible* vram increase.",amd_gpu
"If they knock AMD out of the high-end GPU game, they can charge what they want in future generations. I can’t see shareholders complaining about that.",amd_gpu
"SUPER interested as to what amd is gonna do to their pricing structure now that we've seen this, crazy shit",amd_gpu
"Even if it's $300, that's way higher than that tier of card was 3-4 years ago.",amd_gpu
"The problem with that ""2080 Ti for $500"" perspective is that the 2080 Ti wasn't really a good card in the first place. It's $1200, some 70% more expensive than it's predecessor, but only 30 to 35% faster on avg. It was overpriced, and underperformed. The 1080 Ti, was only $50 more expensive than its predecessor, and 50% faster.

And let's not forget that at that $500 price point, you're still only getting 8GB of vram, and not even the GDDR6X kind.",amd_gpu
It's possible the 3080 TI will be replacing the 3080's price and the 3080 gets bumped down in price depending on RDNA2. That's my speculation on pricing though.,amd_gpu
">vram

How much will vram matter for gaming going forward? Does the beastly vram count of 3090 make it as much of a future proof card as the 1080ti proved to be?",amd_gpu
"Because the top amd card will be more efficient than Nvidia cards in perf/w even if Nvidia may keep the crown with that ridiculous 400w 3900.

Idk why you think 8nm Samsung would be more efficient than mature 7nm tsmc. Samsung has like 50% bin rate on those.

Why would Nvidia want tsmc chips if Samsung made better ones?",amd_gpu
Intel Inside,amd_gpu
Tapeworms plan for long-term viability,amd_gpu
"Animals like that act out of instinct and evolution, don't compare a company run by intelligent people to them",amd_gpu
Not fair to the tapeworms,amd_gpu
"On a global impact scale nothing compares to the Mongols. Locally and nationally, both the Rape of Nanking and generalized Nazi tactics were fairly fucking bad. If on a global level, both would have been possibly as bad as the Mongols in that it wasn't just death/slaughter/rape but also systemic torture.",amd_gpu
"lmao intel is much worse than Nvidia tf u talking about

Intel stagnated the market for 10 years, nVidia might've dreamed with doing the same but didn't.",amd_gpu
"> but at least Intel doesn't also try to screw over the users

YMMV I guess but artificially holding the consumer market back at four cores for years on end would seem to be exactly that imo.",amd_gpu
Edgy,amd_gpu
APU's does not have its own memory space like GDDR6 or HBM2. They use the computer main ram.,amd_gpu
got that right.,amd_gpu
The 2080ti is equivalent to the 3070,amd_gpu
Fix your comment. A 2080ti comparable card for $500. Not 2080.,amd_gpu
"I have a 2080 FE and cant play at max settings in 4K 60FPS to save my life. a 30-40% increase in performance also wouldn't get me where I need to be. the 3080 might cut it, but the 3090 will almost certainly seal the deal and force me to get a monitor with more than a 60Hz refresh rate.",amd_gpu
"I don't know about 'complete' show off - Pretty sure that's reserved for 3090 buyers right?

The £/Teraflop (FWIW) is the best on the 3080, so I'm going for that and hoping it lasts me 6+ years as a minimum.",amd_gpu
Delusional,amd_gpu
"Weird how people are doubting this. Sure, it will not scale perfectly and all but the performance we can safely expect of the top card is like 80% more performance than the 5700 XT. That's right above a 3080... People thinking the 3070 is hard to compete with, lmao.",amd_gpu
"Navi seems to finally be starting to get initial unofficial support, latest updates finally allow compiling some simple rocm code for it. But yeah, it's way too slow progress.

I've been trying to hold out thus far, but as I get more involved in ML research style stuff, it's basically not possible to go AMD due to how dominant NVIDIA is already. Can't exactly convince someone to limit their project to linux just to support the underdog when they're more concerned about cross-platform support than the hardware cost.",amd_gpu
I'm hoping they'll have PyTorch and TF support figured out by the time CDNA (their compute cards) hit the market.,amd_gpu
"With a navi card?

One of the best things about nvidia is their consumer cards are great for experimenting with ML. AMD is not even on the playing field realistically. At best there is experimental support for navi in rocm and you have to do a bunch of compiling yourself.",amd_gpu
"sadly not only that, look at video encoding and decoding. Nvidia doesn't even have damn good encoders with NVEnc, but they also support decoding for basically all video formats out there, including AV1(!) with RTX 3000.

AMD *really* needs to step up their game.",amd_gpu
That's easy when the TAA implementation is smudgy like a 7 year old's glasses,amd_gpu
"Try Control. I just bought it on Steam, getting solid 60fps+ at 1440p on an RTX 2070 Super with all ray tracing on and set to High with DLSS. It's like magic.",amd_gpu
I wouldn't be surprised if it gets supported by the major game engines soon and then game developers won't even have to worry about it.,amd_gpu
[deleted],amd_gpu
"If you're using the cards for AI work then sure. I used my 2080 TIs for AI projects.

AI features for gaming aren't there. They're not marketing bull AI. They're marking AI gaming features is bull.",amd_gpu
"Yep, that card will be a beast for its price.",amd_gpu
Happy Birthday in advance,amd_gpu
Hopefully you are getting a new GPU! Happy Early Bday!,amd_gpu
That’s what happened since the 390 series until the 5700 series I felt like,amd_gpu
"Because price to performance definitely worked out for Navi. 

Except it didn't. Navi market share was tiny compared to Turing.",amd_gpu
"Yeah, because they're trying to outdo AMD. As soon as AMD is gone they'll go back to sitting on their asses because that's the smart thing to do.",amd_gpu
For now. Because of competition.,amd_gpu
"Yeah, like even with competition now intel is still piddling thumbs lol",amd_gpu
"Nvidia also heavily ""improves"" their prices when they don't have competition though.",amd_gpu
AMD didn't have a bulldozer moment with GPUs. They've always been competitive in the midrange if not the high end.,amd_gpu
"Define ""improve"", because my 10700k absolutely smokes the 4790k it just replaced, and they're just six years apart. Also, the latter had 22nm tech, while the 10700k has 14nm. The hype over AMD price/performance is getting out of hand in the gaming community. Intel still reigns supreme in CPU heavy games like Escape From Tarkov, DayZ, Squad, Arma 3, & more.",amd_gpu
"The problem is if it's another Vega situation.  The GTX 1070 ti and 1080 were cheaper to produce than the Vega 56 and 64.  They provided the same performance but with less power cost so over time technically cheaper, but the same buy-in price.

If nvidia is capable of profiting off GPUs low enough that AMD can't compete on pricing because it's cheaper enough to make the same performance and do this enough times while their marketshare is already heavily dominant... it could push AMD out of the market.",amd_gpu
"They had a failed philosophy with Turing, but it was technically a significant technological increase from Pascal due to real time ray tracing. It just wasn't one most gamers cared about (or could even use, because games), so the line ""flopped"" comparatively.

They got fairly lucky AMD didn't surpass them from the lack of rasterization performance though.",amd_gpu
I agree. I'm not saying anyone should buy a worse product just because they are loyal to a company. I'm just saying I'd be concerned if AMD fell far behind.,amd_gpu
"Yea, AMD doesn't need to compete on the titan tier, but mid to high would be ideal. As long as they can compete with the 3070 they can keep their position a bit. If they want to gain market share they have to put out something like ryzen(competitive from low to top end) on the gpu side though.",amd_gpu
"Realistically I would say 3070. 3080 is the new 2080 ti and most people will buy 3070, because that card is actually better than 2080ti for 600-700$.",amd_gpu
"Performance is not that important alone, price is too. Most people are on xx60 series and most of the remaining are on xx70. No one has xx80 or Titan in their systems. If AMD can just match the 3070 (or 3060 if it comes out) or even 80% of the performance of an 3070 at 50% of the price ($250) they can gain some market share. For example RTX 3090 Ti can offer 300% performance increase over 3090 and 99% of the people will still not buy it at $1500 because that's over their budget and most people cannot afford to drop such money on a video game equipment. As it stands, NV's cheapest card is $500. There is a lot of room there in sub-500$ range. If AMD half asses the pricing and puts out a $450 card with  3070 performance then they will crash and burn yet again. People should look at the cards and say ""all things considered AMD one is a better offer than Nvidia at this price"" then we will see AMD gaining traction. On top of performance and price there is also the feature support. When BF6 comes along and gives 50% more performance on NV cards because of some DLSS or something then even that $400 3070-performing AMD card will lose out.

Nvidia fucked up with the 2000 series and most people are sitting at their 1000 series cards. On top of that people who held out with 900 series for 2000 series were disappointed even more and still holding onto their 900 series cards. Pleasing these people at that <$500 range should not be that difficult.

Edit: The real AMD killer will be the 3060 which Nvidia generally announces a month or two later than the big bros in the line up. However some people say that Nvidia shifted the lineup one down and there is no 3060 coming. RAM configuration looks like 3070 is actually 3060 but named differently. That's why there is a new 3090 card out there. It is the 3080.",amd_gpu
"Agreed. AMD needs to come out swinging, and beat the 3080. 

I do hope this aggressive pricing is a sign that Navi 2 is going to be great.",amd_gpu
I just hope people will actually buy AMD and bot just please AMD release something so I can buy NVIDIA cheaper.,amd_gpu
just hope they wont have to push it way above its sweetspot to get there :),amd_gpu
"I don't know if 3080 is a goal they *need* to beat. I'd put that at above the 3070/possible 3070Ti(Super, or whatever they decide to come up with). That will be the difference between losing gracefully and being embarrassed.",amd_gpu
"I don't see AMD matching a 3080 with big navi, maybe they'll close the gap/maybe match 2080ti/3070 if they did really well.",amd_gpu
They will,amd_gpu
"AMD needs to compete with the 3090 to gain mindshare. Folks will still spend a little more to have a product on the ""winning team"", even though their not buying the halo product. Nvidia and AMD make far more money on the lower end skus, more volume, and obsolescence is greater.  


The 1080ti longevity likely annoyed Nvidia to some extent... lol.",amd_gpu
Performance around the 3080 AND more then the 10GB VRAM from Nvidias cards and AMD has a seller :D,amd_gpu
"Not everyone buys them on release, usually more people wait at least for AIB cards. I'm expecting AMD to start revealing stuff before either anyway.",amd_gpu
"Sept 17th, exactly right.",amd_gpu
"The consoles will be bringing in new blood for years, and they have RDNA2.",amd_gpu
"I'm not representative of the average consumer, but I'm waiting on rdna2 before I buy either or.",amd_gpu
I think these prices are screaming that RDNA2 is actually a competitor. But let’s wait and see.,amd_gpu
"Let's be honest, AMD ain't impressing anyone. That's what Nvidia with flagship cards do.

AMD is what people settle with.",amd_gpu
"It will take a while for the release of RDNA2. There is no leak of pcb, shroud anything!. remember the 5700xt leaks we used to know that they had blower fans 3 months before the release, we knew that it was a 8 gb card there was a pcb shot, people were dissecting the pcb even. Not a single word is out yet for RDNA2 only a VR benchmark for a gpu which we do not know what that is.",amd_gpu
"Most gamers don't have $500+ sitting around rn -- or ever -- so, no, Nvidia isn't going to sell millions of 30-series cards in the next month or two and completely saturate that market. Relax.",amd_gpu
"Well they definitely needed a good reason to lower the prices *that much*.

It could be because they know something about AMD's plans, or maybe it's about the new consoles : they are being speculated to be around $500 and would offer a really great perf/$ ratio for a full system so it would be bad for Nvidia to pull out new GPU that do 30% better for 300% the price.",amd_gpu
"I personally think the only reason NVIDIA's showing is as good as it is right now is because AMD was competing.  If NVIDIA didn't feel any pressure, I doubt the 3000 would have the prices we're seeing today.  Hopefully AMD will continue to compete after this.",amd_gpu
"I'm not saying it isn't nice that Nvidia improved their cards, I'm saying I hope AMD can improve theirs in the same way.",amd_gpu
[deleted],amd_gpu
">  remember MS assisting Apple back in the day?

I remember M$ being lawfully required to do so. The current administration seems to have little interest in fostering competition however.",amd_gpu
[deleted],amd_gpu
"Are we sure amd even CAN compete? I much prefer amd gpu as I like hackintosh... But holy shit nvidia.

Not only are the cards slightly cheaper than their 2000 series, but they cut price/perf by about half simply by doubling performance and keeping price the same. 

Amd has held their cards close, perhaps they do have something to compete, but this was far better than I think anybody was expecting. Amd might find themselves in another Radeon 7 position where they simply can't slash prices lower without taking a loss (which they can't afford). 

Nvidia is much larger, buying in bulk is cheaper, they are on inferior Samsung which is probably cheaper than the contested tsmc, and of course they have much deeper wallet if they did need to take a loss. It will be interesting to see what amd has to respond with.",amd_gpu
"Agreed. AMD has historically been the value brand for graphics cards. Hell, in both CPUs and GPUs they've spent enough time at #2 to know how to leverage that position. 

There are also ""unfair"" market forces at work on the high end, the Titans/3090's get far better support by leading applications (Adobe, Plex, etc), so even if they can compete at a hardware level that still takes AMD gpu's off the table for a wide swath of consumers and professionals. 

I have no problem with AMD remaining the value proposition in the gamer space until such a time that their R&D can trounce Nvidia the way they did with Intel. Might not be this generation but it will be a nice day when it happens.",amd_gpu
I wouldn’t use a 5700xt if it was given to me right now,amd_gpu
"I mean I'm not going to buy an inferior product to support a company, but I'd prefer if they stay competitive as that drives prices down.",amd_gpu
"That's a rather silly statement. If all you need is a card at the price range AMD offers, and it's better value, then what's the sense of paying more? If you buy NVIDIA to ""show AMD a lesson"", all you're saying is that you're fine with paying more.",amd_gpu
Yeah i will vote with my wallet for AMD because they support open source linux drivers.,amd_gpu
"Dum to say ''vote with your wallet'' while 8 years ago no one did it when AMD was ahead and cheaper. You are the guy who wants AMD to make better cards not to buy them but in the hope, Nvidia's cards get cheaper witch won't, and they buttf\*\*k you with a TI for 100$ more and still buy it.",amd_gpu
"Idk. RTX 3080 performance but with 16GB of RAM, for $599 sounds good to me.",amd_gpu
Thats how AMD almost went under. Voting with your wallet is good but they need to be able to handle a bad launch. With Intel due to release a gpu by 2023 and ampere as good as the slides show AMD might not be able to handle a bad gpu gen again right now. That's not to say I won't buy NVIDIA if AMD falls short again.,amd_gpu
"AMD has no worries for GPU's for at least this console cycle. They might not do great for high end but they at least can hold on for a bit in the mid to low range.

I doubt intel's gpus are going to be competitive with high end either for their first attempt.",amd_gpu
"By that logic AMD isn't that competitive in the CPU side either as they have a market share of 35% to intel's 65%. 

I'm just hoping AMD can at least stay as competitive as they are in the mid range to keep nvidia pricing in check a bit. I don't buy AMD to support them, I buy it when the value makes sense for the performance I want. 

If amd gets steamrolled this time, I'll be worried for rtx4000 and such as Nvidia won't feel threatened and will be able to raise prices.",amd_gpu
"That is not historically true. People bought inferior GTX 960s over discounted 280x, 290s and 380s.


This idea that the consumer can do no wrong and is never responsible for bad things happening to said consumer is really bad.",amd_gpu
If AMD doesn't have competition for it then the voting you can do with your wallet is limited.,amd_gpu
"I never implied that. I didn't say we should go buy amd gpu's to help them out, I just stated my worries that AMD might not be able to compete which will make things pricier in the future.",amd_gpu
"tbf, that was kinda expected.",amd_gpu
Why? Even a basic 550W PSU can handle a 300W GPU.,amd_gpu
Just hawk ebay for a bit... I picked up a 1200W Corsair for like $75 just make sure you have all the cables... I could run like 3 cards on this thing easily. All I'm saying is you have options you might even score an 850w or so for even less.,amd_gpu
Isn't their next GPU series supposed to cut power by like 50% for the same performance?,amd_gpu
"I use Titan RTX for Deep Learning on Linux at 5k2k, before used 2080Ti and 970M in SteamOS computers and never had a slightest issue with NVidia. I'd say for Deep Learning they are running better than on Windows...",amd_gpu
"im planning to do a huge upgrade from an AMD R9 390 to a RTX 3070, but as far as i know, Nvidia is the much better card for linux if you are trying to do Deep Learning, there is not as much support for AMD cards, which is the reason I am upgrading. What kind of trouble do you have with Nvidia and linux exactly? AMD on linux has not been great either, i had problems with my graphics drivers for years",amd_gpu
[deleted],amd_gpu
Your mindset is why Linux still hasn't got crucial tools that Windows has.,amd_gpu
Use Wayland and get back to me on that.,amd_gpu
"Aside from HPC, which is incredibly important to NVIDIA, there are actually a lot of people using Linux on the desktop. Last I checked, Linux marketshare was ~2%, which may seem incredibly small until you realize that MacOS is well under 10%.

However, what it's really about is NVIDIA selling a product which they don't really care about supporting. They shouldn't sell you a product that they claim supports Linux and then act like you're lucky it even works at all, but that's basically their attitude. And Linux users are pretty much used to being treated this way so a lot of people don't complain, but the reality is that things have been changing and almost every major vendor has their drivers in the kernel nowadays, except for NVIDIA. And so what was considered good enough 10-20 years ago is not good enough today, as their competitor now has very high quality open-source drivers.

So, if NVIDIA isn't interested in Linux users' business, that's fine, they can pull support and walk away, and it probably won't hurt their bottom line very much. Except in doing so they'll lose HPC, and they can't afford to do that.

Edit: tl;dr: the problem is that they want Linux users' business, but they don't want to actually do the work to support said users.",amd_gpu
Yeah I read somewhere (and I think even LTT mentioned it?) that Jensen was disappointed by sales of Turing (I guess it was because of the price and mining craze disappearing),amd_gpu
"Nvidia had no competition in that area.

Easy to charge whatever you want when no one else can make a similar product.",amd_gpu
"8800 Ultra was around $1000 when it launched.

We've had expensive GPUs before.",amd_gpu
"Consoles sucked, AMD wasn't competing GPU wise, mining was still dumb, putting RT on a consumer card was expensive to R&D. All of those things contributed.

Consoles won't suck now, AMD is competing, mining moved to ASICs, the RT R&D is already paid for.",amd_gpu
3070 is really not that overpriced when you consider the massive die size and yields.,amd_gpu
YEEHAW BROTHER,amd_gpu
oof,amd_gpu
Maybe. Tarkov is poorly optimised in general though so... Eh.,amd_gpu
"I just started playing tarkov a few weeks ago. My 5700xt still has some breathing room at max settings 1440p. The killer is my R5 2600.

Depending on the map I get 90-100. A couple maps I never go above 80.",amd_gpu
Yeah I was wondering why the leaks about power consumption were so high. Makes sense now. The 90% increase in performance per watt is still amazing. Almost twice than what RDNA2 has.,amd_gpu
Their best has to be better than MS and Sony and they sure are bragging about them. So yeah it will be interesting.,amd_gpu
"[Here's the timestamp](https://youtu.be/E98hC9e__Xs?t=1851). The 10-series is on there too, and the performance lines up with what independent benchmarks say.

And cross-reference the ""2x 2080"" to Techpowerup's benchmark data.",amd_gpu
"I agree, I can easily imagine AMD matching Ampere's RTX performance penalty since they were watching the Turing launch too but DLSS is going to be the killer. If it's as trivial to add to TAA-enabled games as they say, game over...",amd_gpu
"They have directML super resolution on every gpu possible, already used in the Xbox so they already have ti implement It for the console version",amd_gpu
Have an Nvidia shield with AI upscaling. Their upscaling abilities are awesome! Excited to upgrade from my GTX 1080.,amd_gpu
"Yeah, not having to brute force resolution at the expense of performance is huge. AMD is going to need some other things to offer that is similar aside from just performance, which seems like it may be difficult. If there's a $100 difference between comparable AMD and NVIDIA cards then the drivers and things like DLSS may be something people are willing to pay extra for.",amd_gpu
"DLSS is probably a side result of the whole ai cloud business, where Nvidia is owning the market. That money can be put in lots of man power. AMD doesn't have anything like that. On top they are not so good in software and their cpus probably don't have the necessary in hardware support if they would come up with something.

The only option I see for AMD is either buying someone with this tech or just radically cheap their cards.",amd_gpu
"> DLSS2.0 is GPU wizardry.

Its upsampling and look like it.",amd_gpu
"A 3080 with DLSS2.0+ sounds stupid, it's been a long time for tech to sound stupid... as you know in a good way. Awaiting to hear now from AMD.",amd_gpu
"Yep. 

A 52CU GPU in the XSX does 12TF and performs on-paper about at the 2080/S level out the box, without utilizing any new RDNA2 features.  

An 80CU part will have a bit more than 50% more shading power.  It will easily beat a 3070.  The 3080 is the main question, which is looking more up in the air now.  3080 is faster than many probably anticipated, and its 19gbps GDDR6X is probably the one aspect that could give it an undeniable edge unless AMD goes back to using HBM again, which will mean less room for undercutting on price.",amd_gpu
"If they measure rt performance like nvidia and that ""95 something"" in the xsx slides are the same rt-tflops nvidia uses well, amd rt will destroy things..",amd_gpu
">AND if DLSS were to get more popular

Notice the *if*, not when",amd_gpu
"If you dont play the latest AAA games that push the hardware, might as well buy an old gpu or a low end gpu.",amd_gpu
"I'm really glad I was 😂

I still want to see more benchmarks but RX 6X00 gpus are looking good 😎",amd_gpu
"Now that the 3000 series can actually.playably raytrace

If all amd has to offer is non raytraced performance matching, man, its gonna suck to move over but team green it is",amd_gpu
"> All AMD needs to do is offer similar performance at better prices and they will net a lot of customers.

for the same performance and lower price i would still buy buy a bit more expensive nvidia card simply because of the features package (and that's ignoring any potential driver issues on amd side)",amd_gpu
Cuz that totally worked for Navi.,amd_gpu
">All AMD needs to do is offer similar performance at better prices and they will net a lot of customers.

Remember HD5000...?",amd_gpu
No need for AI cores when DLSS 1.9 ran on shaders and had similar quality to 2.0.,amd_gpu
Xbox Talk included details about RDNA 2... and AMD does have ML and RT acceleration in RDNA 2.,amd_gpu
AMD doesn't need AI cores. Rapid Packed Math is what they're doing to help along FP16.,amd_gpu
"Same performance and slightly cheaper isn't enough anymore.

AMD would need 3080 performance for 3070 price and 3070 performance for 349/399$ to even be considered as a purchase option.

Nobody who's willing to spend 700$ is gonna buy a worse product to save just 50-80 bucks..

It has to be a **thicc** discount to convince people to go with an AMD GPU.
(Why would anyone willingly choose less features, worse drivers, worse RT performance, no DLSS, unless it's a really big cost saving).",amd_gpu
"Hello 580 brother, our Polaris replacement will be finally sold for Polaris prices. :)",amd_gpu
">Digital Foundry already benchmarked 3080 performance and found 60%-80% performance increase over 2080 Ti without raytracing/DLSS at 4k.

You mean the 2080, not the 2080 Ti right?",amd_gpu
"What I find suspicious is he said he wasn't allowed to show actual FPS and could only show the % increase, and the way he put on such a show of following the cable from the PC to the screen just seemed odd, never seen that before.

Whole thing was super fishy.

As always, bench for waitmarks",amd_gpu
"But you can't do that shit on default. That's false advertising. That's like a magazine reviewing NVdia and AMD cards, with only the new NVidia cards reduced to 70% render resolution.",amd_gpu
"Still have fond memories of my 8800GT, which was a SINGLE SLOT high-end gpu. The last one I've seen afaik",amd_gpu
"My first from-scratch build was an 8800GTS 640MB build. I was an ATi person before that but the 2900XT was nowhere to be found when I wanted to build. Still, good times.",amd_gpu
My first ever GPU(s),amd_gpu
My uncle's machine (which I played on growing up) was an absolute monster with it's 8800GTX and 768mb of VRAM. And it could run crisis at 1200 x 1600...On high! Crank it to ultra and it crashed in about 5 minutes.,amd_gpu
"I still remember when ATI just couldn't compete, after 2 years nvidia just rename 8800 to 9800 still have a edge on performance...",amd_gpu
I'm still rocking my 8800GTX+ in my old-old rig (with a Phenom II 965 BE). Still doing the business,amd_gpu
ATI so not amd?,amd_gpu
At these wattages?,amd_gpu
Im in the same boat here. The last year has been pretty miserable for me when it comes to the drivers and system crashes.,amd_gpu
"RTX 8090 TI-me machine launching September 2034, according to my sources",amd_gpu
"It was wild, when they were showing the new Marbles demo I was talking in the presentation thread about how in our lifetime we'll have holodecks. Then he talked about holodecks at the end. wtf",amd_gpu
"That was the dumbest shit to tack on the end, should have been cut, would have been far better without it.",amd_gpu
"This does it with nearly zero additional CPU or GPU load. This is the same reason Shadowplay, RTX voice (now part of broadcast suite) etc were so amazing at the time.",amd_gpu
"I used RTX voice ever since it was released, it's really good.",amd_gpu
Why would they release a 3080 Ti when they have a 3090?,amd_gpu
ah sorry you are right,amd_gpu
[deleted],amd_gpu
Nvidia had it first too. It's Gamestream isn't it?,amd_gpu
AMD is not trying to copy DLSS and raytracing is an old as fuck idea that has nothing to do with Nvidia. Stop pretending to be dense.,amd_gpu
Nvidia went to market extra early with a kludge implementation... period.,amd_gpu
Wtf,amd_gpu
[deleted],amd_gpu
I guess it worked.,amd_gpu
Works every time,amd_gpu
"Heh. Step the pricing down?

The flagship card is $1,500.

That's $300 **more** than the 2080 Ti.

I don't care what nomenclature Nvidia uses, it's a bald fact that they're releasing their top Ampere gaming GPU for substantially *more* than they did last gen. In the midst of a global pandemic. 

It's so brazen I'm laughing. Laughing nervously, because sweet baby Jesus we could really use some competition from AMD right about **now.**",amd_gpu
"Downgrade , and sell what was one standard issue as premium service. It's the oldest trick in every corporate accountant's book.",amd_gpu
"You aren't even wrong too. It's a known strategy in retail: mark up some absurd price but discount it to regular price during a sale and people will buy it because ""it's discounted"" even though it isn't.",amd_gpu
"If only! I think it has far more to do with covering their massive R&D bill for the first Rtx tech. It seems it's matured, and anything matured or well understood can get price optimized quick. I genuinely believe they wanted to sell the RTX 20XX for less than they did, but simply couldn't. They figured given their position, they could do what they had to do (sell for crazy high prices) and fix it later. 

Anyway, couple that RTX maturity with using the cheaper 8nm samsung process vs the very expensive 7nm process from tsmc, and boom. You've got your reasonable prices back and just in time to maintain your absolute market dominance.",amd_gpu
"Like when the $330 970 replaced the outgoing $700 780ti? 

Does no-one have any fucking perspective any more? Or do we just have to wait a little longer for the knee-jerk reactions to some slick marketing presentations to subside?",amd_gpu
And they still sold the overpriced shit in good enough numbers thanks to being stuck on the previous generation for four freaking years. People were so ready to upgrade they would have bought anything.,amd_gpu
AMD was a little busy working on 2 different custom designs on RDNA2 in addition to 3 different dGPU dies. AMD took a generation off from producing a large die in order to work on the next consoles and move to 7nm early.,amd_gpu
"Unfortunately for NVidia, there are fewer and fewer people with that kind of money to spend. We are in the middle of a pandemic, and the world economies aren't doing so great at the moment.",amd_gpu
The Navi 10 die was powerful for its size and transistor count. And the 5600XT showed that the die can be very efficient if not pushed to be more than its transistor count will allow.,amd_gpu
"Nonsense. You were never going to buy an AMD card no matter how cheap. 

The only reason Nvidia stepped their prices down this gen is RDNA competition.",amd_gpu
"iF yOu NeEd It BuY iT nOw. If YoU cAn WaIt, WaIt",amd_gpu
"> Everyone told them to wait.

na there's always idiots who say 'buy now. if you wait now, you might as well wait forever because the next thing is always right around the corner'

so infuriating but it's always upvoted too

edit: even in non-tech subreddits https://www.reddit.com/r/LivestreamFail/comments/iknlp4/2080_ti_users_right_now/g3mw65r/
>[–]CreativeGore

>[-1] 297 points 12 hours ago 

>If you always wait you will wait forever cause new parts drop all the time",amd_gpu
I had people calling me stupid just a little over a week ago for telling people to wait.,amd_gpu
"Yeah, I didn't think that far, I just saw the graph showing ""2080 Ti perf but somewhere between a half and a third of the price"" and I was just shocked there.",amd_gpu
You are talking about a $800 loss vs a $100.  Not even anywhere on the same level of screwed.,amd_gpu
$250 5600XT though still looking pretty solid,amd_gpu
"I've seen most 5700 XT's at about $330, which isn't too bad. If your GPU failed or something and you needed a new one immediately, it wouldn't have been a *bad* buy. Sometimes you just end up with a card that isn't the best, but it's still serviceable for another year or two. The 5700 XT is kind of in that lane right now, I wouldn't recommend it to anyone who doesn't need a new card right this moment, but it will carry you till the generation after this next one alright.",amd_gpu
How does step up work?,amd_gpu
It only works if you bought an evga card within 90 days,amd_gpu
"Be interesting, I'm glad it wasn't just me who thought it wasn't that clear and the experts don't know. Ah well, about two weeks for benchmarks and hopefully some good AMD news.",amd_gpu
Of course it's rasterization. People are too focused on the price and not realizing the 2070 Super and 2080 ti aren't that far apart performance wise in the first place.,amd_gpu
"They announced Fortnite RT during the stream, so they could be including titles like that",amd_gpu
"Oh yeah, I'm not a first day buyer and i'll be waiting for AMD's hand. Just seems like people are getting a bit carried away.",amd_gpu
if it were all with RT on then the 2070S' lead over the 1080Ti should be much bigger than they showed in the graph,amd_gpu
"Digital Foundry had early access to 3080 and saw 70-90+% improvement over 2080 in tested titles. The less raster dependant and more RT focused the game was, the higher the improvements were. 100% improvement was seen in some moments but not as an average in any tested title. Still, an 80% improvement as an average likely validates their ""biggest generational leap"" claims.",amd_gpu
"It's around 1.5x ish based on the slide showing the 3080 offers 2x the performance over the 2080

https://images.anandtech.com/doci/16060/20200901173013.jpg",amd_gpu
It says in average across multiple games at 4k.  Nowhere does it mention they are rtx games,amd_gpu
digital foundry showed 3080 about 80% faster than 2080,amd_gpu
That's a good point.,amd_gpu
Wasn’t it rt AND dlss? They have more cores for that according to the slides. So dlss should run faster. I’ll be waiting on benchmarks as always. Marketing slides are piss in the water.,amd_gpu
"I’m estimating 1.15x over 2080Ti, or 1.5x 2080.",amd_gpu
"Yeah, the chart on the 3080's homepage isn't actually that promising, it compares the 3080 to the 2080 (not the ti) and just about achieves 2x performance on minecraft with RT. Borderlands without RT and Control with RT are just under 2x.

Obviously against the TI this would be worse. https://www.nvidia.com/en-gb/geforce/graphics-cards/30-series/rtx-3080/",amd_gpu
DLSS won't make a difference between generations.  They both have it.  The RT performance increase will though.,amd_gpu
"The 3080 has almost double the cuda cores than the 2080ti and apparently 2x the throughput on those cores but can only maintain a 30-50% uplift from them after two years, it seems weird. 

The return of 1000 series pricing is a bonus though. I'm glad he acknowledged the misstep in the release.",amd_gpu
"No, The 2080Ti is 13.45 FP32 Tflops and that's what they're referring to with Tflops, not the FP16 number. The 3070 has almost 6K cuda cores while the 2080Ti has 4352.

But Tflops are never a good performance indicator. Ampere will most certainly run worse in terms of performance/Tflops when it has 128 Cuda cores/SM.

The 2070S is not that far off from 77% honestly.",amd_gpu
"The 2080ti is 13.45 TFLOPs (FP32) officially (real clock speed is variable than the listed boost used to calculate that).

Although bear in mind that comparing TFLOPs across architectures is a bit apples to oranges.",amd_gpu
Also with leakers screeching to sell your flagship ASAP.,amd_gpu
"I mean, it's the same rule of do I spend now, wait until something new comes out, get to that time, hey if I wait more something even better will come out type of thing. I bought my 2080ti back in February and even then...",amd_gpu
"You would be surprised at how many people in my country buy top tier iphones in installments when they cant even pay to get the screen fixed if they break it.

I know a guy who bought iphone 10 for 80k while his monthly salary was just 10k. 
And the sad/funny thing is it got stolen.",amd_gpu
"People are like that bro, why drive toyota when you can afford bmw easily and why drive bmw when you can afford porsche easily and so on...",amd_gpu
"> do 2080 Ti buyers even care?

Those that bought one this past month do lol. They must be rushing to refund the card as we speak.",amd_gpu
"To an extent I care. I have money. Im not happy taking such a big value loss, but it only impacts me if I sell my GPU. At 1440p its still pretty damn good.",amd_gpu
Sharply? Previous gen was so overpriced that in comparison this seems cheap is what you mean.,amd_gpu
"Nvidias toughest competition is nvidia itself, not AMD. Most of nvidias customers are previous nvidia customers (due to sheer market share), thus they need something with better value again. Turing didnt provide good value so many people skipped upgrading and they probably noticed.",amd_gpu
Nvidia being scared is what brought us 1080 ti at that pricepoint. Vega 64 hype lul,amd_gpu
That's also my guess. I was surprised that they've keep the 20-series launch prices (for 3070/3080).,amd_gpu
"Morelikely because turing was way too overpriced. retardly overpriced ""RTX ON""",amd_gpu
"There is a reason - consoles. Nvidia competes here with people that will consider ""PC or new generation console"", not ""Nvidia or AMD"".",amd_gpu
"They knew, so they bumped the $1400 leak of the 3090 to $1500 post-leak.",amd_gpu
Should have just not bought the 2080ti in the first place.,amd_gpu
You're right. Nvidia wouldn't have come out with this level of price/performance if they weren't expecting competition from AMD.,amd_gpu
I assume such card would be $600 or $500 at the lowest. No way would they sell a card 10-15% faster than the 3700 for that cheap unless it's dropping the ball somewhere else. Like not having a DLSS or RTX IO equivalent.,amd_gpu
Here is a benchmark of the 3080 from digital foundry https://www.youtube.com/watch?v=cWD01yUQdVA,amd_gpu
"Price per performance is everything that matters *within* each price segment.

If you were competing for the $50k customer then price per performance would be everything.",amd_gpu
[deleted],amd_gpu
That picture always reminds me of Fermi memes,amd_gpu
"Not to be a fanboy,I actually am not,but they also implemented more things such as DLSS and Ray Tracing so can't really complain...",amd_gpu
"> Turing GPUs have been selling out everywhere

Covid. A re-release of Fermi for these prices with new names would sell. Everyone has been reporting on the strong bubble effect and it doesn't just affect Nvidia. Nvidia were incredibly lucky because pre-Covid Turing was doing badly.",amd_gpu
I didn't say they didn't sell. I said they sold below Nvidia's expectations.,amd_gpu
"Because...they DID. The xx70 tier for Turing was $700 in many regions. For Ampere it is retailing at $499. 

That absolutely qualified as dropping.",amd_gpu
"To be fair, we're plateauing on silicon, materials for manufacturing hasn't gotten cheaper, and you have to take into account inflation",amd_gpu
I got a 290X for roughly $400 in 2014. It was near TOTL at the time. For a *staggering* $550 you could get a 980.,amd_gpu
"I think part of it though is that GPUs today offer so much more. Rtx is a good example. Not that rtx is perfected by any means, but for every additional hyped up feature they add that wasn’t on the last one, it can justifiably go up in price a bit. I do agree they’re a bit too high right now but $200-400 for top line current cards probably isn’t realistic",amd_gpu
"This stuff isn't opinion.  This is in the world of objective measurement. 

Even in your computerbase link, the only time it's less than 30% is at 1080p.",amd_gpu
Model number really doesn't mean anything unless you also include performance increases between series.,amd_gpu
"What are you talking about?

What do you think, AMD is laying out transistors by hand?   AI isn’t some magical thing that makes GPUs better, it’s an approach to solving some problems that were previously difficult to do.

NVidia focuses on AI because model training requires generally relies on doing a lot of math that GPUs typically are really good at.",amd_gpu
https://www.amd.com/en/products/professional-graphics/instinct-mi50,amd_gpu
"AMDs massive growth over the past few years has been pretty much solely due to its CPU division. AMD has been DOA in the GPU space for a while, at least for enthusiasts. I'd reckon that AMD would sell off Radeon if it wasn't for video game consoles.",amd_gpu
"And then after 5 years of nvidia dominance they become complacent and AMD returns from the dead with AMD Radeon Gryzen.

Or something like that idk.",amd_gpu
"Honestly that would actually not be so bad, it would force software engineers to write efficient code instead of just brute forcing shit.",amd_gpu
AMD is getting all the console money. They will be in the game for a while. They will have a chance to catch up.,amd_gpu
AMD GPUs will be in like 200 million PS5 and xboxs. They won't be going anywhere,amd_gpu
2080Ti performance without the same features for $299 is a dream so pipe-y I think I saw an Italian plumber go through it.,amd_gpu
"The 5700xt can be had for $200 less than some 2070super’s, but the 2070s is still outselling the 5700xt like hot cakes. 

Nvidia just has bigger mind share. Their brand is just bigger. I don’t really know what AMD could do to take market share from Nvidia.",amd_gpu
Let's just be real... AMD is going to get smoked this gen. Nvidia has sooo much money to invest into this stuff and is the industry leader. They went all out this gen. It could end up with AMD selling it's GPU tech to someone else at some point. If the gap between the two companies gets too big how can they come back? This stuff takes years of development and billions in R&D. At a certain point AMD will just be dead in the water on graphics.,amd_gpu
$200 less sounds unrealistic,amd_gpu
"I don't think it's that they haven't bothered, I think it's that they can't. They have sold plenty of expensive and poor performing gpus before, but they largely haven't been competitive for the last decade. 

People put way too much weight on console sales. It's an extremely low margin market that AMD owned last gen. Not like it helped their growth much. Their semi custom chip revenue (consoles) is not a large part of their growth and represents a shrinking part of their revenue.

https://inspectcompany.com/amd/metrics/revenue-by-segment",amd_gpu
"sure but profit margins are insanely low, they are not making much out of that deal",amd_gpu
[deleted],amd_gpu
"You might be right. 3090 is literally just a Titan. Like the Titan RTX, and look how 2080 Ti got close to it. $999 for 16 GB 3080 Ti seems awesome. Personally, I’d like for it to be massive and chonky like the 3090, cause I like chonky cards.

Also don’t forget over clocking performance!!!!!

AND AIB PERFORMANCE TOO",amd_gpu
"I mean, a 2080ti is a good card, its just the pricing of 3000 that totally kills it.",amd_gpu
Buy another one for half the price and put them in SLI.,amd_gpu
"Good call man. 
In about october, I'm giving away my Vega 64 to a friend of mine, getting my HD 7970 back from him and giving that to my dad XD",amd_gpu
150€ and 3 Reese's bars :D,amd_gpu
"Holy shit, 2080Tis are already less than that right now.",amd_gpu
Huh? Tested with a couple different supplies and had the same problem.,amd_gpu
Do you? So far everyone is getting excited about Nvidias marketing materials.,amd_gpu
"That's great and all, but what about with DLSS (which seems to be in every AAA game coming out these days) enabled? 

I think AMD expected nvidia to do an intel and have another Turing launch with no performance uplift and higher prices, when in reality the 3080 bc its on what is usually a ti or titan die is nearly double the performance of a 2080.",amd_gpu
[deleted],amd_gpu
return that shit. what's wrong with you. spend your money on something better.,amd_gpu
"> you can't just expect nvidia to click a button with +30% performance every 2 years and keep selling GPUs at the same price

?? 

You actually can lol, and this is what used to happen. No need to get your panties in a twist about daddy Nvidia being still overpriced.",amd_gpu
"> I don't think you've been a PC gamer for very long if you're making statements like that.

Lol says the guy who thinks TURING is the only outlier. Pascal was overpriced too. 

[Oh look](https://web.archive.org/web/20111021064123/http://www.newegg.com/Store/SubCategory.aspx?SubCategory=48&name=Desktop-Graphics-Video-Cards), x80 tier cards for $499. What is the 3080 going for, $700? 

x90 tier card for ~$750, what's the 3090? $1400?",amd_gpu
"Microsoft hinted at their Hot Chips conference that they have something cooked up as a DLSS-like AI upscaling alternative - when asked about it, they said there weren't able to go into detail. Seems very, very possible that AMD has something.

Also, AMD has mentioned in the past that they're capable of doing something similar to DLSS through DirectML, which is basically DirectX's machine learning/AI API.",amd_gpu
"DLSS was announced at the same time as 20x0 GPUs, so that's around september 2018. In April 2020 DLSS 2.0 was announced.

Again, how many games actually support DLSS? I agree the results are outstanding but it requires for the game to actually include DLSS support, and for nVidia to train their neural networks with your game (the latter might not be completely true, as there seems to be a lower quality option that requires no training?). My pet peeve with this kind of solution is that it's not a general solution that can be applied to any software without the need to explicitly add support for it. I rather a lower-quality similar feature that works out-of-the-box for any software once enabled via drivers.

I hope that in the future DLSS can be used that way, no idea if that's even possible tho. Until then I won't vouch for it

Back to my original question: how many games support DLSS as of today, 2 years after launch? I'm sure it's lower than the number of games supporting RT, but I can be wrong here.

I don't get how DLSS is receiving so much weight when it's such unused feature (same as PhysX, which ended up phasing out for good).",amd_gpu
"Yeah I know, and there's a handful of AAA titles that use or will use it. But it's just that... a handful of games. Not a perfect solution in my eyes.",amd_gpu
"https://images.anandtech.com/doci/16060/20200901171847.jpg

It's at iso-performance.",amd_gpu
"Easy, just read the specification then your done. GOOGLE is your friend.",amd_gpu
"Is that the same year?

GTX 680 kepler - 2012 
GTX 770 kepler - 2013 refresh
GTX 980ti maxwell - 2015 (approx 80% faster than 770)

Took them 3 years and a brand new architecture of the SMs not a revision. 

MAXWELL to KEPLER is 100% performance per watt imrpovement.",amd_gpu
"It might take less space but it still takes space. I don't see a big value in DLSS. Rughly the same image quality still isn't the same. Not a fan of upscaling things at the cost of reducing quality. I'm fine with resolutions that GPU can handle normally.

Tricks like DLSS might be useful for very massive resolutions the are needed for VR and such (there they have a reason to be so large), but for regular use cases? I'd rather GPU crank up more regular performance, instead of wasting die space on upscaling ASICs.",amd_gpu
Nvidia should have improved memory compression..... but WAIT FOR BENCHMARK!,amd_gpu
seems like it would be enough for 1440p at least but who knows,amd_gpu
Very true,amd_gpu
"For me it's the 650W recommended power supply, the power consumption on the new cards is insane.",amd_gpu
LOL are you kidding? Games today already look better on Turing than Pascal thanks to raytracing + DLSS. Everything apart from Turing has aged horribly.,amd_gpu
Why not just say 'its looking' like a normal human being,amd_gpu
Can't imagine why there would be. It's got hyperthreading and works without any issues with current games. Guess I'll wait and see,amd_gpu
"Just FYI, [V-Ray supports RTX](https://www.chaosgroup.com/blog/v-ray-gpu-adds-support-for-nvidia-rtx).",amd_gpu
RemindMe! 2 months,amd_gpu
"Lol even AMD fanboys are getting downvoted in /r/AMD because everyone knows Ampere is a fucking monster.

It's literally twice as powerful as the products its replacing, even if AMD pulled off such a feat it still won't match Ampere.",amd_gpu
RemindMe! 2 months,amd_gpu
Guess we are clowns,amd_gpu
"Obviously, yes. RTX was a big misstep in light of Unreal 5's lighting capabilities.",amd_gpu
"They compared 1080 with 3080 by enabling rtx on both and dlss for 3080. Its on their website.

Numbers are bullshit",amd_gpu
I remember them using relative non-rtx (grey dots),amd_gpu
"MSFS is a terrible example. The game doesn't even support DX12. 

Also, here's the full list of upcoming DLSS games: Boundary, Bright Memory Infinite, Call of Duty: Black Ops Cold War, Cyberpunk 2077, Fortnite, Ready or Not, Scavengers, and Watch Dogs: Legion.",amd_gpu
"My dream is a 4K120 fully raytraced HDR OLED VR experience. I expected something like that to be viable in 10 years but if Nvidia keeps making leaps this big, it might be possible in 5.

I think Nvidia will focus on reducing power consumption next rather than crazily improving performance. I expect another turing generation after this one.",amd_gpu
"Well the cards to draw quite a lot of power.

  
Side effect of Samsung 8nm

&#x200B;

But at that price, who cares?",amd_gpu
Yea this hard caps the new consoles at 500 usd. 3070 is just insane value. Unless it really shits the bed at higher resolutions because of worse vram it's the best mid range card we could have hoped for.,amd_gpu
"yeah, they placed 3070 and 3080 spectacularly. Although we need to wait benchmarks, only based on TFLOPs, I can only expect great results.",amd_gpu
"All of the things you've said will already be happening if Ampere cards are always out of stock. 

I suppose the pricing strategy also makes sense if they are able to produce a ton of cards at launch, but that basically never happens.",amd_gpu
"It's also what people want, to upgrade at the beginning of the console generation and then again half way through after 3-5 years until the next console gen starts.",amd_gpu
DLSS is the obvious one.,amd_gpu
"First, I did research online and it was only later I found out about their high RMA rates. Second, powercolor is one reason I'm staying away from AMD but the high thermals and driver issues also don't help.

By the way, I proudly have a ryzen 2700x, bought a Athlon64 and Phenom back in the 2000s, and will buy AMD when I feel comfortable that the product provides quality and performance. If RDNA2 really improves more than just on the price front then I will gladly buy team red again. At this point I'm hoping even Intel can provide competition at all levels for Nvidia. I'm not an Nvidia homer, I just want a GPU that I'm not afraid of catching fire or breaking after 3 months.",amd_gpu
"Yeah, I think that AMD is screwed in the GPU market. Maybe they will pull a rabbit out of the hat but I doubt they have anything to compete with 3080 or 3090 and they will have a tough time even with the 3070 now. The 3070 should be about 35% faster than the 5700XT.",amd_gpu
"780Ti vs 290X IIRC, performance was damn close between those 2.  PS4 was close to a 7850 which was way below those 2 flagship cards and had crappy Jaguar CPU.",amd_gpu
"Oh absolutely, I'm just saying there's 3 avenues of competition from AMD  - PS5, XSX, and PC. The GPUs in the consoles aren't going to be exactly the same as what's going to be out for the PC so I'm counting that as something Nvidia needs to show value against as well.",amd_gpu
"Fair. But consoles are rumored to be what, $500-600? That's still sinking the entire budget into just a GPU.",amd_gpu
"not right now, but with rdna2 why not? Wasn't a console marketed as a 8K capable?",amd_gpu
all the 10 people who bought it /s,amd_gpu
"Damn, next you're going to tell me a $20k engine is more powerful than a $20k car",amd_gpu
"I find it *amusing* that some people find 499$ for the entry card ""the budget option"".

Other people on this sub try to get a full build for 1080p low end gaming with a little more than that.",amd_gpu
"Because there were no new consoles coming out. Also, AMD is now getting a lot of money from the ryzen cpus, so now is the time to strike.",amd_gpu
"Zen 2, RDNA... seems the tide is changing.  Just wanted to say you shouldn't be surprised if the 3080 is taken on, at least in raw perf.",amd_gpu
"I didn't realize Intel had budgetary issues, my bad! You're right in that context.",amd_gpu
"DLSS 3.0 is supposed to improve upon the 2.0 technology and be compatible with all games supporting TAA. This paired with their current user base means they have a lot of data to further develop the software. 

I really want AMD to knock it our of the park with Navi 2, and by all accounts they should make some large leaps, but Nvidia just shifted their flagship down to 3080 and are making some serious claims against the gains over the 2080ti. Which seemed like the target for Big Navi. 

The consoles are promising, but the 5700xt was already based on 7nm. Ampere just went from 14 nm to 7nm, meaning there is likely more to be gained from the node shrink alone. 

The optimist in me sees a big gap between the 3080 and 3090, maybe this is where AMD can have a hit for $1000, which would then be responded to with a 3080 ti. It almost feels like Nvidia shifted the pricing and product stack down in anticipation of AMDs upcoming releases. 

Let’s hope we hear some big news soon from Lisa Su.",amd_gpu
"If Microsoft is leveraging it sure, and maybe AMD has had this in the works silently. 

Nvidia has also been partnering with brands for years working on self driving tech and this probably led to the development of their AI network. I know from experience that the more data the more advanced deep learning systems become. Nvidia has that base sample (DLSS) AMD have been able to evolve it with continued updates with additional data (DLSS 2.0). Time will continue to refine the system. 

A DLSS system would be huge for a console as it would help prolong the life of the hardware and prevent an overtake by pc performance so early. I think if they had a DLSS competitor they likely would have at least hinted at it with the console specs. That would be a big selling point, especially if MS designed it.",amd_gpu
Try $300. Maybe you can get someone that hasn't seen the Nvidia news yet.,amd_gpu
"2080 is over 20% faster https://tpucdn.com/review/amd-radeon-rx-5700-xt/images/relative-performance_3840-2160.png

Would make the 3080 double the speed of a 5700xt if you  believe its 70% faster than a 2080.",amd_gpu
"From the presentation - 3070 is on par or better than a 2080ti.

Plus we already know that 3080 is 30-50% better than 2080ti, and it costs 40% more than a 3070.",amd_gpu
well they claimed so at least and new cards have crazy FP32 tflops figures so that might be a part of why,amd_gpu
"Right, it would be one thing if one company just had raw performance and the other had all the nice to have software options but AMD is just getting beat down in both corners. AMD is going to have to go above abd beyond to compete.",amd_gpu
"Dude, just watch Digital Foundry's video, it tells you all you need to know in percentages, basically.",amd_gpu
"for now. would not be surprised for it or a non-proprietary replacement to be come standard in the next 5 years. we will see what the consoles pull out in this regard (maybe nothing until their refresh?).

this is the one Nvidia tech that doesn't reek of marketing bullshit. RTX, Hairworks (lmfao), etc. don't even come close to the impact that DLSS can have.",amd_gpu
">Upcoming Console/2080Ti

So the 2070 as in ps5 perf?",amd_gpu
290 was the last time I was impressed by an AMD gpu.,amd_gpu
700,amd_gpu
The RTX 3080 is 70% better than the RTX 2080FE and it sells for $700. The RTX3090 \*might get close to 90% for a bazillion dollars.,amd_gpu
"Considering the 3070 is an improved 2080 ti, that would put the 3060 - 2080 at what, $300-350? That's not impressive anymore.",amd_gpu
They are priced this way because of the new consoles. That’s it. The new consoles are so much closer to high end PCs that NVIDIA is competing with them.,amd_gpu
"I mean, they aren't proper separate cores architecturally anyway, so they can call them whatever the hell they want to. It's all marketing anyway.",amd_gpu
"Crippled? 

You have no idea what kind of an impact 4 vs 3 will make. You’re literally just making things up. 

Until benchmarks come out, no one will know. Realistically it will be a less than 10% difference, probably closer to 5%. 

SSD performance is also not a huge issue. In practice the difference between a standard ssd and a nvme ssd is so close that it usually doesn’t merit the price increase.",amd_gpu
I meant weaker gpus but aimed at the 1080p 60fps market. You can't make a 500 bucks gpu that is as powerful or more than 2080 ti,amd_gpu
Man I was agreeing with you.... OP can't speak properly,amd_gpu
So it was the drivers and not the gpu...,amd_gpu
Nope. GDDR6 only.,amd_gpu
I bet GDDR6x is nvidia exclusive.,amd_gpu
Not gonna help when the chip is slow and the drivers are hot garbage. I'd love for the day AMD makes something worth considering. But it just ain't happening it seems.,amd_gpu
I miss hbm2 memory being a thing in gpus,amd_gpu
3080 and 3090 are GDDDR6X 10Gb and 24Gb.,amd_gpu
"Honestly, I feel like everyone always focuses on the xx80 and above, but the real meat of the market is the xx70 and below.  If AMD can win there, like they did with the 5700 xt, they can win period.  It's a big *if* though.",amd_gpu
But hes GENUINELY scares guys!,amd_gpu
"Nvidia have already released transistor count and die size for GA102. From those you can calculate that transistor density of the GPU is 44.5MTr/mm^2.

On the flip side, transistor density of Navi10 is 41MTr/mm^2 if memory serves me correctly. Navi10 is well below the theoretical density for the HPC libs on N7, but that's a design choice on AMD's part.

No comment on RDNA2 transistor density yet. But the Series X shows that nothing has changed.",amd_gpu
The benchmarks!,amd_gpu
"Wait, what are my choices again?",amd_gpu
"Honestly, dude?  I've seen nVidia's business practices...

So I'm gonna have to go with random guy on reddit for this one.",amd_gpu
From my experience it's the random guy on the internet...,amd_gpu
"There are leaks from Samsung that prove it. It's also how Samsung does things, they've done it for some time",amd_gpu
tough call,amd_gpu
I'm not sure if I'd trust a graphics card for advice on judging between sources,amd_gpu
I mean I corrected my comment within 15 minutes after I rewatched the presentation?,amd_gpu
Pretty sure Ice Lake and Tiger Lake are legitimately 10nm.,amd_gpu
"Yeah, numbers haven't meant anything in the industry for a while. Intel 7nm should be quite a bit denser than TSMC N7, if it ever comes out.",amd_gpu
"Yes I know. Just laughing how there were ton of rumors about 7nm and 5nm and all that, and it ended up being 8nm anyway. A lot of commenters in different threads have been off the loop and saying it's 7nm, when it's not.",amd_gpu
Nvidia announced an hour ago in their reveal it is samsung 8nm all the way.,amd_gpu
I have never heard anyone outside of crypto mining make a graphics card decision based off power consumption.,amd_gpu
[deleted],amd_gpu
"That's fine if it's subjective, You can choose whichever temperature stat. 
Like you said T-junction will differ based on GPU model. Obviously different components will have different temps depending on functions. But I'd rather
choose the overall temps in benchmarks that makes an overall system ""hotter"". And objectively speaking In benchmarks (such as techpowerup), the 5700xt make an overall PC system hotter vs. a 2060s/2070s/2080s.",amd_gpu
"They were using a custom TSMC process before. It sounds more like Samsung cut them a sweet deal on a new custom process in order to get their business back from TSMC, after having lost it for RTX 20 series",amd_gpu
"""Just build a warehouse to manage stock or something, what can go wrong with that?""

And then the Crypto hype arrived.",amd_gpu
Thats a negative ghost rider.,amd_gpu
Intel performing a goatse on the core arch,amd_gpu
"Nvidia has been working with TSMC basically since they started making GPUs, dont listen to idiots like MLID making up stories. Nvidia realized TSMC was charging more and had no capacity left, so they went to samsung. 

Hopper (RTX 4000) will almost certainly be on TSMC 5nm, no other fab is even making 7nm rn with proper yields.",amd_gpu
Stop making up drama,amd_gpu
"Nvidia doesn’t build the chips themselves, but intel does, intel designs their own node and has fabs for it. Nvidia just throws money at TSMC/Samsung and use their existing node. This means while Intel can be stuck in R&D with 14nm, NVIDIA pays Samsung to use their 8nm",amd_gpu
"AMD and Nvidia buy all of their silicon from other companies, mainly Samsung and tsmc. Intel makes their own silicon chips, however they do buy when they need to. What happened to intel was that they had problems producing their 10nm node, while AMD was able to go to TSMCs 7nm node, leaving Intel behind AMD.

AMD and Nvidia are immune to the problems of having to manufacture their own silicon, making them immune to what happened to intel. 

However fab space for companies like TSMC is extremely competitive and probably expensive, intel doesn't have to fight for this space (in theory). 

Ups and downs of having your own fab. AMD and Nvidia are much smaller than Intel, so they can't make as expensive moves like making your own fab plant. I hope that helps!",amd_gpu
Amd actively got shot of theirs because it was technically so far behind TSMC. Seems like a great efficency on the face of it but if the R&D can't keep pace you end up with the products Amd was putting out a few years back.,amd_gpu
"Don’t think so. Costs and complexity to build and run fabs are skyrocketing. 

They might go custom nodes though like Nvidia.",amd_gpu
[deleted],amd_gpu
"RDNA2 can't even do RT and regular shading at the same time, their RT performance will be worse than Turing.

The advantage of that is that they are not ""wasting"" die space on RT therefore the GPUs will be cheaper for AMD to produce and cheaper for consumers to buy at the same non-RT performance.",amd_gpu
"I'm very aware that not many people like ""that cartoon game"" haha",amd_gpu
"So we've had 300% inflation in the last 5 years?

500 bucks used to be enough for a top of the line GPU and now it's more than triple that.",amd_gpu
That's what I was wondering. 300fps doesn't mean a thing on a 60hz monitor,amd_gpu
"Well, same here. Most of the time, overwatch runs just fine. But sometimes in the middle of a game, I have between 20 and 30 fps for a few seconds (like 5 or 10) or if I use alt+tab I have to reset the graphic card driver (alt+control+shift+b) because it seems like everything is at 60hz instead of 144hz

That never happened with the 2070 super I had for 3 weeks, only with my 5700xt",amd_gpu
Uh why not just turn up the setting?,amd_gpu
But those cars MSRP'd at the same price.,amd_gpu
Sarcastic quotes lol. Talk about reading into things.  Wait for benchmarks either way.,amd_gpu
Fidelity fx is amd's competing and better version,amd_gpu
"I've had AMD for nearly 10 years in a row, with the Radeon 6950 (biosmodded to unlock shaders and effectively turning it into a 6970). After that I got an r9 290 which I still use to this day. Now I may have had the occasional driver hiccup with a handful of beta/optional drivers but nothing a rollback couldn't fix or that wasn't fixed in the next release otherwise.

And by handful I literally mean I can count the occurances on one hand. Minor at best. So I count that as a great experience over a full decade. The 290 has also really delivered in terms of value over the past six years. I'm still able to play modern titles on high/ultra on 1080p from 30 to 60 fps depending on the type of title and the engine. 

Of course it struggles more now and 30fps is not a great target value maybe, and it may not be able to handle higher resolutions, but I'l be dammed if those ~400 bucks I spent back then didn't go a long way. The same thing goes for the value of that 6950 which I could just turn into a flagship model with a simple mod, for a midrange price.

Nothing but praise for AMD really. Hope they remain competitive with this new Nvidia offering on the horizon, because if they do I have no issues remaining on team red.",amd_gpu
"Are you using mesa drivers, or the pro drivers for VR? Part of my motivation for AMD is that it all ""just works"" with the mesa drivers (unless you buy day 1. You have to wait for the updates to come).

Also, are you running via xorg, or wayland+xwayland. I've seen there's little performance impact while running games via xwayland, but VR is a lot more latency sensitive.",amd_gpu
Nvidia will basically never have Linux parity with AMD in their drivers because a nice chunk of core functionality is 3rd-party copyrighted and patented.,amd_gpu
Try Pop OS,amd_gpu
I know a decent amount of people use Linux but I still feel like it's a way smaller portion of the consumer base for gaming GPUs than most people would think.,amd_gpu
"That's unusual, what card do you have?

My dev machine has a 1070 and I've had no issues with multimonitor, passing the GPU into docker containers, or running bare metal in blender. 

My personal rig has an r9 290 and it works pretty decent although you have to toggle freesync every boot and they don't support multi monitor with it at all!",amd_gpu
"Back in the day with xorg on an nvidia-only desktop, I found the nvidia drivers merely annoying (not being updated in time and losing graphics during kernel upgrades, for example. This is still a think, and happened this week for fedora/nvidia users upgrading to 5.8.4). But ~~multi-gpu~~ multi-monitor seemed to work fine at the time.

My last nvidia device was a dual-gpu laptop (intel + nvidia), which was a royal PITA. External ports were wired directly to the dGPU, and a lot of the software to manage all this was very early (and typically you had to follow instructions to muck-about with GL library swapping and LD_PRELOAD stuff iirc). Getting a display on an extenal screen required the dGPU to be on and rendering a framebuffer provided by the iGPU. I sold that laptop and haven't touched nvidia (or dual-gpu) since.",amd_gpu
Try Pop OS,amd_gpu
"Try Manjaro, it has a native utility for GPU packages and is arguably more user friendly than Ubuntu",amd_gpu
"Dude is THAT why I couldn't login anymore?! What?! It was a relatively fresh install so I said screw it and went to Manjaro. I never would have guessed my drivers kept me from logging in.

I would hit enter and then nothing. lol",amd_gpu
"On a completely unrelated topic, what is your Linux? Can it run fusion 360, SketchUp and some windows only programs now? I'm completely out of the news on Linux.",amd_gpu
"Just the announcement has obliterated the used market.  /r/hardwareswap has quite a few 2080tis being sold for $4-500 right now.

Yesterday they were about twice that.",amd_gpu
"TL;DR: I'm not upgrading and sticking with the Vega 56. The price for performance gain of a potential upgrade will need to be a lot better before I upgrade.

I got the Valve Index a few months ago. I found that I had to put some settings down in some games, and/or run at a slightly lower scaling factor to get good performance. TBH, that's fine.

I've played HL:Alyx, a Tonne of Beat Sabre, and a variety of other games without issue.

My recent motivation was caused by Project Cars 2. It seemed to stick to 45fps and use 50% reprojection. I could only get 90fps with literally every setting at it's lowest, and it looked like I'm playing on a PS1. Though after some reading and experimenting, I found that since it realizes it takes slightly longer than 11ms (1/90th of a second) to draw a frame, rather than try to draw as many as it can & end up with timing issues, it just draws every other frame, leading to a 50% reprojection rate. I still thought this was shit, and was trying to do whatever the VR equivilent of ""turn off vsync"" is.

After spending about two days fucking about with things, I found that most cards would have this issue, short of going to a top-shelf nvidia card.

So I turned off the stats, and just tried to play the game. Turns out, the method they're using to do predictable reprojection is actually not noticeable once I turned the stats off, and the game is just fine (and the immersion is still a better experience than whatever non-VR fps it was pushing to my 144Hz monitor)

While troubleshooting settings, I did find that some recent driver update appears to have decided to run my card at 150W (is that stock for a Vega56?), and therefore lower (stock?) clocks. [My card is rated at 210W](https://www.msi.com/Graphics-card/Radeon-RX-Vega-56-Air-Boost-8G-OC). So fixing that in the power settings got me a slight gain in performance improvements (though not enough to matter for Project Cars, specifically). I don't know how long it was at the lower settings, and I've been playing a lot of other VR titles without issues.

The other reason was the blower style cooler is loud. But that's not new, I've put up with it for a few years so far, and I'll stick with it. I'll never buy another blower again, though...",amd_gpu
"Are you currently using AMD? their windows drivers have been pretty fine since 2.4.2 (ie, since March). I know there were a lot of issues prior.",amd_gpu
"The `amdgpu` driver kind of changed things. Good opengl support, included in the kernel/mesa. So I can grab any liveusb and have accellerated graphics, wayland, whatever, right from the start. No mucking about with post-install drivers, blacklisting modules, shims that break during kernel upgrades, etc. Point to AMD.

The downside is because they're following the standard ""send it upstream and let distros package it"" model, that means day one support is a weak point. The code will be there, but your distro may not have an updated kernel or mesa. Point to Nvidia.",amd_gpu
"A quick google suggests that mesa is simply passed-through from Ubuntu, and anything more up-to-date requires a PPA.",amd_gpu
"You'd be better off upgrading the 1600 to a new APU if that's your angle, 1600 will probably have issues even running that game.",amd_gpu
"I haven't tried yet. My primary machine is an old (linux-only) Thinkpad, and the ryzen machine is mostly for games. Due to disk space issues (I only had a spare 128GB SSD for Linux), all my games are installed in Windows, currently.

I only really boot linux on the gaming machine when I want to run something CPU-intensive instead of doing it on my laptop.",amd_gpu
"> VR on AMD has a lot more reported problems with bugs and crashes

No VR stability issues on my Vega56 other than being a few years behind in performance. I doubt many indie devs are using one of these.

Even if AMD's new cards are only good enough, and not top-tier, I'm still more likely to buy it due to the linux support.",amd_gpu
"I might be. From what I've seen, the VII was really roughly equivalent to the 5700 xt for games, but better at compute tasks (which sometimes helps synthetic benchmarks). Looking up gaming benchmarks shows a very minimal performance difference.

Also, I thought the VII is discontinued now. For the same reason, I had left out other nvidia cards (the non-super 20xx cards).",amd_gpu
"Well and that's while they are moving to a new process node which is typically more costly. Unless Nvidia have got a great deal for the wafers, or the yields are very good. The die sizes look like they have shrank but they are still big.",amd_gpu
"The 3090 is a titan and it is still higher than the $1,200 it used to cost.",amd_gpu
"Honestly I found the super naming quite clear - I don't expect the average user to know what 'Ti' stands for whereas super is a clear 'this is better' naming scheme.

So long as they don't do BOTH I think either is fine though.",amd_gpu
"that's because no one actually bothered taking a look at turing sales. Huang *consistently* said that turing sales were poor, they were *never* going to raise prices above that this generation. the only reason people wanted higher prices is so that AMD could undercut nvidia more significantly, which is ridiculous.",amd_gpu
"Excellent! Always nice to see proof of suppositions. Rare to see.

I suspect amd get a better rate than the official one, though maybe not enough to offset all the difference.",amd_gpu
"And for $1500 it costs way less than a Titan normally would. So technically it's an amazing deal. 

Unfortunately because they are now marketing it as the 3090 and not ""Titan"", people equate it as the new 2080 Ti equivalent for Ampere, and saying they kept the jacked prices. Which is false and even Jensen clarified this during the presentation, saying it is replacing the Titan for Ampere. 

So long story short, the 3090 is actually a great price considering what youre getting.",amd_gpu
They put that into amd stock instead.,amd_gpu
I dont think you have idea how are people living in poor states around the world,amd_gpu
"> Everyone was hit by this pandemic. From Doctors and engineers to black jack dealers.

No they don't. I have a job that lets me work from home so financially nothing happened to me. This isn't the case for everyone",amd_gpu
Layoffs and furloughs have disproportionately affected lower income workers so far,amd_gpu
"True true, sorta like the 2080ti and rtx Titan. I suppose they've been fused.",amd_gpu
Or people that need the performance and aren't playing games all day long.,amd_gpu
"I mean I can run pong at 1000fps.

Let's be real here. None of the cards of the current generation are doing 8K native/60fps without multi-GPU. The processing power isn't there for AAA games and i/o is 1/2 that of a console.",amd_gpu
what sense has to do with any of that? If somebody can easily afford that card that means they doesn't have much sense?,amd_gpu
"The more money than sense part is debatable. 

If you're pulling in 700k a year and love playing games (think 3 hours/day average over 2 years) it comes out to under $2/hr. It might be an extra $1/hr more than some other option but compared to most other things the price is very reasonable. 


How do you think Nvidia priced this? They probably checked the effective cost of other things high earners who like games did and decided it was still way cheaper than building a drone, 3d printing stuff, audio gear, etc.",amd_gpu
"Well, it would fit right in for the Microsoft Flight Sim crowd.",amd_gpu
"$2500 but yes, I believe you're right",amd_gpu
That's what they say to get you to accept a higher price tag.,amd_gpu
Almost a year. Ya I remember the yearly high end refreshes too =(,amd_gpu
It launched at $600. I bought both on launch day lol.  You may be thinking of the 1080 FE which did launch for $100 more.,amd_gpu
"the 3080 ti will be 900 if it comes out, I can pretty much guarantee",amd_gpu
"While I agree. Most shareholders don't actually have the attention span to care about future revenue. They want to see a quick return, otherwise they sell their stock and just move onto the next hot thing.",amd_gpu
"You could even argue that Nvidia was forced to drop prices because the consoles were so competitive. These cards would have been an utter laughing stock if they weren't 80%+ faster than the consoles, considering what Nvidia is charging for them.",amd_gpu
It certainly will. If you're going to use vr or want to game on 4k resolution the 10GB of the 3080 will become a bottleneck very fast. In FS2020 I can already max out my 11GB of the 1080 Ti on WQHD resolution. It actually screams for a super or Ti version with 20GB and a Ti with probably the 3090 chip. The gap is just too large. I guess depending on what AMD does they can react very fast,amd_gpu
He isn't referring to a company ran by intelligent people. He's referring to Intel.,amd_gpu
"No actually I think he's right, even by your explanation. Smart people can make stupid decisions. That's why INT and WIS are two different stats

https://www.cvedetails.com/vulnerability-list/vendor_id-238/Intel.html

https://www.cvedetails.com/vulnerability-list/vendor_id-7043/AMD.html",amd_gpu
Did the Mongols want to exterminate races though? I thought Gengis Khan just wanted more fucking land and power etc.,amd_gpu
"This is absurd. The Nazis literally planned on exterminating the Slavs to make room for the Aryan race to settle Eastern Europe. 

The Mongols desired to rule over the existing people living in any region, at no point did they intend to exterminate the Chinese or the Muslims. 

In that way the Mongols weren't even as bad as the European/American invaders of North America that displaced the Native Americans into reservations and settled the lands for themselves.

edit. I can see the future is really fucked. Standing up for Nazis is ok in 2020.",amd_gpu
"Ha, I wouldn't know.",amd_gpu
The memory in the Xbox is Gddr6 though and it works as both ram and vram.,amd_gpu
[deleted],amd_gpu
Yah.. plenty have said that.. no need to fix it.,amd_gpu
Don't see why the 3070 which is faster than a 2080ti can't last 6 years,amd_gpu
"Buy 3090 then, I own equal amounts of both stocks, I really don't care.",amd_gpu
"It seems like you're forgetting about DLSS, which AMD has no answer for and will make it hard to compete with the 3070",amd_gpu
"Exactly. People who do actual real world work with their PCs aren't all that concerned about brand loyalty. They're concerned with what hardware and software options they get and how that contributes to their workflow. 

Nobody who works in machine learning, coding, compiling, or AI is sitting around waiting for RDNA2 because they ""want to support the underdog."" They get Nvidia because it actually has the tools they need.",amd_gpu
"Oddly specific.

Anyways, Native also looks bad on sharp edges, even with SSAA 4X while DLSS implement TAA like anti aliasing but better.",amd_gpu
"Looking at the interpretation of a NN, I still think it is a performance cheat more than a feature. It is very clever though.",amd_gpu
"Yeah Quake II RTX ran at a whopping 8 FPS on my 1070, but at a 60-70 FPS on my 2070S.",amd_gpu
Thanks!,amd_gpu
"Cheers 😀
Looking forward to grabbing a 3050/amd equivalent next year!",amd_gpu
"Not quite. The drive for GPU compute in edge-computing, datacenter, and automotives is exploding. NVIDIA needs to keep up with computational demand in those segments. The consumer cards are trickled down enterprise designs.

In many ways NVIDIA is its own competitor, but it is also competing against Google's TPU, Intel's FPGAs and Xe, and AMDs Instinct cards.

Ampere is a jack-of-all-trades uarch, from Orin (cars), to Quadro/""not-Tesla-anymore"" (workstations, datacenter), to GeForce (consumers).

&#x200B;

Intel doesn't really have anyone else to compete against on the x86 market. It's AMD or bust. They had way more room to be lazy than NVIDIA does.",amd_gpu
"Not so much because of AMD. But generally because of the consoles. They over good performance in cheap hardware. The specs for the next gen PS5 and Xbox sound fabulous for the price. Thus also the timing for the announcement. It's not about being afraid of losing to AMD as they are afraid that if GPU are so expensive like the 2000 series where people would be shifting to different platforms.

Nvidia's only competitor is not just AMD.",amd_gpu
And the prices will start going up again. Even these prices are too much in comparison to the old days.,amd_gpu
"yeah because they stop their engineering department from working once they see they have no competition huh?

All of these new tech isnt solely for gaming, did u miss the May Keynote?

wtf kind of stupid argument is this",amd_gpu
"AMD is not gonna be gone even if they have a bad generation. 

I think the performance of the next gen consoles tells us AMD is gonna at least hold their own and not get entirely destroyed by Nvidia.",amd_gpu
"Lul, you just got a skylake, enjoy, more cores, more power hungry than ever, Ryzen is already superior in IPC and way more power efficiente and better at multi tasking, true, intel is still ahead in gaming for a reason, games still being reliant on clock speed and intel able to 5.x GHz to get a ""bit"" more fps, just remember you have the same performance as 9900k because it's still skylake , came out this year, and with Ryzen 4000x on the way this year too intel is probably gonna get smoked

I'm not trying to be rude, it's not your fault, but if you really think intel is innovating or improving you're being delusional, if it wasn't for Ryzen we would probably still be stuck with 4/8 and videos with ""4 cores is still fine for gaming""",amd_gpu
Imagine if AMD releases a card more powerful than the 3080? Considering the 3090 is the new titan that would mean AMD takes the performance crown... at least until Supers/tis launch.,amd_gpu
"Obviously they can compete with the 3070. The 5700xt overclocked is almost 2080 level. So whatever big Navi is, will obviously be at least 2080 ti level. I hope they put out a gpu that will be 3070 level but for even cheaper. Would be amazing. Not sure if theyl match 3080 though",amd_gpu
The most perfect scenario is lower price with performance in between 3070 and 3080 like 5700XT. I don't need them to compete with 3090 or titan. I never buy highest end of a GPU anyway. Look at 2080Ti now.,amd_gpu
Just look at the Steam survey. The most popular card is a frigging 1060. The most popular AMD card is RX 580. The loudest and most popular people are always playing with their 2080Ti's and 3090s but most people aren't in the market for those.,amd_gpu
"Everything you say is true to those super observant, but I think in order for a company to get more market share they need to compete at the top so they aren't seen as the budget option. Look how popular Intel still is with system builders and laptops for instance. As long as the general consumer thinks Nvidia graphics > AMD graphics it will hurt them.",amd_gpu
"> usually more people wait at least for AIB cards

It's gonna be tough for AIBs this generation. The stock cooling looks impressive (in terms of performance) and there's no bullshit ""founder's edition"" pricing either. 

If anything is gonna stop Nvidia's landslide is that there won't be enough stock of the 3070 because they will sell like hotcakes.",amd_gpu
[deleted],amd_gpu
"That was the case before nvidia started hoarding all the best binned chips for founders edition cards. With Turing, Founders is a top binned chip with a decent non-blower cooler that could OC past most AIB cards in spite of their better coolers and higher prices.

I suspect Ampere will just up the ante with even better stock cooling on best binned Founders Edition cards. AMD really needs to step up their ""reference"" design game.",amd_gpu
"AIB is releasing in a month already.  AMD has till mid October at the latest to announce something concrete but even then, it's probably too late.  I don't see any current 2080/2090 owners waiting patiently around for big Navi release to make their decision.  AMD will probably compete in the 1080p/1440p market again like last generation.",amd_gpu
Aib are releasing thr same day or close to it,amd_gpu
It would be stupid to lose a good chunk of people buying the FE model.. They have to do something before the 17th,amd_gpu
"Lots of times it is because they can't even find them to buy, release day quantities of these things are usually low on purpose to build up sell out hype.  AMD just has to hit at the right time if they do have something to compete.",amd_gpu
AIB cards are coming out on release for the 30xx series. They did for the 20xx series as well. There's no reason for waiting.,amd_gpu
"Because of the inflated price on the 3090, I will wait for a 3080 ti with more memory. Hopefully AMD will create some competition.",amd_gpu
AIB?,amd_gpu
AIB cards are likely expected to launch along side the FE models. ASUS has their 3080 and 3090 series listed for September so I suspect they're for the respective launch dates and I'm sure others are planning the same.,amd_gpu
"Yup, I'm definitely waiting for AIB cards. 

Not a fan of the Nvidia reference design pushing hot air into my cpu cooler considering I have an air cooled 3900x. It won't be good for my mp600 drive either because it sits above that fan as well.

This will also give reviewers like GN time to release tests and benchmarks / AMD to release their gpus / comparison videos.",amd_gpu
"I've waited for example my Sapphire Nitro + to be released to jump into the train, that was months after the first 5700 XT founder edition one year ago.
I didn't want that crappy founder edition anyways, and I don't regret my choice, the 5700 xt Nitro + is a beast for it's price, arguably the best custom you can find.",amd_gpu
"It is stupid to buy on release cause prices are high and it is as sure as death that Nvidia will ""surprise"" everyone during the AMD RDNA launch. New 3xxx versions with more VRAM , more clock speed , price drops or at least a game bundle.",amd_gpu
"You should check /r/pcgaming , lots of fanbois are creaming their pants rn",amd_gpu
And? All the late buyers will want this thing.,amd_gpu
its consoles.....they are worried about loosing ppl to console like they did with the \~$200 XBoxOneS during the last recession.,amd_gpu
"Worst case is out of fear.

Anyhow, 10nm rebranded as 8nm, 2.5 times 2080Ti CU cores... how big is that thing??? Well, regardless, 1.5k bucks, who cares.

But then, 8k CUs, ok, scary power consumption, but $700 only? Hm, for big that is how big???

Now, NV's claims bout performance are of course overblown, but 3080 is too good for the named price regardless.",amd_gpu
">to lower the prices that much

Oh my fucking god, they didn't LOWER the prices at all! lol

They are the same prices as Turing, which were a price hike!!!

Are people really that blind?  I hate to do the whole ""Everybody is stupid except me"", but jesus christ.",amd_gpu
"The horrible 20 series pricing caused them to have lower sales and Jenson said last quarter was a punch to the gut.
The prices were high as it was basically RTX beta. 1st gen tech is always pricey. Add to that some bad binning chips, them still recovering from the crypto hype and sprinkle a bit of corporate greed and you get those prices.

With Ampere they have better binned chips with Samsung 8n(just an enhanced 10n) and 2nd gen RTX plus some big architecture advancements. Add to that them not wanting to be like Intel and sitting on their asses and pricing competitively along with wanting more sales compared to 20 series, limiting NVlink/SLI to Titan/3090 and wanting to crush AMD down to the atom we get the reasonable priced 3000 series 

Don't expect the 4000 to be as good performance wise nor price wise tho.",amd_gpu
"The thing is, consoles are generally sold at a loss for the first couple years. MS/Sony know that they'll make more than their losses back through accessory/game sales over the lifetime of the console so they're willing to eat that loss up front.",amd_gpu
"I think it is TSMC that nvidia is worried about, they messed up by trying to screw them and now have to use Samsungs inferior process, but they fully know what TSMC 7nm is able to do.",amd_gpu
"unrelated but uh, how do you have a 5700xt and a 480  
Different computers? or can you somehow put both on the same system",amd_gpu
"It's in their best interests to keep AMD 's Radeon Group alive. Regardless of whether or not they've made moves to kill them in anyway will be fuel for Anti-trust suits and fines. And considering how the EU is actively pushingfor domestic silicon. A single 'hostile' US corp owning the only option will be kicked in the teeth, as Google, Facebook, and Apple have been.",amd_gpu
"I can't find anything on MS being legally required to do it, just that if apple would have died, MS could have faced antitrust lawsuits.",amd_gpu
"to be fair that was down to driver issues though, I see so many people say that they wanted to go AMD as it is so much better value than Nvidia but chose not to because of the driver issues, even after they where supposedly fixed, it is ridiculous.",amd_gpu
"When did they try that and lose market share?

People like to repay this hot it isn't actually true.",amd_gpu
">  They e spent the entire RX 5000 series launching different mid-range and low-end cards. Nobody is buying them.

i'll tell you why nobody is buying them (at least in my country) - because they are not really competitive here. even if we set aside all the software problems, AMD cards were basically within few percent price difference with competing nvidia cards (5700xt with similar price to 2070 super, etc) without all the ""new jazz"" of RTX.",amd_gpu
"Dude the drivers on the 5700xt still suck. I’m upgrading to a 3080 and I own AMD stock. If AMD beats a 3080 for $200 I might consider them, but my current experience with them is pretty sour.",amd_gpu
"RX 5700 was priced the same as RTX 2060 while not having any ray-tracing capabilities (you know, the revolutionary tech that was supposed to justify Nvidia's high pricing on RTX cards) or DLSS 2.0 and being half a year late. I'd hardly call that competing with pricing.",amd_gpu
Then why do I have a hard time finding them on the market lately when I want to buy tons of them?,amd_gpu
"> Nobody is buying them.

I was curious so I went and checked what the most popular graphics cards were on the price aggregators in Norway.

Gigabyte Gaming 5700 XT is at #1. Granted there are only two different 5700 XT SKUs in the top 10. But to say nobody is buying them is hogwash, AMD seems to have at least 40% this time around, and Norway is a traditionally very Nvidia-skewed market.

Nobody seems to be buying 5600 XTs though. Completely outside of top 30. First 5600 XT shows up at #32 *behind* the Turing Titan. **The Turing Titan**.",amd_gpu
"My friend got a 5700 shortly after launch for just $280, He's super happy with it. They're a great value. I think their loss of market share can more be attributed to Nvidia's marketing with RTX. ""If I'm going to spend XXX I might as well get a card that can ray-trace"". That being said I have an RTX 2060, and I have yet to play a game  that convinces me the FPS loss from RTX is worth it (and I'm Abit of a graphics whore)",amd_gpu
"I'm not buying Nvidia to ""show AMD a lesson"". I'm *probably* going to be buying Nvidia because I need a new GPU and they've got what fits what I want in terms of price/performance.",amd_gpu
That's a great reason to but AMD cards but it's not one that the majority of consumers share.,amd_gpu
Great! Go for it. If that's what's important to you then you should absolutely spend your money with them.,amd_gpu
"Lol, do not vote with your wallet. Let the other people do that. If Nvidia is the better product for you, just get it. You're one or two or 5 purchase's won't help anyone, nor can you change what other people buy.",amd_gpu
"I'm going to buy the card that fits my needs for price/performance, be that AMD, Intel, or Nvidia. I'm shocked that anyone would do otherwise just to prop a company up.",amd_gpu
Great! Go for it! I don't see why anyone is arguing about this. If you see something that you want -- you should buy it. The company that slaps their name on it shouldn't matter all that much,amd_gpu
[deleted],amd_gpu
"True, Xe cannot be taken seriously until they are out and about.",amd_gpu
[deleted],amd_gpu
"If you look at the CPU market as a whole AMD really isn't yet.. They are very competitive in the enthusiast market segment. They are growing in the datacenter market, but the datacenter market is slow to change. However, the enthusiast/pc builder market isn't that big in comparison to ultrabooks/tablets/laptop/mobile markets where intel still does really well.

We are just now we are seeing viable mobile CPU from AMD and if they can actually get mainstream consumers to switch over to an AMD CPU has yet to be seen. As a lot of mainstream people who buy laptops/ultrabooks/tablets/etc have been trained to look for intel and the i5 and i7 designations. So that onus is on AMD to educate those consumers.

I hope AMD can be competitive on all fronts as its good for consumers. However, i'm not going to buy an AMD product just because its AMD.  I bought a Ryzen 3700x because they proved to me it was a more than a viable alternative. They have yet to do that in other market segments and that's on them to win those battles and educate those consumers.",amd_gpu
"Nonsense, cpu share more than doubled since Zen. Gpu share slowly declining.",amd_gpu
"wait, skip, go to console, buy used card and so on. We could almost be certain that amd gonna rock the console scene.",amd_gpu
Some of us don't want to game in a sauna,amd_gpu
"Generally, you'd want to run it between 50% and 80% for max efficiency. Hitting the wall for the PSU isn't exactly a good idea. Torture anything at full load with some power spikes, not a good thing.",amd_gpu
"Yeah, no. That is how you kill your PCs. It can handle a 300w GPU, but for how long?",amd_gpu
Haha same boat here got my hx1200 v2 for 80 euros,amd_gpu
I have a PSU that can handle the 350 watts no big deal. But A) Power Bill and B) I dont need an space heater in middle east,amd_gpu
"how can you trust a secondhand psu though?  
I feel like that's the one thing you should never get secondhand / used.  


Was I just bamboozled by the media / youtubers or something? Any thoughts?",amd_gpu
"ah, I wrote a comment before seeing this.
Would you say Nvidia driver support is better than AMD for linux?
I am planning to switch to NVIDIA, but am worried about the support. Are there workarounds you need to use to install Nvida cards or is it a pretty standard install?",amd_gpu
"For one, the NVidia drivers are closed source.  Linux is a FOSS system and it's tarnished by proprietary drivers.  The NVidia proprietary drivers don't interact with the Linux kernel or desktop environment in the same way as the open source drivers, so you end up having to use NVidia's proprietary control panel to tweak some things.  The NVidia proprietary driver doesn't support all the things necessary for Wayland, and for a long time Gallium Nine was the best way to play D3D9 games which only worked on FOSS drivers.  It also seems to crash in some multi-monitor scenarios (it hates my TV).

To top it off, trying to set up NVidia Optimus configurations is absolute hell on most distros.  With AMD/Intel you can just use DRI_PRIME=1 and it will work no questions asked, but offloading to an NVidia GPU is a nightmare because they had to hack up their own proprietary PRIME implementation because they're stubborn assholes who refuse to join AMD and Intel in making good open drivers that integrate well with the OS.

They also literally go out of their way to restrict the development of open source drivers.  Digitally signed firmware that they only ship with their proprietary drivers allows the cards to clock up to their high performance level while the table scraps of firmware they hand out for FOSS driver development are locked to boot clocks which means even if Nouveau had a pristine compiler it would still perform like garbage because it can't clock the GPU to a useful level.

AMD had some rough years on Linux, and when I first got into Linux (2008) ATI cards were practically unusable, but AMD actually focused on FOSS driver development for 10 years and now you can just drop in any AMD card from the past 10 years or so and it will just work with minimal issues, with Wayland, on fully open source software that uses the standardized kernel, X.org, Mesa, and Wayland interfaces.",amd_gpu
"In that case, why not just pull Linux support instead of throwing a buggy port of their Windows driver up on their website and acting like they're doing us a favor?

Perhaps it might have something to do with the fact that HPC, which is pretty much entirely Linux nowadays, is a critical part of their business? I think a lot of people forget that NVIDIA is *not* a gaming company. Sure, it's a very large part of their business, but HPC is more important to them. They cannot afford to lose it.",amd_gpu
[k](https://itsfoss.com/linux-runs-top-supercomputers/),amd_gpu
"Which tools, exactly?",amd_gpu
"Like *what*? Windows rules the world because of *enterprise software*, not the OS itself. (And, just, the self-reinforcing fact that it's the most popular OS by a country mile.)",amd_gpu
"Also crypto miners drove prices for gpus way up a while ago, hasn’t really recovered",amd_gpu
"Yeah but die size and yields aren't our concerns.

Just what you get for the money and it has been slipping every generation.",amd_gpu
What graphics settings?,amd_gpu
"RDNA 2 is said to have 70% the perf/watt, and the RDNA arch can scale very well.",amd_gpu
"Yes, that's the same graph I'm referencing as well. Where are you getting 60% from? I showed you my calculation based on the same graph but I'm not seeing how you're getting 60%?",amd_gpu
"I'd imagine you don't need lots of man power, just a few very smart people.",amd_gpu
"It’s not just upsampling. In some cases, it adds detail that isn’t even there in native 4K (see Digital Foundry’s analysis on the Death Stranding PC port).",amd_gpu
"I think you don't even have a minute understanding of what a tensor core does.

And if you somehow do, what you just said comes across even sillier.",amd_gpu
"Can't say anything bad about DLSS man, this is the second coming of christ for some people here even though it's clearly a upscaling method with the problems upscaling brings like artifacts and lower image quality.",amd_gpu
"So..big math time..the 2080ti is 20% faster than a 2080. 3080 is 60-80% faster than a 2080. So if the 2080 gets 100fps, the 3080 gets 160-180fps and the 2080ti 120. This mean that the 3080 is 30-50% faster than the 2080ti (40-60 fps difference)..of the rumored big navi can get up to 2080ti + 50% we have an amd 3080. The only thing is..are amd so stupid to launch another halo product with only reference crappy design leaving the custom 3080 to sell like hotcakes aka 2080 vs Radeon vii or will they launch a proper real product with better aibs designs? I hope it's the latter, or I'm switching back to nvidia.",amd_gpu
"Marketing is always an 'if', 'when'..",amd_gpu
"Oddly for me, I've had far less issues with AMD than Nvidia for some reason and that is through numerous cards (650, 960, 970, RX380, Vega 64). I honestly can't be bothered with raytracing either since I want to push higher framerates instead so if AMD comes out with something at a far better value, that'll take it for me already.",amd_gpu
AMD needs to either offer a DLSS 2.0 equivalent or 3000 series Ray Tracing performance at a lower price to be competitive.,amd_gpu
"I use Linux. On that side, Nvidia drivers are barely functioning garbage, while AMD drivers are rock solid.",amd_gpu
"Unfortunately, same here. On the bright side Zen3 is 100% solid. We can still be team red, we just might not be 100% team red like we wanted.",amd_gpu
"The Hardware was great .. RTG drivers as usual totally let the hardware down.

Don't blame the hardware it wasn't at fault.

AMD knows their drivers stink the huge improvements they have made show they are trying to get their software shit together.",amd_gpu
I own a 5700xt and that card is fucking excellent. It could have similar performance to a 2070 Super for significantly less. The problem was AMD drivers were problematic for a lot of people.,amd_gpu
"To be fair, Navi wasn't that much cheaper than Turing.",amd_gpu
"Mate .. judging from how many anti DLSS replies ive gotten im inclined to believe some die hards would buy AMD even if they came in with HD 4890 levels of performance just to spite nVidia.

I like what nVidia is doing with DLSS and believe that its the future for high resolution gaming without GPU crushing performance levels required.

Throwing more silicon at the problem isn't solving it and GPUs are not getting hugely faster so they need better more efficient ways of solving the problem that dont require bigger bits of silicon. (GPUs have hit the same TDP walls CPUs have, they cant get any bigger or faster due to heat and power requirements)",amd_gpu
"RX 480 here. I've bought my card for $225 nearly 4 years ago. If I spent $225 right now on an AMD card, I would only get a 12% performance improvement.",amd_gpu
"Hopefully. Well I bought my 580 for 100€, I guess I won't be getting such a good deal any time soon. But I am willing to spend 200-300€ for 5700/xt. I just want something to keep playing 1080p @100+fps. :)",amd_gpu
"Typo, I fixed it, thanks.",amd_gpu
He meant 2080 which is what Richard said. Watching the video right now.,amd_gpu
"During tomb raider, you could see an FPS counter on the screen.  But for comparison, % is just easier.  

I highly doubt an independent group like Digital Foundry is somehow conspiring with Nvidia to fake their performance numbers. They would be risking their channel's reputation to put up a false video only to be disproven a few weeks later? Doesn't make any sense...",amd_gpu
Its not on by default so I dont think this is something youll have to ever worry about for reviews but where it can be used it should be included as part of the review.,amd_gpu
Tbh I think calling DLSS “upscaling” is a bit misleading. Technically it is but it looks a gazillion times better than any upscaling that’s been done in the past. It’s not like a 720p picture on a 1440p monitor or something.,amd_gpu
Shout out to my 8600 GTS. Good times with that little guy.,amd_gpu
"8800gt was my first ever build, mind blowing value",amd_gpu
It was an amazing card.,amd_gpu
I had a single slot gts 450,amd_gpu
Future is going to be fun if Holodecks are as wonky as they are in Star Trek series.,amd_gpu
"> RTX 8090 TI-me machine launching September 2034, according to my sources

A big crowd turned up, only to learn that the Ti-me machine could only go back in time, more specifically to *Windows me*",amd_gpu
"The last line about their GPU bringing those things to you wasn't that bad... but I was too busy laughing about the first part with holodeck to pay attention to it, so it fell flat.",amd_gpu
"I thought that was dialogue pretty cringe too, but it seems like a lot of people liked it from the votes.",amd_gpu
"agreed, holodecks sure, transporters and time machines? dude are you on lsd?",amd_gpu
"Why would they release any previous titan when they previously had Ti versions every gen?

Jensen specifically said the 3090 was a Titan replacement.",amd_gpu
"I mean maybe. It's all speculation. As much as my claim of 7nm Samsung.

7nm EUV Samsung IS full 7nm. 8nm Samsung is fairly garbage in comparison.

I'm sure nvidia would be fine with Samsung or TSMC 7nm given that fact.",amd_gpu
"Shitty AMD drivers and issues.

Name a more iconic duo.

https://www.pcgamesn.com/amd/radeon-big-navi-driver-issues-fix?amp

I love the performance of the G14, but even several months after launch the drivers are still garbage. Go browse the subreddit.",amd_gpu
"Oh yeah, I guess I'm really Bimpson.",amd_gpu
">Heh. Step the pricing down?
>
>The flagship card is $1,500.

While I agree its technically the flagship, its a titan with a less confusing name. And as you've said down below, marketing.

>That's $300 **more** than the 2080 Ti.

Well, yeah, and its $1000 less than the Titan RTX it replaces

There will (presumably) be a 3080s refresh to replace the 2080ti.

>I don't care what nomenclature Nvidia uses, it's a bald fact that they're releasing their top Ampere gaming GPU for substantially *more* than they did last gen. In the midst of a global pandemic. 

No, its $1000 less. It was absurdly priced last gen though

>It's so brazen I'm laughing. Laughing nervously, because sweet baby Jesus we could really use some competition from AMD right about **now.**

Oh yeah im still going to wait for AMD to fire a shot or two.

If the 3070 performs real-world, anything like its claimed (2080ti level), thats a compelling proposition and will take some work to beat...",amd_gpu
"They said that thing is a Titan replacement, and it is meant more professional usage. Obviously tons of games that can afford it will buy it, just like people bought Titans, but they are't meant for gaming.

That being said, that thing has x2 the amount of RAM of the 3080, and can apparently play games at 8k at 60fps, which is insane.   


In any case, 2080ti performance (probably a little better) for $500 is not bad, although I wish it was $400. Maybe AMD will make that happen ;)",amd_gpu
"The 90 does appear to be their Titan Replacement this year. 

Or that's how they're trying to push It.",amd_gpu
Hah true,amd_gpu
"
>Anyway, couple that RTX maturity with using the cheaper 8nm samsung process 

That was surprising to me tbh, see how it plays out",amd_gpu
"People have very short memories/attention-spans.

You'll find all the people who remember are people interested/immersed/it's their hobby, so keep track of this stuff.

And everyone else is casual/normal/busy/whatever.

This generally applies to everything in life, not just GPUs.",amd_gpu
Or the 1070 being same performance as 980ti?,amd_gpu
I think we should wait a bit. my discord server had a bunch of morons freaking out about *omg AMD ded holy shit* and a few hours later they were more sane and realizing that Nvidia did a whole lot of smoke and mirrors.,amd_gpu
">Like when the $330 970 replaced the outgoing *$1000 Titan*?

Fixed that for you.

Shit, I dont even expect to see 970-esque pricing again, as amazing as that *actually* was.  

Even back to the standard $400 pricetag would have been great.  But nope, now $500 for the x70 cards is the bargain of a century. smh",amd_gpu
"Gotta be honest though chief, I miss the fact that I could buy my 1080 for $505 in 2016...",amd_gpu
"You are still in 2014 it seems. If someone told you 6 months ago that you could get an rtx 2080 ti for 499 you'd bought it in heartbeat. Of course, that is assuming the 3070 is faster than a 2080 ti.",amd_gpu
"How efficient can it really be, when AMD claims the new generation is 50% more efficient? And at the end of the day, the performance / $ compared to AMD's own 480, 580 series is atrocious. 

That's why those Navi cards were epic failures because they offered shitty performance / $. AMD thought they could get away with it riding the Ryzen bandwagon, but people aren't stupid.",amd_gpu
Either that or to finally stomp AMD while they are down.,amd_gpu
"Why would I buy a garbage AMD card? I'm not loyal to AMD because AMD isn't loyal to me. I'm loyal to my wallet. If AMD gives me 3070 performance for 400$, I'll buy the AMD card, if they offer me 98% of 3070 for 480$, ofc I'm gonna buy nVidia, what do you expect?",amd_gpu
Real question as someone who bought a 5700XT in August.  What is the correct corollary to the statement you made? Should you just wait or wait?,amd_gpu
https://www.evga.com/support/stepup/,amd_gpu
Duh.,amd_gpu
"As someone that was looking into the Unreal engine a few months ago that isn't a fair comparison to other games. Epic Games test runs new Unreal engine features on Fortnite and they have Unreal engine 5 coming out early next year with massive improvements all across the board including performance. If there's some special Nvidia on top of that for Unreal engine, it wouldn't be a fair reflection of how the GPU would run on other engines.",amd_gpu
"I sold my 2080ti for $950... I paid 920 for it last year. Ofc im buying a 3080 for $699.  

Its a win/win",amd_gpu
One can always ride they hype without ordering things at launch. I too will wait for benchmarks.,amd_gpu
"Nvidia's stock jumped around 10% from Friday to Tuesday. Yeah, people were freaking the hell out.",amd_gpu
Hopefully we see similar improvements on AMDs side of things.,amd_gpu
"Somebody in the NVIDIA subreddit confirmed RT was on. And given that the focus of the stream was on ray tracing I'd be inclined to agree, it makes sense they'd want to show off the ray-tracing performance. The fact that they left it vague seems intentional to me to give people the impression that it's a flat 2x increase in performance no matter what even if it's only 2x in one specific scenario. Seems like it's the typical marketing stuff. 

If I'm wrong then great, a real 2x performance increase in a generation is unprecedented but I'm going to wait for benchmarks to be safe.",amd_gpu
Its specified on nvidia website under individual cards (eg 3080) under performance tab.,amd_gpu
they have more tensor performance so they can do the upscale more quickly,amd_gpu
"Hmm actually it's [exactly double](https://www.anandtech.com/show/16057/nvidia-announces-the-geforce-rtx-30-series-ampere-for-gaming-starting-with-rtx-3080-rtx-3090). There are definitely diminishing returns on cuda cores/performance, but you're right, it seems smaller than expected.  Cuda cores must just not be the main bottleneck.

What I find odd is that they keep on talking about \~1.9x more efficiency. If that were true, the card should have the same TDP as a 2080 and produce 90% more performance.  Assuming a 3080 is 90% faster than a 2080 (debatable), it still clearly uses 100W more than a 2080, so those efficiency claims are bs.  Or looking at it another way, they should be able to get 2080 ti performance for half the power.  2070 gets 2080 ti performance, but the TDP is only 30W less, or 15% less power, a far cry from 50%.",amd_gpu
"Oh, my bad, I thought it was the FP16 number...",amd_gpu
There is a difference between waiting 25 months and waiting only 3 months. Especially if you are going to spend $1200.,amd_gpu
I guess people just got to steal those high end GPUs then? /s,amd_gpu
[deleted],amd_gpu
Lol yeah,amd_gpu
[deleted],amd_gpu
">Sharply? Previous gen was so overpriced that in comparison this seems cheap is what you mean.

Yeah sharply compared to the 2000

If theyre offering $1200 last gen card performance for $499.",amd_gpu
"Yeah, they literally called out Pascal owners by name. And you know what, as a Pascal (1070) owner I'm ready for that 3080.",amd_gpu
True,amd_gpu
"Yep, pretty much this. I am still on a gtx 980 as I only play in 1080p. Still is decent enough. Had no incentive for the last two generations.",amd_gpu
There's also a non-trivial number of gamers who have G-Sync monitors that aren't fully compatible with Radeon GPUs. You lose the adaptive refresh feature that is the whole point of buying such a display.,amd_gpu
"This right here. The pricing is in response to nvidia themselves, not AMDs still unknown products.",amd_gpu
">Nvidia being scared is what brought us 1080 ti at that pricepoint. Vega 64 hype lul

Tbf Vega64 wasn't bad with some tweaking

Just miners made sure no one could buy one to game on",amd_gpu
">Morelikely because turing was way too overpriced. retardly overpriced ""RTX ON""

But now no memes :(",amd_gpu
">There is a reason - consoles. Nvidia competes here with people that will consider ""PC or new generation console"", not ""Nvidia or AMD"".

Given AMD is whats making the new consoles that comparison though?",amd_gpu
"Not really, if you bought it 2 years ago and sold it one month ago you would have barely lost any money, it was an amazing deal.",amd_gpu
Well one guy in this thread actually made money reselling his a few weeks ago lol.,amd_gpu
Lol,amd_gpu
Guess I'm a genius /s,amd_gpu
">Here is a benchmark of the 3080 from digital foundry https://www.youtube.com/watch?v=cWD01yUQdVA

Yeah I mean properly unbiased post-NDA etc",amd_gpu
"The same Digital Foundry that praised DLSS 1.0 on it's debut? The same DLSS 1.0 that was promised on over 25 games, and appeared in roughly about 5? The same DLSS that Hardware Unboxed demonstrated looked, and performed, worse than an 20% resolution reduction from 4K? The same DLSS that was, according to Nvidia, so ridiculously easy to implement that all devs had to do was send Nvidia their finished code and Nvidia would do pretty much all the work?

Now I'm not saying DF is wrong, or that DLSS didn't come a long way, at least in performance, since. But DF gave the 2000 series a huge pass, and their glowing analysis never really came to fruition within the acceptable life of the series. So I'm gonna wait for some sites like HU or GN to deliver their takes before I start looking at the 3000 series for sure.",amd_gpu
"Even just the Xbox GPU running slightly faster will match it. Nvidia is pricing competitively, sure, but only because they know AMD is right there with them.",amd_gpu
"> so can't really complain...

Improving technology is a natural part of the process.  Whether price goes up or down depends on how much power the market dominator has.

Yes, RTX/DLSS is cool, but the only reason they are priced higher is because they can.  Nothing to do with R&D or profit margins.  Nvidia knows how to make money even better than they make cards.",amd_gpu
"It doesn't change the fact that their GPUs are selling everywhere. They just had their best quarter as well. Plus despite the original Turing lineup not doing the greatest, the super lineup was just fine.",amd_gpu
Inflation averageS ~ 1% a year,amd_gpu
"Well in this case, the 3070 seems to be a significant upgrade over a 2070, which IIRC launched at a higher price point.  There's no need for pointless nit-picking this time.",amd_gpu
Nobody uses this for deep learning though... They need a library like CUDA if they want it used for ML,amd_gpu
I thought they were complacent right now with turing and then they do this. Biggest generational leap since the 8800 ultra or something like that?,amd_gpu
"It's already been 5 years. And Nvidia already has 80%+ market share in desktop GPU and probably 95%+ in ML.

So yeah.. that's probably not the way.

AMD GPU's in my opinion solely survive on the backs of consoles.",amd_gpu
Amd: zombie company electric bugaloo the revenging,amd_gpu
"I got a decent laugh out of this, thank you",amd_gpu
"Yeah, we're just gonna pretend the Xbox Series X isn't a thing?

AMD could easily come out with a $300-$400 RX6700 with rasterisation performance matching a 2080 Ti (but probably inferior features/drivers).",amd_gpu
"Here's what they can do. Write working drivers. The mindshare of Nvidia is much more on that back of ""it just works"" than people here want to give it credit for. The current Navi drivers still have what I consider deal breaking bugs in Freesync flicker on application/monitor switch and random stuttering, along with numerous other smaller bugs.

It's not like the AMD brand itself immediately means no one will buy it. We see this on the CPU side, as soon as Zen came out and was actually good, people started buying AMD CPU's. Years of shit CPU's in Bulldozer/Piledriver and all it took was one good product that (mostly) worked the way it was supposed to and people were able to get over Intel. Zen 2 pushed forward even more here.",amd_gpu
"We don’t need the masses to buy them, we need the option for us to buy them. $200 less sounds a bit unrealistic, but $100 not so much.",amd_gpu
"Gsync monitors, once you have one you are trapped into Nvidea.",amd_gpu
"Navi 22 is supposed to be able to compete and perhaps be better than 3070. Navi 21 is supposed to be 50% more powerful than 2080ti which is about 3080 level because 3080 seemingly is 70% better in performance than 2080 (not ti).

Take streaming features away and all AMD lacks is AI. But we shall see later do they have something on their sleeve.

One of the reasons they are able to compete this year is because tsmc 7nm architecture which is leaps ahead of Samsung 7-8 hybrid I guess (nvidia was supposed to use 7nm but for some reason or another didn't). Nvidia's pricing is a further proof that they are afraid of what's coming from AMD this year, so I wouldn't say the game is over. Rather Nvidia knows what happened to Intel when AMD started collaboration with TSMC. If they didn't price their products correctly this year then AMD might have caught up this year. Worst case scenario would be they overtaken Nvidia gen or two later if TSMC continues as market leader and Samsung couldn't caught up.",amd_gpu
It aint gonna sell it any time soon. Console and semi custom money. They need both GPU and CPU cores to do that.,amd_gpu
it's really not tho  you can get a 5700xt for less than 400 the 2070s is way past that,amd_gpu
"True enough, if you need CUDA you're, well, locked in. I needed OpenCL though, which works on both.",amd_gpu
"I have no worries about not having a more massive 3090 on the market. AIBs just got a challenge. It's interesting to see how far they can push it, but I prefer doing an undervolt+overclock combo. Room gets too toasty. 

I have no issues with Turing, but this is so exciting with everyone on board.",amd_gpu
"It's a great card but for what I paid, shit sucks. Lol 🤷‍♂️",amd_gpu
Damn that's some big brain thinking 😂🤔,amd_gpu
2060 doesn't support SLI,amd_gpu
"150e and 5 fun size bags of Reese's pieces.

ᵀʰᵉʸ ʷᵒⁿ'ᵗ ⁿᵒᵗᶦᶜᵉ ᴵ'ᵐ ᵃⁿ ᶦᵐᵖᵒˢᵗᵉʳ",amd_gpu
no but i can read slides which apparently OP can't,amd_gpu
"RDNA 2.0 and AMD has the tech to do DLSS like features. We'll have to wait and see how well its implementedm. I believe both the PS5 and Xbox Series X will feature something similar to DLSS, and we know both of these console will feature a RDNA 2.0 Navi based GPU. AMD's RIS at the moment is essentially a bootleg version of DLSS.",amd_gpu
There are 14 games that support DLSS 2.0. Unless Nvidia expand that number greatly it will remain a niche technology. It needs to be an open standard for it to take off.,amd_gpu
"Ok but here’s the thing. Do *I* need that? I know only I can answer that but hear me out. As far as DLSS and HDMI go, I am already way maxing out my monitor. DX12.2 support would be fantastic I admit. I usually play games a year or so after release to take advantage of Steam sales, so for me, good RTX implementation won’t enter my Steam library till 2022 or 2023 realistically.

The biggest thing would be if DLSS really is a game changer, and full DX12.2 feature support. The question is do I return it and game on my old RX480 for a few months and then drop $1-$200 more on a card? It could be December before decently priced inventory is here.",amd_gpu
"Yeah sure what a ripoff Ryzen processors are, in Athlon x64 days top Athlon used to cost $650 and now we have to pay $750 for Ryzen 3950x, damn it Zen 2 overpriced hurr durr!",amd_gpu
Yea I’m sure AMD will have something comparable but I don’t think it will be as good as DLSS for a good while.,amd_gpu
This guy gets it.,amd_gpu
"Even if you took NVIDIA 100% at their word, a 3080 that's twice as fast as a 2080 has a performance per watt improvement of only 34% since the 3080 has a stock TGP of 320w, which is 49% higher than a 2080 (non Super).",amd_gpu
"The ""quality"" mode, which gives ~35% more performance and *better* image quality in most cases.

Tensor cores do not take up 35% of the die, and they can also be used for other tasks like RT denoising (so increase RT performance at less die space than more RT cores), RTX voice (you can do it without Tensor cores but it causes performance drops), and other useful software.

Dedicated AI cores are definitely a net-positive. AMD will be adding them themselves at some point.",amd_gpu
This is true,amd_gpu
Yeah I like VR stuff so that’s more of a worry than resolution,amd_gpu
Would definitely pay an extra $100 or so for 2-4gb of ram just to have a bit more of a buffer,amd_gpu
"I will be messaging you in 2 months on [**2020-11-01 19:11:40 UTC**](http://www.wolframalpha.com/input/?i=2020-11-01%2019:11:40%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://np.reddit.com/r/Amd/comments/iknr7g/i_am_genuinely_scared_for_amd_gpus/g3mmb70/?context=3)

[**4 OTHERS CLICKED THIS LINK**](https://np.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FAmd%2Fcomments%2Fiknr7g%2Fi_am_genuinely_scared_for_amd_gpus%2Fg3mmb70%2F%5D%0A%0ARemindMe%21%202020-11-01%2019%3A11%3A40%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://np.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%20iknr7g)

*****

|[^(Info)](https://np.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://np.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://np.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://np.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|
|-|-|-|-|",amd_gpu
Well well well how the tables have turned,amd_gpu
"LOL! This sub is crawling NVidiots, fool.",amd_gpu
"Where? [Can't find comparisons for 1080 and 3080, but here without rtx and DLSS the gains still are there, even if the gap gets wider with those options enabled](https://www.nvidia.com/en-us/geforce/news/introducing-rtx-30-series-graphics-cards/)

And they wouldn't be able to compare with a 980 with RTX. Maxwell doesn't even support software RT. Moreover, the difference between 1080Ti and 2080Ti wouldn't be 1/3 but 2/3 if RTX was enabled (I am extrapolating this data from SW RTX figures on BF V comparing 1080Ti and 2080Ti)",amd_gpu
Is this a haiku?,amd_gpu
nVidia has fantastic texture compression software.,amd_gpu
">High thermals

If you pick the right one, unlike me, you would get good thermals. My RX 5700 MECH OC after I fixed the piece of crap runs at 65c edge temp and 85c junction temp, those are good temps. You can't really make that generalization when the cards don't draw that much power, that'd mean it's just a bad design.

>driver issues

This is a lingering mentality at this point, you have no idea how many times I've had to tell some uninformed soul that no, your games crashing aren't ""driver issues"", it's just your RAM acting up or a bad install. Everything is a driver issue to people these days.

Maybe at the time you bought yours it was a disaster, but since April they've been making some great drivers.",amd_gpu
"That's kind of what it's always been like though. PS4 was $400 and the 970 launch price was $370.

Not everyone does a complete new build right away either, so sometimes it comes down to whether to upgrade a gpu or buy a console first.",amd_gpu
"No, I'm telling you that a PC is more powerful than a console.",amd_gpu
"Not sure you're if you're trying to disagree or agree with me, but I agree with your point.

Budget in my opinion is more like an RX580 - pretty good for 1080p gaming, at around 160-180 dollars.",amd_gpu
I'm not sure consoles are a big factor here - there hasn't been much evidence of competition between the two spheres of PC gaming.,amd_gpu
"It could happen. But I usually am more reserved. Nvidia proved me wrong, really wrong lol. Lets see what AMD can do.",amd_gpu
My point is that Intel had all the money and the best fabs and amd had no budget and was getting thier ass kicked for a decade on the cpu side. People said AMD would never catch up because they didn't have the budget or the fabs. Now AMD has caught up and passed Intel,amd_gpu
"An important caveat - Amphere is on Samsung's 8nm (as far as I can tell), which is actually inferior to TSMC N7. Lower yields, etc. Density isn't too bad, but clock/voltage scaling is horrendous, which would explain the high power usage that we see (320 watts for RTX 3080, jeez).

AMD would be on TSMC N7P, or 7nm+. This should mean higher clocks and lower power consumption.

And if we look at the clocks for the consoles - I would be very, very surprised if AMD can't break 2 Ghz this gen, considering that the PS5 has a max frequency of 2230 mhz. To me, Amphere's clocks are actually surprisingly low - 1700 mhz is not very impressive, even if its the base clock. However, it's not entirely unexpected - Samsung 8nm apparently scales clockspeeds very poorly. It was rumored that Nvidia was testing >2ghz samples of their GPUs on TSMC 7nm, which would make more sense. However, their dispute with TSMC seems to have limited their wafer supply - they're using Samsung for a big portion, of their lineup.",amd_gpu
"> DLSS 3.0 is supposed to improve upon the 2.0 technology and be compatible with all games supporting TAA.

This isn't real. This ‘leak’ came from MLiD, but MLiD later retracted the claim, his ‘leaks’ have been almost completely incorrect wrt. the Ampere launch, and it never made sense anyway.",amd_gpu
"Microsoft has designed it. Its called DirectML (Machine learning) Its part of the Xbox Series x.

The original DLSS models used the shaders and then they moved to tensor cores. AMD can use shader code also. They have int 4 and 8 added into RDNA 2 for Microsoft so they can do a lot of data crunching . 

http://media.redgamingtech.com/rgt-website/2020/08/xboxseries-xhot-chips-machine-learning-5f3e959451f26.jpg

I mean I don't know how much more they can say aside that  ML for resolution scaling",amd_gpu
Or xbox one series X,amd_gpu
"The desktop version won't have the same power and thermal constraints, also the PS5 GPU is cut down.",amd_gpu
"You claim I'm making things up when I provide facts, yet you make statements about waiting until benchmarks come out and talk out your ass with ""Realistically it will be a less than 10% difference, probably closer to 5%.""..

Fact: Comet Lake is crippled by being stuck with PCIe 3.0

PCIe 3.0 4x = 4GB/s or roughly 3-3.5 GB/s
PCIe 4.0 4x = 8GB/s or roughly 7-7.5 GB/s

So that is 2x performance in regards to bandwidth and this is not considering the reduced latency with 4.0>3.0 when going over the pcie bus. The PS5 SSD can deliver uncompressed data to other system components at up to 5.5GB/sec.

Per Nvidia the GeForce RTX GPUs are capable of decompression performance beyond the limits of even Gen4 SSDs, offloading dozens of CPU cores’ worth of work to deliver maximum overall system performance for next generation games.

So yah pairing a i9 10900K and 3080/3090 is a huge lulz when considering you'll be stuck with crippled PCIe 3.0 and outclassed by a PS5 potato.",amd_gpu
Okay Racist,amd_gpu
"You got a reliable source? There's a lot of rumors; GDDR6x, GDDR6, HBME2..",amd_gpu
"Iirc gddr6x is custom made in collaboration by micron and nvidia

Edit: thought it was a collaboration between Samsung and Nvidia but it's micron and nvidia",amd_gpu
Well that's unfortunate.,amd_gpu
"yeah gonna need a source on that, big if true",amd_gpu
Apparently it's not.,amd_gpu
[deleted],amd_gpu
But intel said not to use those anymore,amd_gpu
"Now we need a meme genius..

THE SACRED BENCHMARKS!",amd_gpu
"CEO vs ârmçhær rëddïtør

> avkhauly I'm a certified programmer (just wrote my first hello world in Python) and now let me lecture you about why capitalism is bad and the government sending you a monthly weed package (like in Sweden and all of europe 🤤) should be HUMAN RIGHT",amd_gpu
Boom roasted,amd_gpu
Doesn't really matter when they are not going to compete against each other.,amd_gpu
"Yeah, the issue isn't that. The issue is that by the time Intel 7nm drops TSMC will be shipping 3N. So it really doesn't matter anymore.",amd_gpu
I've heard of a lot of people going with NVidia because Vega runs too hot.,amd_gpu
"Did I say that a GPU could hit 5 GHz? I don't know where you pulled that from.

I know GPUs are fundamentally different than CPUs, microarchitecture-wise. Of course a GPU won't hit 5 GHz (at least for now). That doesn't detract from my point. Guess what? Intel has to increase voltage (and total) power if they want to push up clocks. An Intel CPU clocked at 4 ghz draws far less power than one clocked at 5 ghz. That's just how the frequency/voltage curve works. 

My point was that the heat density isn't usually the biggest constraint of clock speed - it's actually power consumption. u/myrne suggested that clock speeds may not suffer. I agree - my point is that it will take more voltage/power to hit the same frequencies on Samsung 8nm. 

I seriously don't know where you pulled the ""5ghz GPU"" idea from. And come on, no need to be a smartass about it lmao",amd_gpu
"There doesn't seem to be much evidence (that I've seen) showing Navi be objectively ""hotter"" than Turing. 

Of course, a card that draws more power will also put out more heat. I have a lot of trouble believing that a 225w card like the RX 5700 XT will be objectively hotter in a system than a 250w card like the RTX 2080 SUPER. 

... the temperatures in benchmarks are completely dependent on what AIB model you buy... This is true of both AMD and Nvidia.",amd_gpu
Samsung's yields are so low they might as well have zero capacity as well >.<,amd_gpu
"Drama? This isn't drama, it's business.",amd_gpu
"They're not; Intel Fab 42 in Arizona was just 10nm certified last month (or late July, I forgot exactly when), Tiger Lake launch event is tomorrow. I hope it's good or this is going to be sad",amd_gpu
Theres another problem with Intel owning its own fab it means they almost have to produce their own because even if they see better yields from other manufacturers for them to then go out and purchase in large quantities from external sources would ring alarm bells on the stock market. Bad enough having manufacturing problems but to basically say that those very expensive foundaries are useless would be stock market suicide so Intel has to put a brave face on.,amd_gpu
This does make a lot more sense. I had a feeling I was missing stuff. Ryzen is amazing but it’s crazy how much more valuable intel is than amd. I know intel does more than make cpus but that’s just what I’m so used to hearing about.,amd_gpu
It does... thanks!,amd_gpu
I run VR just fine on AMD and have for years.,amd_gpu
On Turing the RT parts of the GPU heavily bottlenecked the rasterisation parts. RDNA2 will probably not beat Ampere in RT but it will definitely beat Turing in RT performance by a good margin.,amd_gpu
They can make up for it with the massively increased density of 7nm over the 12nm Turing used.,amd_gpu
BuT tHe hUmAn BrAin cAn't seE MoRe ThAn 299 fpS!!11,amd_gpu
Uh what? It was like one of the biggest games when it came out and for years after...,amd_gpu
I mean it still means something because you're still getting better responses. You just aren't going to see it visually. It's just not *as* meaningful when you are pumping more frames than you can see.,amd_gpu
heat. my case can barely handle it as it is - I'd probably have to undervolt if I wasn't upgrading in a month or so.,amd_gpu
"Both the base model and the average model has gone up over the years.

1998 started at 16-17k

2005 started at 18k

2009 around 19k 

2013 around 21k 

2019 around 22k

  
Most of that is called inflation but standards and features also have gone up.",amd_gpu
"That’s absolutely insane! I can’t believe a card 7 years old can still run modern warfare decently well. Do you have any intentions of upgrading any time soon? I’m curious as to whether or not you have upgraded other components of your pc over the years like maybe an ssd or a cpu like the 1600af because they such an insane value. 

I know I have kind of a bad tech obsession. I really don’t need to upgrade and if I do it wouldn’t be for another 6 months but ray tracing is really the thing pulling me now. I play such an absurd amount of video games a few of which have the option that it just keeps compelling me, and with the new 3000 series bringing true ray tracing performance it’s definitely been a struggle to keep telling myself I don’t need it.",amd_gpu
"I'm just using mesa and the latest stable kernel. It all worked out of the box for VR which was really nice. That being said, I recently started building the latest mesa from git so I could play Red Dead Redemption 2.

I've tried Wayland. But for screen recording and other compatibility reasons, I've gone back to Xorg.

It's weird. On paper, there shouldn't have been a noticable difference between the GTX 1080 and the RX 5700 but for first person shooters like DOOM Eternal, even though I'm getting similar framerates, there was a very noticable latency improvement. On Nvidia I could move my mouse and observe a minute delay on screen. Now, with the open source Radeon drivers, everything runs crisp and smooth.",amd_gpu
"I have never seen an amd driver work without bugs in Linux. It can also be that the hardware just sucks. 

nvidia is not something I even consider for even more obvious reasons. 

Intel drivers also lockup after an uptime of eight months or so on a desktop.

I wish the rest of humanity would also learn how to write software.",amd_gpu
why?,amd_gpu
"I have a 1080 ti. I wonder if my issue partially stems from different high refresh monitors (I have a 240 and 144). Multi monitor eventually worked okay, but then gaming screwed the whole thing up. It would always be on the wrong monitor and I had a lot of difficult moving it around.",amd_gpu
"My 290X does multi-head just fine, and has for nearly 1.5yr on Arch.

This is over DP + HDMI though; not sure if other combos have issues.",amd_gpu
Gotta go get those black box drivers,amd_gpu
">My personal rig has an r9 290 and it works pretty decent although you have to toggle freesync every boot and they don't support multi monitor with it at all!

Well that is a problem with XOrg. Luckily, unlike with NVidia, AMD GPUs work just fine on Wayland and there multi monitor VRR is a done deal on Sway and soon coming to Plasma and GNOME, too. Toggling it should them only be a matter of starting the game then :)",amd_gpu
"I only have a single GPU. Main issue is after I finally wrangle down multi monitor, gaming was super screwed up and would always display out wrong. I wonder if it has to do with my super high refresh monitors (I have a 240 and 144, at different resolutions to boot).",amd_gpu
"See I've actually been told that before, and I still had problems. I have an external SSD, maybe I'll try an install on that so it doesn't screw with my internal drive",amd_gpu
"Basically if you checked auto log me in, the driver broke it on reboot. Don't remember what I did to fix the problem, but I had enough other issues that I gave up anyway.",amd_gpu
https://youtu.be/Co6FePZoNgE,amd_gpu
"I guess I don't fully understand the question. The distro I am most comfortable with is Debian / Ubuntu, but I actually ran a centOS server for a while. Proton solves a lot of the game issues when developers won't or can't. Unless you need a specific tool, a lot of open source replacements that are getting better have popped up. They aren't always as good due to volunteers, not having decades of running, and probably just monopolies in general, but it's way better than it used to be from my understanding",amd_gpu
"Ah i see, for me personally i have a psvr and was turned off by the mediocre graphics, but here in israel it'll cost me 1000$-1500$\~ for a pc vr headset and that's just insane.

I really think that pc users upgrade too much it's unwise, people that upgrade from a 1070 or 1080 ti level performance, i just don't see the reason? it just isn't worth it especially considering i don't even play that much but when i do i get 120\~ fps ( 1080p ), make no mistake, the vega 56 is still a beast and im still proud of it.",amd_gpu
"> I'm not upgrading and sticking with the Vega 56. The price for performance gain of a potential upgrade will need to be a lot better before I upgrade.

I'm wondering what your goal is then, because personally a 75-90% increase seems like a damn good upgrade cycle to me.  Unless $500 for the 3070 is just out of your budget for a GPU?",amd_gpu
"Thanks. I use Arch Linux, so that should be  as up to date as possible. What about hardware decoding. NVENC was excellent for 4k HEVC decoding with minimal CPU usage, and we'll supported by Linux apps.",amd_gpu
"Yeh I am thinking about it... a big navi and ryzen 4700x bundle would be quite nice.

Justifiable? Perhaps not. Nice? Surely.",amd_gpu
"The VII is really meant to have a water cooling block applied to it and cranked up since you can get somewhere on the order of 20-30% more performance out of the card from stock settings. It has the largest overhead I've seen in a while on a GPU. When cranked up it definitely out-competes a 5700 XT but not by enough to matter in a comparison against what Nvidia's putting on the table from what I'm seeing lately.

Just wanted to drop a note here about the VII being used to its full potential. I really wish I could get my hands on a replacement card but they're never in stock. I've fallen back on my Vega 64. :/",amd_gpu
"Depends on what sort of games you were playing, but slightly below the rtx 2080 (non-super), and priced accordingly on release.  Might be discontinued, but a recent search showed it fairly available.",amd_gpu
">Unless Nvidia have got a great deal for the wafers, or the yields are very good

If Moores Law Is Dead is to be believed Samsung's yields on 8nm are probably still at like 30% for those big wafers but at the same time NVidia got a great deal. Samsungs 8nm is already 30% cheaper than TSMCs 7nm per wafer and I imagine they made a deal with NVidia and betting on yields increasing big time (which they usually do, in only a couple months it will probably be at 80% or so)",amd_gpu
Unfortunately Nvidia critics for some reason believe Nvidia should basically be selling GPUs with either zero profit margin or negative margins considering how much they demonize Nvidia prices.,amd_gpu
"The Ti naming is pretty old, that's why I think they'd rather be going with that. But yeah, maybe you're right, Super does transfer the meaning better.

>So long as they don't do BOTH I think either is fine though.

100% agreed.",amd_gpu
"honestly AMD or Nvidia stock at this point, they are both performing great",amd_gpu
"
.. or mega church preachers.",amd_gpu
Lmao nobody is using their stimulus cheques to buy company shares. They're using it to pay their bills and buy food.,amd_gpu
"I'm not saying there aren't poor people out there, I know there are a ton of people doing worse than me by a lot.

I'm just saying that I game on a high end pc, and I was hit hard by the pandemic.",amd_gpu
Did you think my comment meant that everyone was fired from their jobs?,amd_gpu
Okay. Plenty of higher income people were also hit that would have bought something like this and now will not.,amd_gpu
"Nivida called their 3080 the ""flagship"" on stream, so they probably just nixed the TI this time around. Meanwhile when they started talking about the 3090 they opened with the history of the Titan cards and how ""clearly there was a demand"" for that product.

The 3090 looks to be the Titan replacement, which would technically be a (significant) drop in price for that ""tier"" of product from Nvidia.",amd_gpu
"Lmao, you are debating me about financial sense while putting an example of someone making 700k a year.

Thanks for the laugh.",amd_gpu
Hell you dont even need to be pulling 60k a year to consider buying it.,amd_gpu
I don’t think a single person on here is making 700k a year lmao,amd_gpu
"There is no Ampere Titan (so far), and the 3090 is $1000 cheaper than Titan RTX. This is NOT a higher price tag, it is the opposite.",amd_gpu
"Yeah my bad, though this time it seems the FE will be the same price as AIB cards (supposedly, who knows with scalpers/availability).",amd_gpu
"If the performance is there, i could stomach that",amd_gpu
"Not only that, but this is just the beginning of the new console cycle, nVidia will have to keep prices competitive as the consoles are locked into the AMD stack and will certainly obtain an APU refresh mid and late cycle, with Microsoft having already committed to more frequent refreshes than entirely new designs.

Waiting for reviews, but I am sorely tempted to buy my first console since the PS2 just for the crossplay, etc in the Win10 ecosystem (that, and have one available for when my brother visits and we get home from the bar).",amd_gpu
"Ah well, time to dip into my life savings",amd_gpu
They make a sweet living off selling subpar products. Like them or loathe them there's undeniably some smarts in there somewhere.,amd_gpu
We're talking about malice and ethics here. I don't see the relevance of those links,amd_gpu
You missed a comma before land,amd_gpu
"I'm not talking about intent, just result. (Though an intent to radically depopulate an entire area and then return to make sure no one survived is severe.)",amd_gpu
"> Did the Mongols want to exterminate races though?

The term ""race"" is a modern invention. The Mongols, like many invaders before and after, had no problem with systematically exterminating entire ethnic groups that opposed them.

The Romans did the same thing: If a city surrendered they would grant them generous terms. If *anyone* resisted, then the entire city would be massacred, and the surviving women and children would be sold into slavery",amd_gpu
">Did the Mongols want to exterminate races though?

A means to an end. While I'd assume there were likely at least some xenophobic mongols (as tribalism has been present in most if not all peoples for all of humanity's history), the main reason for conquering neighbouring territories would not have been ""racial purity"" or something similar. But honestly, does that really matter?

If entire villages, towns, or nations get raped, tortured, enslaved, or summarily executed, it doesn't really matter to the victims what the reasoning behind these horrible acts is. 

And let's be fair, it was just an excuse for the Nazi's too. They didn't conquer Europe solely because they wanted to get rid of the jews. They used the excuse of wanting to get rid of ""undesirables"" and restoring the great germanic race/empire to get themselves more ""lebensraum"". 

That's not to say that many didn't believe in this horrible propaganda (unfortunately), but push comes to shove it was also just a means to an end.",amd_gpu
Ya but they acheieved it by committing large scale genocide and death,amd_gpu
Mongolian guy here. Back then Mongol's purpose wasn't land or domination. They always want diplomatic relationship but opposing sides werent.,amd_gpu
"Why does the reason for mass murder matter? If person A kills 10mil people by coin flip decisions and person B kills 10mil Jews specifically, is there really a moral difference? Seems pretty crazy to try and say one is worse then the other.",amd_gpu
Up until the Xbox one they did not even use x86 and even then the architecture cant run any other software than the xbox os based on windows 2000. I dont really see how you could call an xbox a computer in good faith.,amd_gpu
"Yeah, because consoles do that as streamlined gaming boxes. PCs don't.",amd_gpu
"A 2080 ti is on average ~30% faster than a 2080. If a 3080 is 70-80% faster than a 2080, it would be pretty reasonable for the 3070 to be at or a bit above the 2080 ti level.",amd_gpu
"I mean nvidia said that it's faster than the 2080 ti, even in rasterization. They showed a chart of where it'll be in terms of performance compared to the rest of turing and ampere.",amd_gpu
"Remember that these results are at 4k, so the performance difference at 1440p should be much, much more.",amd_gpu
"Yeah, right, pshhh who cares 30-40% performance, what a tiny difference and totally does not invalidate some of your comment.",amd_gpu
"I expect it will last 6 years, my 970 has \^\^. The + was intended to indicate that I'm hoping the 3080 will last me an extra generation or two past that from the amount of extra performance its giving per £ I spend :)

I have a higher res monitor that I bought so I'm a bit more hesitant about the 70 this time around.

Still a fantastic purchase to go for though - Everyone getting it will be super happy with its longevity I'm sure!",amd_gpu
"I am always surprised of the number of people around here who own stocks (I dont have any) but than I remember that things are different on other places, on the USA for example more than 50% of the adult population own stocks, here in Brazil is less than 0.5%, yes, less than half a percent.",amd_gpu
[deleted],amd_gpu
">DLSS, which AMD has no answer for

Where are your sources for that?",amd_gpu
I mean: it works. Death Stranding looks better with DLSS than without it and runs like butter.,amd_gpu
Lmao video game is founded on performance cheat. Why do you think we have precalculated lighting instead of actual path traced lighting for decades,amd_gpu
"As long as they're getting better performance, it doesn't matter how they do it",amd_gpu
8 FPS be hella fast on my old quadro 600 Xeon system Minecraft was like 20fps,amd_gpu
"Following your own logic they're also competing with ARM, RISC-V and whatnot and those designs are catching up quickly. Apple CPUs, Graviton, Ampere (not Nvidia, the CPU company) etc.

x86 is not some kind of a holy grail.",amd_gpu
"The consoles in the end just lead back to AMD anyway. Even if GPU prices makes somebody walk away from PC space entirely and towards a console, AMD is still getting a cut of that.",amd_gpu
It's the kind of argument that comes from either a naive shareholder or someone who literally only uses their PC to game. I'm going to assume he's the latter.,amd_gpu
"You're an AMD hyperboy. Skylake came out in 2015 with 6th gen, 9900k is coffeelake....the 10700k is cometlake. You're spewing bullshit out your neck because of the rendering benchmarks. Intel is still supreme in gaming, some games up to 20%+ increase FPS. To say that Intel hasn't improved in ten years simply isn't true, and you know it. They have not improved much, in comparison to AMD in everything except gaming, but to just flat out say they have not improved in ten years makes it sound like their CPUs today are only 15% faster than their CPUs from 8 years ago, and that's just fake news. Get your facts straight.",amd_gpu
"I wouldn't be surprised if they do but then again, I wouldn't be surprised if drivers sucked a major dick in comaprision to nvdia.",amd_gpu
"It's why I'm confident RDNA2 is looking good. Why would Nvidia change the name (and price) of the titan if AMD isn't going to at least get close to the 3080? They don't win by doing that, unless they're trying to ""claim"" the performance crown.",amd_gpu
Strange to me how much more expensive a 3090 is over twice as much as the 3080 but like 20 percent better performance.,amd_gpu
"AMD is touting 2x performance per watt - even with perfect scaling which is not how p/w works - it would be twice the performance of the 5700XT.

The 2080 Ti was already 50% faster than the 5700XT at 4K --- this means unless AMD has been underselling to their investors, AMD top end will be inbetween the 3070 and 3080 in performance.

If AMD throws it all out and makes another 350-400W card though, it could give the 3080 a run.

This would likely make NVIDIA issue a 3080 Ti in response.",amd_gpu
"Theres a wide margin of price and specs between the 3080 and 3090, expect a 3080 super/ti there for around $999-$1099.",amd_gpu
History dictates that isn't going to happen though.,amd_gpu
No it doesn't. They take the performance crown when they overtake the 3090. You can't just artifically exclude certain GPUs just because jensen called the 3080 their flagship minutes before revealing a faster card that they also market towards gamers.,amd_gpu
"Exactly, but Nvidia went back to their old price performance tactics. 3070 is a solid product for a fair price. It seems like 1080TI way of being worth.",amd_gpu
"What's interesting is the price per performance actually favors the 3080, where for the past two gens the XX70 has been the sweet spot. The increase in CUDA cores between the 3070 and 3080 is a 47.8% increase, whereas the difference between the 2070 and 2080 was only a 27.7% increase. That's a pretty big difference.",amd_gpu
"We don't know actual pricing of AIB's yet. They could end up being cheaper still, not that I think they will.",amd_gpu
">and there's no bullshit ""founder's edition"" pricing either.

where this information came from? All that was said - starting from X price. it was not mentioned anywhere that those prices in the presentation are for FE cards from Nvidia",amd_gpu
"""They need to get their house in order,"" is what we've all been saying for the better part of a decade and AMD marketing just keeps reaching new lows.",amd_gpu
"Absolutely, AMD is really failing to show anything at the moment. Even teasers would be a good idea now to make sure people don't forget that they are releasing gpus this year too.",amd_gpu
[https://twitter.com/sherkelman/status/1300842481886662658](https://twitter.com/sherkelman/status/1300842481886662658),amd_gpu
"I mean Nvidia was just leaking so it's not like they really put much out while AMD is staying dry, I feel it could go either way still.",amd_gpu
They hardly said a word about Zen. Nothing substantive. Or zen 2 not to mention the radio silence about zen 3. Silence is not a defacto bad choice.,amd_gpu
"I was content on waiting to see what AMD has to offer, but after watching the showing... if I don’t see anything between now and the 3080, I will probably end up buying the 3080.",amd_gpu
"Sony and Microsoft have some leverage over Nvidia, but they have AMD by the balls. That's why Nvidia is not releasing a console killer sub $400 3060. That's why AMD has to be quiet and generate as little hype as possible until Sony and Microsoft secure the volume sales for the holiday season.",amd_gpu
"I agree, AMD needs to come out of nowhere and hit Nvidia HARD if they actually have something that competes.... even if its just a paper launch to get the specs out there and minds thinking ""team red"" but they need the hype to make people WAIT from buying Nvidia, otherwise as you stated, people are just gonna buy Nvidia anyway and be done with their upgrade for 2-3 years.",amd_gpu
I think AIB are on launch this time,amd_gpu
"I've been team red on GPUs ever since I got rid of my gts 8800, but think I've gotta go green for this gen.",amd_gpu
"They've been losing for quite sometime now. If they haven't figured that out then there is no hope. Fingers crossed they have wised up, but not holding my breath.",amd_gpu
"Either the product delivers or it doesn't . Bravado has done them no favors in the past and now would be no different.  People who buy Nvidia will always buy Nvidia for the most part at the start and they know that.  Also why let your main competitor know what you are doing before launch.  No company worth their salt would do something that stupid. 

Nvidia won the brand loyalty war decades ago, as such the only prudent thing to do is stay quite and hit with a big right when its least expected if they want to change fortunes.  

Silence from AMD is refreshing.",amd_gpu
"Honestly, I don’t think any vendors are going to design a much better cooling solution this time around, excluding liquid blocks. It really is a complete card.",amd_gpu
"best thing AMD could do (other than competent drivers) is just drop reference coolers all together......sure, design a reference board and spec a minimum TDP cooler and let the partners just go for it. Hell people were throwing 390 coolers onto Navi cards so its not like the layout changes much.",amd_gpu
I was unaware of that.,amd_gpu
"That's unusual. Their wording kind of implies it without confirming it.

> Starting September 17th, NVIDIA and our partners will release the GeForce RTX 3090, GeForce RTX 3080, and GeForce RTX 3070

>Partners from around the world, including ASUS, Colorful, EVGA, Gainward, Galaxy, Gigabyte, Innovision 3D, MSI, Palit, PNY and Zotac, will have custom cards on shelves alongside NVIDIA Founders Edition models

I don't have a microcenter near me but did founder's editions normally get released on store shelves, I assumed they were just online purchases?",amd_gpu
"But they don't get to decide that, Nvidia does.",amd_gpu
Hopefully they have aib cards for 3080 with 20gb,amd_gpu
"Add In Board, it is used to refer to cards released by 3rd parties.",amd_gpu
"And AMD still has opportunity. How is this controversial?

Some who WOULD buy 3080 / 3070 in October if they COULD may well be AMD customers by the time they have the money gathered. As for 3090 folks, they may as well jump on that, as I doubt AMD is looking to compete at such an absurd price point.",amd_gpu
Nv does not care for the console market in general since the gpu's are sold to sony and ms with little to no profit.,amd_gpu
It’s sad that the market is to a point where a $700 video card is described with “only.”,amd_gpu
"I think the most impressive card they announced is the 3070. It packs a lot of power for just $500, and I'm not sure that the other 2 are worth the extra money.",amd_gpu
"The top of the line got even more expensive, but on the other hand, were you seriously and truthfully expecting the performance of RTX 2080ti, sold somewhere in the $1000-$1400 (I haven't been actively monitoring the price of it, because it's too damn expensive), to come down to just $500 with that new GPU ?

It's an impressive move on the perf/$ ratio.",amd_gpu
"That really doesn't matter for a customer.

When you are looking at a ""box that does game"", and you have to choose between a $2000 massive desktop with a RTX 2080 Ti, or a smaller $500 console that does roughly the same performance in games, it's kind of hard to go for the PC.

But since the 3070 will now provide the same range of performance for much less, the overall price of the PC will come down, which will make the comparison a bit easier.",amd_gpu
"At the same time, Nvidia has been able to get away with using a worse process and still be actually ahead in competition. The better pricing from Samsung also allows them more design room to throw stuff on a card or be more flexible with pricing and still be decently profitable.",amd_gpu
"Sure you can, you can put a 2080 Ti and a 970 in the same system as well.",amd_gpu
"You're the first person to mention it. 
It was the same computer originally. When the Ryzen 3000 came out I was planning on upgrading from my intel i5 6500.

My SO was also looking to upgrade. I figured that I could save a bit of money on a mobo and cpu by just using vm's to share the pc. So I built the system in my flair and used unraid at first to run 2 windows 10 vm's. This ran into a few issues that I tried to fix by using a headless manjaro install instead. 

Eventually I gave up trying to fix the issues I had and found the Multiseat software Aster. This worked almost perfectly except in order to use my VR headset I had to unplug it and reboot the system and then plug it in after it booted, even then it would sometimes crash when the headset turned on.

Because of the issues I split the pc's up again. I'm now running the same 3900x with 32gb of ram with the 5700xt while my SO is running a 3600x with 16gb and a 5600.

It was fun while it lasted and if better ways to hide vm's from software come along I might look into it in the future. But the games I wanted to play did not allow it to be played in a vm.",amd_gpu
"Yeah, Nvidia can't leave themselves open for Monopoly, that would be devastating to say the least.",amd_gpu
"Maybe, but CP2077 will be released soon and if DLSS 2.0 as good as it looks from other games, this sole game will sell more RTX cards than AMD will next generation.   


Also, Fortnite RTX + DLSS will be big selling point for many. AMD really needs to bring something similar - otherwise, I believe, they are screwed.",amd_gpu
"Can relate. My wife plays one game: Conan Exiles. She had crash after crash after crash on her RX590. Threw my 1070 in there and it ran like a dream. Ended up getting her a 2070Super and calling it a day. She refuses to touch Radeon ever again and I can't blame her. I doubt she's the only person with that experience, either.",amd_gpu
They didn’t really fix the drivers though. My computer still crashes occasionally and never did with my 980ti.,amd_gpu
"because people are not going to wait and return their nvidia once the driver issues were sorted out. First impression counts, many people are still haunted with their personal exp with the driver issues, it clouds their judgement on picking gpu.",amd_gpu
Drivers are not fixed - games crash all the time for me,amd_gpu
The driver issues are still here,amd_gpu
"ATI/AMD have had driver issues from time immemorial. 

My last card before I gave them another chance with the (2nd hand) rx500 series was a 9500 from the early 00s. 

Guess what? They still seem to have a bunch of monkeys writing drivers.

That's how long some people remember. 

Nvidia's had some issues in that time, but nothing like the weird shit you see people complain about with the radeons.",amd_gpu
The average person buying a GPU doesn't look into it that much. Go to Microcenter and see how many people are asking for help not knowing what GPU to pick.,amd_gpu
[deleted],amd_gpu
"That's fine, but that's not ""a message"". That's just buying what you need. You seemed to be advocating something beyond that.",amd_gpu
I'm going to go out on a limb and guess that the person who's main feature of concern for a graphics card is open source linux drivers is actually a linux *user*.,amd_gpu
"You want Nvidia getting in trouble on anti-trust laws? Trust me, you don't want a complete monopoly on the GPU market.",amd_gpu
They won't be pushed out of the market until the end of this console cycle at the earliest. I still doubt intel Xe is going to be anything competitive for high end.,amd_gpu
"On the cpu side AMD is taking the approach of getting the enthusiast's to want to recommend AMD to their friends/family. Their mobile chips are amazing now in comparison to intel's for power draw. The big issue on the laptop side is manufacturers didn't pair amd cpu's with high end nvidia gpu's.

Amd definitely has a lot to work on in their marketing/advertising but they have the hardware to compete which needs to back up that marketing in the first place. Epyc is also a important to AMD provided they can get over that view of Intel>AMD from the people deciding to purchase servers.",amd_gpu
Air conditioning exists,amd_gpu
"However long the warranty is? If the power supply is rated at something like 550W, it can handle it for 7-9 years or whatever the warranty period is.",amd_gpu
"I mean... power is 9 cent per kw here... If I gamed full blast for 12 hours straight I might spend oh maybe 50 cents.... saying power is a huge consideration is irrational for most of the world. See the link below, if anything many middle eastern countries have lower electriciy costs than even me. The areas with high cost happen to be european... Germany is probably due to high amounts of renewables etc.. I mean in Germany my small apartment's power bill would be > $400USD!

https://www.globalpetrolprices.com/United-Arab-Emirates/electricity_prices/",amd_gpu
"I think people who are seeing any issues are using non-standard distros. I use Linux Mint/Ubuntu and there drivers are just packaged. Very rarely I had some issues, usually when I switched cards or did a major OS upgrade, and in such cases deleting X config or similar resolved the issues (but I can understand that somebody might be frustrated by this). Performance and stability is top on Linux.


I don't own any AMD card so I can't really tell anything about AMD drivers on Linux.",amd_gpu
[deleted],amd_gpu
That doesn't explain at launch prices which were still ludicrous.,amd_gpu
It's not them being greedy necessarily but the fact that die shrinking is getting more and more expensive.,amd_gpu
I have everything maxed except ssr is off I believe. I’ve spent way too much time trying to get as many frames as possible and it didn’t seem like any setting I changed made a difference. The only difference was overclocking my 2600 to 4.2,amd_gpu
AMD said 50% https://www.techpowerup.com/img/OpW1my228D8ebDYX.jpg,amd_gpu
"If we take Nvidia's words that the 3080 is 2x faster than then 2080, then it would be (2 x 100) /128% = 1.56X the performance for the 2080Ti at 4K. 

[https://www.techpowerup.com/review/nvidia-geforce-rtx-2080-founders-edition/33.html](https://www.techpowerup.com/review/nvidia-geforce-rtx-2080-founders-edition/33.html)

Again, it's probably best to wait for reviews to come out to see what the actual performance is across different games.",amd_gpu
"The bubbles are large. It's better to just go off the ""2x 2080"" claim, and see if the graph lines up with independent benchmarks in general.

Which it does.",amd_gpu
"Its a new technical area, there is not much industry knowledge. The pro's working at Nvidia, Google, Apple etc. probably wouldn't change jobs. That means empty whiteboards and a lots of cash. To ramp things up, a couple of dozen well paid people with interest/basic knowledge is a good start.

AMD got Jim Keller to help fix the cpu issues they had, they would need some of his elite level knowledge to save a year or two. If you can't get anyone, its going to be the long sweaty hours way.",amd_gpu
"> In some cases

And in most cases it looks horrible, loses a lot of detail and is full of artifacts.",amd_gpu
"You are the easiest target for BS marketing, I love it. Yeah, its AI-Blockchain-MachineLearning-SpaceX-Upsampling :D",amd_gpu
Yh but for the most part it's basically free 4k,amd_gpu
"The idea is great and it has a lot of potential, but even with DLSS 2.0 it just lacks detail most of the time and is littered with artifacts.",amd_gpu
"Yes hypotheticals are always ""if"" something happened, that is the point of a hypothetical",amd_gpu
that's still not enough imo unless amd dlss and rt are noticeably better,amd_gpu
"For Linux AMD is better due to its drivers and raw compute, even Ryzen performs better on Linux... Nvidia really wants the gamer audience so Windows is the target cause sadly devs don't make games for Linux",amd_gpu
well ok but im on windows,amd_gpu
i dont want or care to be part of any team,amd_gpu
"It wasn't the drivers, it was the garbage prices. AMD were offering cards 5% less performing for 7% less the price, where's the sense in that when your market position is really bad?

If AMD don't significantly undercut nVidia, they are fucked again.",amd_gpu
"People were saying that a decade ago, hopefully they actually can get it together this time.",amd_gpu
"Great, I'm personally more inclined for UW 1080p @ 75Hz since I also use the PC for programming and watching movies, a cheap RX 5700 XT should suffice even on next-gen games.",amd_gpu
"You don't know that, those are game settings. NVidia also had stupid high tesselation default settings in the sponsored games years ago, because their cards could handle it better at the time.
Reviewers who set the game settings to high or ultra and aren't looking closely, could then compare apples to oranges in favor of team green.",amd_gpu
"Yea I know its not just upscaling but other people keep using that term, I keep saying to not compare RiS and DLSS as they are not the same.",amd_gpu
I had one too!  I remember experincing single digit FPS in crysis with high graphics.  at 720p lol.,amd_gpu
That's hardly a high-end GPU tho ;p,amd_gpu
"Fuck safety protocols, we're fighting with Kahless and drinking blood wine like real warriors!!",amd_gpu
"He didn't mean literally he just meant it will be comparable to the concept of Time machines since we will probably be simulating little VR Matrix's within the next 50-100 years on Home PCs with cloud streaming, AI and such",amd_gpu
"all virtual, not real.

Transporters = Virtual presence

Time Machines = Neural Network de-aging",amd_gpu
he was talking in example of if youre entire body can be simulated whats the difference?,amd_gpu
[deleted],amd_gpu
"That's how they justify the price increase from the 2080 Ti to the 3090 to make it seem like a good deal. It isn't a Titan replacement, you've fallen for nVidia's marketing.",amd_gpu
My 5700xt wasn’t even bootable out of the box with current software drivers. I only got it to boot by rolling back to software from 2 months prior,amd_gpu
[deleted],amd_gpu
">They said that thing is a Titan replacement, and it is meant more professional usage. Obviously tons of games that can afford it will buy it, just like people bought Titans, but they are't meant for gaming.

But the 3090 **is** meant for gaming. Putting it in the RTX lineup makes that clear. I suspect they did it for one fundamental reason:

- To make it clear to reviewers that the 3090 must be included in all gaming benchmarks because Nvidia suspect that AMD will be able to beat the 3080. Nvidia can't allow AMD to outclass them in their RTX lineup and say *""oh but we beat it with our Ampere Titan""* because they've been very clear with their marketing in the past that Titan cards are not gaming cards. If they were to go against this trend reviewers would call them out for it. So Nvidia was forced to kill Titan for this gen to save face. 

>That being said, that thing has x2 the amount of RAM of the 3080, and can apparently play games at 8k at 60fps, which is insane.   
>
>
>In any case, 2080ti performance (probably a little better) for $500 is not bad, although I wish it was $400. Maybe AMD will make that happen ;)

It's compelling, that's what worries me lol. Because I typically wouldn't even consider an Nvidia card for a plethora of reasons, but even I have to admit that the presentation moved me to stoking my beard, wondering if two kidneys are necessary.

The spell was broken by the cries of my empty wallet, but for any neutral party just looking for perf per $ with good RT performance, Ampere is no joke in the mid-to-high-end. RTG will have a hard time converting those **without** brand loyalty to go RDNA2 this gen. I suspect even Radeon loyalists are looking sideways at Ampere with intrigue slathered on their faces. 

I really hope AMD can pull a competitive launch off. Come on AMD, amaze us.",amd_gpu
"I heard what Jensen said, but what I see is a whole bunch of gamers considering a 3090 who would never have considered buying a Titan class card.

Do you think that's a happy accident on Nvidia's part? Or by design?",amd_gpu
"> If someone told you 6 months ago that you could get an rtx 2080 ti for 499 you'd bought it in heartbeat

No, but I might have if you'd told me that in late 2018, when it first launched. Of course, that's because I recall the 780ti launching at $700 and the 980ti launching at $650. The only reason I'd ever consider this generational upgrade a value proposition at $500 is if I first fooled myself into thinking that the 2080ti was worth upwards of $800 in the first place.",amd_gpu
Don't count on it. AMD will easily steal market share this generation.,amd_gpu
X to doubt,amd_gpu
"That kind of people will ridicule you either way.

You buy it ""LMAO TOLD YA SUCKER""

 You wait, then buy ""LMAO SHOULD'VE WAITED FOR THE NEXT ONE SUCKER""",amd_gpu
Have fun getting a step up. They wont have enough stock for new buyers let alone the step up program,amd_gpu
"Going by that logic in your particular usercase, why not wait for the obvious 3080 ti at the 900~ dollar pricepoint gap that is likely to release in a few months?",amd_gpu
More of a win/win/win ;),amd_gpu
"lol, AMD's jumped 11%. Stock prices aren't much to do with excitement.",amd_gpu
"Hopefully. More excited for this gen of hardware than any other I can remember. Coming from a heavily OC'd 1080, I'm gonna win no matter what comes around.",amd_gpu
"I see. Without RTX it says about +80% in Borderlands 3 at 4k max

https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080/",amd_gpu
Doubtful.  Do you have a source for DLSS using more tensor cores on the 3000 series?,amd_gpu
Indian rupees,amd_gpu
Lol. Thanks.,amd_gpu
"Yeah, sharply compared to one of the most overpriced generations ever. 2080 to was never worth anything near 1000, it should've been a 750 USD GPU.",amd_gpu
Not just that but 2500 for 1500,amd_gpu
"Same here, 1070 to 3080 probably for me, unless AMD come out with something that can match performance AND features at that price. I feel like even if AMD can match the raw performance of the 30 series they might not have anything to really compete properly with DLSS, which is kind of huge.",amd_gpu
"I had a good laugh when I heard that. I think he’s right, it’s finally time. 

I’m going to wait for AMD’s counter and then see if there’a going to be a 3080Ti.",amd_gpu
"cries in maxwell, but seriously at least upgrading from my 970 will feel good now",amd_gpu
1080 to 3080 probably here. The only thing I'm currently sad about is the 10gb vram... Hope the rumours about the 20gb 3080 will be true once AMD tries to counter...,amd_gpu
"Same, I will be going from a 1080 to a 3090.",amd_gpu
"I had 3 of those and all of them had such severe coil whine that I returned them all the same day. Would‘ve loved to actually run one, because I do a lot on Hackintosh and NVidia drivers are a piece of crap on OSX",amd_gpu
"Not really. ""Nvidia is afraid of AMD and priced low"" narrative says ""Nvidia is afraid of competition within PC market"", while ""Nvidia is afraid of new consoles and priced low"" says ""Nvidia is afraid of competition OUTSIDE of PC market"". Let's face it - in PC and server market, they pretty much won (for now at least).",amd_gpu
"Honestly it doesn't matter if there is no rasterized bump (though it seems to be 65-85%), DLSS is going to rip them a new asshole in terms of frame rates in AAA games.",amd_gpu
"Isn't the 3070 hitting about 20 Tflops whereas xbox GPU hits 13?

That's a pretty significant difference, I know tflops isn't end-all be-all, but it should be *some* indication. I don't think just running the xbox slightly faster could make up 7tflops",amd_gpu
"You are right,but at the end of the day - 

Someone has to pay all the engineers,

Someone has to pay all the ads,

Someone has to pay for all the utilities + factories + taxes,

And last but not least,make profit.

&#x200B;

That's how business works and that's how they make money.

&#x200B;

But I gotta agree that the 2000 series cards sucked when it came to price and just weren't worth it even for ""RTX!!!"" which had bad performance and only few games used it.

&#x200B;

Now more devs implement Ray Tracing and DLSS which in combo are amazing and since the 3000 series cards actually give PLAYABLE Ray Tracing performance,I can say that it's worth it and Ampere is what Turing should have been.",amd_gpu
2011 to 2020 has seen over 15% increase here in the US,amd_gpu
"Then there's no need to mention model number and relating it to price then right? 2070 MSRP was $500, they claim the 3070 is better than the 2080 ti at $500. Again, you can't say X model is apparently 'value' these days without relating the performance changes from generation to generation.",amd_gpu
"Nope.  The 2070 and 3070 are the same price.  And it's only a pretty standard jump in performance.  It just seems amazing cuz Turing sucked. 

I swear Nvidia has scrambled everybody's brain.",amd_gpu
"Not to mention next to 0 support for tensorflow/PyTorch

I mean there is ROCm, but support is terrible, and no one uses that really at school/professional settings (I'm sure it's used somewhere in a niche but it's not widespread), so Nvidia has the whole DL ecosystem on lockdown

AMD shot itself in the leg with regards to DL",amd_gpu
"As usual, my response to the same old ""AMD could totally X, AMD could easily Y"" that has been repeated with every new GPU launch for *years* is ""I'll believe it when I see it.""",amd_gpu
"We don't know the Xbox pricing and I have a feeling it will be above $500, it will not be $300 that much is for sure. Also it will have performance between a 2070S and a 2080S, not a 2080ti.",amd_gpu
"A lot of the flicker has to do with the monitors themselves, not the GPU’s. Several monitors flicker if you enable both overdrive and free sync. It’s a monitor issue, not a AMD issue.

That’s one of AMD’s problems - there’s all kinds of confusion about issues with AMD hardware and software, some of which isn’t even AMD related.


If AMD releases a card that beats the 2080ti, has its own ray tracing and deep learning super sampling solutions, and costs under $500, I will eat a shoe. And even if they do release such a card, Nvidia still has the bigger mindshare and marketing budget.


Nvidia would really need to shoot themselves in the foot in order for AMD to catch up.",amd_gpu
"Zen 1 was a bit shit on linux for a year though. I still bought it for my server though. Had monthly pci-e issues on it with nic's dropping out and that compile thing, but got ironed out eventually.

But yeah, they just need a good product, sadly it'll be a much, much harder uphill battle on the GPU side due to software and features. But if they make something competitive in at least some areas (areas as in gaming, scientific e.t.c.) they'll find a customer. ML aint gonna happen though.",amd_gpu
"A $300 AMD card would be pretty cool. But, if the 3060 is $300 for similar performance, and offers the whole RTX feature set, it’s a no brainer for team green",amd_gpu
"Sure, but it works great.

Plus you can have some really good freesync ones that work on Green too. Good ones are well.. kinda hard to find, but they are out there. For example LG 27GL850 is great and brand agnostic.

Worse in some respects to true Gsync ones (mostly variable overdrive and VRR range) but it's very close. And probably has one of the better panels out there currently.",amd_gpu
"7nm is better, but nvidia architecture is way ahead of AMD and they also pay a lot less for samsung 8nm vs TSMC 7nm. If AMD can't compete on price because of that then that node won't help them a ton. We've seen nvidia beat AMD while using a bigger node no problem.",amd_gpu
Yeah probably. Unfortunately there's very little money in console hardware though. My company is a hardware supplier for consoles. You barely make any profit. Nvidia probably makes more profit off one standalone video card than AMD will make from 5-10 consoles.,amd_gpu
Launch price difference between 5700 xt vs 2070s was $100.  It would be hard for me to see amd price their 3070 competitor less than $400.,amd_gpu
Yep. Only thing I’m interested in are the FE cards and RDNA2 reference cards. I don’t like the AIB designs.,amd_gpu
Username checks out hahah.,amd_gpu
"Cheer up, mate Ü",amd_gpu
"Your ping ist atrocious, mate Ü",amd_gpu
[deleted],amd_gpu
Go assembly rally infront of Nvidia HQ now if you dont believe it. Its actually on their slides lol. But you believe AMDs 50% improvement or polaris 2.8times or vega 4x etc etc.,amd_gpu
You can't have better image quality and better performance by trying to reproduce the image with AI. That's just not how things work. You pay for better resolution with lower quality. It's all a trade off.,amd_gpu
Would it be stupid to buy a 5700xt today then lol,amd_gpu
They removed the 3080 specific page for one generalized 3000 series page. PCWorld stream had the page up in their stream if you can be arsed to look through it.,amd_gpu
Yup,amd_gpu
"Not to be mean but this isn't exactly an astonishing revelation. AMD's own Navi 21 will be substantially faster than the consoles as well. Consoles are designed for a relatively low cost, not to be the absolute quickest thing out there.",amd_gpu
"The first step is realizing that CPU and GPU are different markets, and Intel and Nvidia are different companies. AMD had to do a lot of things right so that Ryzen could be a success, including recruitment, *focusing* resources, killing other projects, etc. AND the extra component is a complacent Intel that didn't really innovate in consumer CPUs for almost a decade. In other words, Ryzen wouldn't be a success today if it weren't for Intel dropping the ball.

Nvidia is an entirely different story, they haven't slept on anything. They have capitalized on opportunities and have even branched out to offer software features that AMD can't compete with. So while Intel wasted their advantage, Nvidia never did.

RDNA2 is the foundation in which they will base future competition for sure, but nothing they come up with now will give them similar advantages to what they have in the CPU market, because GPUs weren't their focus.

For AMD to really beat down Nvidia, first they need to make the decision that such a thing is their goal and then start allocating resources to it, because focus is what gave them success in the CPU market; as a company you can choose to win or just to play, and in the last couple of years AMD made the (right) choice to only want to play while they focused on winning in the CPU arena.",amd_gpu
"I said that more to show the shift from a 14nm node to 7nm. Even if it is on Samsung’s dyes I think the shrinkage from Turing is big. Yes, rumors are suggesting the TSMC 7nm+ could give AMD a big boost, but the 5700xt is the best that they did with 7nm last year. 

Hoping for something big, but if it comes down to identical hardware numbers I think Nvidia has the edge with the software side. 

But agreed that AMD has the dye advantage going with TSMC.",amd_gpu
Consumer Ampere will be on Samsung 8N - it was shown in the stream.,amd_gpu
"I have not seen that, so very interesting. I’m interested to see how the implementations compare then.",amd_gpu
"PS5 will at least outsell the Xbox 2:1, so this time the weaker console will be the baseline.",amd_gpu
"When mentioning the 2080, I was referring to the gpu of the XSX, which DF tested in Gears 5 and the performance approached a 2080.

The PS5 should be slower, like a 2070 perhaps.",amd_gpu
"> You claim I'm making things up when I provide facts

Fact is Nvidia benched on a 10900k because pcie3 still doesnt stop intel being faster in games.",amd_gpu
"They going to use neuralink, direct pipe to synapses",amd_gpu
[You can settle for this for now.](https://twitter.com/_rogame/status/1289281758618419200?s=19),amd_gpu
"NVIDIA has specs of the 3,000 cards on their website, 3090 and 3080 will use GDDR6X and the 3070 will be GDDR6. It's funny, I was updating my GPU driver a few minutes ago and there was an ad to learn more about it and I decided I'd check it out, even though I have no intentions to pay for a new GPU.",amd_gpu
"nVidia and Micron have a contract that says so, as long as no one else produces GDDR6x.",amd_gpu
"If the 512 bit interface is true, they'll use GDDR6
That's more than enough bandwidth",amd_gpu
"nvidia.com did have it, but the pages got pulled?

https://videocardz.com/newz/nvidia-announces-geforce-rtx-3090-rtx-3080-and-rtx-3070 shows it.",amd_gpu
https://www.extremetech.com/computing/313829-micron-introduces-hbmnext-gddr6x-confirms-rtx-3090,amd_gpu
"Micron and Nvidia, not Samsung",amd_gpu
"It's not custom made though., and according to Micron it's not exclusively made for Nvidia.",amd_gpu
"For who? GDDR6X signalling concerns are a pain the arse, a good old 384-bit bus of GDDR6 memory will do plenty fine.

:P",amd_gpu
[Settle with this for now.](https://twitter.com/_rogame/status/1289281758618419200?s=19),amd_gpu
"Who knows? Maybe they do, maybe they don't.",amd_gpu
Let's see how 3090 does on Excel.,amd_gpu
"Yea, after they had their ass handed to them lol.",amd_gpu
i've finally found it after 15 years...the benchmarks of truth!,amd_gpu
Your views are interesting and I would like to subscribe to your newsletter.,amd_gpu
"That's my point?

>If it ever comes out",amd_gpu
"vega ran hot, was loud, and nowhere near powerful enough. if the 3080 is as good nvidia claims it is, it'll still be quiet and run cool. no one will care.",amd_gpu
well if Vega did outperform the 1080ti nobody would have cared...,amd_gpu
[deleted],amd_gpu
"I have to say I find it amusing to compare a 130w max cpu to a 320w+ GPU and argue that the CPU throws shitloads of power at the problem to solve it. 

It's ~7bn transistors vs 28 so yes, each one on average uses a bit less, but your original point was on the process node being limited clock wise. It shouldn't be. It's limited by other factors.",amd_gpu
"I don't exactly remember all of the cards. But 2080s aside, the more powerful 2070s is cooler with the 10nm architecture you mentioned. 

Tldr: forget I mentioned 2080. Rest of the point still stands",amd_gpu
"Yup. AMD processors plus graphics processors is a much larger set of contracts than Nvidia could even hope to bring the fab. And seeing as the fab makes money on wafers not end devices, they don't care if they're producing $50 or $500 parts. They just want guaranteed volume and well, processors sell better.",amd_gpu
"Intel won’t be competitive in the mainstream GPU segment for a long time. AMD already has the low end-mid range segment on hand and have plenty of fanboys. And there’s no way whatever they come up with will too anything NVIDIAs high end can put out, specially not at a competitive price.  They’ll only be successful in the laptop market if at all.",amd_gpu
">those very expensive foundaries are useless

Not quite useless but they won't be producing flagship products with them.  14nm chips will probably still be in production even 10 years from now with global demand growing as it is.  Today I think there are fabs still producing 65nm chips or at least there were in the last few years and that node came out in like 2005 or something.",amd_gpu
And that assumes these 3rd party fabs have the capacity for Intel!,amd_gpu
"Yeah, but have you got an R285?",amd_gpu
"are you saying rt block rasterisation or the other way around on my half month old 2070s
?????",amd_gpu
Absolutely not mark this post and come back in a few months!:),amd_gpu
"If I'm not wrong, you will se an improvement if you can get a x*hz of your monitor as fps and it will actually help with the ms. So he can still cap his fps at 120, 180 etc.",amd_gpu
Well that's not the whole story... if you are producing more FPS than your monitor can handle it's actually a bad thing. You can experience screen tearing. That's exactly why GSYNC and FREESYNC exist... they cap the GPU at the framerate of your monitor. So anyway... 300fps is useless on a 60hz monitor,amd_gpu
"It's not a loaf of bread, there's more at work than ""a thing called inflation,"" which you can tell by how those numbers don't follow inflation. They went down comparatively. That's why it's ridiculous when graphics cards increase by 60%. Partially.

I just didn't understand your comparison. It was a poor one. But I guess it's just not cool to do anything other than double down.",amd_gpu
"I've had an SSD for years now, but it's quite an old one. It's an OCZ Vertex 3 Max IOPS 128GB. As you can guess from the size, it doesn't house a lot of games, especially since a ton of games are so large these days. The SSD just runs my OS and most default programs and software suites. Most of my games just run off oldfashioned 7200 RPM HDDs. 

As far as the CPU goes, I bought that around the same time I got my 290. I'm currently running a 3770k OC'd to 4.5Ghz, with 12GB of  DDR3 1600Mhz RAM.

I used to be a tech obsessed guy too, and by my old standards all of this stuff is ancient and obsolete. But I've fallen on some hard times financially in the past few years, so I've had to make do with what I have. And in that sense I was really surprised by the longevity of these parts and how much performance I'm able to squeeze out of them.

Don't get me wrong; I do really notice that I need to upgrade these days. I'm not able to smoothly run Star Citizen at all for example (15/20fps at best), and FS2020 gives me around 20/30 frames at best on medium settings with a lot of stuttering and framedrops depending on the area (and horrendous loadtimes due to the old HDDs). Stuff like AC: Odyssey or Shadow of the Tomb Raider has to be customized in terms of settings from anywhere between medium and ultra to get it to run at around 30 to 45 frames depending on the area. Stuff like The Witcher 3 never ran at a full 60fps on ultra with hairworks on, I always had to play that at around 30/45 fps too.

In that sense I'm really worried about whether I'll be able to run Cyberpunk 2077 at any decent settings or framerate...

But still. 6 or 7 years with a single configuration and STILL able to play relatively well, at the very least similar to a console experience at 1080p30 in most games, is astonishing. And some stuff like Battlefield 1 or Modern Warfare or Doom Eternal still runs at 50/60fps which is mindblowing.",amd_gpu
"Awesome.

I got the RX480 when they were brand new. I've always been a ""put my money where my mouth is"" and my mouth has been calling for Linux support for years. So when the RX480 was announced with actual *AMD-developed open source drivers* I decided to buy one. (By sheer luck, I won one from AMD via reddit instead. Heh).

Back then, it was an entirely new driver stack, rather than the typically smaller ""add support for"" patches, so I had to custom-build mesa and a kernel with out-of-tree patches (then some smarter people started nightly COPR repos I could use instead). Then again through the Display Core migration. So I feel the pain.

I'm much, much lazier now though, so I'll just wait the extra 3-6 months for driver support to settle before buying a new card.",amd_gpu
"I had a fair number of issues with `amdgpu` was still new, but it's settled now. Their drivers are more stable than for windows, but I'm also using them for different use-cases. My work machine is on 24/7 with an rx550 that has given me zero issues (running gnome-shell in wayland on Fedora).

I used to buy specifically Intel GPU laptops for the driver support, but if I was to replace my current laptop, I'd probably go ryzen/vega. My wife's laptop is zen+, and it's worked fine via liveusb, but the best uptime I've had on that was really just a few hours of playing around on it.

I've never really run a GUI-interactive machine longer than 2-3 weeks uptime as I prefer to keep up on updates.",amd_gpu
It has an ISO option with Nvidia drivers preinstalled ready for any Nvidia GPU from any generation.,amd_gpu
"I use a 144hz monitor just fine alongside a 60. It's fully possible to get by using Nvidia on Linux as long as you do a few things properly.

If you're playing games at all on newer cards you basically have to use their proprietary drivers. This also means that they break whenever you do a kernel upgrade. Their driver has to have its module rebuilt and then you have to restart the machine to make sure the new kernel and module have been reloaded (I think there may technically be a way to avoid this but it's not worth it for me). Without the restart games just can't open when this happens. Your distro may do the work for this for you, but it may depend and I can't say.

Beyond that you can't run certain software. I've wanted to look into Wayland for a while now but it's just not feasible. When I get an AMD GPU finally then things will go a lot more smoothly, but it technically does work now.",amd_gpu
Are you using proton? I had some trouble with the wrong monitor issue as well- slay the spire would refuse to open on my nice monitor if I had it on full screen or windowed full screen. It's less of an issue now because I'm running single monitor on my personal rig but that is one of the few issues I ran into consistently.,amd_gpu
"What drivers are you running? The amd drivers and site mentioned that freesync doesn't work on multimonitor setups when I checked early this month.

I just wish their ROCM wasn't hot garbage for tensorflow/pytorch. Nvidia might have some shitty practices but their products are well put together.",amd_gpu
"Playing on 1080p, no RTX, there isn't much of a reason from the 1080ti especailly.

However 1440p/4k resolutions with high refresh rate (especially for 1440p) is very common for people that spend that much on GPUs.  New games absolutely can cause people to not be fully utilizing their monitors at those higher resolutions/fps.

I use a 3440x1440 100hz Ultrawide monitor, and my 1080ti struggled to keep up with Jedi:Fallen Order from last year.  While it was playable, I didn't buy a 100hz monitor to play at 60fps.  If I played more new games (I don't really) I would absolutely be considering the 3080 for myself.",amd_gpu
"That was just announced today, and I'm not up to date on their pricing or performance claims. If their claimed numbers are real, it will be interesting to see if AMD responds with a price drop on their whole lineup and/or finally releasing 'big navi'.

Either way, it is still fairly unlikely that I'd buy an nvidia card.",amd_gpu
"No idea, I use a TV for media. I rarely play anything other than youtube on my computers, and Firefox hardware decoding for that is fairly bleeding-edge. What is there does work with intel + amdgpu (vaapi-based iirc), though there's no performance or resource benefit to using it yet (that's a firefox implementation issue, not a vaapi issue specifically)",amd_gpu
"You'll have to search eBay for a used one, every manufacturer stopped with the VII months ago.",amd_gpu
"> If Moores Law Is Dead is to be believed  

He isn't. so no worries there.",amd_gpu
Which means they missed the gravy train,amd_gpu
Yeah i like them both too. Even as gamer with my amd cpu and nvidia gpu.,amd_gpu
Who happens to be an AMD investor.,amd_gpu
A fool and his money are easily parted.,amd_gpu
Sure,amd_gpu
"Everyone was hit by pandemic, i had to move to another country to a get job. I was just saying that poor people were hit the most and those dont game on High end PCs.",amd_gpu
"you said everyone was ""hit"". When it comes to affording expensive GPUs, I would not say I was ""hit"" in any way",amd_gpu
Yeah after thinking about it for a while I definitely see the 3090 as a titan replacement. And I do see an rtx 3080ti dropping in case AMD is able to beat or match the 3080. There’s definitely a gap big enough for the 3080ti.,amd_gpu
"Very much depends on a LOT of other factors, but yea.  A tradesman in the midwest with no collage debt and a dual income household could easily justify that.

At least if they don't have more than one kid xD",amd_gpu
"Ok, 23 year old at Google making 200k straight out of college.",amd_gpu
There is no 3080Ti either. This is their flagship. They can call it whatever they want.,amd_gpu
"yeah, it's 100 bucks off and wayy more powerful lol",amd_gpu
Actually I wouldn't do that if you can wait. Leaks showed us 3080s with 20GB and I really doubt there won't be a 3080 super or 3080 Ti at all. It just depends on AMD how high the price will be and when it's released but it will most certainly come,amd_gpu
"That’s not about smarts; that’s about a shitty CEO inheriting a previously good company. Any time you see a company take a dive like Intel, it’s because of a change of CEOs.",amd_gpu
"Intel has made lots of progress at the cost of security. As a platform, they're just gunning for the next inch on the benchmark graph, and they'll do almost anything for it.",amd_gpu
You clearly never fucked with a tapeworm,amd_gpu
did he?,amd_gpu
Not sure any empire was created without genocide.,amd_gpu
Can I disagree without everyone I know being slaughtered or enslaved?,amd_gpu
"Because there's a reasoning for the coin flip (whatever it is). There'd no extrinsic force pushing to kill 10mil Jews, you just don't like Jews. Idk where your morals lie, but humans generally don't like it when you are killed for something other than simply being what you are. There's a reason it has its own term (genocide) and not simply called mass murder.",amd_gpu
"Because intent always matters. If the Nazis won WW2, there wouldn't have been anything a Slav could have done to avoid death. On the other hand to avoid death at the hands of the Mongols all you had to do was not to resist and pay taxes.",amd_gpu
Huh? All consoles are computers. That statement doesn't make sense.,amd_gpu
Despite it being all custom hardware it still shows how much they charge for something of that power. Even with the reduced 2080 prices you'd never get it down to 500$ with a 8 core Ryzen.,amd_gpu
"Makes sense.. just surprising that they are pricing a 2080ti at 1100 or so out of the market in 2 weeks when the 3070s hit for 500 and 3080s hit for 700. I am really really curious what is going to happen to all the 2080/super/ti stock. I can't imagine anyone buying one at more than 200 or so.. given that 3070 at 500 has updated RTX, faster, etc.. but you know nobody is going to sell those for that price. Maybe there will be some insane prices next week to try to sell stock out like crazy!",amd_gpu
Never just trust data that hasn't been independently verified. They might just have cherry picked the results,amd_gpu
"I used to live in China, because there wasn't much growth and you couldn't buy foreign stocks, not a lot of people bought stocks. Most bought funds, so I'm not surprised that Brazil doesn't have a lot of stock holders.",amd_gpu
"Buy their stocks, it will grow no matter what.",amd_gpu
"If the RDNA2 GPUs in the Xbox Series X and the PS5 had sufficient ML and AI capabilities to pull off some DLSS-type wizardry, it would be advertised to hell and back.

Instead both are hellbent on advertising the fact that they can both render native 4k at 60fps lmao.",amd_gpu
"It works, as in that it successfully convinces you that what you're seeing is what the game developer wanted you to see, yes, it does so very well. It is very clever. It's still a performance cheat.",amd_gpu
So you'd want to go back to baked lighting? Dlss is just a temporary cheat for performance.,amd_gpu
"x86 is what matters in a lot of spaces, including most consumer desktops, datacenter, and enterprise.

We run lots of datacenters, and the number of non-x86 servers in them can be counted on one hand.

To get for example ML software stacks running on those aforementioned devices from Google, Intel, and AMD isn't a matter of doing specialized work, as it is with PowerPC, RISC-V, ARM-based uarchs, and more. In most cases you run TF on top of them, minor tweaks, and you're good to go. Besides, the latter in almost all cases do not compete with Intel on most metrics of performance, even when they were on their asses.

NVIDIA has several real competitors right now for their intended markets. Intel has so far only really had one.

With the rise of performance-oriented ARM chips, that might change.",amd_gpu
"I know its an amd sub but jesus some people are giving amd credit for nvidia’s technology 

makes no sense this level of fanboyism",amd_gpu
I'm not the same person but just wanted to point out that for Intel anything-lake is just a fancy way to say its skylake architecture thats been slightly improved. A quick [Google will show that](https://en.m.wikipedia.org/wiki/Comet_Lake_(microprocessor\)). The original comment is right they haven't dramatically changed there CPUs in a LONG time. Not saying things didn't improve but they haven't changed much while waiting for 7nm.,amd_gpu
"The new ""smart"" drivers are actually what makes me unable to use my AMD graphics for what it should be able to do.",amd_gpu
AMD drivers have been fine for AMD for years.,amd_gpu
"It's the new Titan, not a gaming GPU",amd_gpu
"It's mostly because of the 24GB of GDDR6X RAM - that is not cheap.

Same reason the Radeon VII was so expensive and still a money loser for AMD.",amd_gpu
Sooo... you know exactly how big and how many transistors are in big Navi?  Your argument is only valid if they make the flagship in the exact configuration of the 5700XT.,amd_gpu
Yup. There's been rumors of 16GB 3070s and 20GB 3080s for months.,amd_gpu
3090 isn’t a gaming card,amd_gpu
"yup, either the 3070 is overpriced or the 3080 is a bargain to undercut AMD's Big Navi.

As I said elsewhere the 320W & 350W power envelopes don't make much sense if AMD has no answer even for a xx70 level card. So my gut feeling tells me Big Navi is actually bringing the big guns and Nvidia was forced to get a bigger GPU with an aggressive price tag that can't be jebaited.",amd_gpu
"If AIB can undercut further, this can't be good for AMD.",amd_gpu
[deleted],amd_gpu
"Right now I can see them waiting for the Nvidia 3000 hype to die down.

Considering they're the smaller of the two, it would probably be wise to throw info out after Nvidia is done on the spotlight. If they did it before, they'd just be over shadowed by Nvidia simply because Nvidia has a bigger mindshare.",amd_gpu
My worry is they don't have anything to show.,amd_gpu
Why its not going to change anyone's minds people are going to buy Nvidia anyway.  AMD is playing poker.,amd_gpu
$499 card matching 2080ti vs one Thinky boi 🤔,amd_gpu
[deleted],amd_gpu
The reference design means you're blowing hot air directly to where the RAM and CPU would usually be. I'm pretty sure AIB designs with normal fans would be very interesting for non AIO people,amd_gpu
"At least for the 3080 they could turn it into a triple slot and add another fan. Since one can already be place on the back it'll end up as a push/pull.

That's assuming they are allowed to use the reference board.",amd_gpu
AMD should have done this when launching Fury and continued the practice into Polaris.,amd_gpu
"We still don't know about the chip binning or whether there will even be a Founder's edition, but I can't see any reason why Nvidia would design such good reference coolers if they weren't keeping the best chips for themselves. At the very least, we can appreciate that with Turing the ""Founders Tax"" was a justified price increase, unlike with Maxwell where it was $100 more, didn't include the best chips, and came with a blower cooler.",amd_gpu
Yes they were no idea now. I just know that zotac Germany wrote it on Facebook,amd_gpu
"Every day will be lost sales. Especially with massive number of Pascal, Maxwell owners itching to safely upgrade, some of whom could be swayed.",amd_gpu
"It’s not about gpus sold to ms and Sony, it’s about any customer looking to buy nvidia card and thinking eh consoles at this price offers better value and potentially losing a customer forever, because now consoles have backward compatibility so once they buy consoles they will most likely stick to it because of library they built",amd_gpu
"8GB though, when even consoles have 10GB for 4k can hurt.",amd_gpu
"Top line is actually down in price. The 3090 is a marketing trick to get people to buy the Titan card. It’s the equivalent of past Titans, which were always around the $1200-1500 mark. 

The 3070 being just $500 is on par with the 1070 at launch, so it’s definitely a good thing.",amd_gpu
"Huh, neat. Thanks for the info  


Never heard of that program, nor did I know you can have multiple different gpus in a single system.",amd_gpu
Correct me if I'm wrong but isn't the ps5 supposed to have some sort of ray tracing on an amd gpu?,amd_gpu
Is she me (also a female),amd_gpu
"I had problems with them a few decades ago that were so bad that I haven’t used their cards since. I kept checking back hoping they’d changed.

Nope.",amd_gpu
Well alot of people buy online and all the cards with driver issues have terrible reviews because of them.,amd_gpu
"I was in Micro Center here in the US Midwest yesterday for unrelated reasons and went through the GPU area.

The NVidia side had one Titan and one 2060. The Radeon side was pretty full.

Either the purchasing manager messed up or people don’t want Radeon in my area.",amd_gpu
Absolutely not. I'm not trying to send a message and I don't think anyone should. In fact I'm explicitly saying the opposite. Just do what's best for you and the market should follow,amd_gpu
"Impossible, there are only 6 people alive who use linux",amd_gpu
"Yes, let me just buy air conditioning so I can run a GPU. Good idea, next time account for that in the cost.",amd_gpu
"PSUs need an overhead. If you assume 300 watt GPU, you require 25 amps on the rail that handles the GPU. The other 21 amps should cover the motherboard, CPU, RAM, and every other thing? With a high end GPU you use a high end CPU. So with all of that, not only would you push the PSU past it's efficiency curve, you are risking a god damn fire. That is using the best 550 watt PSU I could find, and assuming ideal conditions where the consistency of the power delivered is good and doesn't vary due to whatever reason. And oscillations are common, even with brands like seasonic. If the voltage regulation craps out, you're looking at something dead, most often the GPU. 
yeah",amd_gpu
"i had a traumatizing experience with fglrx, ever since i found mesa i never look back to amd's proprietary driver. i still dont understand the motivation behind amdgpu-pro and amdvlk. radv was conceived earlier and why not support those from the start? some bits are hidden in amdgpu-pro too and I wonder why they didn't follow intel steps by fully committed to mesa instead of further splitting resource between open and closed driver

for nvidia, i had a time to try it with my gtx 550 ti. sure it's still painful with kernel upgrade but it doesn't broke lightdm randomly like fglrx. afaik last time the dependency is just supported kernel version.",amd_gpu
"I'm flattered that you think I'm the only consumer that matters, dear.",amd_gpu
"If you sell out at launch and the resale is 2x what you are selling them for then you didn't price high enough and you adjust up for the next launch, which is exactly what happened.",amd_gpu
Got it. That makes sense. I think I totally missed the TechPowerUp part before. Thanks!,amd_gpu
"If you were talking about pre 2.0, you would have a point. But the artefacting in 2.0 is negligible and in almost all cases it looks at least as good, if not better than running native resolution. There's plenty of comparisons on Youtube ever since it was released earlier this year, which you clearly haven't seen. It is literally an industry-changing technology, and it won't be long until most new titles implement it.",amd_gpu
You're not wrong. DLSS 2.0 causes a lot of artifacts.,amd_gpu
"Instead of using facts to prove me wrong and show you're informed you doubled down on juggling piss-filled balloons.

Whatever makes you happy, I guess.",amd_gpu
A lot of reviewers are showing that DLSS actually looks better than rendering it at the full resolution because there is less aliasing.,amd_gpu
That's marketing...,amd_gpu
You make me sad. I still love you tho,amd_gpu
"AMD has had good drivers on average over the generations. They've just had really bad lows. RDNA drivers have seemingly been a big problem (I don't have one, so just going off what I've seen posted here), but my 7970 and 290x's never had driver problems.",amd_gpu
"Are you another one of these DLSS hating resolution snobbs .. if it isn't true 4k then GTFO ?

you sound like one.

go away",amd_gpu
"He poorly conveyed that thought process if that is the case, otherwise great presentation besides the awkward call of the guys wife to blow, dry her hair lol",amd_gpu
Fuck I’m gonna die before the cool shit,amd_gpu
That was not the context,amd_gpu
"No he wasn't, and it was cringe",amd_gpu
Idc  it was cringe,amd_gpu
"Except it is. Because it positions them for super and TI releases.

$5 bucks says you'll make some excuse when that happens too.",amd_gpu
What are problems you have with geforce experience?,amd_gpu
"
>- To make it clear to reviewers that the 3090 must be included in all gaming benchmarks because Nvidia suspect that AMD will be able to beat the 3080. Nvidia can't allow AMD to outclass them in their RTX lineup and say *""oh but we beat it with our Ampere Titan""* because they've been very clear with their marketing in the past that Titan cards are not gaming cards. If they were to go against this trend reviewers would call them out for it. So Nvidia was forced to kill Titan for this gen to save face. 

I truly hope this is the case.

I dont care if amd can't beat the 3090, I just hope they can come close to the 3080 if not match or beat.

An AMD 3080 competitor will keep.me on team.red.",amd_gpu
"Almost certainly by design. It's a slight step up from the 2080Ti and it looks like, at $2500, they crossed the ""ceiling"" for the RTX Titan, and at $1500, they're trying to see if gamers will pay for it, because so many people paid for a  $1200 2080Ti... 

And going from $1200 to $1500 isn't a huge stretch for those people. 3090 is also only about 20% faster than the 3080, if you go by memory bandwidth, SM count, and clock speed.... and costs over 2x more.

My other guess as to why the 3080 and 3070 are priced so sanely is that Nvidia is pretty sure RDNA2 is actually very good. They had to bring the 3090 down in price so people would actually consider it the top card, or they would lose mindshare if AMD's GPU is faster than anything except a $2000+ Titan that no one will buy. Not only that, but the Consoles matching a PC build with a 2080 Super in it, for just $500 means that it's not even possible for Nvidia to Justify the 2080S price for that level of performance, because a PC builder has to add a CPU / RAM / SSD / Motherboard, which is at least another 200-300 (for a basement tier build) on top of the price of a $800 2080 Super? The value prop was gone. 

So all I can really say to this new pricing level, is thank you AMD, and RDNA 2 in the consoles, because that's the ONLY reason we're seeing sanity in the market again. All these things combined, it makes sense they dropped the Titan >> 3090, and positioned It as an ""8k"" card, because that's the only reason any gamer would want/need that much VRAM right now.",amd_gpu
"I was having some interesting shower thoughts about this the other day lol.  


My guess is that Nvidia was like ""let's see how much we can push the prices up"", once they realized they pushed it too far with the RTX1.0, they decided to lower the prices down again to more ""reasonable"" prices with the RTX2.0, still the cards are expensive, and only AMD (once again) can pull another Ryzen at this point...  


Unlike previous years I feel that AMD will be able to compete for the first time in a long while.",amd_gpu
"I don't know how unless they launch a 2080ti level card starting at $400. And even then, people will still go with the rtx 3700 to avoid potential driver issues and the better software suit.",amd_gpu
Uh not true. This is the first time im probably going with nvidia and i had never issues with amd cards,amd_gpu
That's what I thought.,amd_gpu
Because COVID hit so opportunities to increase performance at a lower cost while bringing in extra cash to the budget can be important.,amd_gpu
"The 2080ti i had was perfect for my setup.  I have the 3900x and I have a 100hz gsync acer predator x35.  Everything I've been playing has been hitting that threshold or exceeding it on ultra, except for the few games that have raytracing.  Trading my 2080ti after a year and selling it for more than I bought it for and then upgrading to something that'll blow it out of the water and still leave me with a couple of hundred leftover is a total no brainer. 

Anything above that 100hz is overkill, so the 3080 will fit the bill.  I'd hold off or get the 3090 if I were to upgrade monitors, such as the acer x38 or something with a higher refresh rate (but that's $2.2k)",amd_gpu
Official RTX 3080 page,amd_gpu
"Yea that is true, but i think what he meant was there’s nothing stopping nvidia from doing the exact same thing for 3000 series unless they know AMD upcoming cards is gonna be competitive with their cards.",amd_gpu
[deleted],amd_gpu
Huh?,amd_gpu
"I'm wondering if they're expecting AMD to have a card that can match or beat the 3080 and thats when they'll drop the 3080ti. 

Launch earlier than AMD for that early adopter money, let AMD launch and have a short shelf life spotlight, then reduce price of 3080 and slot 3080ti in to the 700-750 segment and kill AMD momentum for the rest of the gen.",amd_gpu
">Not really. ""Nvidia is afraid of AMD and priced low"" narrative says ""Nvidia is afraid of competition within PC market"", while ""Nvidia is afraid of new consoles and priced low"" says ""Nvidia is afraid of competition OUTSIDE of PC market"". Let's face it - in PC and server market, they pretty much won (for now at least).

Yeah, still a few weeks to see if amd is competitive",amd_gpu
">Honestly it doesn't matter if there is no rasterized bump (though it seems to be 65-85%), DLSS is going to rip them a new asshole in terms of frame rates in AAA games.

But DLSS isn't downside-free",amd_gpu
"If the Tflops were comparable, then 3070 would be hugely faster than the 2080ti, but they aren't,  just like GCN Tflops didn't compare to NV Tflops.",amd_gpu
"> That's how business works and that's how they make money.

This has absolutely nothing to do with RTX pricing and lack of competition.

> Ampere is what Turing should have been.

I can agree with that.",amd_gpu
(2020-2011) / .15 = 1.66% per year - on average.,amd_gpu
"Nvidia does one thing very good. AMD competes in 10 different cpu markets plus the gpu one. It would be reasonable to expect that Nvidias one pony show runs well.

There is a reason that Nvidia is in talks to buy ARM.  Because AMD still has all the new game consoles and special builds in their corner, due to having cpu cores to sell. With more money, AMD will probably catch up and this will result in lower overall pricing, which is good.

Nvidia has to diversify. Their cloud/ai game is premium, but this will not carry the pony forever.",amd_gpu
"That's partly an AMD issue, there's a reason for early Gsync, and the lock-in only part of it, other part was QC - they could make it ""just work"" that way.

AMD at least needed some sort of QС for the spec, so that display makers could not fuck it up so much. IMO AMD kinda likes to make (half-arse to be more precise) something and let others figure out how to make use of it, fix it e.t.c. and that does tend to backfire occasionally.

> That’s one of AMD’s problems - there’s all kinds of confusion about issues with AMD hardware and software, some of which isn’t even AMD related.

User does not really care about the details. He bought shit that said ""Works great on AMD!"" and it did not, user could not care less why or who to blame, he just avoided buying same shit again.",amd_gpu
Indeed. So we shall see fierce competition this year if the rumors are right and Nvidia dropped the prices/perf back to normal,amd_gpu
"Sure, but still that's a market they mostly have to themselves. It makes them probably not an insignificant amount of money on the whole. And probably it also contributes some RnD to them that MS/Sony made/requested to be made. Plus they need iGPU's for their desktop/laptop parts. And they are actually doing pretty well there, even GPU wise.

So they need Radeon group. It would be nice to have them in other segments too, but it's certainly quite important to them.",amd_gpu
That was launch prices they've gone down over time,amd_gpu
"If AMD does release a 3070 competitor for $400, it will probably be slightly slower and have a weaker feature set (weaker ray tracing, no good DLSS alternative).

It might still be a decent value, but it won’t sway people from getting the 3070.

A card that’s weaker than a 3070 and offered fewer features doesn’t really sound that compelling.",amd_gpu
"Well I have a bunch of EVGA bucks to use, and they have a better warranty (3vs2 years) so think that's the option to go for. And we haven't seen EVGA's take on it yet, one of the few besides MSI that have not been leaked yet. 

> RDNA2

I have no interest in this. they're doing 1080p MC 30-60 fps with a 52 CU chip. An RTX 2070 can do better with the help of DLSS. There's nothing hype worthy about them. Zen 3 is where I'll turn my gaze, as my current cpu actually gets bottlenecked at 1440p ray tracing on in Control and Metro Exodus. With the power of the 30 series, I'm anticipating a near total cpu bottleneck. That, or go with Intel. The struggle atm.",amd_gpu
When RIS first came out it was being marketed as a competitor to DLSS...Do you not remember this?,amd_gpu
"I don't know the context of the 1.9X to say that NVIDIA is lying. I could believe if it was comparing datacenter and compute workloads, but it's pretty apparent that it isn't the case for gaming and/or the RTX 3000 cards. With Polaris, Fiji, Vega... personally I don't really care, I already knew RTG marketing was amped up on bullshit and I just waited for other information to confirm the clains.


For what it's worth, I also didn't initially believe AMD's 50% perf per watt claim either. However, it can be deduced that the claim is somewhat true using information that we have from the recent Xbox Series X information. 

Back in March, [Digital Foundry benchmarked the Xbox Series X running a two week old build of Gears of Wars 5](https://youtu.be/qcY4nRHapmE?t=433) that was apparently able to keep up with a RTX 2080 Super. A RTX 2080 Super has a TGP of 240W and Microsoft during Hot Chips has more or less confirmed that the Xbox Series X will have a system power consumption that is more or less equal to the Xbox One X, which consumes around 170-190w at load. [Keep in mind that the RTX 2080 Super is around the same efficiency as a RX 5700](https://tpucdn.com/review/nvidia-geforce-rtx-2080-super-founders-edition/images/performance-per-watt_2560-1440.png).

For the Xbox Series X to be able to keep up with a 2080S that uses more power than it necessitates at least a 26% efficiency improvement if you compare the XSX power consumption of 190W to a 2080S' 240w. That's also not considering that the Xbox Series X is an entire system that has an 8 core Zen 2 APU and a sophisticated SoC to power, so its also likely to be quite a bit greater than 26%. If the CPU and the other ancillary features was using around 30W of that 190w that makes RDNA 2 already exactly 1.5x more efficient than the 2080s. I'm going to say 2080s/Turing = 5700/RDNA 1 in terms of efficiency since I've hopefully established that well enough earlier.

Even if we were to consider the fact that a two week old game build could still be giving the XSX GPU an unfair boost, the XSX system uses less power than the 5700xt - which has 768 less cores and half memory than the XSX has. Comparing the 5700xt to the XSX APU, for how much more stuff the XSX GPU has logically, it would need quite an efficiency boost to manage to be significantly less power hungry than the 5700XT as it is now.

Is the 50% performance per watt claim concrete? Idk for a fact yet, but there's a whole lot more evidence to it than NVIDIA's 90% improvement right now.",amd_gpu
"You need to look at some analysis of DLSS 2.0, in games like Death Stranding.

The image quality very much is perceptibly better in some ways. You're just uninformed.

And, just because I feel I have to say this, I don't own a 20-series GPU. So I have no stake in shilling or wanting to defend my purchase.",amd_gpu
My birthday is in November so I’m just waiting for that atm,amd_gpu
Yes,amd_gpu
"Indeed you are right! Around 1:18:30 on the stream. They're on [this page](https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080/) which is still up although it can't be accessed by the website itself (or if it can, it's really not intuitive).

My observations still stand though. The other available graphs made no mention of DLSS or RTX, and the performance remains excellent even in rasterization only workloads.

[Here's an internet archive link if it gets put down](https://web.archive.org/web/20200901205822/https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080/)",amd_gpu
we will see soon enough,amd_gpu
"AMD apparently prepared a 64 CU version of the RX 5700 XT, but ditched it because it apparently used too much power, and they also wanted to focus their efforts on RDNA2. RDNA1 was a temporary ""hold over"" generation, until AMD can really get their shit together.

Remember, the RX 5700XT is a very small die, at around 250 mm\^2. It's absolutely tiny. If nothing else at all, AMD can literally double the CU count, to 80 CUs, clock it a bit lower and stick slightly faster GDDR6, and see a pretty good performance increase. And with a die size of 500-550 mm\^2, that would STILL be a much smaller die than Nvidia. TU-104 is 545 mm\^2, by comparison.",amd_gpu
"I have updated my comment to reflect that. 

I think my point stands - 8nm is an even worse node than 7nm EUV. It's basically just an optimized 10nm.",amd_gpu
"I am sure it will take time to get good but MS and AMD will be working on it along with every other game studio that puts games on on the Xbox.

I am doubly sure that Sony will also be working on a solution based on the rdna 2 hardware they have. So i don't see an issue for AMD.

Nvidia is going to have to keep up with 3 companies",amd_gpu
I am not future teller but Xbox should outsell PS5 going by the hardware,amd_gpu
Almost shat my pants xD,amd_gpu
"im sorry what does bus and size has to do with it being PAM4?   
doesn't PAM concern speeds? size is still 1gb per chip x 12 chips @ 32 bits each? 12gb @ 384 bits...????????",amd_gpu
"I think they were asking about AMD, not NVIDIA",amd_gpu
You got a copy or a link where it's disclosed?,amd_gpu
"Found this... ""Nvidia is Micron's only GDDR6X launch partner, but Micron stresses that it didn't design the new type of memory exclusively for the GPU developer. The DRAM maker plans to offer GDDR6X to other companies, too.

""We now start offering and opening this up to the industry, GDDR6X is not customer-specific,"" said Ebert. ""We expect other customers to have interest moving forward, and then we will also engage with them.""

source: https://www.tomshardware.com/news/micron-reveals-gddr6x-details-the-future-of-memory-or-a-proprietary-dram",amd_gpu
"512bit seems unlikely for several reasons, then it's more likely they'd use HBME2. On the other  hand GDDR6x exclusivity to Nvidia hasn't been disclosed anywhere.",amd_gpu
https://www.tomshardware.com/news/micron-reveals-gddr6x-details-the-future-of-memory-or-a-proprietary-dram,amd_gpu
"Oh sorry. My bad, I'll update it",amd_gpu
[deleted],amd_gpu
"I mean not really tho? You're saying ""if it ever comes out"". We know it's not coming out in say the next idk 6-12 months? And we know in 12-18 months Zen 4 will drop with 5nm. 

My point was it doesn't matter if/when it drops anymore. They've already lost that battle.",amd_gpu
That's not how people buy GPUs.,amd_gpu
I mean is that wrong? Intel does pump a lot of power into their CPUs to compete with AMD.,amd_gpu
"... Isn't that exactly what Nvidia is doing? If I remember correctly, one of their graphs showed the RTX 3080 at 320 watts? That's even higher than Vega 64, which peaked at the 290-300 watt range (according to Tom's Hardware).

The founders edition RTX 2080 had a TDP of 225 watts, for comparison.

According to [Anandtech](https://www.anandtech.com/show/16057/nvidia-announces-the-geforce-rtx-30-series-ampere-for-gaming-starting-with-rtx-3080-rtx-3090), the RTX 3080 has a boost clock of 1.71 GHz The reference RTX 2080 has a boost clock of 1710 MHz. To be fair, reference clocks don't mean much because of GPU Boost 3.0 (or 4.0???).

TLDR: The process node is limited - at least the frequency/voltage curve is. Because they didn't end up using TSMC, Nvidia is being forced to use the 8nm node, which is inferior. To compensate,  Nvidia is raising TDPs by around 100 watts to hit the same clock speeds that they would have hit on TSMC N7.",amd_gpu
Rekt,amd_gpu
"Not only that, but processor dies are smaller and therefore have higher yields. AMD can afford to pay more for wafers for CPUs because an 80mm^2 3800XT sells for the same as a 251mm^2 5700XT.",amd_gpu
"Oh, well yea. That's not what I was referring to, I was just talking about the 10nm process in general :P",amd_gpu
"idk if you have seen Intel's cash flow, but other than Apple they can outbid just about anyone. They can also cross license very valuable patents and trade secret information.",amd_gpu
"I had an R9 380 and VR with a Lenovo Explorer was no issue. The only drivers that were absolutely useless with this card were all the Crimson ones. You are better off using the last Catalyst driver, 15.7.1, or one of the current drivers. They're usually fine with GCN cards.",amd_gpu
"I'm saying that the ray tracing performance of the 2070S is low compared to the rasterisation, for current games. For next gen games there should be more RT used, so there is will be even worse.",amd_gpu
Either way you will still get better response times simply because there is no latency from making the gpu wait to push a new frame so your response times will be better. It often ends up with tearing and other issues but it's definitely not useless as claimed though.,amd_gpu
"Screen tearing has nothing to do with what I said and you might not like it but even if you get it you still get a better response because there is no latency from buffering frames to sync to 60. This has been shown and explained in other cases and all you have to refute it is ""TEARING BAD"" and you didn't even address what I said.

Also, gsync and freesync don't exist to cap the gpu to your monitor refresh rate. They exist to make your monitor refresh rate match your framerate so that you don't need to run constantly capped at the monitor's refresh rate and to reduce the drawbacks of variable framerates. *Vsync* exists to cap your framerate to your refresh rate. You can *still* push 300 fps to an adaptive sync monitor only capable of 144 or 165 or 200 or whatever.

Useless intrinsically means that there is 0 value but there *is* value whether you refuse to acknowledge it or not.",amd_gpu
"I should admit that I'm just using mesa-git and lib32-mesa-git from the AUR, so the process of building the latest mesa is pretty simple and well integrated with Arch. I built the drivers with znver2 optimizations, I haven't benchmarked whether it makes a difference, but it's pretty awesome to have the option to compile graphics drivers from source.",amd_gpu
"Ah thanks. Sadly, the problem isn't installing the NVIDIA drivers. I can do that on any Linux distribution.   


The problem is that NVIDIA's Linux drivers don't provide a high priority compute queue and, consequently, cannot perform asynchronous reprojection.",amd_gpu
I was using Ubuntu because I am at least comfortable with it. The driver broke the login function on a fresh load. All of the issues were experienced with fresh loads of the OS in question. I also was using the proprietary stuff because I wanted the full function of the card.,amd_gpu
"How do you get your desktop environment to run multiple monitors with different refresh rates? I Run Fedora with a 60hz and a 144hz monitor. Xorg wont run 144hz with a second 60hz screen. I've read wayland does, but Nvidia doesnt support wayland and it seems like they are not really eager to do so. Drives me mad... I really consider to switch to AMD. How did you solve this issue? That would really help me out",amd_gpu
"I played a game on Proton just to see what it was like (it deleted my progress after...). But native games seemed to have issues. CSGO for instance would not move over to the right monitor, even after using some launch commands. ATS would load the 1440p resolution on the 1080p monitor so I could not click anything to fix it.",amd_gpu
"Oh, I missed your mention of Freesync. Neither of my monitors supports adaptive refresh rate, unfortunately.

Which I guess is good, because I would have been pretty mad to find out it would never work with dual monitors _after_ paying for a FreeSync display.",amd_gpu
"The 3070 is ""better than the 2080ti"" according to Nvidia, at $499 for the reference card. To account for ""marketing inflation"" I just used 2080ti numbers vs a 1070 the performance to get a %range.

It's basically Impossible to find any direct benchmarks with both the 2080ti and Vega 56, so I used the 1070 as a proxy and bumped the range by about 5%.",amd_gpu
My sadness is immense. Where are my damn AMD GPUs?,amd_gpu
People said that months ago when it hit $50.,amd_gpu
"I was obviously speaking in general terms. Just like the guy I responded to also was. 

Also pretty lucky that your job is on Mars.",amd_gpu
"They didn't actually show any graphs placing the 3090, so we don't really know what the performance gap is.

We do know it has ~25% more cores, but that isn't always 1:1 on performance.  The gap very much could only be 20%, but even a full 25% would be pushing it to try and place another card in the middle.  Doing so would effectively ""kill"" the 3090 unless it's actually a cut down die and they can release a 3090ti as well.",amd_gpu
"They announced the regular 3080 as their flagship, the 3090 is their Titan replacement.",amd_gpu
"That would still have less tensor cores and have comparatively lower future proofing, wouldn't it? But yeah, good idea to wait for benchmarks.",amd_gpu
Boeing comes to mind.,amd_gpu
"Bob swan, while not having made amazing progress does seem to care at least.",amd_gpu
Anything except innovate or compete fairly,amd_gpu
As someone with a haswell xeon I am definitely worried about the security concerns. Who knows how many other vulnerabilities hide in old intel chips.,amd_gpu
"Yes. For all his many qualities, questionable and otherwise, the one truly undeniable thing we know about the guy was he liked to fuck. A lot. Probably not a generous lover.",amd_gpu
"Things having their own term does not mean one is worse then the other. That is a silly argument, and nothing else you wrote was an argument. Also there is no reason for the coin flip. The fact that people are being murdered and who is being murdered is pure chance.",amd_gpu
Explain to me how person B is worse then person A.,amd_gpu
And sometimes just be short!,amd_gpu
"Not when it's not even vaguely provable it isn't. Not even the most well sourced thesis can really claim to know how or why the Mongols did something so absurdly unprecedented. Maybe one of the other Khan's got off with a lass Ghengos had his eye on at the annual Christmas party and he was so furious that he went out, united the tribes and then the politics all got a bit out of hand. At the end of the day its all unsourced bollocks and best guesses which is interesting as a curiousity but quite possibly has the actual historical accuracy of a Disney film.",amd_gpu
Consoles are as much computers as smart fridges. They both have CPUs' and ram but you cant really run your own software on them.,amd_gpu
"There will probably be some sales, but as I'm looking around, I'm not seeing a lot of stock. nVidia is usually pretty good at managing supply close to the EOL.",amd_gpu
">If the RDNA2 GPUs in the Xbox Series X and the PS5 had sufficient ML and AI capabilities to pull off some DLSS-type wizardry, it would be advertised to hell and back.

You don't even need special hardware to pull DLSS off, although reportedly RDNA2 does have special AI hardware. It may not be in the consoles though.

I don't think it's unlikely though that in like three years or so Sony and MS will come out with their ""new"" super duper upscaling method that makes 8k viable on their consoles or something like that.",amd_gpu
"Wait till you hear about games actually not rendering the whole area, but just your vision area lol

Graphics rendering is all about performance cheat to squeeze more out of it. It has been since the start",amd_gpu
What does it matter when at the end of the day you play games for performance. Idc if nvidia somehow got a single pixel to a photorealistic image. I only care what the end result looks like.,amd_gpu
"Well to that matter Screen space effects are a cheat. RT is the true thing and all that. /s

It's a tech that does what it promises to do. 3D Graphics in general are full of ""cheats"" yet we are perfectly fine with that.

Hell, movies are one big cheat by that logic.",amd_gpu
I don't agree. That's like saying TAA is cheating.,amd_gpu
"yep, I agree. I prefer the actual rendering or full resolution from actual graphical assets. No scale ups, no AI BS. I rather not have the fake frames. I guess phones has trained people to believe they can match full frame or higher sensor cameras.",amd_gpu
If I can't see the difference why the fuck should I care?,amd_gpu
"If by ""specialized work"" you mean invoking a C compiler with a different set of flags, then it's not too hard.

[Desktop](https://www.apple.com/uk/newsroom/2020/06/apple-announces-mac-transition-to-apple-silicon/)


[Server](https://www.phoronix.com/scan.php?page=article&item=epyc-vs-graviton2&num=1)

I mean, the fucking Switch is able to run a lot of recent AAA games and it's by far not the best example of an ARM-based platform.",amd_gpu
Isn't the world's most powerful super computer on ARM,amd_gpu
"I see what you're saying, it's still 14nm tech from 2015, but that's still five or six years since nanometer tech improved....",amd_gpu
"haha, yeah, no",amd_gpu
Ah that makes some sense,amd_gpu
"I don't have to know how big it is to understand statements like 2 times the performance per watt.

I can use that and interpret what is reasonably possible on the top end.

5700XT was 200ish watts.

So in the best case scenario you would get a 100% increase of the 5700XT at 200 watts which still doesn't beat a 3080 but it would be competitive (it will likely be closer to 250-280 watts).

All that said, the efficiency curve is usually at a much lower wattage and then gets much worse.  Don't expect more than something 20-30% over the 3070/2080 Ti but they can always surprise us but it would have to be way more efficient to beat the 3080 (or near 400 watts).

I think RDNA 3 is going to be the one that will be very competitive and or better at the top end.",amd_gpu
"Im holding out until we hear more, a 20gb 3080 would fit nicely.",amd_gpu
It is. It is marketed in the RTX brand which is their gaming brand and has the exact naming scheme and was unveiled at their gaming event. How much more proof do you need?,amd_gpu
"I believe the 3080 is an absolute STEAL at today's GPU prices, right? It slays the 2080Ti & is half the price. I can't wait to see what happens to 2080 GPU prices this Holiday :)",amd_gpu
"yep, sounds right. do take into account the 8nm Samsung node w. r. t. power. that could have been",amd_gpu
"I wouldn't call first generation Navi disruptive. They put in the bare minimum level of competition, and were forced to drop prices anyways while pretending that was their plan all along. Not to mention, they competed in exactly one segment square in the center of the mid-range, and eventually released a lower mid-range card in the 5500 XT that did nothing interesting price to Performance wise. I understand wanting to put your best foot forward, but they have waited so long to try the high end again. They could have at least had a Polaris moment with Navi, since they had the node advantage, and they didn't. They released a Polaris 10 tier GPU at Vega 10 Tier pricing, and the situation with nvidia's outlandish RTX pricing meant that even that weak attempt managed to bring mid-range pricing down a little, or at least force Nvidia to refresh. The fact that you can still purchase Polaris cards for close to launch pricing (and call it a GOOD VALUE) 4 years after launch is infuriating.",amd_gpu
"Too heavily focused on consoles to be able to get BN out ahead of Nvidia. Not that they'd really want to do so anyway - easier to just forgo all of the market research etc. and simply release a few months later, pricing your product according to the competition. AMD just wasn't expecting Nvidia to hammer them with ""you want to make money versus our x70? Well we're going to cut the price so low that you'll have to decide between earning nothing or losing every customer you have.""",amd_gpu
They keep repeating that both Big Navi and Zen 3 are on schedule for a 2020 release. But I'll believe it when I see it. I'm still a lot more optimistic than it seems most of the people in this thread are.,amd_gpu
"Matching 2080Ti with RTX and DLSS on.
In titles that don't have those it won't match.",amd_gpu
"How much they tell you about future products tells you something about how good current products sell and absolutely nothing about the future product. 

It's all about either being quiet and not hurting sales now, or being loud and preventing competitor sales while you get ready to launch.  So AMD is probably about to switch gears in that now.",amd_gpu
"True. They look gaudy though. I really like the industrial design of these default coolers; it looks relatively muted in comparison to board partners’ designs, with their heavy emphasis on RGB LEDs and GOTTA GO FAST designs.",amd_gpu
"True, but with other designs the hot air ends up in the case anyway, at least some of the air is being dumped out the back with the 3000 cards. And if you have an AIO it shouldn’t affect temps too much",amd_gpu
"AMD has to be strategic about what it does and when, and I'm sure they're more realistic than some of us about how likely existing owners of high-end Nvidia cards were gonna be to switch even if AMD rushed to launch early. Radeon is NOT on equal footing with Nvidia in the graphics market, so this is very much an asymmetric war. AMD is waging a guerilla campaign until it's in a position to take on more conventional approaches. 

There are disadvantages —but also advantages — to letting development take its FULL course.",amd_gpu
but it doesn't have DLSS. AMD need something similar to DLSS to compete with Nvidia.,amd_gpu
"yep, both the PS5 and Xbox Series X or whatever its called will be using an RDNA2 GPU (or APU, whatever)",amd_gpu
"But question is, will games, like Cyberpunk , support it?   


Again, RT is great for visuals, but DLSS allows you to play it with solid FPS.",amd_gpu
Uh oh she found my reddit username,amd_gpu
"You and your microcenters. I have to hunt on online marketplaces and got told several times: this gpu is not available. Even one vendor said they have them, got paid for them, the told me they were actually not in stocks and I had to raise a complaint to get money back.",amd_gpu
"So I guess what you're saying is: if you buy a GPU that's less powerful that you need just to support AMD, then you're making a mistake. I'd agree with you there. I don't think many do that kind of thing though.",amd_gpu
"That's very true, but don't discount the *undead* userbase!",amd_gpu
[removed],amd_gpu
"No they really don’t. You can run a 550W PSU at 540W and it’ll be fine. Inefficient but fine.

I have a EVGA G3 550W and will be pairing it with a 3070. Ive seen people run servers that pull 590W from the wall on it for 2 years now and be fine(535 without the conversion inefficiency).",amd_gpu
[deleted],amd_gpu
I am really hoping AMD surprise us with Big Navi. It's a bad idea if one vendor dominates the industry.,amd_gpu
"That’s just not true at all, why are you lying?",amd_gpu
"Ah, you are allowed to just post BS, but I have to use ""facts"" and even more so, you decide what """"facts"" are? I get it. You are also anti-vax, right?",amd_gpu
Look at the pictures they provide.,amd_gpu
"It's marketing if it comes from a company that wants to sell you that product, if it's a random person talking about a hypothetical situation it's a hypothetical question



By your logic I assume you think everyone talking about potential RDNA2 performance is marketing? Or are we not being consistent here",amd_gpu
"companies are not your friend, there is nothing to be sad about",amd_gpu
"It's mostly certain cards. If you look at the RMA rates for 5700XTs it is pretty good all around, except that for some reason one of the big companies has a really high RMA rate.

I have a 5700 MSI Evoke OC, a card everyone said is mediocre and has problems. Yet I was still able to flash it to 5700XT, overclock, and have had zero issues with it. I think aforementioned big company fucked up somewhere and everyone blamed AMD for it.",amd_gpu
"All my previous AMD cards never had issues either, 290, 4850, ect.. But none of my Nvidia cards did either... 6800gt, 560ti, 1070, 1080ti...",amd_gpu
"AMD lost me due to driver issues over the 7000 and 3xx series’ lifespan. 

My 7850 was crippled for practically two months where BSODs would seemingly occur at random. It got better, but multiple driver revisions still BSOD’d due to browser hardware acceleration. Real fun to have to fall back to writing papers on your rapidly aging netbook because your college PC continues to blow up at random. 

The drivers around the release of the R9 390 were better, but power management never worked. Power saving would just never shut itself off when gaming, so it needed to stay off in the drivers lest you immediately lose 10% of your card’s performance. 

AMD could release a viable competitor to the 3080 and I wouldn’t even consider it since I know the drivers are going to be a mess at launch, and probably for a while afterwards. I wish this weren’t the case, as I’m thoroughly impressed with their desktop and datacenter CPUs (I have a 3700X at home, and I’ve convinced two employers to buy Epyc-based servers).",amd_gpu
No they haven’t.,amd_gpu
"It positions them for a Titan 48GB release as well, which I wonder what'll be the excuse when it's released.",amd_gpu
"This is definitely just the result of Nvidia gouging the fuck out of people. The trouble is that it all comes from them having an insane degree of mindshare, to the extent that people in the r/pcgaming thread only want AMD to be able to compete to bring down that 3090 price. _Again_. 

There were a few people lamenting their expensive 2080ti purchases in there, and I haven't the slightest sympathy for them. They paid >$1000 for something that should have cost ~$700, so they deserve to be milked for all they're worth.",amd_gpu
">I don't know how unless they launch a 2080ti level card starting at $400.

And why wouldn't this be possible? Big Navi will easily exceed the performance of the 2080 Ti. All they have to do is bump up the transistor count by 50% on a Navi 10 size die on TSMC N7+, and they'll have $400 2080Ti.

>And even then, people will still go with the rtx 3700 to avoid potential driver issues and the better software suit.

Yet, despite the ""potential driver issues"", the 5700XT regularly outsells the 2070 Super at Mindfactory. Maybe people don't love NVidia as much as you think.",amd_gpu
I wasn't replying to you. What exactly isn't true?,amd_gpu
"Continuing that logic though, you should see if AMD produce anything competitive or lower Nvidia's prices, or a 3070ti is released?",amd_gpu
"But a potential 3080ti might have much better longevity, such as better ram options or performance without spending more than you currently have spent?  or you can get better performance than a 2080ti for cheaper with a 3070ti.

Seems for your particular case at least, but it also seems like you weren't in the market for anything else.",amd_gpu
Nothing there about tensor core usage of DLSS compared to 20 series.,amd_gpu
"Same reason AMD did threadripper 64 core. Establish dominance, show yourself as a leader in every way. Just outright have nothing your opposition can compete with. Easy",amd_gpu
"2080 ti*, I have shit tier autocorrect",amd_gpu
The titan was 2500 and the 3090 the successor is 1500,amd_gpu
"That’s Nvidia’s standard procedure for the last several years, so we will see! I’m just glad we’re back to more exciting times for GPUs. Turing was awful...",amd_gpu
It mostly is.  Downsides are negligible in most cases.,amd_gpu
might be a bit nit picky but that's closer to 2% than it is 1%,amd_gpu
"Yeah, AMD does a lot more. But their GPU’s aren’t as compelling as Nvidias. I understand why they aren’t as competitive in that segment, but I wish they were.

Maybe some if that CPU money will be funneled into their GPU division.",amd_gpu
"Those monitors work the same on Nvidia though. 

It’s up to buyers to do the research on a monitor before you buy. There are GSync monitors that have horrible colors and washed out black levels and backlight bleed.

You should research a monitor before you buy it. If some units can’t have overdrive enabled with free sync, don’t buy it, unless they doesn’t bother you. I don’t really blame AMD for someone else making a bad product, or for other people buying bad products",amd_gpu
6700XT at 2080ti perf for $400 seems obvious,amd_gpu
"Keep in mind that consoles are power limited.

To sum this up, NVIDIA is talking about 8K gaming. AMD hasn’t reached 4K gaming yet. Expect them to compete with the 3080 / 3080 Ti, not 3090. I hope they can compete.

Their CPUs are helping them.",amd_gpu
[deleted],amd_gpu
"Shenanigans. It's simply math. Restoring an image can't look better than the actual image that's not scaled. At most you can make it look close enough to be acceptable. Better? I don't buy it.

It's like saying that any lossy encoding can make things better than the original. That's just impossible by definition.",amd_gpu
Happy early as fuck birthday,amd_gpu
"Great points! 

Still comes down to:

can they maintain efficiency with the increased die size? 

What can they clock it at and how much juice does it need?

The 5700xt pulled similar juice to the 2070S, so AMD will also need to be mindful of their power draw if they double their core count even with more efficient 7+. This also may give them more room to boost standard performance to compete. 

Exciting times!",amd_gpu
"People buy the consoles mainly for the games and ecosystem not only the hardware,if it was only about the hardware than consoles wouldn't even be a thing because everyone will just a buy a pc instead.",amd_gpu
"If history has shown one thing, then it is that they do not care about hw specs.",amd_gpu
"Yep, if nothing else it even suggests a GDDR6x is more likely.",amd_gpu
"Well RDNA is rumored to be 16GB 
And 256 bit is n it enough. It has to be 512 or HBME, which is even more expensive",amd_gpu
"Wonder if they're just like me?

Ready to laugh at the general consensus of various forum boards and whatnot once they release the cards as they fly way past people's expectations.",amd_gpu
"That's my point too? Maybe I should have phrased it better. If that's the case, I apologize.",amd_gpu
"4x the transistors of 5700xt on tsmc 7nm, same clocks, 55% more power.",amd_gpu
"Oh well I’m pretty sure I’ve read a few months ago that intel pretty much gave up on 10mn since they were getting shitty yields and are going straight to 7nm and that won’t come until 2021 or something. They fucked up by sitting on their laurels for the last 8 years.  I have zero sympathy or respect for them as a company. Say what you want about NVIDIA and their insane prices with the RTX, but atleast they’ve been innovative and keeping ahead of AMD.",amd_gpu
"You can’t out bid capacity that is already locked up in years+ contracts.

You think TSMC would just void their contracts with AMD and pay whatever fine comes along with it?

Yeah not a chance.  The ramp up alone for Intel to a 3rd party fab just isn’t feasible",amd_gpu
"yeah and i will be buying the 40xx if it comes to that. the next gen games aren't coming any time soon and anyone knows it. for now they are just playing dated pvp titles, or single player walking/cg ppt simulators, as has been for the past half decade. pretty yawnfest if you ask me, and i'm pretty sure Huang knows this as he  remarks ""can't wait for 20 yrs later zzzz""",amd_gpu
That bit is patented I believe.,amd_gpu
K,amd_gpu
"Part of my luck might come from being in a bit different of an environment. I've been using tiling window managers and can send my windows to whichever screen I want with a key combination. Some games will fight it still but I've had a lot of good luck.

I recall having the same problem with login being broken on Ubuntu. Unfortunately I can't offer much advice for that. I ended up leaving Ubuntu entirely because I would run into ridiculous unfixable problems like that. I've rarely had good experiences with Ubuntu, despite what other people might think. Maybe you could try something just a bit different such as Manjaro and see what your luck is? I jumped ship to Arch and then Gentoo after Ubuntu but that's hardly necessary. I also don't have a fancy login screen anymore, just the default console prompt. Zee",amd_gpu
Try Pop OS,amd_gpu
"Oh the hours I've spent on the login loop issue.  
  
You can switch to a tty and use prime-select to change to a config that will let you login again. Doesn't help the root cause, but makes the troubleshooting easier.",amd_gpu
"Basically all I did on that front was to use nvidia-xconfig and then afterwards nvidia-settings. In the settings window you can select each monitor and the desired refresh rate. Beyond that, I'm not aware of anything else I had to do. I do have a config file I edited relating to Nvidia but I'm pretty sure that was for an unrelated reason.

Really though if it's at all possible in the future you should still try to head towards AMD. Nvidia is more trouble than it's worth in the long run. I get it though because I'd have switched by now if my finances allowed it, so I'm stuck with Nvidia too.",amd_gpu
Cant make that bet forever,amd_gpu
"Hmm very true as well, maybe they’d pull a 1080ti move and make a 3080ti with same perf as the 3090 but less Vram. We’ll see anyway, definitely an exciting launch.",amd_gpu
"What about a 3080 “super” or whatever you want to call it with and increased ram pool? I’d like to see a 16GB+ option on the 3080, especially for rendering purposes",amd_gpu
I don't really think so. The general performance is 36 TFlops vs 30 TFlops so you'd have to pay more than twice for 20% more performance.,amd_gpu
That’s amazing. I haven’t been keeping up as much since Bryan Krzanich resigned a couple years ago. I’m glad to hear that Intel could have some real leadership again after that fiasco.,amd_gpu
"I read it as ""fucking land"" as in land on which to fuck. Gengis was a top shagger",amd_gpu
"I'd rather die and have it be by chance than because of something arbitrary like me being a redditor. It's why there's a whole subreddit for ""Thanos did nothing wrong."" Chance is cleaner. Picking who gets exterminated is ugly, and should spark a negative reaction in you.

And yes, things having their own term does mean one is worse than the other. It's why murder sounds worse than killing. It's why rape is worse than sex. Intentions matter. The consequences of the two hypotheticals you gave me are drastically different. In one world, there are no more Jews. To believe that they are the same sounds delusional to me.

The only way your argument makes sense to me is if you tell me you especially don't like a certain group of people (in this case Jews). Only then can I understand your perspective of moral equivalency.",amd_gpu
"Let me try this way, you live in a house. You have the choice of dealing with two different people. 

- Person A wants to come and take over your house and will kill you no matter what you do. Your only option is death. 

- Person B wants to come and take over your house but they don't want to kill you, they want to own your house but you can continue to live there. But if you resist they will kill you.

Which do you choose?",amd_gpu
"Whatever are you talking about? The Mongol actions upon conquering an area are well documented, no guesswork required.",amd_gpu
"Err, you don't need to run your own software on something for it to be a computer...

A smart fridge is a computer, modern cars contain computers, smart phones are computers, etc.

Computers aren't limited to PCs.",amd_gpu
"I am guessing that because of the heavy amounts of co development with MS there will be an answer for DLSS. 

[https://i.imgur.com/0ZBtjuv.png](https://i.imgur.com/0ZBtjuv.png) \-xbox slide mentioning ML

[https://www.techradar.com/news/xbox-series-x-specs](https://www.techradar.com/news/xbox-series-x-specs) \- look for dlss

[https://www.overclock3d.net/news/software/microsoft\_s\_directml\_is\_the\_next-generation\_game-changer\_that\_nobody\_s\_talking\_about/1](https://www.overclock3d.net/news/software/microsoft_s_directml_is_the_next-generation_game-changer_that_nobody_s_talking_about/1)

Who knows how well it compares to DLSS in the real world but it is being worked on.",amd_gpu
"Sure, you're allowed to use and enjoy this tech. I just think it's a very temporary cheat to improve performance until path tracing hardware matures.",amd_gpu
So we went from screen space reflections to ray traced reflections. That's like ditching a graphics cheat for realism. But then you're applying a cheat to get acceptable performance. Dlss just sounds like growth pains to me.,amd_gpu
"No, not really, TAA is a predictable, written algorithm. The artefacting of TAA is predictable, a motion blur. Because ai upscaling is learned and low res images are interpreted, artefacting is unpredictable. A fence might not look like a fence under certain angles. I'm not saying you shouldn't use, it is very impressive.",amd_gpu
"I think it's fine if you market the feature the right way. It's definitely better than RTX with low framerates. Having to enable an AI interpretation of a low res frame is just nothing I get very excited for. Seems more like a temporary framerate cheat to me. There's nothing wrong with using it of course, in fact I'd love to see something like that on lower end cards. Everyone is talking about DLSS while the most impressive and impactful thing in that whole presentation was the data decompression from disk. That's a way bigger deal.",amd_gpu
"I never said you should care. It's just a clever and temporary performance cheat for us with ray tracing, that's really all.",amd_gpu
"Framing it as simply needing to invoke some flags is disingenous, as in many cases that is **not** all you need to do.

Especially not for what runs in datacenters and enterprise. Completely untested and un-validated, too. Not to mention that Intel and AMD have an entire ecosystem built around their x86 offerings which we haven't seen based on other ISAs/uarchs.

In a matter of hours I can have an Intel-based server configured and delivered to one of our locations, with the customer's x86 software tested and ready to go. Many corporations and institutions aren't willing to spend time and resources testing another ISA when x86 (IA-32/x86-64) is proven and readily available.

That's (slowly) changing, but it has been and currently still is the case. It's the very reason why x86 is dominant.

Using the Switch as an example is somewhat piss-poor as the majority of those games are built using tools that are intended for cross-building. Getting a few FPS lower on the Switch with bottomed-out settings is the same as thinking that it's acceptable to run your time-critical code dozens if not hundreds of times slower, ""but it works!"".

&#x200B;

If you're someone who works with ML, you can *easily* evaluate several solutions and have your code run on it by the end of the day, which is NVIDIAs territory. The secondary question you need to ask yourself is performance.

If you ask yourself the same thing from any of the large OEMs in terms of general compute/CPU availability, it's almost exclusively x86, either Intel or AMD based.

So yeah, for years Intel has only had one real competitor in that market, and for the better part of the last decade, they'd been lacking in fighting back. NVIDIA has not had that ""luxury"".",amd_gpu
It sounds like you clearly have not been using the drivers.,amd_gpu
"They even called the 3080 flagship multiple times during the presentation and the 3090 something beyond flagship. Which is stupid, but at least the Titan naming made that clear. 3090 does not.",amd_gpu
"NVIDIA is showing 1.9 times the efficiency of Turing with Ampere (again at a much lower wattage)

2080 was 215 watts  
3080 is 320 watts

The 3080 is 60-90% faster than the 2080 for almost 50% more power",amd_gpu
"Perf per watt is just marketing buzz.  This is a new Arch and we didn't get a high end part last gen.  Doubling up on a 80cu part had we had one would fair your argument a bit better.  Either way its stupid to speculate when you know nothing.  

No one really knows anything so not sure why anyone would be willing to put their foot in their mouth either way unless its purely trying to sow discord.",amd_gpu
They literally said it’s their titan replacement,amd_gpu
"We don't actually know if it slaughters the 2080 ti yet.  All we have are some hand-wavy performance metrics.  In theory it should but we really need to wait for actual benchmarks to compare.

Personally I am curious to see what AMD has in it's hand.  They have been holding their cards really close to their chest with the only tell that they have is the specifications of the consoles.  We literally know nothing beyond what we know from the console verisons of RDNA2 and that performance is actually pretty impressive considering that it is basically a APU.  What will RDNA2 bring to the table when it is left to run free with better cooling and (relatively) unlimited power budget?",amd_gpu
They forced nvidia to move their xx70 refresh to the same GPU as the xx80 series in order to stay ahead. Barely.,amd_gpu
"I meant anything that would be a threat. They will probably release something. My hopes the card will be able to compete with the 3070 or better. Currently, I have skepticism.",amd_gpu
Considering the stuff we've seen of the 3080 vs 2080 i highly doubt that. But feel free to come back and tell me i told you so in a month.,amd_gpu
"The 3070 has 35% more CUDA cores and almost 50% improvement in FP32 performance, a much higher clock, and faster VRAM speeds.

&#x200B;

Is it really out of the question?",amd_gpu
"
 | CUDA cores | Boost Clock
----|----------|-----
[2080ti](https://www.nvidia.com/en-us/geforce/graphics-cards/rtx-2080-ti/) | 4352 | 1635mhz
[3070](https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3070/) | 5888 | 1730mhz
Percent increase | 35% | 5.8%

Even if the cores got 25% worse somehow, it's safe to assume their claims are pretty close just looking at the spec sheet.",amd_gpu
The 3080 is 80% faster than a 2080ti in borderlands 3 (which is not a DLSS title). their claims seem to be true.,amd_gpu
Yeah thought so.,amd_gpu
I would be genuinely surprised if it didn't support DLSS. DLSS is like magic for RT.,amd_gpu
You’re in trouble S,amd_gpu
I thought so too. But I'm getting tons of responses saying that we should buy AMD to support competition. Makes no sense to me.,amd_gpu
I don't need air conditioning where I live. It's not a standard. I have heating. For me it's a standard to not justify spending literally 2000 dollars to be able to run an overpriced GPU.,amd_gpu
"Again, you're assuming that those PSUs that claim 550 watts can consistently deliver 550 watts. While with a single huge power consumer like a GPU, realistically you'd have to daisy chain something and that's a fire hazard buddy, at least for the voltage regulators in there.",amd_gpu
"No, I already got the confirmation I wanted, thanks.",amd_gpu
Agreed! Look at what happened when AMD fell out of the fight with Intel and how great all the competition has been for us consumers. Definitely want the same level of competition in GPU.,amd_gpu
But it is true. You seem to be on denial,amd_gpu
It is true. Have you checked yourself DLSS 2.0 (everything before was crap).,amd_gpu
I would have assumed you were anti vaxx,amd_gpu
"Us, 'consumers', talking about a product is a part of it yes. Marketing at work.",amd_gpu
Some people have sports teams. I have random internet shit.,amd_gpu
That would honestly be believable. I honestly wish AMD had the resources to just build their own cards and do an FE style release.,amd_gpu
"I had issues with my 9800gtx, but they eventually got fixed. Same with my 670.",amd_gpu
From my personal experience they have. There was very little issues being posted during the 7970 nor the 290x days.,amd_gpu
Probably will. Good for them. That's what happens when your competition is relatively crap.,amd_gpu
[deleted],amd_gpu
Good for them. I would never trade a 2070 Super for a 5700xt though.,amd_gpu
It's not true that people weren't going to buy Amd anyways. I should have made the comment longer. He probably aswell,amd_gpu
">The titan was 2500 and the 3090 the successor is 1500

Ah yeah gotcha",amd_gpu
">It mostly is.  Downsides are negligible in most cases.

Visually from.what ive experienced its often jarring

Maybe with the 3000 series it won't be",amd_gpu
"I dont blame anyone for buying it, I'm just saying that AMD could've done a better job making sure their customer (since nvidia customer would not buy a freesync display until recently) would have a good expirience. 

Nvidia did a much better job at that with G-Sync. Sure they were more expensive, but generally speaking you had a near 100% chance of getting at least a non-flickering and behaving monitor due to them being validated by Nvidia. Sure there were rather shit TN panels on some e.t.c. but they still worked as VRR displays. That cant be said for freesync, especially in the beginning with v.1",amd_gpu
"It would be very very difficult for them to reach that price point. Even still, for $100 more, most people would opt to get the Nvidia card for all the extra features.

I can see them offering comparable raw performance for $450, but without DLSS and with worse ray tracing support.",amd_gpu
"They are power limited, but the Series X already runs at 1800 MHz which is basically the sweet spot. There is a huge drop off in clocks to performance from my experience. I'm not even expecting to compete with the 3070. DLSS along with the other features are just too good to pass up to save your ass maybe 10%.",amd_gpu
"You can use a lower resolution with RIS and get similar results as DLSS 1.0, when RIS originally dropped with the VII. Thats how reviewers compared the two. I know what it is. Same/=/similar

Read here: https://www.igorslab.de/en/ultimate-visual-comparison-between-amd-ris-nvidia-dlss-and-freestyle/",amd_gpu
"Again, just look at some analysis, there is complete consensus.

But also, it appears you may be misunderstanding what DLSS does.

It's not doing image restoration, and it's not a ""normal"" mathematical algorithm.

It's as if you've trained a robot to paint, give it an incomplete image, and ask it to paint what should be there.

So information is being added to the image. The original information isn't just being ""stretched out"" through clever math to fill in the gaps.

Hence how variations of these neural networks can generate images of things which don't exist, like faces of humans who don't exist. They can do it at whatever resolution you ask for, and don't require some kind of ""starter image"" to do it.",amd_gpu
"What we need to take into account is the fact that bigger dies that are clocked lower, are almost always more efficient than smaller dies that are clocked higher. 

This is what a lot of people missed - Nvidia's strategy had always been to use cheap, mature nodes, and just compensate with die space and architectural prowess. AMD has recently leaned in the opposite direction - using cutting edge nodes and small dies, and basically pushing most of the energy efficiency benefits that come with a node shrink into higher clocks. AMD in general tried to push their flagship cards as far as humanly possible, because they have to. Overclocking is cheap. Optimizing your architecture is not. They tried this with the 290X/390X, then the Fury cards, then Vega 64, and to a lesser degree, RX 5700 XT. 

Many reviewers noted this on their reviews of the RX 5700XT. A 5700XT that's tuned properly actually delivered most of the performance with lower power consumption than Turing. AMD's short sightedness in the Navi launch unfortunately obscured how much of an improvement in both efficiency and performance RDNA was, over rewarmed GCN.

However, this year may be different. AMD is making more money than ever, from Ryzen and consoles. They now have the budget to compete on an architectural level.

Just judging from what Microsoft and Sony have said, RDNA2 looks really compelling. They're cooking something up, I don't think we need to worry too much.",amd_gpu
">can they maintain efficiency with the increased die size?

According to AMD themselves, we should be expecting 50% more performance per watt for RNDA 2, so the answer would probably be yes.",amd_gpu
[deleted],amd_gpu
"512bit is way too expensive and very complex to implement for a 'simple' consumer card. It either has to be HBME2, which is expensive too but not as..., or GDDR6x....or worst case...GDDR6 and put the cards significantly at a lower price.",amd_gpu
"I will say that in think they'll sell all of the initial stock, both matter what. 
That said, idk if that'll be a success. I personally prefer buying amd. I prefer the support for open standards, etc. That said, my main reason for upgrading is cp77. Been waiting for it for several years now, and would like to enjoy it to its fullest (visual prowess). But I did try to get an rtx card today, knowing its unlikely I'll get one, starting early and hoping to get one before cp77 launches. 
AMD just left a very little time window to get a card in time with how many bots buy everything new these days (be it concert tickets or hardware).
Tbh, I more or less stopped going to concerts because of it (back when those existed), and I'm pretty sure I'll stop doing so with hardware pretty soon too. Or just code a buy-bot myself :/",amd_gpu
"I work in Fab 42, there's been a huge sign out front that says ""CONGRATULATIONS FAB 42"" (I'm allowed to say this since you can see it from the unsecured parking lot, right Intel?) And also *just so happens* to have been publicly announced (among other things I've seen *cough* ""internally"" that I can't talk about) that 42 is producing 10nm... ""something"" Idk, I'm just up close and personal with this stuff so it's sort of exciting. Can't say I have any opinions about AMD stuff since I've never had the opportunity to try it (I just have last gen gaming laptop, oh well) I'm sure it's great though. Also the GTX1650 in my laptop hasn't let me down yet, I like it. Didn't say anything about these companies though, the only thing I'm saying is that Intel isn't stuck on 14nm RND like the parent comment said.",amd_gpu
"I did try Arch on a laptop. Cool project, honestly too much work for me though right now. I love understanding the inner workings of something, but I just don't have the desire to learn that deep currently. It was super fast though. I'll have to try Manjaro again, I had issues last time unfortunately.",amd_gpu
"Tries it, same issues as Ubuntu. Both are Debian based so they are pretty similar if I remember right. Debian was actually much worse and practically gave me a seizure trying to get the driver loaded. It made my monitor flicker like crazy",amd_gpu
"Right, but AMD's position on the cpu front is only getting stronger. GPU side remains to be seen. AMD's market cap is only about half that compared to Intel's, they still have room to grow.",amd_gpu
"Not sure there’s a use case for that. Most people  buy Titans for rendering or AI purposes where vram is crucial and high cuda count is essential. The confusing part is the naming. Dropping the “Titan” label sounds like an attempt from Nvidia to reach more into the gamers pool as well as (as they mentioned in the announcement) allowing AIBs for Titan boards as well, which up until now where Nvidia exclusives.",amd_gpu
"It's possible as a refresh a year from now, like the 2080S, but I don't see a situation like that in the next 6 months.

Maybe a version with more ram if RDNA2 comes out with a crap load, but otherwise the same performance.",amd_gpu
"not sure it's what i'd call real leadership, still not an actual engineer which is really what intel needs, but yeah at least he seems to care and be willing to listen to the engineers, which is a good start.",amd_gpu
"I find it incredibly interesting that you say things having their own term means one is worse than the other. Nothing in creating a new word entails that it is morally worse then a similar word created previously. Is manslaughter worse then murder? Is homicide worse then murder? Is the death penalty worse then capital punishment? Don't be silly. I really don't see how if Hitler just grabbed a random person on the street and threw them in the gas chamber they would be saying, well at least I'm not being killed because of some trait. Also why couldn't a group be wiped out by chance? I don't see how my hypothetical entails that a group partition of people with the same trait couldn't still be wiped out.",amd_gpu
"So my options are die, die, or lose everything I have in life leaving me without any possessions to wander the wasteland? I guess I choose death. Would you like to engage with my hypothetical?",amd_gpu
Computers is not even limited to machines made of silicone either. A [person with a calculator](https://en.wikipedia.org/wiki/Computer_\(job_description\)) is also a computer. Dont be disingenuous when talking about what definition i used as we both know that the term computer is used interchangeable with personal computers.,amd_gpu
"Basically every single thing in realtime graphics is a ""cheat to improve performance""

Hell, you could say rasterized lighting as a whole is a temporary cheat to improve performance until ray tracing could be done in realtime.",amd_gpu
Why do you care?,amd_gpu
"Man you are dense... 

SSR was a cheat for performance. It was there to get acceptable performance.

Any way, not going to continue that discussion.",amd_gpu
"> A fence might not look like a fence under certain angles. 

Can you provide some example screenshots where DLSS 2.0 made it worse?",amd_gpu
By that logic everything in the history of real time graphics processing is a *performance cheat*. I can't believe that cognitive dissonance has hit you *this* hard,amd_gpu
"I've linked an example of literally a hundred typical server side apps exhibiting competitive performance on an ARM-based CPU not being hand-optimized. I get it that if you're doing some super specialized ML or other nerdy stuff then it is not really that straightforward, but porting your typical boring Node.js or JVM apps and SQL DBs is completely painless right now.

> In a matter of hours I can have an Intel-based server configured and delivered to one of our locations, with the customer's x86 software tested and ready to go. Many corporations and institutions aren't willing to spend time and resources testing another ISA when x86 (IA-32/x86-64) is proven and readily available.

I don't get this argument, in a similar fashion I can click a couple of buttons and have a bunch of AWS instances ready to go. I can run my shit on EPYCs for a couple of months and then try their new Gravitons and switch back to Xeons if something doesn't work out, but most of the time all three work just fine.

> Using the Switch as an example is somewhat piss-poor as the majority of those games are built using tools that are intended for cross-building. Getting a few FPS lower on the Switch with bottomed-out settings is the same as thinking that it's acceptable to run your time-critical code dozens if not hundreds of times slower, ""but it works!"".

Running games is probably the worst case scenario for non-x86 CPUs. If the Switch can provide gaming performance that is acceptable to a lot of people, those people care even less if their silly new app runs on an ARM or an x86, it's all IO bound anyway.

Your example where the application is severely CPU bound is a small niche.",amd_gpu
"It's the same tactic Samsung is using with the Note 20. Sure the Note 20 is the flagship... but do you really have the best there is if you don't buy the Ultra?

The Titan branding didn't sell to gamers, the RTX 3000 branding does. And just like with the phone example above: sure the 3080 is the flagship... but do you really have the best there is if you don't buy the 3090?",amd_gpu
If AMD beats their 3080 people have it in their head that the 3090 is part of the gaming lineup. It's done on purpose so that the rest of their marketing still works. If AMD did take the performance crown then that would shatter a lot of green hearts.,amd_gpu
"I looked it up to grab an article and AMD is actually only claiming a 50% increase to their investors - so that is what everyone should expect.
https://www.tomshardware.com/news/amd-rdna-2-navi-2xl-boost-performance-per-watt-50-percent

https://www.extremetech.com/gaming/307085-amd-announces-cdna-rdna2-architectures",amd_gpu
"Yes, which they now included in their gaming line-up as their top end gaming card. They even introduced the 3090 with 8k gaming.",amd_gpu
"You're right, technically, but the ""Cuda Cores"" are there. It's about time GPUs dip in price, they've gone parabolic in pricing since Quarantine-along with everything else of course.",amd_gpu
"The 2070 super was moved to a cut down version of the same die, sure. That probably means it cost Nvidia a bit more money per GPU. But what did that actually accomplish in the price to Performance metric? We got maybe 15% better performance at the $500 price point? That's barely worth mentioning, and certainly not disruptive. I think the only reason it even stands out as a minor blip on the radar is because of the absolute drought of value that had persisted everywhere else up until that point. Zen one was disruptive, bringing 8-core processors to the mainstream at a fraction of the price point of Intel's high-end desktop offering. Threadripper 1000 and 3000 were disruptive, basically making Intel's entire high-end desktop offering redundant for most users and even putting dual xeon configs to shame in terms of computing power. Polaris was even disruptive, for the short time it was uncontested by Pascal, for bringing top end Maxwell level performance down to the $200 price point while also beating it in efficiency. Don't let the complete lack of movement over the last four years trick you into thinking that either AMD or Nvidia have done anything interesting graphics wise until now.",amd_gpu
"Edit: nevermind found it.https://www.eurogamer.net/articles/digitalfoundry-2020-hands-on-with-nvidia-rtx-3080
Source. I may have underestimated the performance",amd_gpu
"I get you completely now. Yes, it doesn't make sense. It's fine to buy an AMD card if it fits your need, and if you're an AMD fan I'd say that it's okay to buy one even if it has some drawbacks compared to the competition. But if it doesn't fit your needs, it makes no sense.",amd_gpu
"If you can buy an AMD for the same price or less for the same performance as a Nvidia, then ye buy the AMD card. That's what people are saying, don't confuse yourself.",amd_gpu
Who needs central AC? A window unit costs a fraction and costs a lot less to run.,amd_gpu
"For the record you are debating an edgy username, basically troll.",amd_gpu
"Unless you have a shitty no name PSU, you’ll be fine.

And if you have a shitty no name PSU, you should be getting rid of that before buying anything new for the PC anyways.",amd_gpu
"You think this https://1images.cgames.de/images/gamestar/279/dlss-20-control-4k-sz-2-rt-off-dlss-q-on-300-prozent_6109610.jpg looks better than this https://10images.cgames.de/images/gamestar/279/dlss-20-control-4k-sz-8-rt-off-dlss-off-300-prozent_6109609.jpg ?

Honest answer pls.",amd_gpu
I want good competition to enjoy a good game. In this case price for performance. I rarely care for teams.,amd_gpu
"That would be awesome. Here's a link to one of the charts floating around [link](https://www.extremetech.com/gaming/313458-reseller-rma-data-shows-fascinating-pattern-between-amd-nvidia-gpus). RMA is 2-3% all around except XFC and PowerColor. I've mentioned this here before and some people said it is because the buyers of these cards expect better performance. If you come across the issues reported though, things like screen flickering, crashing, restarting, etc. those aren't minor issues and everyone would notice it.",amd_gpu
Wait amd doesnt do reference cards anymore?,amd_gpu
"Anyone can say their personal experience was flawless. There were lots of issues with that bloated, slow catalyst software. Read the internet. 

Also, AMD had much worse support for their cards over time. They dropped support much faster than Nvidia, which drove a lot of people away because driver models were not as stable then as they are now. 

It wasn't much better on Linux, where cards were dropped from the binary driver at warp speed, and the F/OSS drivers performed like ass (I am aware that those have improved over the years).",amd_gpu
Thanks for proving my point.,amd_gpu
"I extend that lack of sympathy all the way down the product stack, though. Anyone lamenting their new 2060 got what they deserved for buying into that extortion racket, while also ending up with little more than buyers remorse for not waiting until their value plummeted in the wake of this latest round of overpriced upgrades.

Take a look at other subs - and even some parts of this thread too - and you'll quickly find plenty of people marvelling at how generous it is that they can get a mid-range xx70 series GPU for ""only"" $500, rather than the $600 that was being whispered beforehand. 

People are openly thanking Nvidia for ripping them off, and it's hysterical.",amd_gpu
Good for you.,amd_gpu
Was my bad,amd_gpu
"DLSS 1.0 was blurry and had artifacts, however they fixed those with 2.0 and now in some cases it even looks better than native (on quality mode).",amd_gpu
">Visually from.what ive experienced its often jarring

I dont know what you've seen, but I seriously doubt you're being truthful about your observations here.  Cuz no, on any reasonable level, it's definitely not at all 'jarring'.  Even for somebody with higher image quality standards.",amd_gpu
"Yeah, GSync was a more foolproof ecosystem technically. AMD now has different tiers of free sync, so, maybe that’s helpful",amd_gpu
"They are already selling a Navi10 GPU (5600XT) at like $250 on the low end, they are clearly not very expensive to make.

A slightly wider die running 20% faster with slightly faster memory is not really going to cost much more to make than Navi10. Maybe an extra $20-40 per unit, and that's all it takes to match 3070 on perf/rt and efficiency, I think. 

And that's not even talking about actual Big Navi. Nvidia has pretty clearly telegraphed what they think the competitive landscape is going to look like.

The fact that they are selling a 102 die in the xx80 slot says a lot.",amd_gpu
"3060 is gonna match the Series X, plus DLSS will bring it faster than the 2080 Ti. Even though 3070 is $499 and about the same as 2080 Ti OC, 3060 is gonna sell like crazy. 

This is why AMD needs to hurry. I hope they can announce or tease something quick. I want competition. We need competition.",amd_gpu
[deleted],amd_gpu
"I know it's an AI algorithm, but it's still about restoring based on training on the original (using a neural network for example). In some trained case it can look close. Looking better? Not convinced.",amd_gpu
Ok but you're convinced it's going to have GDDR6?,amd_gpu
"HBM2E has a 4096 Bit-Bus with 4 Stacks of HBM2E, and a 2048 Bit-Bus for 2 8Gb Stacks of HBM2E.",amd_gpu
"I mean Intel only producing CPUs in volume on 14nm still sounds like they are stuck on it.

Are there actually any 10nm desktop chips out?  I've only seen small low power laptop chips.",amd_gpu
"Yea, I don’t see them boosting anything but the vram on the 3080s. As you said, anything in between would get to close to the 3090, and probably too expensive too to justify the effort. <$1000 3080ti would kill the 3090 and for anyone willing to shell more than $1k on a GPU $1200 or $1500 doesn’t really make a difference and they’d go for the 3090 anyways at that point.",amd_gpu
"Okay. How about person A wants to kill your kids/wife/parents regardless of what you do or have.

Person B wants whatever you have your home, your money. But if you comply he'll let your family live. 

Are you still gonna let your family die?",amd_gpu
"Yeah it's easy to say ""I'd rather die"" until you're actually in that situation. I bet you'd be on your knees begging for life when it does actually happen.",amd_gpu
"Hey there!  A calculator is a computer too!

A computer is any system that is turing complete (including the fridge, calculator, the SIM card in your cell phone, etc).  This is actually universal and the definition of a computer.

The profession of people being called computers is interesting, but you could call it a gray area to consider people computers (we are also turing complete, but error prone and slow at the task).

The implications of this are pretty wild.  The calculator doesn't have enough memory to run a modern video game, but if it did, it could do everything your PC can, literally every single thing -- at the bottom level they are turing machines.  Obviously it would have very poor performance and be impractical for the purpose of playing games.

Computers are in everything and programmers rule the world.  Peace!",amd_gpu
"An Xbox/smart fridge is  entirely different than a human with a calculator. You bring me that example and somehow manage to say I'm the one being disingenuous? C'mon.

You said an Xbox isn't a computer. It is. Plain and simple.",amd_gpu
"Because an AI upscaler makes errors. Deviations from the source material. From what the game developer wanted to show you. The end result looks impressive, but it has artefacts. It should be used as a last ditch effort to increase performance, but it shouldn't replace raw compute power in my opinion. That being said, it is very cool and you should use it if you have to.",amd_gpu
... this is what I said,amd_gpu
Worse than what?,amd_gpu
"Okay, so you get it. You go from screen space reflections to ray traced reflections, which is one less performance cheat. As time goes on you'd expect less cheats to be used as hardware gets better. DLSS is like a temporary fix for ray tracing hardware that isn't matured yet. I'm not opposed to it, but that is just a fact. It would be very useful to have on older, less powerful hardware too, although that's probably not going to happen. It's just strange to get excited for a performance cheat imho. It's fine if you use it.",amd_gpu
You realize those AWS instances run mostly Intel under the hood for a reason right?,amd_gpu
"My theory on the departure from Titan branding might simply be due to running out of names to tack onto the word Titan:

* [GTX Titan](https://en.wikipedia.org/wiki/GTX_Titan), released in 2013
* [GTX Titan Black](https://en.wikipedia.org/wiki/GTX_Titan_Black), released in February 2014
* [GTX Titan Z](https://en.wikipedia.org/wiki/GTX_Titan_Z), released in March 2014
* [GTX Titan X](https://en.wikipedia.org/wiki/GTX_Titan_X), released in 2015
* [Titan X (2016)](https://en.wikipedia.org/wiki/Titan_X_(2016)), released in 2016
* [Titan Xp](https://en.wikipedia.org/wiki/Titan_Xp), released in April 2017
* [Titan V](https://en.wikipedia.org/wiki/Volta_(microarchitecture)), released in December 2017
* [Titan RTX](https://en.wikipedia.org/wiki/Titan_RTX), released in 2018

Taking the xx90 numbering allows them to settle into a simpler naming scheme for generations to come (4090, 5090, etc).",amd_gpu
"Well not quite. The note20 sucks for the price. Like almost nobody should buy it kind of sucks. Like either get a note10 plus or note20 ultra kind of sucks.

No expandable storage? Plastic build? Inferior processor? No high refresh rate screen and 1080p? And costs nearly 50% more than phones that actually are better than it? It's just a phone that exists to justify the price of the note20 ultra.

The 3080 at least is a good product in its own right",amd_gpu
">We got maybe 15% better performance at the $500 price point?

no, we got better then the old 500 dollar price point performance for 400 dollars.",amd_gpu
"Many, if not most, Western European windows are on hinges so a window unit won't fit. _If_ people have AC it's either a full split system or a single-hose mobile unit.",amd_gpu
"Yeah, I've been in the industry long enough, I know what I'm saying. Enjoy your time bomb buddy.",amd_gpu
"They both look pretty shitty tbh but this is an example where dlss looks A BIT worse. There are other examples like this:

https://www.computerbase.de/2020-07/death-stranding-benchmark-test/3/

Here DLSS looks BETTER than native resolution. Both of us are cherrypicking though. On average from what I have seen so far, DLSS 2.0 and native are very very close together which is incredible when looking at the performance gains.",amd_gpu
"Honestly, they look exactly the same. I couldn't tell what pic is supposed to be the bad one.",amd_gpu
"They have a reference design, but they don't produce them themselves.",amd_gpu
"I was reading tons of stuff with enthusiasts with the new hardware. I used to spend way too much time on overclock.net before they redesigned it. During the 7970 and 290x days there weren't nearly as many problems as there were with 5700xt. Drivers were not an issue during those times. Catalyst was slow, but that's not something that's really considered a driver issue. That's a minor annoyance that doesn't affect your day to day operation. The only thing they changed back then that bothered me, and it was just something that they randomly dropped/broke, was the removal/breakage of hotkeys. I used to switch between different display modes (eyefinity vs regular monitors and stuff).",amd_gpu
"What point? The point is there is NOT going to be an excuse. If a higher VRAM Titan or it's variant comes out. It comes out. At a higher price.

This doesn't stop a super and a Ti slotting in after the 3080 and before the 3090 though.

So nice try at winning something.",amd_gpu
">I seriously doubt you're being truthful about your observations here.

what a weird thing to accuse me of, what would i have to gain?

i've mentioned elsewhere i'm buying a 3080 unless AMD can pull well above double the performance of a 5700XT.

> Even for somebody with higher image quality standards.

i don't like ANY kind of setting that worsens an image under any circumstance. that's a pretty low standard imo.",amd_gpu
"5600xt is a pretty new card, and they had to cut the price to be competitive with Nvidia in that price segment. They wanted to charge more, because their profit margins are so low. Their GPU profit margins are SLIM, and they don’t have much wiggle room in price.


Just because the 5600xt is affordable to produce doesn’t mean a higher end card will be affordable to produce. Typically the more “stuff” you pack into a chip, and the larger the die, the lower your yields will be and the more expensive it will be. Not to mention the RnD costs.


Even if AMD can match the 3070 in raw performance, I don’t think it can be done for less than $450. And at that price, the 3070 is the better choice because you get the RTX feature set.

Historically, over the last 6 years, AMD has only been able to play catch-up and offer a similar performance to Nvidia for a similar price. I don’t see how they can offer anything as compelling as the 3070 unless it’s like $350. 

I want to be wrong and I want AMD to release a banger. But after today I just don’t know if they will offer anything that compelling.",amd_gpu
"A $350 3060 likely already kills the value of a console sans exclusives if they want to do $600. That consoles gotta be $500 max now. If new gpus were not being launched then $600 would have been a steal. Luckily, the 3060 is probably not launching until January like it previously did. 

>  I hope they can announce or tease something quick.

The silence is pretty deafening. Their only word was from that jebaited guy with an emoji. Digital Foundry's preview already has the 3080 being 180-200% of the 2080 FE. Fuck the 3090 is going to be an absolute monster at 240% 2080 FE.",amd_gpu
"I'm aware what both of them are you clearly aren't comprehending what I'm saying, I also never called RIS an upscaler. 

👋  bye",amd_gpu
Dude just stop it and watch real life comparisons on youtube. There are shit ton of videos comparing dlss 2.0 on and off. What matters is viewers perception. If you can't tell difference it doesn't matter. We are not going to agree with your theoretical bullshit while we know with complete confidence that dlss 2.0 provides significant performance boost while maintaining image quality.,amd_gpu
G6X was just released and was co-developed by Nvidia and Micron. Nvidia will have some kind of exclusivity deal. They don't want to enable their competitors.,amd_gpu
Yes. G6X is Nvidia locked anyway.,amd_gpu
"Correct, but the difference is it's stacked memory which is relatively less complex because its stacked next to the gpu, unlike GDDR memory modules.",amd_gpu
Could be wrong but I'm pretty sure they're announcing them today,amd_gpu
"How do I provide for myself or family with no possessions? I don't understand how this changes anything or shows who is worse, person A or B. Also I don't think this is analogues to the initial moral claim, but that's fine.",amd_gpu
"I answered your question, I would chose death. It's fine if you don't believe me. Do you have an argument for why person B is worse then person A? It seems like you might be retarded.",amd_gpu
"Game developers would be the ones to set the weights.  That means they train the ai themselves on how its supposed to look.  So yes there will be errors, but if the overall error rate is less than say 5% then you would not be able to tell.",amd_gpu
"Worse than at the same internal resolution - with or without TAA. And significantly worse than at the external resolution.

From what I have seen, DLSS 2.0 at 4K looks better than the actual 4K render (AFAIK as long as you are not using DLSS performance mode). I wouldn't believe it if I hadn't seen it.",amd_gpu
"Well duh, with Intel dominating the server CPU market for 10+ years it isn't going to change overnight.

But AWS are actively adding both EPYC and Graviton instances and Intel's dominance is not going to last for very long because Intel will have pretty much nothing to compete with 5nm CPUs in a year or two.",amd_gpu
"Titan A. The fact is that gamers never really considered Titan cards as an option for gaming and saw them more as a professional user type card. The RTX 2080 ti was basically a Titan with the 2000 branding, and despite the negative reception for the price increase, it sold tenfold compared to the old Pascal Titan which was positioned in the exact same spot price and relative performance wise.

Nvidia were smart with this release. By making the 3000 branded Titan the 3090 instead of 3080 ti people aren't going to complain about its price, while it'll have far more sales than it'd get if it was sold as a Titan A.",amd_gpu
"Ignoring the fact that the 2070 could frequently be found beneath the 500 dollar mark even as far back as spring of 2019, the value figure I gave for the 500 dollar price point is indeed accurate. The 5700 XT would really only offer 20-25% better value in comparison at the 400 dollar price point in a best case scenario. The fact that it's even worth mentioning the extra 5-10% performance per dollar should perfectly illustrate how insane this situation is. 20% better value is pathetic. Remember when we could consistently expect a 40% (or higher!) Improvement at the same price point for a new product launch? Hell, Polaris damn-near doubled performance per dollar over Maxwell and the Hawaii refresh cards, and that was a little GPU that AMD wouldn't even follow up until a completely different architecture. The fact that, as frankly flawed as it was, Vega competed against the 1070 and 1080 was a blessing. These past couple of years sucked. Turing was an expensive, pitiful improvement over Pascal and its headlining feature was not only absent for most of its life, but was effectively unusable on more than half the lineup. AMD should have capitalized on the comparitively weak gains of the 20 series to try to hit the value proposition hard while they still had a significant node advantage. Hopefully Big Navi 2X will be a heavy hitter, because I don't think Nvidia will be quite as generous next time as they seem to have been with the 30 series if they don't have anything scary to contend with.",amd_gpu
I will. EVGA has an amazing warranty and covers running the PSU to its limits. I bought a 550W unit for 550W not 400 W.,amd_gpu
"> A BIT worse

Dude, the image lacks so much detail and is full of artifacts. Sorry, but thats why I cant take all of those DLSS shills serious. They just deny reality.",amd_gpu
"Sorry, but I cant believe you, because the differences are so obvious.",amd_gpu
Ok...,amd_gpu
"If a higher VRAM Titan comes out it's replacing what, a non existant card or the last gen Titan? That's the point. nVidia changed the name of the 3080 Ti for the 3090, doesn't mean a name change makes it replace a higher tier card. nVidia can release a Super or Ti at any price point thanks to this name change, doesn't mean anything.",amd_gpu
"The 5700XT is sold quite profitably at $400. Nvidia sells a bigger die with the same memory at the same price. 

a slightly bigger 256 bit die and slightly faster G6 chips is not going to raise the cost substantially

That's all AMD needs to match the 3070. That's nothing.",amd_gpu
"I mean yeah 3060 will be a good price but doesn’t come with every other component.

>Jebaited guy with the emoji

Link?

3090 chonky thicc boi is definitely gonna be double 2080 Ti. Don’t forget AIBS and overclocking ;)",amd_gpu
"Youtube itself is already lossy. And what exactly some single examples demonstrate? Do you mean they made a general purpose AI that can upscale **any** image to better quality than the original?

You can train a neural network to work on some input set well. You are claiming it works on everything well?",amd_gpu
If they aren't released that definitely counts as stuck on 14 nm.,amd_gpu
You still can if you're alive and if your family is alive. Maybe you'd need to struggle so much initially but if you're alive you still CAN provide. When you're dead its game over although it's easier but watching your kids get slaughtered/raped infront of you without ANY option isn't easy.,amd_gpu
"There's a distinction between looking good and looking faithful to the source. It looks very impressive, it just isn't alwayw faithful.",amd_gpu
"Yeah, that's not how it works but ok.",amd_gpu
"Have you looked at my link? How do you explain that computerbase, one of the most renowned sites out there, provide evidence that DLSS looks better than native in their example?

Do you completely ignore that?",amd_gpu
"I'm genuinely being serious,bi don't know which one looks better and i don't know which one is the dlss",amd_gpu
">If a higher VRAM Titan comes out it's replacing what, a non existant card or the last gen Titan? 

You mean like the 2080 Super ""replaced"" a non-existent card from maxwell too?

Crazy how those things actually happen huh?

Like I said. Nothing will change the fact that a 3080 Super and a 3080Ti will slot in between the 3080 and the 3090. I'll just wait to hear your excuses then.",amd_gpu
Hardware wise - may be. Software is a different story.,amd_gpu
"AMD already had to cut the price of the 5700xt by $50 to $400. Their profit margins on the 5700xt are razor thin - like, single digit.


AMD has been on 7nm way before Nvidia, and they still haven’t been able to catch up. I think there’s a lot more to having a successful GPU than just the die size.


They would need a 3070 killer for less money to compete with Nvidia. Nvidia has too much mind share.",amd_gpu
"It doesn't, but with a 3rd gen Ryzen chip, I'm expecting even better performance. And consoles aren't pcs, there's the opportunity for a lot of game tweaks as well as a general use machine. A 3060 gaming rig built at console launch is attainable for about $800-900 with a better cpu. $600 console doesn't look as good in comparison. 

https://twitter.com/sherkelman/status/1300842481886662658

A wondering emoji. Brilliant marketing.",amd_gpu
"DLSS doesn't claim to be general purpose AI. That's why it needs implementing from the game dev side.  
  
The game dev provides the game to nVidia. nVidia uses a supercomputer to produce 16k frames of the game and trains the ML algorithm on this data. The algorithm is then packaged with the driver and your computer uses this trained algorithm to upscale the image.  
  
The trained agent 'knows' what the game should look like at 16k resolution, it's not just interpolating detail from information available on each frame.  
  
You seem to not know how DLSS works based on your claims. It's a separate 'AI' for each game, not general purpose upscaling technology. It can make image look better than native resolution because the algorithm was trained on images of even greater resolution.",amd_gpu
"If they're actually *mass producing* them in a fab the size of a warehouse with over a thousand machines running 24/7 I wouldn't think so, but uh... ¯\\\_(ツ)_/¯",amd_gpu
"I don't care about what the best choice is, or to explain why I would choose death. I don't know why you bothered to reply if you weren't going to relate it back to the initial point of contention.",amd_gpu
So no?,amd_gpu
"Dude, I am a CompterBase member, are you? They are usually great but their DLSS ""review"" sucks like any other DLSS review.",amd_gpu
"Open both pictures and just look at them. One lacks a lot of detail and is full of artifacts. 

Do you have trouble seeing?",amd_gpu
"No excuses, people are happy to keep paying more and justifying themselves it's a great deal they're getting, nothing I can do I guess.",amd_gpu
[deleted],amd_gpu
"So sounds like they need to train it on each specific game. So for general case - it's not going to work. And if they don't train it on each game, claiming that it will work for any general case is even less realistic.",amd_gpu
"And yet there are several articles from a month ago where Intel doesn't expect 10 nm desktop chips until mid 2021.

The current product stack is a bunch of mobile chips with up to 30W power envelopes.

https://www.pcgamer.com/intels-first-10nm-desktop-cpus-are-still-a-year-awayoh-and-7nm-is-delayed-again/

You can say whatever you want but the evidence doesn't support your claim.",amd_gpu
"He's been talking out of his ass in all these comments, with nothing to back his statements up. Typical arm chair redditor.",amd_gpu
"I am as well, wie vermutlich jeder andere deutsche Hardwareenthusiast auch ;)

LOL so you just tend to ignore all positive reviews and just focus on the critics? That's bias on a next level.",amd_gpu
What's an artifact.,amd_gpu
"I'm flipping between the images, and it seems that the second image seems more blurry than the first, so I'm more inclined to go with the first.",amd_gpu
"It still needs implementation from the dev, doesn't it? I don't think you can turn on DLSS on any game and have it work.  
  
Wouldn't part of that implementation include training the algorithm on that particular game?  
  
The principle is the same. The algorithm is just part of the driver, not the game installation.",amd_gpu
"Im with you Shmerl.

These guys swallowed marketing.

Those of us concerned about true image quality are not interested in dlss whether its 2.0 , 3.0, 69.0.",amd_gpu
"Who said it's going to work in general case? Literally nobody is arguing this.  
  
You claimed it can't look better because it's doing image restoration and it can't add information that isn't there.  
   
I'm explaining why it can actually look better than native. Nobody said anything about it being used for upscaling any image. The algorithm has to be trained for that particular use case.",amd_gpu
"If I back myself up it's going to break NDA so I'll just end it here, sorry to waste your time",amd_gpu
"Nah, I used the positive reviews and used their images to proof to you, that they are wrong. And now you dont want to accept reality.

Sad.",amd_gpu
"DLSS basically tries to reconstruct an image, and during that mistakes happen. so it displays things that are not actually there.",amd_gpu
"Look at the details, like the upside down pyramid or the tower, the DLSS image lacks details. plus the wings are full of artifacts and the latin inscription is hard to read at native resolution, but not visible with DLSS:",amd_gpu
"Yeah, in practice it's more marketing than value. But it can be useful for VR from what I've heard.",amd_gpu
"> Who said it's going to work in general case?

Then what's the point of wasting the space on GPU die on hardware that works for limited number of cases instead of using that space for general purpose compute units that simply give more value overall by being more general? That was my point exactly. It's an anti-feature hyped with marketing, not something really great or useful in **general case** if it comes at the cost of less general performance.

I totally get why Nvidia are doing it. They realize AMD basically caught up to them in raw compute power, so they make ""we have a special feature that you don't"" and hype that up to get some edge. Point is, don't buy into it, unless it's really useful. DLSS doesn't look like a good trade off to me.

> You claimed it can't look better

It totally can't, in general case. That was the exact point. You yourself said it only works in limited cases.",amd_gpu
Lets end this here. I see no point in arguing with you at all.,amd_gpu
"I see it now, but the fact that you had to hold my hand through it kinda proves that dlss is doing it's job",amd_gpu
"Your point was that image upscaling is lossy because of math. You said nothing about hardware space until now.  
  
Anyway, the dlss tech is mostly useful for applications with raytracing.  
  
The difference between raytracing a 4k image and 1080p image is far more than double the resources. If the rtx cores + tensor cores are less than half of the card, then replacing them with general use cuda wouldn't be enough to produce raytraced 4k images.  
  
If the resulting image quality is at least the same as native 4k, then the performance gain can be worth it.  
  
I don't own an rtx card, but I can see why this tech might have potential.",amd_gpu
"I knew you'd give up once you have to face the facts. But you are right, you can go back to you lala-land :)",amd_gpu
"Sorry, it just proofs that you are blind. And you seem to forget, that any GPU can do upsampling and trade image quality for performance. Nothing special about DLSS, it might even look better than DLSS.",amd_gpu
"Again, hyping up something limited, at the cost of all other things sounds like a bad trade off to me. If you think it's good - sure, you can complain AMD aren't buying into it. I have no problem with AMD not jumping on that bandwagon and I see it as a benefit - they can use that space for actually useful compute power, while Nvidia run to stuff their GPU with limited purpose ASICs.",amd_gpu
"No, I just can't stand arguing with close minded, biased morons. Have a nice day ;)",amd_gpu
"You say that as if not seeing the difference between dlss and native is a bad thing. Sucks for you, but for me it's free frames.",amd_gpu
"> No, I just can't stand arguing with close minded, biased morons.

Then why dont you stop being a close minded, biased moron?",amd_gpu
"Dude, every one can see the differences as bright as day. You are either trolling or blind. Sucks for you.

Well, if you want more FPS, why not just reduce settings/resolution? Since it looks the same for you? Because thats what DLSS does.",amd_gpu
Why would it suck for me when i can get a free resolution increase or a free framerate increase.,amd_gpu
Because you cant appreciate the graphics since you are blind.,amd_gpu
"It's the opposite, i think most games look great, even old games. Meaning whatever game i play, i won't be taken away because of graphics. Meaning i will still have a more enjoyable time than you. I win, you lose.",amd_gpu
"Thats OK, but you dont need DLSS for that, simple upsampling does it.

> Meaning i will still have a more enjoyable time than you. I win, you lose.

OK buddy :D",amd_gpu
" dlss is pretty good for what it sets out to, seems like you're seething cuz free frames or resolution comes at a cost for you when it doesn't for me. 

[you right now](https://i.kym-cdn.com/photos/images/original/001/096/564/2f7.jpg)",amd_gpu
"Funny, every time someone realizes they lost the argument, they have to go for personal attacks. Every. Single. Time.

Thanks for being so obvious little fella :)",amd_gpu
"Lost what argument, there isn't even an argument. I'm saying that I can't tell the difference between dlss and native, so it's just extra performance. There's nothing you can say to contend that so you call me blind and that I can't see graphics, so you were right about losers going personal, but to the wrong person. 

Lol I'll be out here with free performance and you and your byakugan can stay at native.",amd_gpu
"The very fact that you are so furious right now, trying so desperately to continue this argument, albeit you lost, shows how dumb you are. Please, continue to entertain me :D",amd_gpu
"How can i lose an arguement that's about me not noticing the difference between dlss and native, what are you even going to be able to argue. You're acting like a child right now.",amd_gpu
"Keep going buddy, you're making my day. Come on, more angry comments!",amd_gpu
Playing the apathetic shitposter role doesn't work when you're the only one downvoting comments. Your own actions betray you.,amd_gpu
"More, give me more anger!",amd_gpu
cope,amd_gpu
More! I want more rage from you kiddo!,amd_gpu
seethe harder,amd_gpu
"Give me more, dont stop!",amd_gpu
"trust me, you'll stop replying before i do.",amd_gpu
